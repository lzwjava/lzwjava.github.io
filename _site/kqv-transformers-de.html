<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>KQV, Transformer und GPT</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>KQV, Transformer und GPT | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="KQV, Transformer und GPT" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="de" />
<meta name="description" content="Wie ich den KQV-Mechanismus in Transformern gelernt habe" />
<meta property="og:description" content="Wie ich den KQV-Mechanismus in Transformern gelernt habe" />
<link rel="canonical" href="https://lzwjava.github.io/kqv-transformers-de" />
<meta property="og:url" content="https://lzwjava.github.io/kqv-transformers-de" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-07-16T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="KQV, Transformer und GPT" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2025-07-16T00:00:00+08:00","datePublished":"2025-07-16T00:00:00+08:00","description":"Wie ich den KQV-Mechanismus in Transformern gelernt habe","headline":"KQV, Transformer und GPT","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/kqv-transformers-de"},"url":"https://lzwjava.github.io/kqv-transformers-de"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=b723421028b8526c972158efc52ea9e8c5663d17">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=b723421028b8526c972158efc52ea9e8c5663d17" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       KQV, Transformer und GPT | Original, von KI übersetzt
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/de/2025-07-16-kqv-transformers-de.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postsde2025-07-16-kqv-transformers-de.md</span> -->
      

      <!-- <span>2025-07-16-kqv-transformers-de.md</span> -->

      
        

        
          
          <a href="#" class="button">2025.07</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/kqv-transformers-en" >English</option>
        <option value="/kqv-transformers-zh" >中文</option>
        <option value="/kqv-transformers-ja" >日本語</option>
        <option value="/kqv-transformers-es" >Español</option>
        <option value="/kqv-transformers-hi" >हिंदी</option>
        <option value="/kqv-transformers-fr" >Français</option>
        <option value="/kqv-transformers-de" selected>Deutsch</option>
        <option value="/kqv-transformers-ar" >العربية</option>
        <option value="/kqv-transformers-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <h2 id="wie-ich-den-kqv-mechanismus-in-transformern-gelernt-habe">Wie ich den KQV-Mechanismus in Transformern gelernt habe</h2>

<p><em>2025.07.16</em></p>

<p>Nach dem Lesen von <a href="https://lzwjava.github.io/notes/2025-06-02-attention-kqv-en">K, Q, V Mechanism in Transformers</a> habe ich irgendwie verstanden, wie K, Q und V funktionieren.</p>

<p>Q steht für Query, K für Key und V für Value. Bei einem Satz ist die Query eine Matrix, die den Wert eines Tokens speichert, über das es andere Token befragen muss. Der Key steht für die Beschreibung der Token, und der Value steht für die eigentliche Bedeutungsmatrix der Token.</p>

<p>Sie haben spezifische Formen, daher muss man ihre Dimensionen und Details kennen.</p>

<p>Ich habe das etwa Anfang Juni 2025 verstanden. Zum ersten Mal davon gehört habe ich Ende 2023. Damals las ich Artikel wie <a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a>, verstand aber nicht viel.</p>

<p>Nach etwa zwei Jahren fällt mir das Verständnis nun leichter. In diesen zwei Jahren konzentrierte ich mich auf Backend-Arbeit und die Vorbereitung auf meine Abschlussprüfungen und las oder lernte nicht viel über maschinelles Lernen. Dennoch dachte ich ab und zu über diese Konzepte nach, zum Beispiel beim Autofahren oder bei anderen Tätigkeiten.</p>

<p>Das erinnert mich an die Wirkung von Zeit. Wir lernen vielleicht viele Dinge auf den ersten Blick, auch wenn wir sie nicht vollständig begreifen. Aber irgendwie löst es einen Denkprozess aus.</p>

<p>Mit der Zeit stellte ich fest, dass es bei Wissen und Entdeckungen schwer ist, Dinge beim ersten Mal zu verstehen oder zu durchdenken. Später scheint das Lernen und Verstehen jedoch einfacher zu werden.</p>

<p>Ein Grund dafür ist, dass es im Zeitalter der KI einfacher ist zu lernen, weil man sich in jeden Detailaspekt vertiefen kann, um seine Fragen zu klären. Es gibt auch mehr verwandte KI-Videos. Noch wichtiger ist, dass man sieht, wie viele Menschen damit lernen und Projekte darauf aufbauen, wie zum Beispiel <a href="https://github.com/ggml-org/llama.cpp">llama.cpp</a>.</p>

<p>Die Geschichte von Georgi Gerganov ist inspirierend. Als neuer Lernender im Bereich maschinelles Lernen, der etwa 2021 begann, hat er einen starken Einfluss in der KI-Community hinterlassen.</p>

<p>Solche Dinge werden sich immer wieder wiederholen. Daher glaube ich, dass ich für bestärkendes Lernen und das neueste KI-Wissen, auch wenn ich nicht viel Zeit investieren kann, trotzdem etwas Zeit finden kann, um schnell zu lernen und viel darüber nachzudenken. Das Gehirn wird seine Arbeit tun.</p>

<hr />

<h2 id="vom-neuronalen-netzwerk-zu-gpt">Vom neuronalen Netzwerk zu GPT</h2>

<p><em>2023.09.28</em></p>

<h3 id="youtube-videos">YouTube-Videos</h3>

<p>Andrej Karpathy - Let’s build GPT: from scratch, in code, spelled out.</p>

<p>Umar Jamil - Attention is all you need (Transformer) - Modell-Erklärung (inkl. Mathematik), Inferenz und Training</p>

<p>StatQuest mit Josh Starmer - Transformer Neural Networks, ChatGPTs Grundlage, klar erklärt!!!</p>

<p>Pascal Poupart - CS480/680 Lecture 19: Attention und Transformer-Netzwerke</p>

<p>The A.I. Hacker - Michael Phi - Illustrierte Anleitung zu Transformers Neural Network: Eine Schritt-für-Schritt-Erklärung</p>

<h3 id="wie-ich-lerne">Wie ich lerne</h3>

<p>Nachdem ich die Hälfte des Buches “Neural Networks and Deep Learning” gelesen hatte, begann ich, das Beispiel eines neuronalen Netzwerks zur Erkennung handgeschriebener Ziffern nachzubauen. Ich erstellte ein Repository auf GitHub, https://github.com/lzwjava/neural-networks-and-zhiwei-learning.</p>

<p>Das ist der wirklich schwierige Teil. Wenn man es von Grund auf schreiben kann, ohne Code zu kopieren, versteht man es sehr gut.</p>

<p>Mein nachgebauter Code enthält noch nicht die Implementierung von update_mini_batch und Backpropagation. Durch das sorgfältige Beobachten der Variablen in den Phasen des Ladens der Daten, des Feed-Forwardings und der Bewertung habe ich jedoch ein viel besseres Verständnis für Vektoren, Dimensionalität, Matrizen und die Formen der Objekte entwickelt.</p>

<p>Und ich begann, die Implementierung von GPT und Transformern zu lernen. Durch Wort-Einbettung und Positionskodierung wird der Text in Zahlen umgewandelt. Im Grunde gibt es dann keinen Unterschied mehr zu einem einfachen neuronalen Netzwerk, das handgeschriebene Ziffern erkennt.</p>

<p>Andrej Karpathys Vortrag “Let’s build GPT” ist sehr gut. Er erklärt die Dinge gut.</p>

<p>Der erste Grund ist, dass es wirklich von Grund auf ist. Zuerst sehen wir, wie Text generiert wird. Es ist irgendwie unscharf und zufällig. Der zweite Grund ist, dass Andrej Dinge sehr intuitiv erklären kann. Andrej arbeitete mehrere Monate am Projekt nanoGPT.</p>

<p>Ich hatte gerade eine neue Idee, um die Qualität eines Vortrags zu beurteilen. Kann der Autor diesen Code wirklich schreiben? Warum verstehe ich etwas nicht und welches Thema hat der Autor ausgelassen? Neben diesen eleganten Diagrammen und Animationen, was sind ihre Mängel und Defekte?</p>

<p>Zurück zum Thema maschinelles Lernen selbst. Wie Andrej erwähnt, gibt es Dropout, Residual Connections, Self-Attention, Multi-Head Attention, Masked Attention.</p>

<p>Durch das Ansehen weiterer Videos begann ich, ein bisschen zu verstehen.</p>

<p>Durch Positionskodierung mit Sinus- und Kosinusfunktionen erhalten wir einige Gewichte. Durch Wort-Einbettung wandeln wir Wörter in Zahlen um.</p>

\[PE_{(pos,2i)} = sin(pos/10000^{2i/d_{model}}) \\
    PE_{(pos,2i+1)} = cos(pos/10000^{2i/d_{model}})\]

<blockquote>
  <p>The pizza came out of the oven and it tasted good.</p>
</blockquote>

<p>In diesem Satz, wie erkennt der Algorithmus, ob es sich auf Pizza oder Ofen bezieht? Wie berechnen wir die Ähnlichkeiten für jedes Wort im Satz?</p>

<p>Wir möchten eine Reihe von Gewichten. Wenn wir das Transformer-Netzwerk für die Aufgabe der Übersetzung verwenden, gibt es bei der Eingabe eines Satzes den entsprechenden Satz in einer anderen Sprache aus.</p>

<p>Zum Skalarprodukt hier. Ein Grund, warum wir das Skalarprodukt verwenden, ist, dass es jede Zahl im Vektor berücksichtigt. Was wäre, wenn wir das quadrierte Skalarprodukt verwenden? Wir würden zuerst das Quadrat der Zahlen berechnen und dann das Skalarprodukt bilden. Was wäre, wenn wir ein umgekehrtes Skalarprodukt durchführen?</p>

<p>Bei der Maskierung hier ändern wir die Zahlen der Hälfte der Matrix in negative Unendlich. Dann verwenden wir Softmax, um die Werte im Bereich von 0 bis 1 zu halten. Wie wäre es, wenn wir die Zahlen in der linken unteren Hälfte in negative Unendlich ändern?</p>

<h3 id="plan">Plan</h3>

<p>Weiterhin Code und Forschungsarbeiten lesen und Videos anschauen. Einfach Spaß haben und meiner Neugier folgen.</p>

<p>https://github.com/karpathy/nanoGPT</p>

<p>https://github.com/jadore801120/attention-is-all-you-need-pytorch</p>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-de" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
