<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Zen y el Arte del Aprendizaje Automático</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Zen y el Arte del Aprendizaje Automático | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Zen y el Arte del Aprendizaje Automático" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="es" />
<meta name="description" content="Zen" />
<meta property="og:description" content="Zen" />
<link rel="canonical" href="https://lzwjava.github.io/zen-neural-es" />
<meta property="og:url" content="https://lzwjava.github.io/zen-neural-es" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-07-03T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Zen y el Arte del Aprendizaje Automático" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2023-07-03T00:00:00+08:00","datePublished":"2023-07-03T00:00:00+08:00","description":"Zen","headline":"Zen y el Arte del Aprendizaje Automático","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/zen-neural-es"},"url":"https://lzwjava.github.io/zen-neural-es"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=e1a45f85d084f6d161d0d100984ef25dfd1ab87c">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=e1a45f85d084f6d161d0d100984ef25dfd1ab87c" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Zen y el Arte del Aprendizaje Automático | Original, traducido por IA
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/es/2023-07-03-zen-neural-es.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postses2023-07-03-zen-neural-es.md</span> -->
      

      <!-- <span>2023-07-03-zen-neural-es.md</span> -->

      
        

        
          
          <a href="#" class="button">2023.07</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/zen-neural-en" >English</option>
        <option value="/zen-neural-zh" >中文</option>
        <option value="/zen-neural-ja" >日本語</option>
        <option value="/zen-neural-es" selected>Español</option>
        <option value="/zen-neural-hi" >हिंदी</option>
        <option value="/zen-neural-fr" >Français</option>
        <option value="/zen-neural-de" >Deutsch</option>
        <option value="/zen-neural-ar" >العربية</option>
        <option value="/zen-neural-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <h2 id="zen">Zen</h2>

<p>Un joven padre está ocupado aprendiendo sobre redes neuronales durante el fin de semana. Sin embargo, este fin de semana, necesitaba acompañar a su pequeña hija a nadar en la piscina del complejo de apartamentos. Se recostó en el agua poco profunda y observó los edificios de apartamentos que se elevaban hacia el cielo. De repente, pensó: “Vaya, se parecen mucho a las redes neuronales. Cada balcón es como una neurona. Y un edificio es como una capa de neuronas. Y un grupo de edificios se combina para formar una red neuronal”.</p>

<p>Luego pensó en la retropropagación. Lo que hace la retropropagación es propagar los errores hacia las neuronas. Al final de un entrenamiento, el algoritmo calcula el error entre la salida de la última capa y el resultado objetivo. En realidad, las redes neuronales no tienen nada que ver con las neuronas. Se trata de computación diferenciable.</p>

<p>Después de escribir el artículo “Finalmente entiendo cómo funciona una red neuronal”, se dio cuenta de que todavía no lo entendía. Entender es algo relativo. Como Richard Feynman señala algo parecido a que nadie puede estar 100% seguro de nada, solo podemos estar relativamente seguros de algo. Por lo tanto, es aceptable que Zhiwei diga eso.</p>

<p>Así que encontró una manera de entender profundamente las Redes Neuronales copiando varias líneas de código de ejemplo cada vez, ejecutándolo y luego imprimiendo las variables. Se trata de una red neuronal simple para reconocer dígitos escritos a mano. El libro que está leyendo recientemente se titula <em>Neural Networks and Deep Learning</em>. Por eso, decidió nombrar su repositorio en GitHub como <em>Neural Networks and Zhiwei Learning</em>.</p>

<p>Antes de usar una Red Neuronal para entrenar nuestros datos, necesitamos cargar los datos primero. Esta parte le costó una semana de tiempo libre para hacerlo. Las cosas siempre requieren más tiempo del que pensamos para completarlas. Pero mientras no nos rindamos, somos capaces de hacer muchas cosas.</p>

<p>En el área de Machine Learning, MNIST significa “Modified National Institute of Standards and Technology database” (Base de Datos Modificada del Instituto Nacional de Estándares y Tecnología). Por lo tanto, nuestro archivo de carga de datos se llama <code class="language-plaintext highlighter-rouge">mnist_loader</code>. Utilizamos la función <code class="language-plaintext highlighter-rouge">print</code> en Python para imprimir muchas listas y arreglos de tipo <code class="language-plaintext highlighter-rouge">ndarray</code>. El “nd” en <code class="language-plaintext highlighter-rouge">ndarray</code> significa “n-dimensional”.</p>

<p>Además de <code class="language-plaintext highlighter-rouge">print</code>, debemos usar la biblioteca <code class="language-plaintext highlighter-rouge">matplotlib</code> para mostrar nuestros dígitos. Como se muestra a continuación.</p>

<div align="center"><img src="/assets/images/zen-neural/figure.png" width="30%" /><img /></div>

<h2 id="arte">Arte</h2>

<p>Veamos más dígitos.</p>

<div align="center">
<img src="/assets/images/zen-neural/figures.jpeg" width="100%" /><img />
(Fuente de la imagen: Neural Networks and Deep Learning)
</div>

<p>Es más alegre cuando, de vez en cuando, puedes ver imágenes en lugar de enfrentarte a códigos ruidosos todo el día.</p>

<div align="center">
<img src="/assets/images/zen-neural/layer.png" width="100%" /><img />
(Fuente de la imagen: Neural Networks and Deep Learning)
</div>

<p>¿Parece complicado? Aquí, podríamos tener demasiadas neuronas en cada capa. Y eso hace que las cosas sean confusas. En realidad, es muy simple una vez que lo entiendes. Lo primero sobre la imagen anterior es que tiene tres capas: la capa de entrada, la capa oculta y la capa de salida. Y una capa se conecta con la siguiente. Pero, ¿cómo pueden 784 neuronas en la capa de entrada convertirse en 15 neuronas en la segunda capa? ¿Y cómo pueden 15 neuronas en la capa oculta convertirse en 10 neuronas en la capa de salida?</p>

<div align="center">
<img src="/assets/images/zen-neural/simple-network.png" width="100%" /><img />
</div>

<p>&lt;/div&gt;</p>

<p>Esta red es mucho más simple. Aunque Zhiwei no quiere incluir ninguna fórmula matemática en este artículo, aquí las matemáticas son demasiado simples y hermosas para ocultarlas.</p>

\[w_1*a_1 + w_2*a_2+...+ w_6*a_6+b_1\]

<p>Supongamos que indicamos la red de la siguiente manera.</p>

<div align="center"><img src="/assets/images/zen-neural/network-1.png" width="30%" /><img /></div>

<p>Así que entre la primera capa y la segunda capa, tenemos las siguientes ecuaciones:</p>

\[\begin{eqnarray}
  w_1*a_1 +...+ w_6*a_6+b_1 = c_1 \\
  w_1*a_1 +...+ w_6*a_6+b_2 = c_2 \\
  w_1*a_1 +...+ w_6*a_6+b_3 = c_3 \\
  w_1*a_1 +...+ w_6*a_6+b_4 = c_4 
\end{eqnarray}\]

<p>Aquí, la Ecuación 1 tiene un conjunto de pesos, y la Ecuación 2 tiene otro conjunto de pesos. Por lo tanto, el $w_1$ en la Ecuación 1 es diferente del $w_1$ en la Ecuación 2. Y así, entre la segunda capa y la tercera capa, tenemos las siguientes ecuaciones.</p>

\[\begin{eqnarray}
  w_1*c_1 + ... + w_4*c_4+b_1 = d_1 \\
  w_1*c_1 + ... + w_4*c_4+b_2 = d_2 \\
  w_1*c_1 + ... + w_4*c_4+b_3 = d_3 
\end{eqnarray}\]

<p>Y en la tercera capa hasta la última capa, tenemos las siguientes ecuaciones.</p>

\[w_1*d_1 + w_2*d_2 + w_3*d_3 + b_1 = e_1\]

<p>El único problema con las ecuaciones anteriores es que el valor no es lo suficientemente simple o formal. El rango del valor de la multiplicación y la suma es bastante amplio. Queremos que esté restringido a un rango pequeño, digamos, de 0 a 1. Así que aquí tenemos la función Sigmoid.</p>

\[\sigma(z) \equiv \frac{1}{1+e^{-z}}\]

<p>No tenemos que intimidarnos por el símbolo sigma $\sigma$. Es simplemente un símbolo, al igual que el símbolo “a”. Si le damos como entrada 0.5, su valor será…</p>

\[\frac{1}{1+e^{-0.5}} \approx 0.622459\]

<p>Y,</p>

\[\begin{eqnarray}
\frac{1}{1+e^{-(-100)}} \approx 3.72*e^{-44}  \\
\frac{1}{1+e^{-(-10)}} \approx 0.000045  \\
\frac{1}{1+e^{-(-1)}} \approx 0.26894  \\
\frac{1}{1+e^{-{0}}} = 0.5  \\
\frac{1}{1+e^{-10}} \approx 0.99995  \\
\frac{1}{1+e^{-100}} = 1
\end{eqnarray}\]

<p>Es intrigante aquí. No sabía lo anterior antes de escribir este artículo. Ahora, tengo una idea de cómo es su valor aproximado para una entrada normal. Y observamos que para la entrada que va de 0 a $\infty$, su valor está entre 0.5 y 1, y para la entrada que va de $-\infty$ a 0, su valor está entre 0 y 0.5.</p>

<div align="center"><img src="/assets/images/zen-neural/curve.png" width="100%" /><img /></div>

<p>Entonces, con respecto a las ecuaciones anteriores, no son precisas. Las más adecuadas deberían ser las siguientes:</p>

\[\begin{eqnarray}
  \sigma(w_1*a_1 + ... + w_6*a_6+b_1) = c_1 \\
  \sigma(w_1*a_1 + ... + w_6*a_6+b_2) = c_2 \\
  \sigma(w_1*a_1 + ... + w_6*a_6+b_3) = c_3 \\
  \sigma(w_1*a_1 + ... + w_6*a_6+b_4) = c_4 
\end{eqnarray}\]

<p>Entonces, para la primera ecuación, es que,</p>

\[\frac{1}{1+e^{-(w_1*a_1 +...+ w_6*a_6+b_1)}}\]

<p>¿Cómo podemos actualizar el nuevo peso para $w_1$? Es decir,</p>

\[w_1 \rightarrow w_1' = w_1- \Delta w\]

<p>A la ecuación,</p>

\[w_1*a_1 + w_2*a_2+...+ w_6*a_6+b_1\]

<p>Su derivada con respecto a $w_1$ es $a_1$. Vamos a darle a la suma un símbolo $S_1$.</p>

<p>Así que,</p>

\[\frac{\partial S_1}{\partial w_1} = a_1 , \frac{\partial S_1}{\partial w_2} = a_2, ...\]

<p>La derivada significa la tasa de cambio. Esto significa que para el cambio $\Delta w$ en $w_1$, su cambio en el resultado $S_1$ es $a_1 * \Delta w$. ¿Y cómo podemos revertir tal cálculo? Vamos a calcularlo.</p>

\[\begin{eqnarray}
S_1' - S_1 = \Delta S_1  \\
\frac{\Delta S_1}{a_1} = \Delta w \\
w_1- \Delta w = w_1'
\end{eqnarray}\]

<p>Y la regla de la cadena explica que la derivada de $f(g(x))$ es $f’(g(x))⋅g’(x)$.</p>

<p>Así que aquí,</p>

\[\begin{eqnarray}
f(z) = \sigma(z) = \frac{1}{1+e^{-z}} \\
g(x) = w_1*a_1 +...+ w_6*a_6+b_1
\end{eqnarray}\]

<p>Y la derivada de la función sigmoide es,</p>

\[\sigma'(z) = \frac{\sigma(z)}{1-\sigma(z)}\]

<p>Entonces, la derivada de $f(g(w_1))$ es $\frac{\sigma(z)}{1-\sigma(z)} * a_1$.</p>

<p>Así que,</p>

\[\begin{eqnarray}
\frac{\sigma(z)}{1-\sigma(z)} * a_1 * \Delta w = \Delta C \\
\Delta w = \frac{\Delta C}{\frac{\sigma(z)}{1-\sigma(z)} * a_1} 
\end{eqnarray}\]

<p>Y para el sesgo $b_1$,</p>

\[\begin{eqnarray}
g'(b_1) = 1 \\
\frac{\sigma(z)}{1-\sigma(z)} * \Delta b = \Delta C \\
\Delta b = \frac{\Delta C}{\frac{\sigma(z)}{1-\sigma(z)}}
\end{eqnarray}\]

<h2 id="código">Código</h2>

<p>La forma de imprimir variables es muy útil y sencilla, aunque hoy en día la gente ha inventado Jupyter Notebook para hacer este tipo de cosas. Como mencionó Zhiwei anteriormente, una de las claves para entender las redes neuronales es que debemos prestar atención a las dimensiones.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">print_shape</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">arr</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span> <span class="c1"># 10
</span><span class="n">print_shape</span><span class="p">(</span><span class="n">training_results</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># (784, 1)
</span><span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">training_data</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># &lt;class 'list'&gt;
</span></code></pre></div></div>

<p>Traducción al español:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">print_shape</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">arr</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span> <span class="c1"># 10
</span><span class="n">print_shape</span><span class="p">(</span><span class="n">training_results</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># (784, 1)
</span><span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">training_data</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># &lt;class 'list'&gt;
</span></code></pre></div></div>

<p>Nota: El código no necesita ser traducido, ya que es un bloque de código y los nombres de las variables y funciones deben permanecer en inglés.</p>

<p>Como ahora Zhiwei acaba de terminar la parte de carga de datos, continuará utilizando la misma forma de copiar varias líneas e imprimir variables para aprender la parte real de la red neuronal. Puedes seguir el progreso aquí: https://github.com/lzwjava/neural-networks-and-zhiwei-learning.</p>

<p>Me quedé atascado varias veces durante el proceso. Aunque parece un código muy simple, después de intentar entenderlo una y otra vez, no lo logré. Luego, me alejé de la línea de código en la que estaba trabajando para observarlo desde una perspectiva más amplia, para pensar por qué el autor escribió esa parte del código, y de repente lo entendí. El código es el siguiente:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_data_wrapper</span><span class="p">():</span>
    <span class="n">tr_d</span><span class="p">,</span> <span class="n">va_d</span><span class="p">,</span> <span class="n">te_d</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]
training_results = [vectorized_result(y) for y in tr_d[1]]
training_data = zip(training_inputs, training_results)

validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]
validation_data = zip(validation_inputs, va_d[1])

test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]
test_data = zip(test_inputs, te_d[1])
return (training_data, validation_data, test_data)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">vectorized_result</span><span class="p">(</span><span class="n">j</span><span class="p">):</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">e</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">e</span>    
</code></pre></div></div>

<p>Aquí, las dimensiones de las variables son complejas. Sin embargo, cuando pensamos en la iniciativa del autor, obtenemos algunas pistas. Observa, el código está compuesto por tres partes similares. Y cada parte es casi la misma, aunque los nombres de las variables son diferentes. Ahora, me parece muy cómodo. El uso de <code class="language-plaintext highlighter-rouge">zip</code>, la operación <code class="language-plaintext highlighter-rouge">for</code> sobre la lista y la función <code class="language-plaintext highlighter-rouge">reshape</code>. La comprensión simplemente se acumula entre las cientos de veces que imprimo variables y trato de entender por qué los valores de las variables son así.</p>

<p>Y Zhiwei siempre encuentra los errores muy valiosos. Como en el siguiente código, se enfrenta a muchos errores, por ejemplo:</p>

<ul>
  <li>TypeError: Forma no válida (784,) para datos de imagen</li>
  <li>ValueError: al establecer un elemento de un array con una secuencia. El array solicitado tiene una forma no homogénea después de 2 dimensiones. La forma detectada fue (1, 2) + parte no homogénea.</li>
</ul>

<p>El rastreo de la pila de errores es como un hermoso poema.</p>

<p>Además, cuando formateamos la salida del valor en Visual Studio Code, es mucho más legible.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.92733598</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.01054299</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">1.0195613</span><span class="p">],</span>
       <span class="p">...</span>
       <span class="p">[</span><span class="mf">0.67045368</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">0.29942482</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">0.35010666</span><span class="p">]]),</span>
 <span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.87093344</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.18758503</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.35792778</span><span class="p">],</span>
        <span class="p">...</span>
        <span class="p">[</span><span class="mf">0.36830578</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.61671649</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.67084213</span><span class="p">]])]</span>
</code></pre></div></div>

<p>Gracias por leer. Thank you for your reading.</p>

<hr />

<p>Nota: Algunas imágenes están copiadas del libro “Redes Neuronales y Aprendizaje Profundo”.</p>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-es" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
