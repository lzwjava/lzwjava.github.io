<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>禪與機器學習的藝術</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>禪與機器學習的藝術 | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="禪與機器學習的藝術" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="hant" />
<meta name="description" content="禪" />
<meta property="og:description" content="禪" />
<link rel="canonical" href="https://lzwjava.github.io/zen-neural-hant" />
<meta property="og:url" content="https://lzwjava.github.io/zen-neural-hant" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-07-03T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="禪與機器學習的藝術" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2023-07-03T00:00:00+08:00","datePublished":"2023-07-03T00:00:00+08:00","description":"禪","headline":"禪與機器學習的藝術","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/zen-neural-hant"},"url":"https://lzwjava.github.io/zen-neural-hant"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=2fde584d40acbc02fd538575043702ef5ed3917d">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=2fde584d40acbc02fd538575043702ef5ed3917d" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       禪與機器學習的藝術 | 原創，AI翻譯
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/hant/2023-07-03-zen-neural-hant.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postshant2023-07-03-zen-neural-hant.md</span> -->
      

      <!-- <span>2023-07-03-zen-neural-hant.md</span> -->

      
        

        
          
          <a href="#" class="button">2023.07</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/zen-neural-en" >English</option>
        <option value="/zen-neural-zh" >中文</option>
        <option value="/zen-neural-ja" >日本語</option>
        <option value="/zen-neural-es" >Español</option>
        <option value="/zen-neural-hi" >हिंदी</option>
        <option value="/zen-neural-fr" >Français</option>
        <option value="/zen-neural-de" >Deutsch</option>
        <option value="/zen-neural-ar" >العربية</option>
        <option value="/zen-neural-hant" selected>繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <h2 id="禪">禪</h2>

<p>一個年輕的爸爸週末忙著學習神經網絡。然而，這個週末，他需要陪他的小女兒在公寓的游泳池裡游泳。他躺在淺水中，看著高聳入雲的公寓大樓。突然間，他想到，哇，它們真的很像神經網絡。每個陽台就像一個神經元。一棟大樓就像一層神經元。而一群大樓組合起來就形成了一個神經網絡。</p>

<p>接著，他想到了反向傳播。反向傳播的作用是將誤差傳播回神經元。在一次訓練結束時，算法會計算最後一層輸出與目標結果之間的誤差。實際上，神經網絡與神經元無關。它關乎的是可微分的計算。</p>

<p>在寫完《我終於理解神經網絡如何運作》這篇文章後，他發現自己仍然沒有完全理解。理解是相對的。正如理查德·費曼所指出的那樣，沒有人能對任何事情百分之百確定，我們只能相對確定某些事情。所以志偉這樣說是可以接受的。</p>

<p>於是，他找到了一種深入理解神經網絡的方法，即每次複製幾行示例代碼，然後運行並打印變量。這是一個用於識別手寫數字的簡單神經網絡。他最近讀的書名為《神經網絡與深度學習》。因此，他將自己的GitHub倉庫命名為《神經網絡與志偉學習》。</p>

<p>在我們使用神經網絡訓練數據之前，首先需要加載數據。這部分花了他一週的閒暇時間來完成。事情總是需要更多的時間來完成。但只要我們不放棄，我們就能做很多事情。</p>

<p>機器學習領域中的mnist代表的是修改後的國家標準與技術研究院數據庫。所以我們的數據加載文件叫做minst_loader。我們使用Python中的print函數來打印大量的列表和ndarray數組。ndarray中的nd代表n維。</p>

<p>除了打印，我們還必須使用matplotlib庫來顯示我們的數字。如下所示。</p>

<div align="center"><img src="/assets/images/zen-neural/figure.png" width="30%" /><img /></div>

<h2 id="藝術">藝術</h2>

<p>讓我們看更多的數字。</p>

<div align="center">
<img src="/assets/images/zen-neural/figures.jpeg" width="100%" /><img />
(圖片來源：神經網絡與深度學習)
</div>

<p>有時候看到圖片比整天面對嘈雜的代碼更讓人愉悅。</p>

<div align="center">
<img src="/assets/images/zen-neural/layer.png" width="100%" /><img />
(圖片來源：神經網絡與深度學習)
</div>

<p>看起來很複雜嗎？這裡，我們可能每層有太多的神經元。這使得事情變得模糊。一旦你理解了，它其實非常簡單。關於上圖的第一件事是它有三層，輸入層、隱藏層和輸出層。一層連接到下一層。但是輸入層的784個神經元如何變成第二層的15個神經元？隱藏層的15個神經元如何變成輸出層的10個神經元？</p>

<div align="center">
<img src="/assets/images/zen-neural/simple-network.png" width="100%" /><img />

</div>

<p>這個網絡要簡單得多。雖然志偉不想在這篇文章中包含任何數學公式，但這裡的數學太簡單和美麗，無法隱藏。</p>

\[w_1*a_1 + w_2*a_2+...+ w_6*a_6+b_1\]

<p>假設我們如下表示網絡。</p>

<div align="center"><img src="/assets/images/zen-neural/network-1.png" width="30%" /><img /></div>

<p>所以，在第一層和第二層之間，我們有以下方程。</p>

\[\begin{eqnarray}
  w_1*a_1 +...+ w_6*a_6+b_1 = c_1 \\
  w_1*a_1 +...+ w_6*a_6+b_2 = c_2 \\
  w_1*a_1 +...+ w_6*a_6+b_3 = c_3 \\
  w_1*a_1 +...+ w_6*a_6+b_4 = c_4 
\end{eqnarray}\]

<p>這裡，方程1有一組權重，方程2有另一組權重。所以方程1中的$w_1$與方程2中的$w_1$不同。在第二層和第三層之間，我們有以下方程。</p>

\[\begin{eqnarray}
  w_1*c_1 + ... + w_4*c_4+b_1 = d_1 \\
  w_1*c_1 + ... + w_4*c_4+b_2 = d_2 \\
  w_1*c_1 + ... + w_4*c_4+b_3 = d_3 
\end{eqnarray}\]

<p>在第三層到最後一層，我們有以下方程。</p>

\[w_1*d_1 + w_2*d_2+ w_3*d_3+ b_1 = e_1\]

<p>上述方程的一個問題是，值的範圍不夠簡單或正式。乘法和加法的值範圍相當大。我們希望它約束在一個小範圍內，比如0到1。所以這裡，我們有Sigmoid函數。</p>

\[\sigma(z) \equiv \frac{1}{1+e^{-z}}\]

<p>我們不需要被符號$\sigma$嚇到。它只是一個符號，就像符號a一樣。如果我們給它輸入0.5，它的值是</p>

\[\frac{1}{1+e^{-0.5}} \approx 0.622459\]

<p>並且，</p>

\[\begin{eqnarray}
\frac{1}{1+e^{-(-100)}} \approx 3.72*e^{-44}  \\
\frac{1}{1+e^{-(-10)}} \approx 0.000045  \\
\frac{1}{1+e^{-(-1)}} \approx 0.26894  \\
\frac{1}{1+e^{-{0}}} = 0.5  \\
\frac{1}{1+e^{-10}} \approx 0.99995  \\
\frac{1}{1+e^{-100}} = 1
\end{eqnarray}\]

<p>這裡很有趣。在寫這篇文章之前，我不知道上面的內容。現在，我對它的正常輸入的近似結果值有了一些感覺。我們觀察到，對於從0到$\infty$的輸入，它的值是從0.5到1，而對於從$-\infty$到0的輸入，它的值是從0到0.5。</p>

<div align="center"><img src="/assets/images/zen-neural/curve.png" width="100%" /><img /></div>

<p>所以關於上述方程，它們並不準確。最合適的應該是如下。</p>

\[\begin{eqnarray}
  \sigma(w_1*a_1 + ... + w_6*a_6+b_1) = c_1 \\
  \sigma(w_1*a_1 + ... + w_6*a_6+b_2) = c_2 \\
  \sigma(w_1*a_1 + ... + w_6*a_6+b_3) = c_3 \\
  \sigma(w_1*a_1 + ... + w_6*a_6+b_4) = c_4 
\end{eqnarray}\]

<p>所以對於第一個方程，它是，</p>

\[\frac{1}{1+e^{-(w_1*a_1 +...+ w_6*a_6+b_1)}}\]

<p>我們如何更新$w_1$的新權重？即，</p>

\[w_1 \rightarrow w_1' = w_1- \Delta w\]

<p>對於方程，</p>

\[w_1*a_1 + w_2*a_2+...+ w_6*a_6+b_1\]

<p>它對$w_1$的導數是$a_1$。讓我們給這個和一個符號$S_1$。</p>

<p>所以，</p>

\[\frac{\partial S_1}{\partial w_1} = a_1 , \frac{\partial S_1}{\partial w_2} = a_2, ...\]

<p>導數意味著變化率。這意味著對於$w_1$的變化$\Delta w$，結果$S_1$的變化是$a_1 * \Delta w$。我們如何反轉這樣的計算？讓我們計算一下。</p>

\[\begin{eqnarray}
S_1' - S_1 = \Delta S_1  \\
\frac{\Delta S_1}{a_1} = \Delta w \\
w_1- \Delta w = w_1'
\end{eqnarray}\]

<p>鏈式法則解釋了$f(g(x))$的導數是$f’(g(x))⋅g’(x)$。</p>

<p>所以在這裡，</p>

\[\begin{eqnarray}
f(z) = \sigma(z) = \frac{1}{1+e^{-z}} \\
g(x) = w_1*a_1 +...+ w_6*a_6+b_1
\end{eqnarray}\]

<p>Sigmoid函數的導數是，</p>

\[\sigma'(z) = \frac{\sigma(z)}{1-\sigma(z)}\]

<p>所以$f(g(w_1))$的導數是$\frac{\sigma(z)}{1-\sigma(z)} * a_1$。</p>

<p>所以，</p>

\[\begin{eqnarray}
\frac{\sigma(z)}{1-\sigma(z)} * a_1 * \Delta w = \Delta C \\
\Delta w = \frac{\Delta C}{\frac{\sigma(z)}{1-\sigma(z)} * a_1} 
\end{eqnarray}\]

<p>對於偏置$b_1$，</p>

\[\begin{eqnarray}
g'(b_1) = 1 \\
\frac{\sigma(z)}{1-\sigma(z)} * \Delta b = \Delta C \\
\Delta b = \frac{\Delta C}{\frac{\sigma(z)}{1-\sigma(z)}}
\end{eqnarray}\]

<h2 id="代碼">代碼</h2>

<p>打印變量的方法非常有用且簡單，儘管現在人們發明了Jupyter Notebook來做這樣的事情。正如志偉之前提到的，理解神經網絡的關鍵之一是我們應該注意維度。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">print_shape</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">arr</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span> <span class="c1"># 10
</span><span class="n">print_shape</span><span class="p">(</span><span class="n">training_results</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># (784, 1)
</span><span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">training_data</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># &lt;class 'list'&gt;
</span></code></pre></div></div>

<p>由於志偉剛剛完成了加載數據的部分，他將繼續使用複製幾行並打印變量的方式來學習神經網絡的實際部分。你可以在此處跟進進度，https://github.com/lzwjava/neural-networks-and-zhiwei-learning。</p>

<p>我在進度中卡住了幾次。即使代碼看起來非常簡單，經過一次又一次地嘗試理解它，我還是失敗了。然後我把自己從當前的代碼行中抽離出來，從更高的層次來看它，思考作者為什麼寫那部分代碼，突然間我明白了。代碼如下。</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_data_wrapper</span><span class="p">():</span>
    <span class="n">tr_d</span><span class="p">,</span> <span class="n">va_d</span><span class="p">,</span> <span class="n">te_d</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>

    <span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">training_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectorized_result</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">training_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">,</span> <span class="n">training_results</span><span class="p">)</span>

    <span class="n">validation_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">validation_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">validation_inputs</span><span class="p">,</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">test_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_inputs</span><span class="p">,</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">vectorized_result</span><span class="p">(</span><span class="n">j</span><span class="p">):</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">e</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">e</span>    
</code></pre></div></div>

<p>這裡，變量的維度很複雜。然而，當我們思考作者的初衷時，我們就有了一些線索。看，代碼由三個相似的部分組成。每個部分幾乎相同，儘管變量的名稱不同。現在，對我來說，它看起來非常舒服。zip，對列表的“for”操作，以及reshape函數。理解就在數百次打印變量和嘗試弄清楚變量的值為什麼是這樣的過程中積累起來。</p>

<p>志偉總是發現錯誤非常有價值。如下面的代碼，他遇到了很多錯誤，例如，</p>

<ul>
  <li>TypeError: Invalid shape (784,) for image data</li>
  <li>ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (1, 2) + inhomogeneous part.</li>
</ul>

<p>錯誤堆棧跟踪就像一首美麗的詩。</p>

<p>此外，當我們在Visual Studio Code中格式化值輸出時，它更具可讀性。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.92733598</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.01054299</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">1.0195613</span><span class="p">],</span>
       <span class="p">...</span>
       <span class="p">[</span><span class="mf">0.67045368</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">0.29942482</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">0.35010666</span><span class="p">]]),</span>
 <span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.87093344</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.18758503</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.35792778</span><span class="p">],</span>
        <span class="p">...</span>
        <span class="p">[</span><span class="mf">0.36830578</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.61671649</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.67084213</span><span class="p">]])]</span>
</code></pre></div></div>

<p>読んでくれてありがとう. 謝謝你的閱讀。</p>

<hr />

<p>註：部分圖片來自《神經網絡與深度學習》一書。</p>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-hant" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
