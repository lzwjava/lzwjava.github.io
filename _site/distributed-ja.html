<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>クラウドコンピューティングとビッグデータ入門</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>クラウドコンピューティングとビッグデータ入門 | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="クラウドコンピューティングとビッグデータ入門" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="ja" />
<meta name="description" content="このレッスンでは以下のトピックを取り上げます：" />
<meta property="og:description" content="このレッスンでは以下のトピックを取り上げます：" />
<link rel="canonical" href="https://lzwjava.github.io/distributed-ja" />
<meta property="og:url" content="https://lzwjava.github.io/distributed-ja" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-10T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="クラウドコンピューティングとビッグデータ入門" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2021-03-10T00:00:00+08:00","datePublished":"2021-03-10T00:00:00+08:00","description":"このレッスンでは以下のトピックを取り上げます：","headline":"クラウドコンピューティングとビッグデータ入門","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/distributed-ja"},"url":"https://lzwjava.github.io/distributed-ja"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=cae3a66c75fa77f6b4cea23a93ef46d4dca9269d">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=cae3a66c75fa77f6b4cea23a93ef46d4dca9269d" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       クラウドコンピューティングとビッグデータ入門 | オリジナル、AI翻訳
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/ja/2021-03-10-distributed-ja.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postsja2021-03-10-distributed-ja.md</span> -->
      

      <!-- <span>2021-03-10-distributed-ja.md</span> -->

      
        

        
          
          <a href="#" class="button">2021.03</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/distributed-en" >English</option>
        <option value="/distributed-zh" >中文</option>
        <option value="/distributed-ja" selected>日本語</option>
        <option value="/distributed-es" >Español</option>
        <option value="/distributed-hi" >हिंदी</option>
        <option value="/distributed-fr" >Français</option>
        <option value="/distributed-de" >Deutsch</option>
        <option value="/distributed-ar" >العربية</option>
        <option value="/distributed-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>このレッスンでは以下のトピックを取り上げます：</p>

<ul>
  <li>Spark</li>
  <li>Hadoop</li>
  <li>Kubernetes</li>
  <li>Docker</li>
  <li>Flink</li>
  <li>MongoDB</li>
</ul>

<p>（注：これらの項目は技術名であり、翻訳の必要はありません。）</p>

<p>クラウドコンピューティングについて語るとき、多くのツールが欠かせません。Hadoop、Hive、Hbase、ZooKeeper、Docker、Kubernetes、Spark、Kafka、MongoDB、Flink、Druid、Presto、Kylin、Elastic Searchなど、聞いたことがありますか？これらのツールのいくつかは、<code class="language-plaintext highlighter-rouge">ビッグデータエンジニア</code>や<code class="language-plaintext highlighter-rouge">分散バックエンドエンジニア</code>の職務記述書から見つけたものです。これらは高給のポジションです。私たちはそれらをすべてインストールして、少し触れてみることにしましょう。</p>
<h2 id="spark初探">Spark初探</h2>

<p>公式サイトによると、<code class="language-plaintext highlighter-rouge">Spark</code>は大規模データの分析エンジンとして使用されます。<code class="language-plaintext highlighter-rouge">spark</code>は一連のライブラリです。<code class="language-plaintext highlighter-rouge">Redis</code>のようにサーバーとクライアントに分かれているわけではなく、<code class="language-plaintext highlighter-rouge">spark</code>はクライアント側でのみ使用されます。公式サイトから最新バージョン、<code class="language-plaintext highlighter-rouge">spark-3.1.1-bin-hadoop3.2.tar</code>をダウンロードしました。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
├── LICENSE
├── NOTICE
├── R
├── README.md
├── RELEASE
├── bin
├── conf
├── data
├── examples
├── jars
├── kubernetes
├── licenses
├── python
├── sbin
└── yarn
</code></pre></div></div>

<p>11ディレクトリ、4ファイル</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
どうやら、各言語で書かれたいくつかの解析ライブラリのようです。

また、公式サイトによると、Python上で直接依存ライブラリをインストールできるとのことです。`pip install pyspark`

```shell
$ pip install pyspark
pysparkを収集中
  pyspark-3.1.1.tar.gz (212.3 MB) をダウンロード中
     |████████████████████████████████| 212.3 MB 14 kB/s
py4j==0.10.9 を収集中
  py4j-0.10.9-py2.py3-none-any.whl (198 kB) をダウンロード中
     |████████████████████████████████| 198 kB 145 kB/s
収集したパッケージのためのホイールを構築中: pyspark
  pysparkのためのホイールを構築中 (setup.py) ... 完了
  pysparkのためのホイールを作成しました: ファイル名=pyspark-3.1.1-py2.py3-none-any.whl サイズ=212767604 sha256=0b8079e82f3a5bcadad99179902d8c8ff9f8eccad928a469c11b97abdc960b72
  ディレクトリに保存: /Users/lzw/Library/Caches/pip/wheels/23/bf/e9/9f3500437422e2ab82246f25a51ee480a44d4efc6c27e50d33
pysparkのビルドに成功しました
収集したパッケージをインストール中: py4j, pyspark
py4j-0.10.9 と pyspark-3.1.1 のインストールに成功しました
</code></pre></div></div>

<p>インストールしました。</p>

<p>これは公式サイトを見て、いくつかの例を確認しています。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/run-example SparkPi 10
</code></pre></div></div>

<p>あ、なるほど、ダウンロードしたインストーラーパッケージ内のプログラムを実行できるんですね。でもエラーが出ました。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/run-example SparkPi 10
21/03/11 00:06:15 WARN NativeCodeLoader: プラットフォーム用のネイティブHadoopライブラリをロードできません... 適用可能な場所では組み込みのJavaクラスを使用します
21/03/11 00:06:16 INFO ResourceUtils: spark.driver用のカスタムリソースは設定されていません。
21/03/11 00:06:16 WARN Utils: サービス <span class="s1">'sparkDriver'</span> がランダムな空きポートにバインドできませんでした。適切なバインドアドレスを設定しているか確認してください。
</code></pre></div></div>

<blockquote>
  <p>Sparkは、Hadoopデータと互換性のある高速で汎用的な処理エンジンです。YARNまたはSparkのスタンドアロンモードを介してHadoopクラスターで実行でき、HDFS、HBase、Cassandra、Hive、および任意のHadoop InputFormatのデータを処理できます。バッチ処理（MapReduceに類似）と、ストリーミング、インタラクティブクエリ、機械学習などの新しいワークロードの両方を実行するように設計されています。</p>
</blockquote>

<p><code class="language-plaintext highlighter-rouge">hadoop</code>が何度も登場しました。<code class="language-plaintext highlighter-rouge">spark depends hadoop</code>をGoogleで検索したところ、以下のような記述が見つかりました。どうやらこれは<code class="language-plaintext highlighter-rouge">Hadoop</code>形式のデータに依存しているようです。まずは<code class="language-plaintext highlighter-rouge">Hadoop</code>について調べてみましょう。</p>

<h2 id="hadoop">Hadoop</h2>

<p>簡単に公式サイトを見た後、インストールしてみましょう。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>hadoop
</code></pre></div></div>

<p>インストールの過程で、少し理解を深めましょう。</p>

<blockquote>
  <p>Apache Hadoopソフトウェアライブラリは、シンプルなプログラミングモデルを使用して、コンピュータのクラスター全体で大規模なデータセットを分散処理するためのフレームワークです。単一のサーバーから数千台のマシンにスケールアップするように設計されており、各マシンがローカルでの計算とストレージを提供します。ハードウェアに依存して高可用性を実現するのではなく、ライブラリ自体がアプリケーション層で障害を検出し、処理するように設計されているため、それぞれが障害を起こしやすいコンピュータのクラスター上で高可用性サービスを提供します。</p>
</blockquote>

<p>つまり、Hadoopは分散データセットを処理するためのフレームワークです。これらのデータセットは多くのコンピュータに分散している可能性があります。非常にシンプルなプログラミングモデルを使用して処理します。Hadoopは、単一のサーバーから数千台のマシンに拡張できるように設計されています。ハードウェアの高可用性に依存するのではなく、このライブラリはアプリケーションレベルでエラーを検出し、処理するように設計されています。そのため、クラスタ内の各コンピュータが故障する可能性があるにもかかわらず、高可用性のサービスをクラスタに展開することができます。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>hadoop
エラー:
  homebrew-core はシャロー（浅い）クローンです。
  homebrew-cask はシャロー（浅い）クローンです。
<span class="sb">`</span>brew update<span class="sb">`</span> を実行する前に、まず以下を実行してください:
  git <span class="nt">-C</span> /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core fetch <span class="nt">--unshallow</span>
  git <span class="nt">-C</span> /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask fetch <span class="nt">--unshallow</span>
これらのコマンドは、リポジトリのサイズが大きいため、実行に数分かかる場合があります。
この制限は、GitHubの要請により設けられました。シャロークローンの更新は、
Homebrew/homebrew-core と Homebrew/homebrew-cask のツリーレイアウトとトラフィックのため、
非常に高コストな操作です。これを自動的に行わないのは、CIシステムで繰り返し高コストな
アンシャロー操作を実行しないようにするためです（CIシステムはシャロークローンを使用しないように修正されるべきです）。
ご不便をおかけして申し訳ありません。
<span class="o">==&gt;</span> Downloading https://homebrew.bintray.com/bottles/openjdk-15.0.1.big_sur.bottle.tar.gz
すでにダウンロード済み: /Users/lzw/Library/Caches/Homebrew/downloads/d1e3ece4af1d225bc2607eaa4ce85a873d2c6d43757ae4415d195751bc431962--openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Downloading https://www.apache.org/dyn/closer.lua?path<span class="o">=</span>hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
すでにダウンロード済み: /Users/lzw/Library/Caches/Homebrew/downloads/764c6a0ea7352bb8bb505989feee1b36dc628c2dcd6b93fef1ca829d191b4e1e--hadoop-3.3.0.tar.gz
<span class="o">==&gt;</span> hadoop の依存関係をインストール中: openjdk
<span class="o">==&gt;</span> hadoop の依存関係をインストール中: openjdk
<span class="o">==&gt;</span> openjdk-15.0.1.big_sur.bottle.tar.gz を展開中
<span class="o">==&gt;</span> 注意
システムのJavaラッパーがこのJDKを見つけるためには、以下のようにシンボリックリンクを作成してください:
  <span class="nb">sudo ln</span> <span class="nt">-sfn</span> /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk
</code></pre></div></div>

<p>openjdk は keg-only です。これは、/usr/local にシンボリックリンクが作成されていないことを意味します。なぜなら、macOS の <code class="language-plaintext highlighter-rouge">java</code> ラッパーと競合するためです。</p>

<p>もしPATHにopenjdkを最初に配置する必要がある場合は、次のコマンドを実行してください:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>コンパイラがopenjdkを見つけるためには、以下の設定が必要かもしれません：</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">export </span><span class="nv">CPPFLAGS</span><span class="o">=</span><span class="s2">"-I/usr/local/opt/openjdk/include"</span>
</code></pre></div></div>

<p>==&gt; 概要
🍺  /usr/local/Cellar/openjdk/15.0.1: 614ファイル, 324.9MB
==&gt; Hadoopをインストール中
🍺  /usr/local/Cellar/hadoop/3.3.0: 21,819ファイル, 954.7MB, 2分15秒でビルド完了
==&gt; 依存関係のアップグレード 1つ:
maven 3.3.3 -&gt; 3.6.3_1
==&gt; maven 3.3.3 -&gt; 3.6.3_1 にアップグレード中
==&gt; https://www.apache.org/dyn/closer.lua?path=maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz をダウンロード中
==&gt; https://mirror.olnevhost.net/pub/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz からダウンロード中
######################################################################## 100.0%
エラー: <code class="language-plaintext highlighter-rouge">brew link</code> ステップが正常に完了しませんでした
フォーミュラはビルドされましたが、/usr/local にシンボリックリンクされていません
bin/mvn をシンボリックリンクできませんでした
ターゲット /usr/local/bin/mvn
は maven に属するシンボリックリンクです。以下のコマンドでリンクを解除できます:
  brew unlink maven</p>

<p>リンクを強制し、すべての競合するファイルを上書きするには:
  brew link –overwrite maven</p>

<p>削除されるすべてのファイルをリストアップするには:
  brew link –overwrite –dry-run maven</p>

<p>競合する可能性のあるファイルは以下の通りです:
/usr/local/bin/mvn -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvn
/usr/local/bin/mvnDebug -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnDebug
/usr/local/bin/mvnyjp -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnyjp
==&gt; 概要
🍺  /usr/local/Cellar/maven/3.6.3_1: 87ファイル, 10.7MB, 7秒でビルド
削除中: /usr/local/Cellar/maven/3.3.3… (92ファイル, 9MB)
==&gt; アップグレードされたフォーミュラの依存関係をチェック中…
==&gt; 壊れた依存関係は見つかりませんでした!
==&gt; 注意事項
==&gt; openjdk
システムのJavaラッパーがこのJDKを見つけるためには、以下のようにシンボリックリンクを作成してください:
  sudo ln -sfn /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk</p>

<p>openjdkはkeg-onlyであり、これは/usr/localにシンボリックリンクされていないことを意味します。なぜなら、macOSの<code class="language-plaintext highlighter-rouge">java</code>ラッパーをシャドウしてしまうからです。</p>

<p>もし <code class="language-plaintext highlighter-rouge">openjdk</code> を PATH の最初に置く必要がある場合は、次のコマンドを実行してください:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>コンパイラがopenjdkを見つけるためには、以下の設定が必要かもしれません:
  export CPPFLAGS=”-I/usr/local/opt/openjdk/include”</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
`brew`の出力ログに`maven`が適切にリンクされていないことに気づきました。次に、バージョン`3.6.3_1`に強制的にリンクします。

```shell
  brew link --overwrite maven
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Hadoop</code>のインストールが成功しました。</p>

<blockquote>
  <h2 id="モジュール">モジュール</h2>

  <p>このプロジェクトには以下のモジュールが含まれています：</p>

  <ul>
    <li><strong>Hadoop Common</strong>: 他のHadoopモジュールをサポートする共通ユーティリティ。</li>
    <li><strong>Hadoop Distributed File System (HDFS™)</strong>: アプリケーションデータへの高スループットアクセスを提供する分散ファイルシステム。</li>
    <li><strong>Hadoop YARN</strong>: ジョブスケジューリングとクラスタリソース管理のためのフレームワーク。</li>
    <li><strong>Hadoop MapReduce</strong>: 大規模データセットの並列処理を行うためのYARNベースのシステム。</li>
    <li><strong>Hadoop Ozone</strong>: Hadoop用のオブジェクトストア。</li>
  </ul>
</blockquote>

<p>これらのモジュールがあると言います。これで<code class="language-plaintext highlighter-rouge">hadoop</code>と入力すると、次のように表示されます：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hadoop
使用方法: hadoop <span class="o">[</span>オプション] サブコマンド <span class="o">[</span>サブコマンド オプション]
または    hadoop <span class="o">[</span>オプション] クラス名 <span class="o">[</span>クラス名 オプション]
  ここで、クラス名はユーザーが提供するJavaクラスです
</code></pre></div></div>

<p>OPTIONS は none または以下のいずれかです:</p>

<p>–config dir                     Hadoopの設定ディレクトリ
–debug                          シェルスクリプトのデバッグモードを有効にする
–help                           使用方法の情報を表示
buildpaths                       ビルドツリーからクラスファイルを追加しようとする
hostnames list[,of,host,names]   スレーブモードで使用するホスト名のリスト
hosts filename                   スレーブモードで使用するホストのリストファイル
loglevel level                   このコマンドのlog4jレベルを設定
workers                          ワーカーモードを有効にする</p>

<p>SUBCOMMAND は以下のいずれかです:
    Admin コマンド:</p>

<p>daemonlog     各デーモンのログレベルを取得/設定する</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>クライアントコマンド:
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>archive       Hadoopアーカイブを作成する
checknative   Hadoopおよび圧縮ライブラリのネイティブ利用可能性を確認する
classpath     Hadoopのjarと必要なライブラリを取得するためのクラスパスを表示する
conftest      設定XMLファイルを検証する
credential    認証プロバイダーと対話する
distch        分散メタデータチェンジャー
distcp        ファイルまたはディレクトリを再帰的にコピーする
dtutil        委譲トークンに関連する操作
envvars       計算されたHadoop環境変数を表示する
fs            汎用ファイルシステムユーザークライアントを実行する
gridmix       プロダクション負荷をモデル化した合成ジョブのミックスを送信する
jar &lt;jar&gt;     jarファイルを実行する。注: YARNアプリケーションを起動するには、"yarn jar"を使用してください。このコマンドは使用しないでください。
jnipath       java.library.pathを表示する
kdiag         Kerberosの問題を診断する
kerbname      auth_to_localプリンシパル変換を表示する
key           KeyProviderを介してキーを管理する
rumenfolder   rumen入力トレースをスケーリングする
rumentrace    ログをrumenトレースに変換する
s3guard       S3上のメタデータを管理する
trace         Hadoopのトレース設定を表示および変更する
version       バージョンを表示する
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>デーモンコマンド:
</code></pre></div></div>

<p>kms           KMS（Key Management Server）を実行する
registrydns   レジストリDNSサーバーを実行する</p>

<p>SUBCOMMANDは、パラメータなしまたは<code class="language-plaintext highlighter-rouge">-h</code>を付けて呼び出された場合にヘルプを表示する場合があります。</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
公式サイトにはいくつかの例が掲載されています。

```shell
  $ mkdir input
  $ cp etc/hadoop/*.xml input
  $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'
  $ cat output/*
</code></pre></div></div>

<p>このシェルコマンドのセットは、Hadoopを使用して特定の正規表現にマッチするテキストを検索するプロセスを示しています。以下に各コマンドの説明を日本語で示します。</p>

<ol>
  <li>
    <p><code class="language-plaintext highlighter-rouge">mkdir input</code><br />
現在のディレクトリに<code class="language-plaintext highlighter-rouge">input</code>という名前のディレクトリを作成します。</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">cp etc/hadoop/*.xml input</code><br />
<code class="language-plaintext highlighter-rouge">etc/hadoop/</code>ディレクトリ内のすべての<code class="language-plaintext highlighter-rouge">.xml</code>ファイルを、新しく作成した<code class="language-plaintext highlighter-rouge">input</code>ディレクトリにコピーします。</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'</code><br />
HadoopのMapReduceサンプルプログラムを実行し、<code class="language-plaintext highlighter-rouge">input</code>ディレクトリ内のファイルから正規表現<code class="language-plaintext highlighter-rouge">'dfs[a-z.]+'</code>にマッチするテキストを検索します。結果は<code class="language-plaintext highlighter-rouge">output</code>ディレクトリに保存されます。</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">cat output/*</code><br />
<code class="language-plaintext highlighter-rouge">output</code>ディレクトリ内のすべてのファイルの内容を表示します。これにより、検索結果を確認できます。</p>
  </li>
</ol>

<p><code class="language-plaintext highlighter-rouge">share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar</code> があることに気づきました。これは、おそらくいくつかのサンプルファイルが含まれていないことを意味します。<code class="language-plaintext highlighter-rouge">Homebrew</code> を使ってインストールすると、これらのファイルが含まれていない可能性があると推測されます。そこで、公式サイトからインストールパッケージをダウンロードしました。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
├── LICENSE-binary
├── LICENSE.txt
├── NOTICE-binary
├── NOTICE.txt
├── README.txt
├── bin
├── etc
├── include
├── lib
├── libexec
├── licenses-binary
├── sbin
└── share
</code></pre></div></div>

<p>このコマンドは、現在のディレクトリ（<code class="language-plaintext highlighter-rouge">.</code>）の内容を、深さ1レベルで表示しています。各エントリは、ファイルやディレクトリを表しています。</p>

<p><code class="language-plaintext highlighter-rouge">share</code>ディレクトリが現れました。しかし、<code class="language-plaintext highlighter-rouge">Homebrew</code>は本当にこれらの追加ファイルを持っていないのでしょうか。<code class="language-plaintext highlighter-rouge">Homebrew</code>がインストールされているディレクトリを見つけましょう。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">type </span>hadoop
hadoop は /usr/local/bin/hadoop です
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-alrt</span> /usr/local/bin/hadoop
lrwxr-xr-x  1 lzw  admin  33  3月 11 00:48 /usr/local/bin/hadoop -&gt; ../Cellar/hadoop/3.3.0/bin/hadoop
<span class="nv">$ </span><span class="nb">cd</span> /usr/local/Cellar/hadoop/3.3.0
</code></pre></div></div>

<p>これは<code class="language-plaintext highlighter-rouge">/usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop</code>ディレクトリの下に表示されたディレクトリツリーです。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 2
<span class="nb">.</span>
├── client
│   ├── hadoop-client-api-3.3.0.jar
│   ├── hadoop-client-minicluster-3.3.0.jar
│   └── hadoop-client-runtime-3.3.0.jar
├── common
│   ├── hadoop-common-3.3.0-tests.jar
│   ├── hadoop-common-3.3.0.jar
│   ├── hadoop-kms-3.3.0.jar
│   ├── hadoop-nfs-3.3.0.jar
│   ├── hadoop-registry-3.3.0.jar
│   ├── jdiff
│   ├── lib
│   ├── sources
│   └── webapps
├── hdfs
│   ├── hadoop-hdfs-3.3.0-tests.jar
│   ├── hadoop-hdfs-3.3.0.jar
│   ├── hadoop-hdfs-client-3.3.0-tests.jar
│   ├── hadoop-hdfs-client-3.3.0.jar
│   ├── hadoop-hdfs-httpfs-3.3.0.jar
│   ├── hadoop-hdfs-native-client-3.3.0-tests.jar
│   ├── hadoop-hdfs-native-client-3.3.0.jar
│   ├── hadoop-hdfs-nfs-3.3.0.jar
│   ├── hadoop-hdfs-rbf-3.3.0-tests.jar
│   ├── hadoop-hdfs-rbf-3.3.0.jar
│   ├── jdiff
│   ├── lib
│   ├── sources
│   └── webapps
├── mapreduce
│   ├── hadoop-mapreduce-client-app-3.3.0.jar
│   ├── hadoop-mapreduce-client-common-3.3.0.jar
│   ├── hadoop-mapreduce-client-core-3.3.0.jar
│   ├── hadoop-mapreduce-client-hs-3.3.0.jar
│   ├── hadoop-mapreduce-client-hs-plugins-3.3.0.jar
│   ├── hadoop-mapreduce-client-jobclient-3.3.0-tests.jar
│   ├── hadoop-mapreduce-client-jobclient-3.3.0.jar
│   ├── hadoop-mapreduce-client-nativetask-3.3.0.jar
│   ├── hadoop-mapreduce-client-shuffle-3.3.0.jar
│   ├── hadoop-mapreduce-client-uploader-3.3.0.jar
│   ├── hadoop-mapreduce-examples-3.3.0.jar
│   ├── jdiff
│   ├── lib-examples
│   └── sources
├── tools
│   ├── dynamometer
│   ├── lib
│   ├── resourceestimator
│   ├── sls
│   └── sources
└── yarn
    ├── csi
    ├── hadoop-yarn-api-3.3.0.jar
    ├── hadoop-yarn-applications-catalog-webapp-3.3.0.war
    ├── hadoop-yarn-applications-distributedshell-3.3.0.jar
    ├── hadoop-yarn-applications-mawo-core-3.3.0.jar
    ├── hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar
    ├── hadoop-yarn-client-3.3.0.jar
    ├── hadoop-yarn-common-3.3.0.jar
    ├── hadoop-yarn-registry-3.3.0.jar
    ├── hadoop-yarn-server-applicationhistoryservice-3.3.0.jar
    ├── hadoop-yarn-server-common-3.3.0.jar
    ├── hadoop-yarn-server-nodemanager-3.3.0.jar
    ├── hadoop-yarn-server-resourcemanager-3.3.0.jar
    ├── hadoop-yarn-server-router-3.3.0.jar
    ├── hadoop-yarn-server-sharedcachemanager-3.3.0.jar
    ├── hadoop-yarn-server-tests-3.3.0.jar
    ├── hadoop-yarn-server-timeline-pluginstorage-3.3.0.jar
    ├── hadoop-yarn-server-web-proxy-3.3.0.jar
    ├── hadoop-yarn-services-api-3.3.0.jar
    ├── hadoop-yarn-services-core-3.3.0.jar
    ├── lib
    ├── sources
    ├── <span class="nb">test</span>
    ├── timelineservice
    ├── webapps
    └── yarn-service-examples
</code></pre></div></div>

<p>多くの<code class="language-plaintext highlighter-rouge">jar</code>パッケージが見られるでしょう。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>input
<span class="nv">$ </span><span class="nb">ls
</span>bin			hadoop-config.sh	hdfs-config.sh		libexec			sbin			yarn-config.sh
etc			hadoop-functions.sh	input			mapred-config.sh	share
<span class="nv">$ </span><span class="nb">cp </span>etc/hadoop/<span class="k">*</span>.xml input
<span class="nv">$ </span><span class="nb">cd </span>input/
<span class="nv">$ </span><span class="nb">ls
</span>capacity-scheduler.xml	hadoop-policy.xml	hdfs-site.xml		kms-acls.xml		mapred-site.xml
core-site.xml		hdfs-rbf-site.xml	httpfs-site.xml		kms-site.xml		yarn-site.xml
<span class="nv">$ </span><span class="nb">cd</span> ..
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
JARが存在しないか、通常のファイルではありません: /usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar
<span class="err">$</span>
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
2021-03-11 01:54:30,791 WARN util.NativeCodeLoader: プラットフォーム用のネイティブHadoopライブラリをロードできません... 適用可能な場所では組み込みのJavaクラスを使用します
2021-03-11 01:54:31,115 INFO impl.MetricsConfig: hadoop-metrics2.propertiesからプロパティをロードしました
2021-03-11 01:54:31,232 INFO impl.MetricsSystemImpl: メトリックスナップショットの周期を10秒に設定しました。
...
</code></pre></div></div>

<p>公式サイトの例に従って進めます。<code class="language-plaintext highlighter-rouge">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input</code> という部分に注目すると、<code class="language-plaintext highlighter-rouge">jar</code> ファイルの前にバージョン番号が付いています。したがって、これを私たちのバージョンである <code class="language-plaintext highlighter-rouge">3.3.0</code> に置き換える必要があります。</p>

<p>ログの最後：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2021-03-11 01:54:35,374 INFO mapreduce.Job:  map 100% reduce 100%
2021-03-11 01:54:35,374 INFO mapreduce.Job: Job job_local2087514596_0002 が正常に完了しました
2021-03-11 01:54:35,377 INFO mapreduce.Job: カウンター: 30
	ファイルシステムカウンター
		FILE: 読み取られたバイト数<span class="o">=</span>1204316
		FILE: 書き込まれたバイト数<span class="o">=</span>3565480
		FILE: 読み取り操作数<span class="o">=</span>0
		FILE: 大規模読み取り操作数<span class="o">=</span>0
		FILE: 書き込み操作数<span class="o">=</span>0
	Map-Reduceフレームワーク
		マップ入力レコード数<span class="o">=</span>1
		マップ出力レコード数<span class="o">=</span>1
		マップ出力バイト数<span class="o">=</span>17
		マップ出力実体化バイト数<span class="o">=</span>25
		入力分割バイト数<span class="o">=</span>141
		結合入力レコード数<span class="o">=</span>0
		結合出力レコード数<span class="o">=</span>0
		リデュース入力グループ数<span class="o">=</span>1
		リデュースシャッフルバイト数<span class="o">=</span>25
		リデュース入力レコード数<span class="o">=</span>1
		リデュース出力レコード数<span class="o">=</span>1
		スピルされたレコード数<span class="o">=</span>2
		シャッフルされたマップ数<span class="o">=</span>1
		失敗したシャッフル数<span class="o">=</span>0
		マージされたマップ出力数<span class="o">=</span>1
		GC経過時間（ミリ秒）<span class="o">=</span>57
		合計コミットされたヒープ使用量（バイト）<span class="o">=</span>772800512
	シャッフルエラー
		<span class="nv">BAD_ID</span><span class="o">=</span>0
		<span class="nv">CONNECTION</span><span class="o">=</span>0
		<span class="nv">IO_ERROR</span><span class="o">=</span>0
		<span class="nv">WRONG_LENGTH</span><span class="o">=</span>0
		<span class="nv">WRONG_MAP</span><span class="o">=</span>0
		<span class="nv">WRONG_REDUCE</span><span class="o">=</span>0
	ファイル入力フォーマットカウンター
		読み取られたバイト数<span class="o">=</span>123
	ファイル出力フォーマットカウンター
		書き込まれたバイト数<span class="o">=</span>23
</code></pre></div></div>

<p>続けて見ていきましょう。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>このコマンドは、<code class="language-plaintext highlighter-rouge">output</code>ディレクトリ内のすべてのファイルの内容を表示します。この例では、<code class="language-plaintext highlighter-rouge">output</code>ディレクトリ内のファイルに「1 dfsadmin」という内容が含まれていることがわかります。</p>

<p>これは一体どういう意味なのでしょうか。心配ありません、とにかく私たちは<code class="language-plaintext highlighter-rouge">Hadoop</code>を起動させました。そして最初のスタンドアロン版の計算例を実行しました。</p>

<h2 id="spark">Spark</h2>

<p>Sparkに戻りましょう。例を見てみましょう。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
</code></pre></div></div>

<p>このコードは、HDFS上にあるテキストファイルを読み込み、単語の出現回数をカウントし、その結果を再びHDFSに保存するものです。以下に各ステップの説明を示します。</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">text_file = sc.textFile("hdfs://...")</code>: HDFS上のテキストファイルを読み込み、RDD（Resilient Distributed Dataset）として<code class="language-plaintext highlighter-rouge">text_file</code>に格納します。</li>
  <li><code class="language-plaintext highlighter-rouge">counts = text_file.flatMap(lambda line: line.split(" "))</code>: 各行をスペースで分割し、単語のリストに変換します。<code class="language-plaintext highlighter-rouge">flatMap</code>は、各行を複数の単語に分割し、それらを単一のリストに平坦化します。</li>
  <li><code class="language-plaintext highlighter-rouge">.map(lambda word: (word, 1))</code>: 各単語をキーとし、値として1を持つタプルに変換します。これにより、各単語の出現回数をカウントする準備が整います。</li>
  <li><code class="language-plaintext highlighter-rouge">.reduceByKey(lambda a, b: a + b)</code>: 同じキー（単語）を持つタプルの値を合計します。これにより、各単語の総出現回数が計算されます。</li>
  <li><code class="language-plaintext highlighter-rouge">counts.saveAsTextFile("hdfs://...")</code>: 計算結果をHDFS上の指定されたパスにテキストファイルとして保存します。</li>
</ol>

<p>このコードは、Apache Sparkを使用して分散処理を行う典型的な例です。</p>

<p>ここに<code class="language-plaintext highlighter-rouge">hdfs</code>ファイルが現れました。調べたところ、以下のようにして<code class="language-plaintext highlighter-rouge">hdfs</code>ファイルを作成できることがわかりました：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-mkdir</span> /test
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">hdfs</code>コマンドを見てみましょう。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hdfs
使用方法: hdfs <span class="o">[</span>オプション] サブコマンド <span class="o">[</span>サブコマンド オプション]
</code></pre></div></div>

<p>OPTIONS は none または以下のいずれかです:</p>

<p>–buildpaths                       ビルドツリーからクラスファイルを追加しようと試みる
–config dir                       Hadoopの設定ディレクトリ
–daemon (start|status|stop)       デーモンの操作を行う
–debug                            シェルスクリプトのデバッグモードを有効にする
–help                             使用方法の情報を表示
–hostnames list[,of,host,names]   ワーカーモードで使用するホストのリスト
–hosts filename                   ワーカーモードで使用するホストのリストを含むファイル
–loglevel level                   このコマンドのlog4jレベルを設定
–workers                          ワーカーモードを有効にする</p>

<p>SUBCOMMAND は以下のいずれかです:
    Admin コマンド:</p>

<p>cacheadmin           HDFSキャッシュを設定する
crypto               HDFS暗号化ゾーンを設定する
debug                HDFSデバッグコマンドを実行するためのデバッグ管理者を実行する
dfsadmin             DFS管理者クライアントを実行する
dfsrouteradmin       ルーターベースのフェデレーションを管理する
ec                   HDFSイレイジャーコーディングCLIを実行する
fsck                 DFSファイルシステムチェックユーティリティを実行する
haadmin              DFS HA管理者クライアントを実行する
jmxget               NameNodeまたはDataNodeからJMXエクスポートされた値を取得する
oev                  オフライン編集ビューアを編集ファイルに適用する
oiv                  オフラインfsimageビューアをfsimageに適用する
oiv_legacy           レガシーfsimageにオフラインfsimageビューアを適用する
storagepolicies      ブロックストレージポリシーをリスト/取得/設定/満たす</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>クライアントコマンド:
</code></pre></div></div>

<p>classpath            Hadoopのjarと必要なライブラリを取得するために必要なクラスパスを表示します
dfs                  ファイルシステム上でファイルシステムコマンドを実行します
envvars              計算されたHadoop環境変数を表示します
fetchdt              NameNodeから委譲トークンを取得します
getconf              設定から設定値を取得します
groups               ユーザーが属するグループを取得します
lsSnapshottableDir   現在のユーザーが所有するすべてのスナップショット可能なディレクトリをリストします
snapshotDiff         ディレクトリの2つのスナップショット間の差分、または現在のディレクトリ内容とスナップショットとの差分を表示します
version              バージョンを表示します</p>

<p>デーモンコマンド:</p>

<p>balancer             クラスタのバランシングユーティリティを実行する
datanode             DFSデータノードを実行する
dfsrouter            DFSルーターを実行する
diskbalancer         指定されたノード上のディスク間でデータを均等に分散する
httpfs               HttpFSサーバー、HDFS HTTPゲートウェイを実行する
journalnode          DFSジャーナルノードを実行する
mover                ストレージタイプ間でブロックレプリカを移動するユーティリティを実行する
namenode             DFSネームノードを実行する
nfs3                 NFSバージョン3ゲートウェイを実行する
portmap              portmapサービスを実行する
secondarynamenode    DFSセカンダリネームノードを実行する
sps                  外部ストレージポリシーサティスファイアを実行する
zkfc                 ZKフェイルオーバーコントローラーデーモンを実行する</p>

<p>SUBCOMMANDは、パラメータなしまたは<code class="language-plaintext highlighter-rouge">-h</code>を指定して呼び出された場合にヘルプを表示する場合があります。</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
コードを引き続き修正します。

```python
from pyspark.sql import SparkSession
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">master</span><span class="p">(</span><span class="s">"local[*]"</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">config</span><span class="p">(</span><span class="s">'spark.driver.bindAddress'</span><span class="p">,</span> <span class="s">'127.0.0.1'</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span>
</code></pre></div></div>

<p>このコードは、Apache Sparkのセッションを作成し、ローカルマシン上で実行するための設定を行っています。<code class="language-plaintext highlighter-rouge">SparkSession.builder</code>を使用して、マスターノードを<code class="language-plaintext highlighter-rouge">local[*]</code>に設定し、すべての利用可能なコアを使用するように指定しています。また、<code class="language-plaintext highlighter-rouge">spark.driver.bindAddress</code>を<code class="language-plaintext highlighter-rouge">127.0.0.1</code>に設定して、ドライバーがローカルホストにバインドされるようにしています。最後に、<code class="language-plaintext highlighter-rouge">getOrCreate()</code>メソッドでセッションを取得または作成し、<code class="language-plaintext highlighter-rouge">sparkContext</code>を<code class="language-plaintext highlighter-rouge">sc</code>変数に格納しています。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"a.txt"</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"b.txt"</span><span class="p">)</span>
</code></pre></div></div>

<p>このコードは、Apache Sparkを使用してテキストファイル内の単語の出現回数をカウントするものです。以下にその内容を説明します。</p>

<ol>
  <li>
    <p><code class="language-plaintext highlighter-rouge">text_file = sc.textFile("a.txt")</code>: テキストファイル “a.txt” を読み込み、<code class="language-plaintext highlighter-rouge">text_file</code> というRDD（Resilient Distributed Dataset）を作成します。</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">counts = text_file.flatMap(lambda line: line.split(" "))</code>: 各行をスペースで分割し、単語のリストに変換します。<code class="language-plaintext highlighter-rouge">flatMap</code> は、各行を単語に分割し、それらを単一のリストに平坦化します。</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">.map(lambda word: (word, 1))</code>: 各単語をキーとし、値として1を持つタプルにマッピングします。これにより、各単語の出現回数をカウントするための準備が整います。</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">.reduceByKey(lambda a, b: a + b)</code>: 同じキー（単語）を持つタプルの値を合計します。これにより、各単語の総出現回数が計算されます。</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">counts.saveAsTextFile("b.txt")</code>: 最終的な結果をテキストファイル “b.txt” として保存します。</p>
  </li>
</ol>

<p>このコードを実行すると、”a.txt” ファイル内の各単語の出現回数がカウントされ、その結果が “b.txt” に保存されます。</p>

<p><code class="language-plaintext highlighter-rouge">.config('spark.driver.bindAddress', '127.0.0.1')</code> を設定することが重要です。そうしないと、<code class="language-plaintext highlighter-rouge">Service 'sparkDriver' could not bind on a random free port. You may check whether configuring an appropriate binding address</code> というエラーが発生します。</p>

<p>しかし、この時またエラーが発生しました。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Caused by: org.apache.spark.api.python.PythonException: Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
  File <span class="s2">"/usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py"</span>, line 473, <span class="k">in </span>main
    raise Exception<span class="o">((</span><span class="s2">"Python in worker has different version %s than that in "</span> +
Exception: Python <span class="k">in </span>worker has different version 3.8 than that <span class="k">in </span>driver 3.9, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.
</code></pre></div></div>

<p>このエラーメッセージは、PySparkが動作している環境で、ワーカーノードとドライバーノードのPythonバージョンが異なるために発生しています。具体的には、ワーカーノードのPythonバージョンが3.8であるのに対し、ドライバーノードのPythonバージョンが3.9となっています。PySparkは、ワーカーとドライバーのPythonのマイナーバージョンが異なる場合に実行できません。</p>

<p>この問題を解決するためには、環境変数 <code class="language-plaintext highlighter-rouge">PYSPARK_PYTHON</code> と <code class="language-plaintext highlighter-rouge">PYSPARK_DRIVER_PYTHON</code> が正しく設定されているか確認する必要があります。これらの環境変数を適切に設定することで、ワーカーとドライバーのPythonバージョンを一致させることができます。</p>

<p>異なるバージョンの<code class="language-plaintext highlighter-rouge">Python</code>が実行されていることを示しています。</p>

<p><code class="language-plaintext highlighter-rouge">.bash_profile</code>を編集する：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
<span class="nv">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
</code></pre></div></div>

<p>しかし、同じエラーが再び発生しました。調査した結果、<code class="language-plaintext highlighter-rouge">spark</code>が実行される際にこの環境変数が読み込まれていない、つまりターミナルのデフォルトの環境変数が使用されていない可能性があることがわかりました。</p>

<p>コード内で設定する必要があります：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
</code></pre></div></div>

<h1 id="spark環境の設定">Spark環境の設定</h1>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYSPARK_PYTHON'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'</span>
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYSPARK_DRIVER_PYTHON'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'</span>
</code></pre></div></div>

<p>これは実行されます。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python sc.py
21/03/11 02:54:52 WARN NativeCodeLoader: プラットフォーム用のネイティブHadoopライブラリをロードできません... 適用可能な場所では組み込みのJavaクラスを使用します
Sparkのデフォルトlog4jプロファイルを使用しています: org/apache/spark/log4j-defaults.properties
デフォルトのログレベルを<span class="s2">"WARN"</span>に設定しています。
ログレベルを調整するにはsc.setLogLevel<span class="o">(</span>newLevel<span class="o">)</span>を使用してください。SparkRの場合はsetLogLevel<span class="o">(</span>newLevel<span class="o">)</span>を使用してください。
PythonRDD[6] at RDD at PythonRDD.scala:53
</code></pre></div></div>

<p>この時点で<code class="language-plaintext highlighter-rouge">b.txt</code>が生成されます。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── b.txt
│   ├── _SUCCESS
│   ├── part-00000
│   └── part-00001
</code></pre></div></div>

<p>このディレクトリ構造は、<code class="language-plaintext highlighter-rouge">b.txt</code>というファイルが存在し、その中に<code class="language-plaintext highlighter-rouge">_SUCCESS</code>、<code class="language-plaintext highlighter-rouge">part-00000</code>、<code class="language-plaintext highlighter-rouge">part-00001</code>というファイルが含まれていることを示しています。</p>

<p>開いてみてください。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>b.txt/part-00000
<span class="o">(</span><span class="s1">'college'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'two'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'things'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'worked'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'on,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'of'</span>, 8<span class="o">)</span>
<span class="o">(</span><span class="s1">'school,'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'writing'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'programming.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s2">"didn't"</span>, 4<span class="o">)</span>
<span class="o">(</span><span class="s1">'then,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'probably'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'are:'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'short'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'awful.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'They'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'plot,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'just'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'characters'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'them'</span>, 2<span class="o">)</span>
...
</code></pre></div></div>

<p>成功しました！これはなじみ深いものではありませんか。まるで<code class="language-plaintext highlighter-rouge">Hadoop</code>の例のようです。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>このコマンドは、<code class="language-plaintext highlighter-rouge">output</code>ディレクトリ内のすべてのファイルの内容を表示します。この例では、<code class="language-plaintext highlighter-rouge">output</code>ディレクトリ内のファイルに「1 dfsadmin」という内容が含まれていることがわかります。</p>

<p>これらのファイルは<code class="language-plaintext highlighter-rouge">HDFS</code>と呼ばれます。ここでは<code class="language-plaintext highlighter-rouge">Spark</code>を使って単語を統計していることがわかります。短い数行で、とても便利そうですね。</p>

<h2 id="kubernetes">Kubernetes</h2>

<p>次に、<code class="language-plaintext highlighter-rouge">Kubernetes</code>、略して<code class="language-plaintext highlighter-rouge">k8s</code>（中間の8文字を8と略す）について触れてみましょう。これは、コンテナ化されたアプリケーションのデプロイ、スケーリング、および管理を自動化するためのオープンソースシステムです。</p>

<p><code class="language-plaintext highlighter-rouge">kubectl</code>コマンドラインツールは、k8sクラスターに対してさまざまなコマンド操作を実行するために使用されます。これを使ってアプリケーションをデプロイしたり、クラスターリソースを表示・管理したり、ログを確認したりすることができます。</p>

<p>同様にHomebrewを使ってインストールすることもできます。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>kubectl
</code></pre></div></div>

<p>ログを出力する：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">==&gt;</span> Downloading https://homebrew.bintray.com/bottles/kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Downloading from https://d29vzk4ow07wi7.cloudfront.net/0b4f08bd1d47cb913d7cd4571e3394c6747dfbad7ff114c5589c8396c1085ecf?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Pouring kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Caveats
Bashの補完機能が以下の場所にインストールされました:
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Summary
🍺  /usr/local/Cellar/kubernetes-cli/1.20.1: 246ファイル, 46.1MB
</code></pre></div></div>

<p>インストールが完了しました。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl
kubectl は Kubernetes クラスターマネージャーを制御します。
</code></pre></div></div>

<p>詳細情報はこちらをご覧ください: https://kubernetes.io/docs/reference/kubectl/overview/</p>

<p>基本的なコマンド（初心者向け）:
  create        ファイルまたは標準入力からリソースを作成します。
  expose        レプリケーションコントローラー、サービス、デプロイメント、またはポッドを新しいKubernetesサービスとして公開します。
  run           クラスタ上で特定のイメージを実行します。
  set           オブジェクトの特定の機能を設定します。</p>

<p>基本的なコマンド（中級）:
  explain       リソースのドキュメントを表示
  get           1つまたは複数のリソースを表示
  edit          サーバー上のリソースを編集
  delete        ファイル名、標準入力、リソースと名前、またはリソースとラベルセレクターによってリソースを削除</p>

<p>デプロイコマンド:
  rollout       リソースのロールアウトを管理します
  scale         Deployment、ReplicaSet、またはReplication Controllerの新しいサイズを設定します
  autoscale     Deployment、ReplicaSet、またはReplicationControllerを自動スケーリングします</p>

<p>クラスタ管理コマンド:
  certificate   証明書リソースを変更します。
  cluster-info  クラスタ情報を表示します。
  top           リソース（CPU/メモリ/ストレージ）の使用状況を表示します。
  cordon        ノードをスケジュール不可としてマークします。
  uncordon      ノードをスケジュール可能としてマークします。
  drain         メンテナンスの準備のためにノードをドレインします。
  taint         1つ以上のノードのテイントを更新します。</p>

<p>トラブルシューティングとデバッグコマンド:
  describe      特定のリソースまたはリソースグループの詳細を表示
  logs          ポッド内のコンテナのログを表示
  attach        実行中のコンテナにアタッチ
  exec          コンテナ内でコマンドを実行
  port-forward  1つ以上のローカルポートをポッドに転送
  proxy         Kubernetes APIサーバーへのプロキシを実行
  cp            コンテナとの間でファイルやディレクトリをコピー
  auth          認可を検査
  debug         ワークロードとノードのトラブルシューティングのためのデバッグセッションを作成</p>

<p>高度なコマンド:
  diff          ライブバージョンと適用される予定のバージョンとの差分を表示
  apply         ファイル名または標準入力からリソースに設定を適用
  patch         リソースのフィールドを更新
  replace       ファイル名または標準入力からリソースを置換
  wait          実験的: 1つまたは複数のリソースの特定の条件を待機
  kustomize     ディレクトリまたはリモートURLからkustomizationターゲットをビルド</p>

<p>設定コマンド:
  label         リソースのラベルを更新する
  annotate      リソースのアノテーションを更新する
  completion    指定されたシェル（bashまたはzsh）のシェル補完コードを出力する</p>

<p>その他のコマンド:
  api-resources サーバーでサポートされているAPIリソースを表示します
  api-versions  サーバーでサポートされているAPIバージョンを”group/version”の形式で表示します
  config        kubeconfigファイルを変更します
  plugin        プラグインとやり取りするためのユーティリティを提供します
  version       クライアントとサーバーのバージョン情報を表示します</p>

<p>使用方法:
  kubectl [フラグ] [オプション]</p>

<p>与えられたコマンドについての詳細情報は、「kubectl <command /> –help」を使用してください。
すべてのコマンドに適用されるグローバルなコマンドラインオプションのリストは、「kubectl options」を使用してください。</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
設定ファイルを作成しましょう。

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  minReadySeconds: 5
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
</code></pre></div></div>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>あなたはプロの翻訳者です。Jekyllブログ投稿のためのマークダウンファイルを翻訳しています。以下のテキストを日本語に翻訳してください。英語の名前は翻訳しないでください。コードブロックに注意し、わからない場合は変更しないでください。
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> simple_deployment.yaml
サーバー localhost:8080 への接続が拒否されました - 正しいホストまたはポートを指定しましたか？
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl cluster-info
</code></pre></div></div>

<p>クラスタの問題をさらにデバッグおよび診断するには、’kubectl cluster-info dump’ を使用してください。
サーバー localhost:8080 への接続が拒否されました - 正しいホストまたはポートを指定しましたか？</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
当社の公式ウェブサイトのターミナルで試しに実行してみてください。

```shell
$ start.sh
Kubernetesを起動中...minikubeバージョン: v1.8.1
コミット: cbda04cf6bbe65e987ae52bb393c10099ab62014
* Ubuntu 18.04上のminikube v1.8.1
* ユーザー設定に基づいてnoneドライバーを使用中
* localhostで実行中 (CPU=2, メモリ=2460MB, ディスク=145651MB) ...
* OSリリースはUbuntu 18.04.4 LTSです
</code></pre></div></div>

<ul>
  <li>Kubernetes v1.17.3をDocker 19.03.6上で準備中…
    <ul>
      <li>kubelet.resolv-conf=/run/systemd/resolve/resolv.conf</li>
    </ul>
  </li>
  <li>Kubernetesを起動中…</li>
  <li>アドオンの有効化: default-storageclass, storage-provisioner</li>
  <li>ローカルホスト環境の設定中…</li>
  <li>完了！kubectlが”minikube”を使用するように設定されました</li>
  <li>‘dashboard’アドオンが有効化されています
Kubernetesが起動しました
```</li>
</ul>

<p>それでは、ターミナルに戻りましょう。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
<span class="nv">$ </span>kubectl version
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
サーバー localhost:8080 への接続が拒否されました - 正しいホストまたはポートを指定しましたか？
</code></pre></div></div>

<p>興味深いことに、<code class="language-plaintext highlighter-rouge">--client</code> オプションを付けてもエラーは発生しませんでした。</p>

<p>ドキュメントによると、まず<code class="language-plaintext highlighter-rouge">Minikube</code>をインストールする必要があるとのことです。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>minikube
<span class="o">==&gt;</span> Downloading https://homebrew.bintray.com/bottles/minikube-1.16.0.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Downloading from https://d29vzk4ow07wi7.cloudfront.net/1b6d7d1b97b11b6b07e4fa531c2dc21770da290da9b2816f360fd923e00c85fc?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Pouring minikube-1.16.0.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Caveats
Bashの補完機能が以下の場所にインストールされました:
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Summary
🍺  /usr/local/Cellar/minikube/1.16.0: 8ファイル, 64.6MB
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube start
😄  minikube v1.16.0 on Darwin 11.2.2
🎉  minikube 1.18.1 が利用可能です！ダウンロードはこちら: https://github.com/kubernetes/minikube/releases/tag/v1.18.1
💡  この通知を無効にするには、次のコマンドを実行してください: <span class="s1">'minikube config set WantUpdateNotification false'</span>
</code></pre></div></div>

<p>✨  virtualboxドライバーを自動選択しました
💿  VMブートイメージをダウンロード中…
    &gt; minikube-v1.16.0.iso.sha256: 65 B / 65 B [————-] 100.00% ? p/s 0s
    &gt; minikube-v1.16.0.iso: 212.62 MiB / 212.62 MiB [] 100.00% 5.32 MiB p/s 40s
👍  minikubeクラスター内でコントロールプレーンノードminikubeを起動中
💾  Kubernetes v1.20.0のプリロードをダウンロード中…
    &gt; preloaded-images-k8s-v8-v1….: 491.00 MiB / 491.00 MiB  100.00% 7.52 MiB
🔥  virtualbox VMを作成中 (CPU=2, メモリ=4000MB, ディスク=20000MB) …
❗  このVMはhttps://k8s.gcr.ioへのアクセスに問題を抱えています
💡  新しい外部イメージをプルするには、プロキシの設定が必要かもしれません: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
🐳  Docker 20.10.0上でKubernetes v1.20.0を準備中…
    ▪ 証明書と鍵を生成中…
    ▪ コントロールプレーンを起動中…
    ▪ RBACルールを設定中…
🔎  Kubernetesコンポーネントを検証中…
🌟  有効化されたアドオン: storage-provisioner, default-storageclass
🏄  完了！kubectlはデフォルトで”minikube”クラスターと”default”ネームスペースを使用するように設定されました</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
次に、このクラスタにアクセスします。

```shell
$ kubectl get po -A
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
kube-system   coredns-74ff55c5b-ndbcr            1/1     Running   0          60s
kube-system   etcd-minikube                      0/1     Running   0          74s
kube-system   kube-apiserver-minikube            1/1     Running   0          74s
kube-system   kube-controller-manager-minikube   1/1     Running   0          74s
kube-system   kube-proxy-g2296                   1/1     Running   0          60s
kube-system   kube-scheduler-minikube            0/1     Running   0          74s
kube-system   storage-provisioner                1/1     Running   1          74s
</code></pre></div></div>

<p>このコマンドは、すべてのネームスペース（<code class="language-plaintext highlighter-rouge">-A</code>オプション）に存在するKubernetesのPod（<code class="language-plaintext highlighter-rouge">po</code>）の状態を取得します。各Podの名前、準備状態（READY）、ステータス（STATUS）、再起動回数（RESTARTS）、および作成からの経過時間（AGE）が表示されます。例えば、<code class="language-plaintext highlighter-rouge">coredns-74ff55c5b-ndbcr</code>というPodは1/1の準備状態で、Runningステータスであり、再起動は0回で、60秒前に作成されました。</p>

<p><code class="language-plaintext highlighter-rouge">minikube</code>のダッシュボードを開きます。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube dashboard
🔌  ダッシュボードを有効化しています...
🤔  ダッシュボードの健全性を確認しています...
🚀  プロキシを起動しています...
🤔  プロキシの健全性を確認しています...
🎉  デフォルトのブラウザで http://127.0.0.1:50030/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ を開いています...
</code></pre></div></div>

<p><img src="assets/images/distributed/k8s.png" alt="k8s" /></p>

<p>どうやってオフにするのでしょうか。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube
minikubeは、開発ワークフローに最適化されたローカルのKubernetesクラスターをプロビジョニングおよび管理します。
</code></pre></div></div>

<p>基本的なコマンド:
  start          ローカルのKubernetesクラスタを起動します
  status         ローカルのKubernetesクラスタのステータスを取得します
  stop           実行中のローカルKubernetesクラスタを停止します
  delete         ローカルのKubernetesクラスタを削除します
  dashboard      minikubeクラスタ内で実行されているKubernetesダッシュボードにアクセスします
  pause          Kubernetesを一時停止します
  unpause        Kubernetesの一時停止を解除します</p>

<p>イメージ関連のコマンド:
  docker-env     minikubeのDockerデーモンを使用するように環境を設定
  podman-env     minikubeのPodmanサービスを使用するように環境を設定
  cache          ローカルイメージをminikubeに追加、削除、またはプッシュ</p>

<p>設定と管理コマンド:
  addons         minikubeのアドオンを有効または無効にする
  config         永続的な設定値を変更する
  profile        現在のプロファイル（クラスタ）を取得または一覧表示する
  update-context IPやポートが変更された場合にkubeconfigを更新する</p>

<p>ネットワーキングと接続コマンド:
  service        サービスに接続するためのURLを返します
  tunnel         ロードバランサーサービスに接続します</p>

<p>高度なコマンド:
  mount          指定されたディレクトリをminikubeにマウントします
  ssh            minikube環境にログインします（デバッグ用）
  kubectl        クラスターバージョンに一致するkubectlバイナリを実行します
  node           追加ノードの追加、削除、またはリスト表示を行います</p>

<p>トラブルシューティングコマンド:
  ssh-key        指定されたノードのSSH識別キーのパスを取得します
  ssh-host       指定されたノードのSSHホストキーを取得します
  ip             指定されたノードのIPアドレスを取得します
  logs           ローカルのKubernetesクラスタをデバッグするためのログを返します
  update-check   現在のバージョンと最新バージョン番号を表示します
  version        minikubeのバージョンを表示します</p>

<p>その他のコマンド:
  completion     シェル用のコマンド補完を生成します</p>

<p>与えられたコマンドについての詳細情報は、”minikube <command /> –help” を使用してください。</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
`minikube stop`であることがわかります。

`kubernetes`に戻ると、今は正常に動作しています。

```shell
$ kubectl cluster-info
Kubernetesコントロールプレーンは https://192.168.99.100:8443 で実行中です
KubeDNSは https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy で実行中です
</code></pre></div></div>

<p>クラスタの問題をさらにデバッグおよび診断するには、’kubectl cluster-info dump’ を使用してください。</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
`https://192.168.99.100:8443` を開くと、ブラウザには以下のように表示されます：

```json
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "Failure",
  "message": "禁止: ユーザー \"system:anonymous\" はパス \"/\" を取得できません",
  "reason": "Forbidden",
  "details": {
    
  },
  "code": 403
}
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</code> にアクセスします：</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Status"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"apiVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Failure"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">"サービス </span><span class="se">\"</span><span class="s2">kube-dns:dns</span><span class="se">\"</span><span class="s2"> は禁止されています: ユーザー </span><span class="se">\"</span><span class="s2">system:anonymous</span><span class="se">\"</span><span class="s2"> は、APIグループ </span><span class="se">\"\"</span><span class="s2"> の名前空間 </span><span class="se">\"</span><span class="s2">kube-system</span><span class="se">\"</span><span class="s2"> 内のリソース </span><span class="se">\"</span><span class="s2">services/proxy</span><span class="se">\"</span><span class="s2"> を取得できません"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"reason"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Forbidden"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"details"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-dns:dns"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"services"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"code"</span><span class="p">:</span><span class="w"> </span><span class="mi">403</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>さっきの設定を試してみましょう。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> simple_deployment.yaml
deployment.apps/nginx-deployment が作成されました
</code></pre></div></div>

<p>少し問題があります。しかし、ここまでで<code class="language-plaintext highlighter-rouge">kubernetes</code>を起動することができました。まずはここで終了します。後でまた遊びましょう。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube stop
✋  <span class="s2">"minikube"</span> ノードを停止中...
🛑  1つのノードが停止しました。
</code></pre></div></div>

<p>終了を確認します。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>w<span class="nv">$ </span>minikube dashboard
🤷  このコマンドを実行するには、コントロールプレーンノードが実行されている必要があります
👉  クラスターを開始するには、次のコマンドを実行してください: <span class="s2">"minikube start"</span>
</code></pre></div></div>

<h2 id="docker">Docker</h2>

<p><code class="language-plaintext highlighter-rouge">Docker</code>もまた、現代のアプリケーションの作成、共有、実行を加速するためのコンテナプラットフォームです。公式サイトからアプリケーションをダウンロードできます。</p>

<p><img src="assets/images/distributed/docker.png" alt="docker" /></p>

<p>クライアントが少し重いです。コマンドラインを使ってみましょう。</p>

<div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker
</code></pre></div></div>

<p>使用方法:  docker [オプション] コマンド</p>

<p>コンテナのための自立型ランタイム</p>

<p>オプション:
      –config string      クライアント設定ファイルの場所 (デフォルト “/Users/lzw/.docker”)
  -c, –context string     デーモンに接続するためのコンテキスト名を指定 (DOCKER_HOST環境変数と”docker context use”で設定されたデフォルトコンテキストを上書き)
  -D, –debug              デバッグモードを有効にする
  -H, –host list          接続するデーモンのソケット
  -l, –log-level string   ログレベルを設定 (“debug”|”info”|”warn”|”error”|”fatal”) (デフォルト “info”)
      –tls                TLSを使用; –tlsverifyによって暗黙的に指定される
      –tlscacert string   このCAによってのみ署名された証明書を信頼 (デフォルト “/Users/lzw/.docker/ca.pem”)
      –tlscert string     TLS証明書ファイルへのパス (デフォルト “/Users/lzw/.docker/cert.pem”)
      –tlskey string      TLSキーファイルへのパス (デフォルト “/Users/lzw/.docker/key.pem”)
      –tlsverify          TLSを使用し、リモートを検証する
  -v, –version            バージョン情報を表示して終了</p>

<p>管理コマンド:
  app*        Docker App (Docker Inc., v0.9.1-beta3)
  builder     ビルドを管理
  buildx*     BuildKitを使用してビルド (Docker Inc., v0.5.1-docker)
  config      Docker設定を管理
  container   コンテナを管理
  context     コンテキストを管理
  image       イメージを管理
  manifest    Dockerイメージマニフェストとマニフェストリストを管理
  network     ネットワークを管理
  node        Swarmノードを管理
  plugin      プラグインを管理
  scan*       Docker Scan (Docker Inc., v0.5.0)
  secret      Dockerシークレットを管理
  service     サービスを管理
  stack       Dockerスタックを管理
  swarm       Swarmを管理
  system      Dockerを管理
  trust       Dockerイメージの信頼を管理
  volume      ボリュームを管理</p>

<p>コマンド:
  attach      実行中のコンテナにローカルの標準入力、出力、エラーストリームを接続します
  build       Dockerfileからイメージをビルドします
  commit      コンテナの変更から新しいイメージを作成します
  cp          コンテナとローカルファイルシステム間でファイル/フォルダをコピーします
  create      新しいコンテナを作成します
  diff        コンテナのファイルシステム上のファイルやディレクトリの変更を検査します
  events      サーバーからのリアルタイムイベントを取得します
  exec        実行中のコンテナ内でコマンドを実行します
  export      コンテナのファイルシステムをtarアーカイブとしてエクスポートします
  history     イメージの履歴を表示します
  images      イメージを一覧表示します
  import      tarballの内容をインポートしてファイルシステムイメージを作成します
  info        システム全体の情報を表示します
  inspect     Dockerオブジェクトの低レベル情報を返します
  kill        1つ以上の実行中のコンテナを強制終了します
  load        tarアーカイブまたはSTDINからイメージをロードします
  login       Dockerレジストリにログインします
  logout      Dockerレジストリからログアウトします
  logs        コンテナのログを取得します
  pause       1つ以上のコンテナ内のすべてのプロセスを一時停止します
  port        コンテナのポートマッピングまたは特定のマッピングを一覧表示します
  ps          コンテナを一覧表示します
  pull        レジストリからイメージまたはリポジトリをプルします
  push        イメージまたはリポジトリをレジストリにプッシュします
  rename      コンテナの名前を変更します
  restart     1つ以上のコンテナを再起動します
  rm          1つ以上のコンテナを削除します
  rmi         1つ以上のイメージを削除します
  run         新しいコンテナ内でコマンドを実行します
  save        1つ以上のイメージをtarアーカイブに保存します（デフォルトではSTDOUTにストリームされます）
  search      Docker Hubでイメージを検索します
  start       1つ以上の停止中のコンテナを起動します
  stats       コンテナのリソース使用統計のライブストリームを表示します
  stop        1つ以上の実行中のコンテナを停止します
  tag         SOURCE_IMAGEを参照するTARGET_IMAGEタグを作成します
  top         コンテナの実行中のプロセスを表示します
  unpause     1つ以上のコンテナ内のすべてのプロセスを再開します
  update      1つ以上のコンテナの設定を更新します
  version     Dockerのバージョン情報を表示します
  wait        1つ以上のコンテナが停止するまでブロックし、その終了コードを出力します</p>

<p>コマンドの詳細情報については、’docker COMMAND –help’ を実行してください。</p>

<p>Dockerの詳細なヘルプが必要な場合は、https://docs.docker.com/go/guides/ のガイドをご覧ください。</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
チュートリアルに従って試してみましょう。

```shell
$ docker run -d -p 80:80 docker/getting-started
Unable to find image 'docker/getting-started:latest' locally
latest: Pulling from docker/getting-started
aad63a933944: Pull complete
b14da7a62044: Pull complete
343784d40d66: Pull complete
6f617e610986: Pull complete
Digest: sha256:d2c4fb0641519ea208f20ab03dc40ec2a5a53fdfbccca90bef14f870158ed577
Status: Downloaded newer image for docker/getting-started:latest
815f13fc8f99f6185257980f74c349e182842ca572fe60ff62cbb15641199eaf
docker: Error response from daemon: Ports are not available: listen tcp 0.0.0.0:80: bind: address already in use.
</code></pre></div></div>

<p>上記のエラーメッセージは、Dockerがポート80を使用しようとした際に、そのポートが既に他のプロセスによって使用されているため、バインドできないというエラーです。この問題を解決するためには、以下のいずれかの方法を試すことができます：</p>

<ol>
  <li><strong>ポートの変更</strong>: Dockerコンテナが使用するポートを変更します。例えば、ポート8080を使用するように変更します。
    <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:80 docker/getting-started
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>既存のプロセスを停止</strong>: ポート80を使用している既存のプロセスを停止します。例えば、ApacheやNginxなどのウェブサーバーがポート80を使用している場合、それらを停止してから再度Dockerコンテナを起動します。</p>
  </li>
  <li><strong>ポートの解放</strong>: ポート80を使用しているプロセスを特定し、そのプロセスを終了します。以下のコマンドを使用して、ポート80を使用しているプロセスを特定できます。
    <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>lsof <span class="nt">-i</span> :80
</code></pre></div>    </div>
    <p>その後、特定されたプロセスID (PID) を使用してプロセスを終了します。</p>
    <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo kill</span> &lt;PID&gt;
</code></pre></div>    </div>
  </li>
</ol>

<p>これらの方法のいずれかを試して、ポート80が使用可能な状態にすることで、Dockerコンテナを正常に起動できるようになります。</p>

<p>ポートを変更します。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:80 docker/getting-started
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p><img src="assets/images/distributed/docker_run.png" alt="docker_run" /></p>

<p>ブラウザを開いて、<code class="language-plaintext highlighter-rouge">docker</code>が正常に動作していることを確認します。</p>

<p><img src="assets/images/distributed/browser.png" alt="ブラウザ" /></p>

<p>コンテナを停止します。先ほど返された<code class="language-plaintext highlighter-rouge">ID</code>を使用してください。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker stop 45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p>このコマンドは、指定されたコンテナIDのDockerコンテナを停止するものです。コンテナIDは、<code class="language-plaintext highlighter-rouge">45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5</code> という長い文字列で、一意にコンテナを識別します。コマンドを実行すると、指定されたコンテナが停止され、そのコンテナIDが再度表示されます。</p>

<p>この時点で、ウェブサイトはすでに開けなくなっていました。</p>

<p>これは<code class="language-plaintext highlighter-rouge">docker</code>が仮想マシンのようなものであることを示しています。</p>

<h2 id="flink">Flink</h2>

<p>公式サイトを開く。</p>

<p><img src="assets/images/distributed/flink-home-graphic.png" alt="flink-home-graphic" /></p>

<p><code class="language-plaintext highlighter-rouge">Flink</code>はデータストリームの<code class="language-plaintext highlighter-rouge">Stateful</code>計算について語っています。<code class="language-plaintext highlighter-rouge">Stateful</code>とは何を指すのでしょうか？まだ理解できていません。上の図はとても興味深いです。試してみましょう。</p>

<p>Java環境が必要だと言われました。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>java <span class="nt">-version</span>
java version <span class="s2">"1.8.0_151"</span>
Java<span class="o">(</span>TM<span class="o">)</span> SE Runtime Environment <span class="o">(</span>build 1.8.0_151-b12<span class="o">)</span>
Java HotSpot<span class="o">(</span>TM<span class="o">)</span> 64-Bit Server VM <span class="o">(</span>build 25.151-b12, mixed mode<span class="o">)</span>
</code></pre></div></div>

<p>公式サイトから最新バージョンの <code class="language-plaintext highlighter-rouge">flink-1.12.2-bin-scala_2.11.tar</code> をダウンロードします。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/start-cluster.sh
クラスターを起動中です。
ホスト lzwjava で standalonesession デーモンを起動中です。
ホスト lzwjava で taskexecutor デーモンを起動中です。
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/flink run examples/streaming/WordCount.jar
WordCountの例をデフォルトの入力データセットで実行中。
ファイル入力を指定するには--inputを使用してください。
結果を標準出力に表示します。出力先を指定するには--outputを使用してください。
JobID 60f37647c20c2a6654359bd34edab807でジョブが送信されました。
プログラムの実行が完了しました
JobID 60f37647c20c2a6654359bd34edab807のジョブが完了しました。
ジョブの実行時間: 757 ms
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">tail </span>log/flink-<span class="k">*</span><span class="nt">-taskexecutor-</span><span class="k">*</span>.out
<span class="o">(</span>nymph,1<span class="o">)</span>
<span class="o">(</span><span class="k">in</span>,3<span class="o">)</span>
<span class="o">(</span>thy,1<span class="o">)</span>
<span class="o">(</span>orisons,1<span class="o">)</span>
<span class="o">(</span>be,4<span class="o">)</span>
<span class="o">(</span>all,2<span class="o">)</span>
<span class="o">(</span>my,1<span class="o">)</span>
<span class="o">(</span>sins,1<span class="o">)</span>
<span class="o">(</span>remember,1<span class="o">)</span>
<span class="o">(</span>d,4<span class="o">)</span>
</code></pre></div></div>

<p>このコードブロックは、Flinkタスクエグゼキュータのログファイルから最後の10行を表示しています。ログには、単語とその出現回数が表示されています。例えば、<code class="language-plaintext highlighter-rouge">(nymph,1)</code>は「nymph」という単語が1回出現したことを示しています。この出力は、テキスト処理や単語の頻度分析の結果を示している可能性があります。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/stop-cluster.sh
タスクエグゼキュータデーモン（pid: 41812）をホスト lzwjava で停止しています。
</code></pre></div></div>

<p>はい、起動に成功しました。見ての通り、これは<code class="language-plaintext highlighter-rouge">Spark</code>とよく似ています。</p>

<h2 id="kylin">Kylin</h2>

<p>公式サイトを開いてみましょう。</p>

<blockquote>
  <p>Apache Kylin™ は、ビッグデータ向けのオープンソースで分散型の分析データウェアハウスです。ビッグデータ時代においてOLAP（オンライン分析処理）機能を提供するために設計されました。HadoopとSpark上での多次元キューブと事前計算技術を革新することで、Kylinはデータ量が増え続けてもほぼ一定のクエリ速度を実現します。クエリの遅延を数分から1秒未満に削減し、Kylinはオンライン分析をビッグデータに戻します。</p>
</blockquote>

<blockquote>
  <p>Apache Kylin™ は、3つのステップで数十億行のデータをサブ秒レベルの遅延でクエリできるようにします。</p>

  <ol>
    <li>Hadoop上のスター/スノーフレークスキーマを特定します。</li>
    <li>特定したテーブルからCubeを構築します。</li>
    <li>ANSI-SQLを使用してクエリを実行し、ODBC、JDBC、またはRESTful APIを介してサブ秒で結果を取得します。</li>
  </ol>
</blockquote>

<p><img src="assets/images/distributed/kylin_diagram.png" alt="kylin_diagram" /></p>

<p>おおよそ、ビッグデータを分析するための層です。それを使えば非常に速く検索できます。橋渡しの役割を果たします。</p>

<p>残念ながら、現在は<code class="language-plaintext highlighter-rouge">Linux</code>環境でのみ使用可能です。後でまた試してみます。</p>

<h2 id="mongodb">MongoDB</h2>

<p>これもデータベースの一種です。インストールを試してみてください。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew tap mongodb/brew
<span class="o">==&gt;</span> mongodb/brewをタップ中
<span class="s1">'/usr/local/Homebrew/Library/Taps/mongodb/homebrew-brew'</span>にクローンしています...
remote: オブジェクトを数えています: 63, 完了.
remote: オブジェクトを数えています: 100% <span class="o">(</span>63/63<span class="o">)</span>, 完了.
remote: オブジェクトを圧縮しています: 100% <span class="o">(</span>62/62<span class="o">)</span>, 完了.
remote: 合計 566 <span class="o">(</span>差分 21<span class="o">)</span>, 再利用 6 <span class="o">(</span>差分 1<span class="o">)</span>, パック再利用 503
オブジェクトを受信中: 100% <span class="o">(</span>566/566<span class="o">)</span>, 121.78 KiB | 335.00 KiB/s, 完了.
差分を解決中: 100% <span class="o">(</span>259/259<span class="o">)</span>, 完了.
11のフォーミュラをタップしました <span class="o">(</span>39ファイル, 196.2KB<span class="o">)</span><span class="nb">.</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>mongodb-community@4.4
<span class="o">==&gt;</span> mongodb/brewからmongodb-communityをインストール中
<span class="o">==&gt;</span> https://fastdl.mongodb.org/tools/db/mongodb-database-tools-macos-x86_64-100.3.0.zipをダウンロード中
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> https://fastdl.mongodb.org/osx/mongodb-macos-x86_64-4.4.3.tgzをダウンロード中
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> mongodb/brew/mongodb-communityの依存関係をインストール中: mongodb-database-tools
<span class="o">==&gt;</span> mongodb/brew/mongodb-communityの依存関係: mongodb-database-toolsをインストール中
エラー: <span class="sb">`</span>brew <span class="nb">link</span><span class="sb">`</span>ステップが正常に完了しませんでした
フォーミュラはビルドされましたが、/usr/localにシンボリックリンクされていません
bin/bsondumpのシンボリックリンクを作成できませんでした
ターゲット /usr/local/bin/bsondump
はmongodbに属するシンボリックリンクです。以下のコマンドでリンクを解除できます:
  brew <span class="nb">unlink </span>mongodb
</code></pre></div></div>

<p>リンクを強制し、すべての競合するファイルを上書きするには：
  brew link –overwrite mongodb-database-tools</p>

<p>削除されるすべてのファイルをリストアップするには:
  brew link –overwrite –dry-run mongodb-database-tools</p>

<p>競合する可能性のあるファイルは以下の通りです：
/usr/local/bin/bsondump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/bsondump
/usr/local/bin/mongodump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongodump
/usr/local/bin/mongoexport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoexport
/usr/local/bin/mongofiles -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongofiles
/usr/local/bin/mongoimport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoimport
/usr/local/bin/mongorestore -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongorestore
/usr/local/bin/mongostat -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongostat
/usr/local/bin/mongotop -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongotop
==&gt; 概要
🍺  /usr/local/Cellar/mongodb-database-tools/100.3.0: 13ファイル, 154MB, 11秒でビルド
==&gt; mongodb/brew/mongodb-communityのインストール
エラー: <code class="language-plaintext highlighter-rouge">brew link</code>ステップが正常に完了しませんでした
フォーミュラはビルドされましたが、/usr/localにシンボリックリンクされていません
bin/mongoのシンボリックリンクを作成できませんでした
ターゲット /usr/local/bin/mongo
はmongodbに属するシンボリックリンクです。以下のコマンドでリンクを解除できます：
  brew unlink mongodb</p>

<p>リンクを強制し、すべての競合するファイルを上書きするには：
  brew link –overwrite mongodb-community</p>

<p>削除されるすべてのファイルをリストアップするには:
  brew link –overwrite –dry-run mongodb-community</p>

<p>競合する可能性のあるファイルは以下の通りです:
/usr/local/bin/mongo -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongo
/usr/local/bin/mongod -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongod
/usr/local/bin/mongos -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongos
==&gt; 注意事項
launchd が mongodb/brew/mongodb-community をすぐに起動し、ログイン時に再起動するようにするには:
  brew services start mongodb/brew/mongodb-community
または、バックグラウンドサービスを必要としない場合は、次のコマンドを実行してください:
  mongod –config /usr/local/etc/mongod.conf
==&gt; 概要
🍺  /usr/local/Cellar/mongodb-community/4.4.3: 11 ファイル, 156.8MB, 10 秒でビルド
==&gt; 注意事項
==&gt; mongodb-community
launchd が mongodb/brew/mongodb-community をすぐに起動し、ログイン時に再起動するようにするには:
  brew services start mongodb/brew/mongodb-community
または、バックグラウンドサービスを必要としない場合は、次のコマンドを実行してください:
  mongod –config /usr/local/etc/mongod.conf</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
以前に古いバージョンをインストールしていました。リンクを解除します。

```shell
$ brew unlink mongodb
/usr/local/Cellar/mongodb/3.0.7 のリンクを解除しています... 11 のシンボリックリンクが削除されました
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--version</span>
db version v4.4.3
Build Info: <span class="o">{</span>
    <span class="s2">"version"</span>: <span class="s2">"4.4.3"</span>,
    <span class="s2">"gitVersion"</span>: <span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span>,
    <span class="s2">"modules"</span>: <span class="o">[]</span>,
    <span class="s2">"allocator"</span>: <span class="s2">"system"</span>,
    <span class="s2">"environment"</span>: <span class="o">{</span>
        <span class="s2">"distarch"</span>: <span class="s2">"x86_64"</span>,
        <span class="s2">"target_arch"</span>: <span class="s2">"x86_64"</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>次に、<code class="language-plaintext highlighter-rouge">mongod</code>を実行してMongoDBデータベースサーバーを起動します。しかし、初回起動時に<code class="language-plaintext highlighter-rouge">/data/db</code>が存在しないというエラーが発生しました。そこで、データベースファイルを保存するためのディレクトリ<code class="language-plaintext highlighter-rouge">~/mongodb</code>を作成します。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--dbpath</span> ~/mongodb
</code></pre></div></div>

<p>このコマンドは、MongoDBのデータベースサーバー（<code class="language-plaintext highlighter-rouge">mongod</code>）を起動し、データベースファイルの保存先として指定されたディレクトリ（<code class="language-plaintext highlighter-rouge">~/mongodb</code>）を使用するように指示します。<code class="language-plaintext highlighter-rouge">--dbpath</code>オプションは、MongoDBがデータを保存するディレクトリを指定するために使用されます。この場合、ホームディレクトリ内の<code class="language-plaintext highlighter-rouge">mongodb</code>フォルダが指定されています。</p>

<p>出力：</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.838+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23285</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"TLS 1.0を自動的に無効化しました。TLS 1.0を強制的に有効にするには、--sslDisabledProtocols 'none'を指定してください"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"W"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"ASIO"</span><span class="p">,</span><span class="w">     </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">22601</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"NetworkInterfaceの起動時にTransportLayerが設定されていません"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"NETWORK"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4648602</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"暗黙的にTCP FastOpenが使用されています。"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"STORAGE"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4615611</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"MongoDBが起動中です"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"pid"</span><span class="p">:</span><span class="mi">46256</span><span class="p">,</span><span class="nl">"port"</span><span class="p">:</span><span class="mi">27017</span><span class="p">,</span><span class="nl">"dbPath"</span><span class="p">:</span><span class="s2">"/Users/lzw/mongodb"</span><span class="p">,</span><span class="nl">"architecture"</span><span class="p">:</span><span class="s2">"64-bit"</span><span class="p">,</span><span class="nl">"host"</span><span class="p">:</span><span class="s2">"lzwjava"</span><span class="p">}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23403</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"ビルド情報"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"buildInfo"</span><span class="p">:{</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"4.4.3"</span><span class="p">,</span><span class="nl">"gitVersion"</span><span class="p">:</span><span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span><span class="p">,</span><span class="nl">"modules"</span><span class="p">:[],</span><span class="nl">"allocator"</span><span class="p">:</span><span class="s2">"system"</span><span class="p">,</span><span class="nl">"environment"</span><span class="p">:{</span><span class="nl">"distarch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">,</span><span class="nl">"target_arch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">}}}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.843+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">51765</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"オペレーティングシステム"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"os"</span><span class="p">:{</span><span class="nl">"name"</span><span class="p">:</span><span class="s2">"Mac OS X"</span><span class="p">,</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"20.3.0"</span><span class="p">}}}</span><span class="w">
</span><span class="err">...</span><span class="w">
</span></code></pre></div></div>

<p>見ての通り、すべて<code class="language-plaintext highlighter-rouge">JSON</code>形式です。MongoDBはすべてのデータファイルを<code class="language-plaintext highlighter-rouge">JSON</code>形式で保存します。次に、別のターミナルタブを開いてください。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongo
MongoDB shell version v4.4.3
接続中: mongodb://127.0.0.1:27017/?compressors<span class="o">=</span>disabled&amp;gssapiServiceName<span class="o">=</span>mongodb
暗黙のセッション: session <span class="o">{</span> <span class="s2">"id"</span> : UUID<span class="o">(</span><span class="s2">"4f55c561-70d3-4289-938d-4b90a284891f"</span><span class="o">)</span> <span class="o">}</span>
MongoDB server version: 4.4.3
<span class="nt">---</span>
サーバー起動時に以下の警告が生成されました:
        2021-03-11T18:17:33.743+08:00: データベースに対してアクセス制御が有効になっていません。データと設定への読み書きアクセスが無制限です
        2021-03-11T18:17:33.743+08:00: このサーバーはlocalhostにバインドされています。リモートシステムはこのサーバーに接続できません。サーバーを--bind_ip &lt;アドレス&gt;で起動して、応答を提供するIPアドレスを指定するか、--bind_ip_allですべてのインターフェースにバインドしてください。この動作が望ましい場合、--bind_ip 127.0.0.1でサーバーを起動してこの警告を無効にしてください
        2021-03-11T18:17:33.743+08:00: ソフトリミットが低すぎます
        2021-03-11T18:17:33.743+08:00:         現在の値: 4864
        2021-03-11T18:17:33.743+08:00:         推奨最小値: 64000
<span class="nt">---</span>
<span class="nt">---</span>
        MongoDBの無料クラウドベースの監視サービスを有効にすると、デプロイメントに関するメトリクス（ディスク使用率、CPU、操作統計など）を受信して表示できます。
</code></pre></div></div>

<p>監視データは、あなたとあなたがURLを共有した誰もがアクセスできる、一意のURLを持つMongoDBのウェブサイトで利用可能になります。MongoDBはこの情報を使用して、製品の改善を行い、MongoDB製品および展開オプションを提案する場合があります。</p>

<p>無料モニタリングを有効にするには、次のコマンドを実行してください: <code class="language-plaintext highlighter-rouge">db.enableFreeMonitoring()</code>
このリマインダーを永続的に無効にするには、次のコマンドを実行してください: <code class="language-plaintext highlighter-rouge">db.disableFreeMonitoring()</code></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
次に、データの挿入やクエリを試すことができます。

```shell
&gt; db.inventory.insertOne(
...    { item: "canvas", qty: 100, tags: ["cotton"], size: { h: 28, w: 35.5, uom: "cm" } }
... )
{
	"acknowledged" : true,
	"insertedId" : ObjectId("6049ef91b653541cf355facb")
}
&gt;
&gt; db.inventory.find()
{ "_id" : ObjectId("6049ef91b653541cf355facb"), "item" : "canvas", "qty" : 100, "tags" : [ "cotton" ], "size" : { "h" : 28, "w" : 35.5, "uom" : "cm" } }
</code></pre></div></div>

<p>このコードは、MongoDBのシェルで実行される操作を示しています。まず、<code class="language-plaintext highlighter-rouge">db.inventory.insertOne()</code>メソッドを使用して、<code class="language-plaintext highlighter-rouge">inventory</code>コレクションに新しいドキュメントを挿入しています。このドキュメントには、<code class="language-plaintext highlighter-rouge">item</code>、<code class="language-plaintext highlighter-rouge">qty</code>、<code class="language-plaintext highlighter-rouge">tags</code>、<code class="language-plaintext highlighter-rouge">size</code>などのフィールドが含まれています。挿入が成功すると、<code class="language-plaintext highlighter-rouge">acknowledged</code>が<code class="language-plaintext highlighter-rouge">true</code>となり、新しく挿入されたドキュメントの<code class="language-plaintext highlighter-rouge">_id</code>が返されます。</p>

<p>次に、<code class="language-plaintext highlighter-rouge">db.inventory.find()</code>メソッドを使用して、<code class="language-plaintext highlighter-rouge">inventory</code>コレクション内のすべてのドキュメントを検索しています。この場合、先ほど挿入したドキュメントが表示されます。</p>

<h2 id="最後に">最後に</h2>

<p>ここまでです。後で他のツールを試してみましょう。私たちがこれらを行う意味は何でしょうか。おそらく、最初に全体像を把握することです。何事も始めるのが難しいですが、私たちは最初からこれらすべてを試してみました。これにより、私たちは自信を持ち、次に進むことができます。次は、これらのソフトウェアをもっと試してみることです。</p>

<h2 id="練習">練習</h2>

<ul>
  <li>学生は上記のように探索を進めます。</li>
</ul>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-ja" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
