<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Coûts des LLM, agents et outils de codage</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Coûts des LLM, agents et outils de codage | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Coûts des LLM, agents et outils de codage" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="fr" />
<meta name="description" content="Table des matières" />
<meta property="og:description" content="Table des matières" />
<link rel="canonical" href="https://lzwjava.github.io/llm-fr" />
<meta property="og:url" content="https://lzwjava.github.io/llm-fr" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-18T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Coûts des LLM, agents et outils de codage" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2025-08-18T00:00:00+08:00","datePublished":"2025-08-18T00:00:00+08:00","description":"Table des matières","headline":"Coûts des LLM, agents et outils de codage","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/llm-fr"},"url":"https://lzwjava.github.io/llm-fr"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=043ee051a893292300d7e0de7f013d5246c3fef4">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=043ee051a893292300d7e0de7f013d5246c3fef4" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Coûts des LLM, agents et outils de codage | Original, traduit par l'IA
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/fr/2025-08-18-llm-fr.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postsfr2025-08-18-llm-fr.md</span> -->
      

      <!-- <span>2025-08-18-llm-fr.md</span> -->

      
        

        
          
          <a href="#" class="button">2025.08</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/llm-en" >English</option>
        <option value="/llm-zh" >中文</option>
        <option value="/llm-ja" >日本語</option>
        <option value="/llm-es" >Español</option>
        <option value="/llm-hi" >हिंदी</option>
        <option value="/llm-fr" selected>Français</option>
        <option value="/llm-de" >Deutsch</option>
        <option value="/llm-ar" >العربية</option>
        <option value="/llm-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <h3 id="table-des-matières">Table des matières</h3>

<ol>
  <li><strong><a href="#optimisation-des-coûts-des-api-llm">Optimisation des coûts des API LLM</a></strong>
    <ul>
      <li>Commencer par les modèles les plus économiques</li>
      <li>Éviter l’utilisation inutile de modèles haut de gamme</li>
      <li>Privilégier les bibliothèques NLP pour les tâches simples</li>
      <li>Créer des agents spécialisés pour plus d’efficacité</li>
      <li>Comparer les modèles via des tests approfondis</li>
    </ul>
  </li>
  <li><strong><a href="#utilisation-des-api-de-deepseek-et-mistral">Utilisation des API de Deepseek et Mistral</a></strong>
    <ul>
      <li>Les coûts de DeepSeek augmentent avec les échecs de cache</li>
      <li>Les tokens de sortie dominent les dépenses de Mistral</li>
      <li>La tarification de Grok favorise largement les tokens d’entrée</li>
      <li>L’utilisation des tokens varie selon la complexité de la tâche</li>
      <li>La tarification correspond aux taux documentés</li>
    </ul>
  </li>
  <li><strong><a href="#agents-généraux-vs-agents-spécialisés">Agents généraux vs agents spécialisés</a></strong>
    <ul>
      <li>Les agents généraux peinent avec la complexité</li>
      <li>Les agents spécialisés excellent dans leur domaine</li>
      <li>Les outils de workflow limitent la flexibilité</li>
      <li>Les agents Python personnalisés offrent plus de contrôle</li>
      <li>Compromis entre commodité et puissance</li>
    </ul>
  </li>
  <li><strong><a href="#le-point-de-vue-dun-ingénieur-exigeant-sur-les-outils-de-codage-ia">Le point de vue d’un ingénieur exigeant sur les outils de codage IA</a></strong>
    <ul>
      <li>Privilégier l’utilité pratique plutôt que le battage médiatique</li>
      <li>VSCode + Copilot reste fiable</li>
      <li>Claude Code impressionne avec ses modifications de type diff</li>
      <li>Les outils de grammaire nécessitent une vérification manuelle</li>
      <li>L’expérimentation prime sur l’adoption aveugle</li>
    </ul>
  </li>
</ol>

<h2 id="optimisation-des-coûts-des-api-llm">Optimisation des coûts des API LLM</h2>

<p><em>2025.08</em></p>

<p class="centered"><img src="assets/images/tokens/tokens1.png" alt="" class="responsive" />
<em class="caption">Source : openrouter.ai</em></p>

<p class="centered"><img src="assets/images/tokens/tokens2.png" alt="" class="responsive" />
<em class="caption">Source : openrouter.ai</em></p>

<p>Lors de l’optimisation de l’utilisation des tokens, il est conseillé de commencer par des modèles plus économiques. Si des problèmes surviennent, envisagez de passer à des modèles plus avancés. Mistral, Gemini Flash et DeepSeek sont généralement économiques, tandis que Claude Sonnet est généralement plus cher. Il est crucial de comprendre comment Claude Code utilise les routeurs présentés ci-dessous.</p>

<p>Dans ma récente expérience, j’ai engendré des coûts importants en négligeant ce principe. J’essayais d’atteindre mon utilisation maximale pour déterminer le coût, ce qui n’est pas une approche rationnelle ; c’est un simple calcul. Par exemple, ai-je vraiment besoin de Sonnet 4 ? Pas nécessairement. Bien que je le perçoive comme un modèle plus avancé d’Anthropic et qu’il soit bien classé sur OpenRouter, je ne comprends pas bien les différences entre Sonnet 4 et Sonnet 3.5.</p>

<p>J’ai appris quelque chose de précieux lors d’une récente <a href="https://www.vanta.com/resources/replit-future-of-code">interview</a> avec le fondateur de Replit, Amjad Masad. Pour de nombreuses tâches, des modèles très avancés ne sont pas nécessaires. Idéalement, si nous pouvons éviter d’utiliser l’API LLM, c’est parfait. Certaines bibliothèques NLP sont efficaces pour les tâches simples ; par exemple, <a href="https://github.com/hankcs/HanLP">HanLP</a> excelle dans le traitement des tâches en chinois.</p>

<p>De plus, nous pouvons développer des agents personnalisés ou spécialisés pour gérer les tâches efficacement dès le départ. Claude Code n’est peut-être pas toujours la meilleure ou la solution la plus économique pour chaque tâche.</p>

<p>Une façon de discerner les différences entre les modèles est de les utiliser abondamment et de comparer leurs performances. Après avoir utilisé Gemini 2.5 Flash pendant un certain temps, je le trouve moins performant que Sonnet 4.</p>

<p>Après quelques jours, j’utilise la configuration ci-dessous pour m’aider. Le paramètre longContextThreshold est très important. Vous pouvez périodiquement vider la console de Claude Code ou la redémarrer. Il est très facile d’atteindre le seuil de contexte long lors de l’utilisation de Claude Code pour écrire du code.</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"PROXY_URL"</span><span class="p">:</span><span class="w"> </span><span class="s2">"http://127.0.0.1:7890"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"LOG"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w">
  </span><span class="nl">"Providers"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"openrouter"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"api_base_url"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://openrouter.ai/api/v1/chat/completions"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"api_key"</span><span class="p">:</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w">
      </span><span class="nl">"models"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="s2">"moonshotai/kimi-k2"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"anthropic/claude-sonnet-4"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"anthropic/claude-3.5-sonnet"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"anthropic/claude-3.7-sonnet:thinking"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"anthropic/claude-opus-4"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"google/gemini-2.5-flash"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"google/gemini-2.5-pro"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"deepseek/deepseek-chat-v3-0324"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"deepseek/deepseek-chat-v3.1"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"deepseek/deepseek-r1"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"mistralai/mistral-medium-3.1"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"qwen/qwen3-coder"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"openai/gpt-oss-120b"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"openai/gpt-5"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"openai/gpt-5-mini"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"x-ai/grok-3-mini"</span><span class="w">
      </span><span class="p">],</span><span class="w">
      </span><span class="nl">"transformer"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"use"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
          </span><span class="s2">"openrouter"</span><span class="w">
        </span><span class="p">]</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">],</span><span class="w">
  </span><span class="nl">"Router"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"default"</span><span class="p">:</span><span class="w"> </span><span class="s2">"openrouter,openai/gpt-5-mini"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"background"</span><span class="p">:</span><span class="w"> </span><span class="s2">"openrouter,google/gemini-2.5-flash"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"think"</span><span class="p">:</span><span class="w"> </span><span class="s2">"openrouter,qwen/qwen3-coder"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"longContext"</span><span class="p">:</span><span class="w"> </span><span class="s2">"openrouter,deepseek/deepseek-chat-v3.1"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"longContextThreshold"</span><span class="p">:</span><span class="w"> </span><span class="mi">2000</span><span class="p">,</span><span class="w">
    </span><span class="nl">"webSearch"</span><span class="p">:</span><span class="w"> </span><span class="s2">"openrouter,mistralai/mistral-medium-3.1"</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<hr />

<h2 id="agents-généraux-vs-agents-spécialisés">Agents généraux vs agents spécialisés</h2>

<p><em>2025.08</em></p>

<p><a href="https://manus.im">Manus</a> est présenté comme un outil d’agent IA général, mais il ne fonctionnera probablement pas très bien.</p>

<p>Une raison est qu’il est très lent, effectuant beaucoup de travail inutile et étant inefficace. Une autre raison est que s’il rencontre un problème complexe ou tombe sur un point faible, vous échouerez probablement dans votre tâche.</p>

<p>Les agents spécialisés fonctionnent bien car ils sont hautement spécialisés. Ils sont adaptés à des tâches très spécifiques. Il existe des dizaines de bases de données et plus d’une centaine de frameworks de développement web comme Spring. Il existe également de nombreux frameworks web, tels que Vue ou React.</p>

<p><a href="https://dify.ai">Dify</a> se concentre sur l’utilisation de l’IA pour connecter des workflows, utilisant une méthode de glisser-déposer pour définir des workflows IA. Ils doivent faire beaucoup pour connecter les informations, les données et les plateformes.</p>

<p>J’ai également construit quelques agents simples, comme un agent de refactorisation de code Python, un agent de correction grammaticale, un agent de correction de bugs et un agent de fusion d’essais.</p>

<p>Le code est très flexible. Ainsi, Dify ne couvre qu’une petite partie de l’espace des idées possibles.</p>

<p>Manus effectue des tâches et montre aux utilisateurs comment il fonctionne en utilisant une méthode VNC pour afficher un ordinateur.</p>

<p>Je pense que l’avenir se jouera entre ces deux approches.</p>

<p>Pour Manus, vous devez télécharger du code ou du texte pour effectuer des tâches, ce qui n’est pas pratique. Avec Dify, vous devez construire des workflows en utilisant le glisser-déposer, similaire à MIT Scratch.</p>

<p>Pourquoi Scratch n’est-il pas aussi populaire que Python ? Parce qu’avec Python, vous pouvez faire tellement de choses, alors que Scratch est limité à des programmes simples à des fins éducatives.</p>

<p>Dify a probablement des limites similaires.</p>

<p>Manus peut gérer beaucoup de tâches simples. Cependant, pour certaines tâches, en particulier celles qui touchent les points faibles de Manus, il échouera.</p>

<p>De plus, de nombreux programmes ou services prennent du temps à configurer. Dans l’approche de Manus, ce processus est lent.</p>

<p>En tant que programmeur, j’utilise l’IA avec Python pour construire mes agents spécialisés. C’est l’approche la plus simple pour moi. Je peux également configurer des invites et des contextes pour garantir une sortie relativement stable des API LLM.</p>

<p>Manus et Dify sont également construits avec ces API LLM. Leur avantage est qu’ils ont déjà beaucoup d’outils ou de code prêts à l’emploi.</p>

<p>Si je veux construire un agent Twitter bot, utiliser Dify peut être plus pratique que d’en construire un moi-même avec des technologies open source.</p>

<hr />

<h2 id="le-point-de-vue-dun-ingénieur-exigeant-sur-les-outils-de-codage-ia">Le point de vue d’un ingénieur exigeant sur les outils de codage IA</h2>

<p><em>2025.08</em></p>

<p>Récemment, j’ai réussi à faire fonctionner Claude Code, alors je veux partager mon parcours de sélection d’outils. J’ai également collecté quelques <a href="ai-tips-en.md">conseils sur les outils IA</a> en chemin.</p>

<p>J’ai adopté Claude Code assez tard.</p>

<p><a href="https://www.anthropic.com/news/claude-3-5-sonnet">Claude Code</a> est sorti vers fin février 2025.</p>

<p>Je n’ai réussi à l’essayer que récemment. Une raison est qu’il nécessite l’API Anthropic, qui ne prend pas en charge les cartes Visa chinoises.</p>

<p>Une autre raison est que <a href="https://github.com/musistudio/claude-code-router">Claude Code Router</a> est devenu disponible, ce qui a rendu ma tentative récente réussie.</p>

<p>J’entends constamment des éloges à son sujet. J’ai essayé le CLI Gemini en juillet 2025 mais l’ai abandonné après plusieurs tentatives infructueuses pour le faire corriger mon code.</p>

<p>J’ai également essayé Aider, un autre agent logiciel. J’ai arrêté d’utiliser Cursor après environ six mois car beaucoup de ses plugins basés sur VSCode dysfonctionnaient. De plus, je ne veux pas trop créditer Cursor puisqu’il est construit sur VSCode. Comme le plugin Copilot dans VSCode s’est amélioré récemment et ne traîne pas trop derrière, je préfère l’utiliser plus souvent.</p>

<p>Cependant, VSCode est construit sur Electron, une technologie open source. Il est difficile d’attribuer le mérite à la bonne équipe ou individu. Considérant que de nombreuses grandes entreprises et startups profitent des projets open source, je dois me concentrer sur mon budget et ce qui me convient le mieux. Je ne devrais pas trop m’inquiéter de donner du crédit. Je préfère utiliser des outils abordables et efficaces.</p>

<p>J’ai brièvement expérimenté Cline mais ne l’ai pas adopté.</p>

<p>J’utilise le plugin Copilot dans VSCode avec un modèle personnalisé, Grok 3 beta via OpenRouter, ce qui fonctionne bien.</p>

<p>Je ne pense pas que Claude Code changera mes habitudes, mais comme je peux le faire fonctionner et que j’ai la patience de l’essayer quelques fois de plus, je verrai comment je me sens dans les semaines à venir.</p>

<p>Je suis un utilisateur exigeant avec 10 ans d’expérience en génie logiciel. J’espère que les outils peuvent être excellents dans une utilisation réelle. Je ne crois pas à la marque — je me soucie seulement de l’utilité quotidienne.</p>

<p>Après avoir utilisé Claude Code pour corriger la grammaire de cet article, j’ai constaté qu’il fonctionne bien dans certains scénarios. Bien que j’apprécie l’IA pour l’aide grammaticale (j’ai même écrit un script Python pour appeler les API LLM à cet effet), j’ai remarqué un schéma frustrant — même lorsque je demande des corrections minimales, les outils continuent de présenter de nombreuses suggestions grammaticales à examiner. Ce processus de vérification manuelle va à l’encontre de l’automatisation. En compromis, je laisse maintenant l’IA traiter des essais entiers, bien que cette approche limite mes opportunités d’apprentissage puisque je ne vois pas les corrections spécifiques effectuées.</p>

<p>Ce qui m’a le plus impressionné, c’est la façon dont Claude Code affiche les modifications — montrant des comparaisons avant-après similaires aux diff de git, ce qui facilite grandement la révision des modifications.</p>

<p>Après une journée, j’ai utilisé Claude pour corriger du code également. Cependant, je continue d’utiliser le plugin Copilot avec le modèle Grok 3 beta, car il est simple et facile pour moi.</p>

<p>Après avoir utilisé Claude Code pendant plusieurs jours, je dois dire qu’il est très impressionnant. J’aime vraiment la façon dont il corrige mon code.</p>

<p class="centered"><img src="assets/images/claude/claude-code.jpg" alt="" class="responsive" />
<em class="caption">Source : Capture d’écran personnelle</em></p>

<p class="centered"><img src="assets/images/claude/claude-fix.jpg" alt="" class="responsive" />
<em class="caption">Source : Capture d’écran personnelle</em></p>

<p class="centered"><img src="assets/images/claude/vscode-fix.jpg" alt="" class="responsive" />
<em class="caption">Source : Capture d’écran personnelle</em></p>

<hr />

<h2 id="utilisation-des-api-de-deepseek-et-mistral">Utilisation des API de Deepseek et Mistral</h2>

<p><em>2025.01.25</em></p>

<h3 id="deepseek">DeepSeek</h3>

<p>En un mois, 15 millions de tokens m’ont coûté environ 23,5 CNY.</p>

<p>Voici mon utilisation en une journée :</p>

<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Tokens</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Entrée (Cache Hit)</td>
      <td>946,816</td>
    </tr>
    <tr>
      <td>Entrée (Cache Miss)</td>
      <td>2,753,752</td>
    </tr>
    <tr>
      <td>Sortie</td>
      <td>3,100,977</td>
    </tr>
  </tbody>
</table>

<p>Le calcul est le suivant :</p>

<p>0.94 * 0.1 + 2.75 * 1 + 3.10 * 2 = 11.83</p>

<p>Donc, selon la tâche, l’utilisation des tokens dépend largement de l’entrée (cache miss) et de la sortie.</p>

<p>Ce résultat correspond au coût attendu.</p>

<p><a href="https://api-docs.deepseek.com/quick_start/pricing/">Tarification de l’API DeepSeek</a></p>

<p class="centered"><img src="assets/images/deepseek/d.jpg" alt="" />
<em class="caption">Source : Capture d’écran personnelle</em></p>

<h3 id="mistral">Mistral</h3>

<p>La tarification des modèles Mistral est la suivante :</p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Entrée (USD par million de tokens)</th>
      <th>Sortie (USD par million de tokens)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">mistral-large-2411</code></td>
      <td>2</td>
      <td>6</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">mistral-small-latest</code></td>
      <td>0.2</td>
      <td>0.6</td>
    </tr>
  </tbody>
</table>

<p>En une journée, l’utilisation de mon compte Mistral était la suivante (Modèle : <code class="language-plaintext highlighter-rouge">mistral-large-2411</code>) :</p>

<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Tokens</th>
      <th>Coût (USD)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Total</td>
      <td>772,284</td>
      <td>3.44</td>
    </tr>
    <tr>
      <td>Sortie</td>
      <td>474,855</td>
      <td>2.85</td>
    </tr>
    <tr>
      <td>Entrée</td>
      <td>297,429</td>
      <td>0.59</td>
    </tr>
  </tbody>
</table>

<p>Pour le modèle <code class="language-plaintext highlighter-rouge">mistral-small-2409</code>, l’utilisation totale était de 1 022 407 tokens.</p>

<p>En supposant qu’un tiers étaient des tokens d’entrée et deux tiers des tokens de sortie :</p>

<p>Il y avait 340 802 tokens d’entrée et 681 605 tokens de sortie.</p>

<p>Par conséquent, le coût total est calculé comme 340 802 * 0.2 / 1 000 000 + 681 605 * 0.6 / 1 000 000 = 0.07 + 0.41 = 0.48 USD.</p>

<p>La console Mistral indique un coût total d’utilisation de 0.43 USD, ce qui correspond approximativement à notre calcul.</p>

<h3 id="grok">Grok</h3>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Entrée (USD par million de tokens)</th>
      <th>Sortie (USD par million de tokens)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">grok-2-latest</code></td>
      <td>2</td>
      <td>10</td>
    </tr>
  </tbody>
</table>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-fr" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
