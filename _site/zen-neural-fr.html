<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Le Zen et l'Art de l'Apprentissage Automatique</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Le Zen et l’Art de l’Apprentissage Automatique | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Le Zen et l’Art de l’Apprentissage Automatique" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="fr" />
<meta name="description" content="Zen" />
<meta property="og:description" content="Zen" />
<link rel="canonical" href="https://lzwjava.github.io/zen-neural-fr" />
<meta property="og:url" content="https://lzwjava.github.io/zen-neural-fr" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-07-03T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Le Zen et l’Art de l’Apprentissage Automatique" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2023-07-03T00:00:00+08:00","datePublished":"2023-07-03T00:00:00+08:00","description":"Zen","headline":"Le Zen et l’Art de l’Apprentissage Automatique","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/zen-neural-fr"},"url":"https://lzwjava.github.io/zen-neural-fr"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=ee00ff73954be30a7c238ca9f2cae1f09c212d61">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=ee00ff73954be30a7c238ca9f2cae1f09c212d61" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Le Zen et l'Art de l'Apprentissage Automatique | Original, traduit par l'IA
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/fr/2023-07-03-zen-neural-fr.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postsfr2023-07-03-zen-neural-fr.md</span> -->
      

      <!-- <span>2023-07-03-zen-neural-fr.md</span> -->

      
        

        
          
          <a href="#" class="button">2023.07</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/zen-neural-en" >English</option>
        <option value="/zen-neural-zh" >中文</option>
        <option value="/zen-neural-ja" >日本語</option>
        <option value="/zen-neural-es" >Español</option>
        <option value="/zen-neural-hi" >हिंदी</option>
        <option value="/zen-neural-fr" selected>Français</option>
        <option value="/zen-neural-de" >Deutsch</option>
        <option value="/zen-neural-ar" >العربية</option>
        <option value="/zen-neural-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <h2 id="zen">Zen</h2>

<p>Un jeune papa est occupé à apprendre les réseaux neuronaux le week-end. Cependant, ce week-end, il devait accompagner sa petite fille à la piscine de la résidence. Il s’est allongé dans l’eau peu profonde et a regardé les immeubles s’élever vers le ciel. Et soudain, il a pensé : “Wow, ils ressemblent beaucoup à des réseaux neuronaux. Chaque balcon est comme un neurone. Et un immeuble est comme une couche de neurones. Et un groupe d’immeubles forme un réseau neuronal.”</p>

<p>Il a ensuite réfléchi à la rétropropagation. Ce que fait la rétropropagation, c’est de propager les erreurs vers les neurones. À la fin d’un entraînement unique, l’algorithme calcule l’erreur entre la sortie de la dernière couche et le résultat cible. En réalité, les réseaux de neurones n’ont rien à voir avec les neurones. Il s’agit de calcul différentiable.</p>

<p>Après avoir rédigé l’article “Je comprends enfin comment fonctionne un réseau de neurones”, il s’est rendu compte qu’il ne comprenait toujours pas. La compréhension est une chose relative. Comme Richard Feynman le souligne, personne ne peut être sûr à 100 % de quoi que ce soit, nous ne pouvons qu’être relativement sûrs de quelque chose. Il est donc acceptable que Zhiwei dise cela.</p>

<p>Il a donc trouvé un moyen de comprendre profondément les réseaux de neurones en utilisant une méthode qui consiste à copier plusieurs lignes de code d’exemple à chaque fois, puis à les exécuter et à afficher les variables. Il s’agit d’un simple réseau de neurones pour reconnaître les chiffres manuscrits. Le livre qu’il lit récemment s’intitule <em>Neural Networks and Deep Learning</em>. C’est pourquoi il a donné à son dépôt GitHub le nom <em>Neural Networks and Zhiwei Learning</em>.</p>

<p>Avant d’utiliser un réseau de neurones pour entraîner nos données, nous devons d’abord charger les données. Cette partie lui a coûté une semaine de temps libre pour y parvenir. Les choses prennent toujours plus de temps qu’on ne le pense pour être accomplies. Mais tant que nous n’abandonnons pas, nous sommes capables de réaliser un grand nombre de choses.</p>

<p>Le terme <strong>mnist</strong> dans le domaine de l’apprentissage automatique fait référence à la base de données <strong>Modified National Institute of Standards and Technology</strong>. Ainsi, notre fichier de chargement de données est appelé <strong>mnist_loader</strong>. Nous utilisons la fonction <code class="language-plaintext highlighter-rouge">print</code> en Python pour afficher de nombreuses listes et tableaux de type <code class="language-plaintext highlighter-rouge">ndarray</code>. Le <strong>nd</strong> dans <code class="language-plaintext highlighter-rouge">ndarray</code> signifie <strong>n-dimensionnel</strong>.</p>

<p>En plus de <code class="language-plaintext highlighter-rouge">print</code>, nous devons utiliser la bibliothèque <code class="language-plaintext highlighter-rouge">matplotlib</code> pour afficher nos chiffres. Comme ci-dessous.</p>

<div align="center"><img src="/assets/images/zen-neural/figure.png" width="30%" /><img /></div>

<h2 id="art">Art</h2>

<p>Voyons plus de chiffres.</p>

<div align="center">
<img src="/assets/images/zen-neural/figures.jpeg" width="100%" /><img />
(Source de l'image : Neural Networks and Deep Learning)
</div>

<p>C’est plus joyeux quand on peut parfois voir des images au lieu de faire face à des codes bruyants toute la journée.</p>

<div align="center">
<img src="/assets/images/zen-neural/layer.png" width="100%" /><img />
(Source de l'image : Neural Networks and Deep Learning)
</div>

<p>Cela semble compliqué ? Ici, nous avons peut-être trop de neurones dans chaque couche. Et cela rend les choses obscures. C’est en fait très simple une fois que vous l’avez compris. La première chose à propos de l’image ci-dessus est qu’elle comporte trois couches : la couche d’entrée, la couche cachée et la couche de sortie. Et une couche se connecte à la suivante. Mais comment 784 neurones dans la couche d’entrée peuvent-ils se transformer en 15 neurones dans la deuxième couche ? Et comment 15 neurones dans la couche cachée peuvent-ils se transformer en 10 neurones dans la couche de sortie ?</p>

<div align="center">
<img src="/assets/images/zen-neural/simple-network.png" width="100%" /><img />
</div>

<p>&lt;/div&gt;</p>

<p>Ce réseau est beaucoup plus simple. Bien que Zhiwei ne souhaite pas inclure de formules mathématiques dans cet article, ici les mathématiques sont trop simples et belles pour être cachées.</p>

\[w_1*a_1 + w_2*a_2+...+ w_6*a_6+b_1\]

<p>Supposons que nous indiquions le réseau comme ci-dessous.</p>

<div align="center"><img src="/assets/images/zen-neural/network-1.png" width="30%" /><img /></div>

<p>Donc, entre la première couche et la deuxième couche, nous avons les équations suivantes.</p>

\[\begin{eqnarray}
  w_1*a_1 +...+ w_6*a_6+b_1 = c_1 \\
  w_1*a_1 +...+ w_6*a_6+b_2 = c_2 \\
  w_1*a_1 +...+ w_6*a_6+b_3 = c_3 \\
  w_1*a_1 +...+ w_6*a_6+b_4 = c_4 
\end{eqnarray}\]

<p>Ici, l’équation 1 possède un ensemble de poids, et l’équation 2 en possède un autre. Ainsi, le $w_1$ dans l’équation 1 est différent du $w_1$ dans l’équation 2. Par conséquent, entre la deuxième couche et la troisième couche, nous avons les équations suivantes.</p>

\[\begin{eqnarray}
  w_1*c_1 + ... + w_4*c_4+b_1 = d_1 \\
  w_1*c_1 + ... + w_4*c_4+b_2 = d_2 \\
  w_1*c_1 + ... + w_4*c_4+b_3 = d_3 
\end{eqnarray}\]

<p>Et dans la troisième couche jusqu’à la dernière couche, nous avons les équations suivantes.</p>

\[w_1*d_1 + w_2*d_2 + w_3*d_3 + b_1 = e_1\]

<p>Le problème avec les équations ci-dessus est que la valeur n’est pas assez simple ou formelle. La plage des valeurs de la multiplication et de l’addition est assez large. Nous souhaitons qu’elle soit contrainte dans une petite plage, par exemple, de 0 à 1. C’est ici qu’intervient la fonction Sigmoïde.</p>

\[\sigma(z) \equiv \frac{1}{1+e^{-z}}\]

<p>Nous n’avons pas besoin d’être intimidés par le symbole sigma $\sigma$. Ce n’est qu’un symbole, tout comme le symbole a. Si nous lui donnons l’entrée 0.5, sa valeur est</p>

\[\frac{1}{1+e^{-0.5}} \approx 0.622459\]

<p>Et,</p>

\[\begin{eqnarray}
\frac{1}{1+e^{-(-100)}} \approx 3.72*e^{-44}  \\
\frac{1}{1+e^{-(-10)}} \approx 0.000045  \\
\frac{1}{1+e^{-(-1)}} \approx 0.26894  \\
\frac{1}{1+e^{-{0}}} = 0.5  \\
\frac{1}{1+e^{-10}} \approx 0.99995  \\
\frac{1}{1+e^{-100}} = 1
\end{eqnarray}\]

<p>C’est intriguant ici. Je ne connaissais pas ce qui précède avant d’écrire cet article. Maintenant, j’ai une idée de la valeur approximative du résultat pour une entrée normale. Et nous observons que pour une entrée allant de 0 à $\infty$, sa valeur est comprise entre 0,5 et 1, et pour une entrée allant de $-\infty$ à 0, sa valeur est comprise entre 0 et 0,5.</p>

<div align="center"><img src="/assets/images/zen-neural/curve.png" width="100%" /><img /></div>

<p>Concernant les équations ci-dessus, elles ne sont pas exactes. Les plus appropriées devraient être les suivantes :</p>

\[\begin{eqnarray}
  \sigma(w_1*a_1 + ... + w_6*a_6+b_1) = c_1 \\
  \sigma(w_1*a_1 + ... + w_6*a_6+b_2) = c_2 \\
  \sigma(w_1*a_1 + ... + w_6*a_6+b_3) = c_3 \\
  \sigma(w_1*a_1 + ... + w_6*a_6+b_4) = c_4 
\end{eqnarray}\]

<p>Donc, pour la première équation, c’est que,</p>

\[\frac{1}{1+e^{-(w_1*a_1 +...+ w_6*a_6+b_1)}}\]

<p>Comment pouvons-nous mettre à jour le nouveau poids pour $w_1$ ? C’est-à-dire,</p>

\[w_1 \rightarrow w_1' = w_1 - \Delta w\]

<p>À l’équation,</p>

\[w_1*a_1 + w_2*a_2+...+ w_6*a_6+b_1\]

<p>Sa dérivée par rapport à $w_1$ est $a_1$. Donnons un symbole $S_1$ à cette somme.</p>

<p>Alors,</p>

\[\frac{\partial S_1}{\partial w_1} = a_1 , \frac{\partial S_1}{\partial w_2} = a_2, ...\]

<p>La dérivée représente le taux de changement. Cela signifie que pour un changement $\Delta w$ dans $w_1$, le changement correspondant dans le résultat $S_1$ est $a_1 * \Delta w$. Mais comment pouvons-nous inverser un tel calcul ? Calculons-le.</p>

\[\begin{eqnarray}
S_1' - S_1 = \Delta S_1  \\
\frac{\Delta S_1}{a_1} = \Delta w \\
w_1- \Delta w = w_1'
\end{eqnarray}\]

<p>Et la règle de la chaîne explique que la dérivée de $f(g(x))$ est $f’(g(x))⋅g’(x)$.</p>

<p>Alors ici,</p>

\[\begin{eqnarray}
f(z) = \sigma(z) = \frac{1}{1+e^{-z}} \\
g(x) = w_1*a_1 +...+ w_6*a_6+b_1
\end{eqnarray}\]

<p>Et la dérivée de la fonction sigmoïde est,</p>

\[\sigma'(z) = \frac{\sigma(z)}{1-\sigma(z)}\]

<p>Ainsi, la dérivée de $f(g(w_1))$ est $\frac{\sigma(z)}{1-\sigma(z)} * a_1$.</p>

<p>Alors,</p>

\[\begin{eqnarray}
\frac{\sigma(z)}{1-\sigma(z)} * a_1 * \Delta w = \Delta C \\
\Delta w = \frac{\Delta C}{\frac{\sigma(z)}{1-\sigma(z)} * a_1} 
\end{eqnarray}\]

<p>Et pour le biais $b_1$,</p>

\[\begin{eqnarray}
g'(b_1) = 1 \\
\frac{\sigma(z)}{1-\sigma(z)} * \Delta b = \Delta C \\
\Delta b = \frac{\Delta C}{\frac{\sigma(z)}{1-\sigma(z)}}
\end{eqnarray}\]

<h2 id="code">Code</h2>

<p>La manière d’afficher les variables est très utile et simple, bien qu’aujourd’hui les gens aient inventé Jupyter Notebook pour faire ce genre de choses. Comme Zhiwei l’a mentionné précédemment, l’une des clés pour comprendre les réseaux de neurones est de prêter attention aux dimensions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">print_shape</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">arr</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span> <span class="c1"># 10
</span><span class="n">print_shape</span><span class="p">(</span><span class="n">training_results</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># (784, 1)
</span><span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">training_data</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># &lt;class 'list'&gt;
</span></code></pre></div></div>

<p>Maintenant que Zhiwei vient de terminer la partie chargement des données, il va continuer à utiliser la même méthode consistant à copier plusieurs lignes et à imprimer des variables pour apprendre la partie réelle du réseau de neurones. Vous pouvez suivre les progrès ici : https://github.com/lzwjava/neural-networks-and-zhiwei-learning.</p>

<p>Je me suis retrouvé bloqué à plusieurs reprises au cours de ce processus. Même si le code semble très simple, après avoir essayé de le comprendre à plusieurs reprises, j’ai échoué. Ensuite, je me suis éloigné de la ligne de code actuelle pour l’examiner d’un point de vue plus global, en réfléchissant à la raison pour laquelle l’auteur a écrit cette partie du code. Et soudain, j’ai compris. Le code est ci-dessous.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_data_wrapper</span><span class="p">():</span>
    <span class="n">tr_d</span><span class="p">,</span> <span class="n">va_d</span><span class="p">,</span> <span class="n">te_d</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">training_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectorized_result</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">training_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">,</span> <span class="n">training_results</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">validation_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">validation_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">validation_inputs</span><span class="p">,</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">test_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_inputs</span><span class="p">,</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">vectorized_result</span><span class="p">(</span><span class="n">j</span><span class="p">):</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">e</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">e</span>
</code></pre></div></div>

<p>Ici, les dimensions des variables sont complexes. Cependant, lorsque nous réfléchissons à l’initiative de l’auteur, nous obtenons quelques indices. Regardez, le code est composé de trois parties similaires. Et chaque partie est presque la même, bien que les noms des variables soient différents. Maintenant, cela me semble très confortable. Le <code class="language-plaintext highlighter-rouge">zip</code>, l’opération <code class="language-plaintext highlighter-rouge">for</code> sur la liste, et la fonction <code class="language-plaintext highlighter-rouge">reshape</code>. La compréhension s’accumule simplement après des centaines de fois où j’ai imprimé les variables et essayé de comprendre pourquoi les valeurs des variables étaient ainsi.</p>

<p>Et Zhiwei trouve toujours les erreurs très précieuses. Comme dans le code ci-dessous, il rencontre de nombreuses erreurs, par exemple,</p>

<ul>
  <li>TypeError: Forme invalide (784,) pour les données d’image</li>
  <li>ValueError: définition d’un élément de tableau avec une séquence. Le tableau demandé a une forme inhomogène après 2 dimensions. La forme détectée était (1, 2) + partie inhomogène.</li>
</ul>

<p>La trace de la pile d’erreurs est comme un magnifique poème.</p>

<p>De plus, lorsque nous formatons la sortie des valeurs dans Visual Studio Code, elle devient beaucoup plus lisible.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.92733598</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.01054299</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">1.0195613</span><span class="p">],</span>
       <span class="p">...</span>
       <span class="p">[</span><span class="mf">0.67045368</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">0.29942482</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">0.35010666</span><span class="p">]]),</span>
 <span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.87093344</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.18758503</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.35792778</span><span class="p">],</span>
        <span class="p">...</span>
        <span class="p">[</span><span class="mf">0.36830578</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.61671649</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.67084213</span><span class="p">]])]</span>
</code></pre></div></div>

<p>Merci d’avoir lu. Thank you for your reading.</p>

<hr />

<p>Remarque : Certaines images sont extraites du livre “Neural Networks and Deep Learning”.</p>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-fr" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
