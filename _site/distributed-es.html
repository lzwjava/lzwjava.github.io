<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>IntroducciÃ³n a la ComputaciÃ³n en la Nube y el Big Data</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>IntroducciÃ³n a la ComputaciÃ³n en la Nube y el Big Data | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="IntroducciÃ³n a la ComputaciÃ³n en la Nube y el Big Data" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="es" />
<meta name="description" content="Esta lecciÃ³n cubre los siguientes temas:" />
<meta property="og:description" content="Esta lecciÃ³n cubre los siguientes temas:" />
<link rel="canonical" href="https://lzwjava.github.io/distributed-es" />
<meta property="og:url" content="https://lzwjava.github.io/distributed-es" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-10T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="IntroducciÃ³n a la ComputaciÃ³n en la Nube y el Big Data" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2021-03-10T00:00:00+08:00","datePublished":"2021-03-10T00:00:00+08:00","description":"Esta lecciÃ³n cubre los siguientes temas:","headline":"IntroducciÃ³n a la ComputaciÃ³n en la Nube y el Big Data","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/distributed-es"},"url":"https://lzwjava.github.io/distributed-es"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=fe13842666dd2631771e2916b70907f46ff54eb6">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=fe13842666dd2631771e2916b70907f46ff54eb6" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       IntroducciÃ³n a la ComputaciÃ³n en la Nube y el Big Data | Original, traducido por IA
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/es/2021-03-10-distributed-es.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postses2021-03-10-distributed-es.md</span> -->
      

      <!-- <span>2021-03-10-distributed-es.md</span> -->

      
        

        
          
          <a href="#" class="button">2021.03</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/distributed-en" >English</option>
        <option value="/distributed-zh" >ä¸­æ–‡</option>
        <option value="/distributed-ja" >æ—¥æœ¬èª</option>
        <option value="/distributed-es" selected>EspaÃ±ol</option>
        <option value="/distributed-hi" >à¤¹à¤¿à¤‚à¤¦à¥€</option>
        <option value="/distributed-fr" >FranÃ§ais</option>
        <option value="/distributed-de" >Deutsch</option>
        <option value="/distributed-ar" >Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</option>
        <option value="/distributed-hant" >ç¹é«”ä¸­æ–‡</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>Esta lecciÃ³n cubre los siguientes temas:</p>

<ul>
  <li>Spark</li>
  <li>Hadoop</li>
  <li>Kubernetes</li>
  <li>Docker</li>
  <li>Flink</li>
  <li>MongoDB</li>
</ul>

<p>Cuando se habla de computaciÃ³n en la nube, parece que no se puede evitar mencionar muchas herramientas: Hadoop, Hive, Hbase, ZooKeeper, Docker, Kubernetes, Spark, Kafka, MongoDB, Flink, Druid, Presto, Kylin, Elastic Search. Â¿Has oÃ­do hablar de todas ellas? Algunas de estas herramientas las encontrÃ© en las descripciones de puestos como <code class="language-plaintext highlighter-rouge">ingeniero de big data</code> e <code class="language-plaintext highlighter-rouge">ingeniero backend distribuido</code>. Estos son puestos bien remunerados. Intentemos instalarlos todos y jugar un poco con ellos.</p>
<h2 id="primer-vistazo-a-spark">Primer vistazo a Spark</h2>

<p>El sitio web oficial dice que <code class="language-plaintext highlighter-rouge">Spark</code> es un motor de anÃ¡lisis utilizado para procesar datos a gran escala. <code class="language-plaintext highlighter-rouge">Spark</code> es esencialmente un conjunto de bibliotecas. Parece que no estÃ¡ dividido en servidor y cliente como <code class="language-plaintext highlighter-rouge">Redis</code>. <code class="language-plaintext highlighter-rouge">Spark</code> se utiliza Ãºnicamente en el lado del cliente. DescarguÃ© la Ãºltima versiÃ³n del sitio web, <code class="language-plaintext highlighter-rouge">spark-3.1.1-bin-hadoop3.2.tar</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
â”œâ”€â”€ LICENSE
â”œâ”€â”€ NOTICE
â”œâ”€â”€ R
â”œâ”€â”€ README.md
â”œâ”€â”€ RELEASE
â”œâ”€â”€ bin
â”œâ”€â”€ conf
â”œâ”€â”€ data
â”œâ”€â”€ examples
â”œâ”€â”€ jars
â”œâ”€â”€ kubernetes
â”œâ”€â”€ licenses
â”œâ”€â”€ python
â”œâ”€â”€ sbin
â””â”€â”€ yarn
</code></pre></div></div>

<p>11 directorios, 4 archivos</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Parece ser una colecciÃ³n de bibliotecas de anÃ¡lisis escritas en varios lenguajes.

Al mismo tiempo, el sitio web oficial menciona que puedes instalar las dependencias directamente en Python. `pip install pyspark`

```shell
$ pip install pyspark
Collecting pyspark
  Descargando pyspark-3.1.1.tar.gz (212.3 MB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212.3 MB 14 kB/s
Collecting py4j==0.10.9
  Descargando py4j-0.10.9-py2.py3-none-any.whl (198 kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198 kB 145 kB/s
Building wheels for collected packages: pyspark
  Building wheel for pyspark (setup.py) ... done
  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=0b8079e82f3a5bcadad99179902d8c8ff9f8eccad928a469c11b97abdc960b72
  Stored in directory: /Users/lzw/Library/Caches/pip/wheels/23/bf/e9/9f3500437422e2ab82246f25a51ee480a44d4efc6c27e50d33
Successfully built pyspark
Installing collected packages: py4j, pyspark
Successfully installed py4j-0.10.9 pyspark-3.1.1
</code></pre></div></div>

<p>Se ha instalado.</p>

<p>Esto se ve en el sitio web oficial, hay algunos ejemplos.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/run-ejemplo SparkPi 10
</code></pre></div></div>

<p>Ah, resulta que puedes ejecutar el programa del paquete de instalaciÃ³n que acabas de descargar. Pero ocurriÃ³ un error.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/run-example SparkPi 10
21/03/11 00:06:15 WARN NativeCodeLoader: No se pudo cargar la biblioteca nativa de Hadoop para su plataforma... utilizando clases integradas de Java donde sea aplicable
21/03/11 00:06:16 INFO ResourceUtils: No se han configurado recursos personalizados para spark.driver.
21/03/11 00:06:16 WARN Utils: El servicio <span class="s1">'sparkDriver'</span> no pudo vincularse a un puerto libre aleatorio. Puede verificar si se ha configurado una direcciÃ³n de enlace adecuada.
</code></pre></div></div>

<blockquote>
  <p>Spark es un motor de procesamiento rÃ¡pido y general compatible con datos de Hadoop. Puede ejecutarse en clÃºsteres de Hadoop a travÃ©s de YARN o en modo independiente de Spark, y puede procesar datos en HDFS, HBase, Cassandra, Hive y cualquier formato de entrada de Hadoop. EstÃ¡ diseÃ±ado para realizar tanto procesamiento por lotes (similar a MapReduce) como nuevas cargas de trabajo como transmisiÃ³n en tiempo real, consultas interactivas y aprendizaje automÃ¡tico.</p>
</blockquote>

<p>ApareciÃ³ varias veces la palabra <code class="language-plaintext highlighter-rouge">hadoop</code>. DespuÃ©s de buscar en Google <code class="language-plaintext highlighter-rouge">spark depends hadoop</code>, encontrÃ© este pÃ¡rrafo. Parece que esto depende de los datos en formato <code class="language-plaintext highlighter-rouge">Hadoop</code>. Primero, vamos a investigar <code class="language-plaintext highlighter-rouge">Hadoop</code>.</p>

<h2 id="hadoop">Hadoop</h2>

<p>DespuÃ©s de echar un vistazo rÃ¡pido a la pÃ¡gina oficial, procedÃ­ a instalarlo.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>hadoop
</code></pre></div></div>

<p>Durante el proceso de instalaciÃ³n, vamos a aprender un poco mÃ¡s.</p>

<blockquote>
  <p>La biblioteca de software Apache Hadoop es un marco que permite el procesamiento distribuido de grandes conjuntos de datos a travÃ©s de clÃºsteres de computadoras utilizando modelos de programaciÃ³n simples. EstÃ¡ diseÃ±ado para escalar desde servidores individuales hasta miles de mÃ¡quinas, cada una ofreciendo capacidad de cÃ¡lculo y almacenamiento local. En lugar de depender del hardware para ofrecer alta disponibilidad, la biblioteca en sÃ­ estÃ¡ diseÃ±ada para detectar y manejar fallos en la capa de aplicaciÃ³n, proporcionando asÃ­ un servicio altamente disponible sobre un clÃºster de computadoras, cada una de las cuales puede ser propensa a fallos.</p>
</blockquote>

<p>En otras palabras, Hadoop es un conjunto de marcos de trabajo diseÃ±ados para procesar conjuntos de datos distribuidos. Estos conjuntos de datos pueden estar distribuidos en muchas computadoras. Se utiliza un modelo de programaciÃ³n muy simple para manejarlos. EstÃ¡ diseÃ±ado para escalar desde un solo servidor hasta miles de mÃ¡quinas. En lugar de depender de la alta disponibilidad del hardware, esta biblioteca estÃ¡ diseÃ±ada para detectar y manejar errores en la capa de aplicaciÃ³n. Por lo tanto, permite implementar servicios de alta disponibilidad en un clÃºster, incluso si cada computadora en el clÃºster puede fallar.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>hadoop
Error:
  homebrew-core es un clon superficial.
  homebrew-cask es un clon superficial.
Para ejecutar <span class="sb">`</span>brew update<span class="sb">`</span>, primero ejecuta:
  git <span class="nt">-C</span> /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core fetch <span class="nt">--unshallow</span>
  git <span class="nt">-C</span> /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask fetch <span class="nt">--unshallow</span>
Estos comandos pueden tardar unos minutos en ejecutarse debido al gran tamaÃ±o de los repositorios.
Esta restricciÃ³n se ha implementado a solicitud de GitHub porque actualizar clones superficiales
es una operaciÃ³n extremadamente costosa debido al diseÃ±o del Ã¡rbol y al trÃ¡fico de
Homebrew/homebrew-core y Homebrew/homebrew-cask. No lo hacemos automÃ¡ticamente para evitar
realizar repetidamente una operaciÃ³n costosa de <span class="s2">"unshallow"</span> en sistemas de CI <span class="o">(</span>que en su lugar
deberÃ­an corregirse para no usar clones superficiales<span class="o">)</span><span class="nb">.</span> Â¡Lamentamos las molestias!
<span class="o">==&gt;</span> Descargando https://homebrew.bintray.com/bottles/openjdk-15.0.1.big_sur.bottle.tar.gz
Ya descargado: /Users/lzw/Library/Caches/Homebrew/downloads/d1e3ece4af1d225bc2607eaa4ce85a873d2c6d43757ae4415d195751bc431962--openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Descargando https://www.apache.org/dyn/closer.lua?path<span class="o">=</span>hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
Ya descargado: /Users/lzw/Library/Caches/Homebrew/downloads/764c6a0ea7352bb8bb505989feee1b36dc628c2dcd6b93fef1ca829d191b4e1e--hadoop-3.3.0.tar.gz
<span class="o">==&gt;</span> Instalando dependencias para hadoop: openjdk
<span class="o">==&gt;</span> Instalando dependencia de hadoop: openjdk
<span class="o">==&gt;</span> Vertiendo openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Advertencias
Para que los wrappers de Java del sistema encuentren este JDK, crea un enlace simbÃ³lico con
  <span class="nb">sudo ln</span> <span class="nt">-sfn</span> /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk
</code></pre></div></div>

<p>openjdk es keg-only, lo que significa que no se ha creado un enlace simbÃ³lico en /usr/local,
porque oscurece el wrapper <code class="language-plaintext highlighter-rouge">java</code> de macOS.</p>

<p>Si necesitas que openjdk estÃ© primero en tu PATH, ejecuta:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>Para que los compiladores encuentren openjdk, es posible que necesites configurar:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">export </span><span class="nv">CPPFLAGS</span><span class="o">=</span><span class="s2">"-I/usr/local/opt/openjdk/include"</span>
</code></pre></div></div>

<p>==&gt; Resumen
ğŸº  /usr/local/Cellar/openjdk/15.0.1: 614 archivos, 324.9MB
==&gt; Instalando hadoop
ğŸº  /usr/local/Cellar/hadoop/3.3.0: 21,819 archivos, 954.7MB, construido en 2 minutos 15 segundos
==&gt; Actualizando 1 dependencia:
maven 3.3.3 -&gt; 3.6.3_1
==&gt; Actualizando maven 3.3.3 -&gt; 3.6.3_1
==&gt; Descargando https://www.apache.org/dyn/closer.lua?path=maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
==&gt; Descargando desde https://mirror.olnevhost.net/pub/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
######################################################################## 100.0%
Error: El paso <code class="language-plaintext highlighter-rouge">brew link</code> no se completÃ³ correctamente
La fÃ³rmula se construyÃ³, pero no se enlazÃ³ simbÃ³licamente en /usr/local
No se pudo crear el enlace simbÃ³lico bin/mvn
El objetivo /usr/local/bin/mvn
es un enlace simbÃ³lico que pertenece a maven. Puedes desenlazarlo:
  brew unlink maven</p>

<p>Para forzar el enlace y sobrescribir todos los archivos en conflicto:
  brew link â€“overwrite maven</p>

<p>Para listar todos los archivos que serÃ­an eliminados:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  brew <span class="nb">link</span> <span class="nt">--overwrite</span> <span class="nt">--dry-run</span> maven
</code></pre></div></div>

<p>Los archivos que podrÃ­an estar en conflicto son:
/usr/local/bin/mvn -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvn
/usr/local/bin/mvnDebug -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnDebug
/usr/local/bin/mvnyjp -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnyjp
==&gt; Resumen
ğŸº  /usr/local/Cellar/maven/3.6.3_1: 87 archivos, 10.7MB, construido en 7 segundos
Eliminando: /usr/local/Cellar/maven/3.3.3â€¦ (92 archivos, 9MB)
==&gt; Verificando dependientes de fÃ³rmulas actualizadasâ€¦
==&gt; Â¡No se encontraron dependientes rotos!
==&gt; Advertencias
==&gt; openjdk
Para que los wrappers de Java del sistema encuentren este JDK, crea un enlace simbÃ³lico con
  sudo ln -sfn /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk</p>

<p>openjdk es keg-only, lo que significa que no se ha creado un enlace simbÃ³lico en /usr/local,
porque oculta el envoltorio <code class="language-plaintext highlighter-rouge">java</code> de macOS.</p>

<p>Si necesitas tener openjdk primero en tu PATH, ejecuta:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>Para que los compiladores encuentren openjdk, es posible que necesites configurar:
  export CPPFLAGS=â€-I/usr/local/opt/openjdk/includeâ€</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
NotÃ© en los registros de salida de `brew` que `maven` no estaba correctamente enlazado. A continuaciÃ³n, procedÃ­ a forzar el enlace a la versiÃ³n `3.6.3_1`.

```shell
  brew link --overwrite maven
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Hadoop</code> se ha instalado correctamente.</p>

<blockquote>
  <h2 id="mÃ³dulos">MÃ³dulos</h2>

  <p>El proyecto incluye los siguientes mÃ³dulos:</p>

  <ul>
    <li><strong>Hadoop Common</strong>: Las utilidades comunes que soportan los otros mÃ³dulos de Hadoop.</li>
    <li><strong>Hadoop Distributed File System (HDFSâ„¢)</strong>: Un sistema de archivos distribuido que proporciona acceso de alto rendimiento a los datos de las aplicaciones.</li>
    <li><strong>Hadoop YARN</strong>: Un marco de trabajo para la planificaciÃ³n de trabajos y la gestiÃ³n de recursos del clÃºster.</li>
    <li><strong>Hadoop MapReduce</strong>: Un sistema basado en YARN para el procesamiento paralelo de grandes conjuntos de datos.</li>
    <li><strong>Hadoop Ozone</strong>: Un almacÃ©n de objetos para Hadoop.</li>
  </ul>
</blockquote>

<p>Dice que tiene estos mÃ³dulos. Esto escribirÃ¡ <code class="language-plaintext highlighter-rouge">hadoop</code> y aparecerÃ¡:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hadoop
Uso: hadoop <span class="o">[</span>OPCIONES] SUBCOMANDO <span class="o">[</span>OPCIONES DEL SUBCOMANDO]
 o     hadoop <span class="o">[</span>OPCIONES] NOMBRE_DE_CLASE <span class="o">[</span>OPCIONES DE NOMBRE_DE_CLASE]
  donde NOMBRE_DE_CLASE es una clase Java proporcionada por el usuario
</code></pre></div></div>

<p>OPTIONS es ninguno o cualquiera de:</p>

<p>â€“config dir                     Directorio de configuraciÃ³n de Hadoop
â€“debug                          Activar el modo de depuraciÃ³n de scripts de shell
â€“help                           InformaciÃ³n de uso
buildpaths                       Intentar agregar archivos de clase desde el Ã¡rbol de compilaciÃ³n
hostnames list[,of,host,names]   Lista de nombres de hosts para usar en modo esclavo
hosts filename                   Archivo con la lista de hosts para usar en modo esclavo
loglevel level                   Establecer el nivel de log4j para este comando
workers                          Activar el modo de trabajador</p>

<p>SUBCOMMAND es uno de:
    Comandos de AdministraciÃ³n:</p>

<p>daemonlog     obtener/establecer el nivel de registro para cada daemon</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Comandos del Cliente:
</code></pre></div></div>

<p>archive       crear un archivo Hadoop
checknative   verificar la disponibilidad de las bibliotecas nativas de Hadoop y compresiÃ³n
classpath     imprime la ruta de clase necesaria para obtener el archivo jar de Hadoop y las bibliotecas requeridas
conftest      validar archivos de configuraciÃ³n XML
credential    interactuar con proveedores de credenciales
distch        cambiador de metadatos distribuido
distcp        copiar archivos o directorios de forma recursiva
dtutil        operaciones relacionadas con tokens de delegaciÃ³n
envvars       mostrar las variables de entorno de Hadoop calculadas
fs            ejecutar un cliente de usuario genÃ©rico del sistema de archivos
gridmix       enviar una mezcla de trabajos sintÃ©ticos, modelando una carga de producciÃ³n perfilada
jar <jar>     ejecutar un archivo jar. NOTA: por favor usa "yarn jar" para lanzar aplicaciones YARN, no este comando.
jnipath       imprime la ruta java.library.path
kdiag         diagnosticar problemas de Kerberos
kerbname      mostrar la conversiÃ³n de principal auth_to_local
key           gestionar claves a travÃ©s del KeyProvider
rumenfolder   escalar un rastro de entrada de rumen
rumentrace    convertir registros en un rastro de rumen
s3guard       gestionar metadatos en S3
trace         ver y modificar configuraciones de rastreo de Hadoop
version       imprimir la versiÃ³n</jar></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Comandos de Daemon:
</code></pre></div></div>

<p>kms           ejecuta KMS, el servidor de gestiÃ³n de claves
registrydns   ejecuta el servidor DNS del registro</p>

<p>SUBCOMMAND puede mostrar ayuda cuando se invoca sin parÃ¡metros o con -h.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
El sitio web oficial proporciona algunos ejemplos.

```shell
  $ mkdir input
  $ cp etc/hadoop/*.xml input
  $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'
  $ cat output/*
</code></pre></div></div>

<p>NotÃ© que existe <code class="language-plaintext highlighter-rouge">share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar</code>. Esto significa que quizÃ¡s algunos archivos de ejemplo no los obtuvimos. Supongo que al instalar con <code class="language-plaintext highlighter-rouge">Homebrew</code> no se incluyen estos archivos. Descargamos el paquete de instalaciÃ³n desde el sitio web oficial.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
â”œâ”€â”€ LICENSE-binary
â”œâ”€â”€ LICENSE.txt
â”œâ”€â”€ NOTICE-binary
â”œâ”€â”€ NOTICE.txt
â”œâ”€â”€ README.txt
â”œâ”€â”€ bin
â”œâ”€â”€ etc
â”œâ”€â”€ include
â”œâ”€â”€ lib
â”œâ”€â”€ libexec
â”œâ”€â”€ licenses-binary
â”œâ”€â”€ sbin
â””â”€â”€ share
</code></pre></div></div>

<p>ApareciÃ³ el directorio <code class="language-plaintext highlighter-rouge">share</code>. Sin embargo, Â¿realmente <code class="language-plaintext highlighter-rouge">Homebrew</code> no tiene estos archivos adicionales? Encuentra el directorio de instalaciÃ³n de <code class="language-plaintext highlighter-rouge">Homebrew</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">type </span>hadoop
hadoop es /usr/local/bin/hadoop
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-alrt</span> /usr/local/bin/hadoop
lrwxr-xr-x  1 lzw  admin  33 Mar 11 00:48 /usr/local/bin/hadoop -&gt; ../Cellar/hadoop/3.3.0/bin/hadoop
<span class="nv">$ </span><span class="nb">cd</span> /usr/local/Cellar/hadoop/3.3.0
</code></pre></div></div>

<p>Este es el Ã¡rbol de directorios impreso en <code class="language-plaintext highlighter-rouge">/usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 2
<span class="nb">.</span>
â”œâ”€â”€ client
â”‚Â Â  â”œâ”€â”€ hadoop-client-api-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-client-minicluster-3.3.0.jar
â”‚Â Â  â””â”€â”€ hadoop-client-runtime-3.3.0.jar
â”œâ”€â”€ common
â”‚Â Â  â”œâ”€â”€ hadoop-common-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-common-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-kms-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-nfs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-registry-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ jdiff
â”‚Â Â  â”œâ”€â”€ lib
â”‚Â Â  â”œâ”€â”€ sources
â”‚Â Â  â””â”€â”€ webapps
â”œâ”€â”€ hdfs
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-client-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-client-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-httpfs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-native-client-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-native-client-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-nfs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-rbf-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-rbf-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ jdiff
â”‚Â Â  â”œâ”€â”€ lib
â”‚Â Â  â”œâ”€â”€ sources
â”‚Â Â  â””â”€â”€ webapps
â”œâ”€â”€ mapreduce
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-app-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-common-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-core-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-hs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-hs-plugins-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-jobclient-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-jobclient-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-nativetask-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-shuffle-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-uploader-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-examples-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ jdiff
â”‚Â Â  â”œâ”€â”€ lib-examples
â”‚Â Â  â””â”€â”€ sources
â”œâ”€â”€ tools
â”‚Â Â  â”œâ”€â”€ dynamometer
â”‚Â Â  â”œâ”€â”€ lib
â”‚Â Â  â”œâ”€â”€ resourceestimator
â”‚Â Â  â”œâ”€â”€ sls
â”‚Â Â  â””â”€â”€ sources
â””â”€â”€ yarn
    â”œâ”€â”€ csi
    â”œâ”€â”€ hadoop-yarn-api-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-applications-catalog-webapp-3.3.0.war
    â”œâ”€â”€ hadoop-yarn-applications-distributedshell-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-applications-mawo-core-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-client-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-common-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-registry-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-applicationhistoryservice-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-common-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-nodemanager-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-resourcemanager-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-router-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-sharedcachemanager-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-tests-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-timeline-pluginstorage-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-web-proxy-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-services-api-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-services-core-3.3.0.jar
    â”œâ”€â”€ lib
    â”œâ”€â”€ sources
    â”œâ”€â”€ <span class="nb">test</span>
    â”œâ”€â”€ timelineservice
    â”œâ”€â”€ webapps
    â””â”€â”€ yarn-service-examples
</code></pre></div></div>

<p>Se pueden ver muchos archivos <code class="language-plaintext highlighter-rouge">jar</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>input
<span class="nv">$ </span><span class="nb">ls
</span>bin			hadoop-config.sh	hdfs-config.sh		libexec			sbin			yarn-config.sh
etc			hadoop-functions.sh	input			mapred-config.sh	share
<span class="nv">$ </span><span class="nb">cp </span>etc/hadoop/<span class="k">*</span>.xml input
<span class="nv">$ </span><span class="nb">cd </span>input/
<span class="nv">$ </span><span class="nb">ls
</span>capacity-scheduler.xml	hadoop-policy.xml	hdfs-site.xml		kms-acls.xml		mapred-site.xml
core-site.xml		hdfs-rbf-site.xml	httpfs-site.xml		kms-site.xml		yarn-site.xml
<span class="nv">$ </span><span class="nb">cd</span> ..
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
El archivo JAR no existe o no es un archivo normal: /usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar
<span class="err">$</span>
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
2021-03-11 01:54:30,791 WARN util.NativeCodeLoader: No se pudo cargar la biblioteca nativa de Hadoop para su plataforma... utilizando clases Java integradas donde sea aplicable
2021-03-11 01:54:31,115 INFO impl.MetricsConfig: Propiedades cargadas desde hadoop-metrics2.properties
2021-03-11 01:54:31,232 INFO impl.MetricsSystemImpl: PerÃ­odo de instantÃ¡nea de mÃ©tricas programado en 10 segundo<span class="o">(</span>s<span class="o">)</span><span class="nb">.</span>
...
</code></pre></div></div>

<p>Siguiendo el ejemplo de la pÃ¡gina oficial. NotÃ© que en <code class="language-plaintext highlighter-rouge">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input</code>, el paquete <code class="language-plaintext highlighter-rouge">jar</code> tiene un nÃºmero de versiÃ³n. Por lo tanto, debemos cambiarlo a nuestra versiÃ³n <code class="language-plaintext highlighter-rouge">3.3.0</code>.</p>

<p>Final del registro:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2021-03-11 01:54:35,374 INFO mapreduce.Job:  map 100% reduce 100%
2021-03-11 01:54:35,374 INFO mapreduce.Job: El trabajo job_local2087514596_0002 se completÃ³ exitosamente
2021-03-11 01:54:35,377 INFO mapreduce.Job: Contadores: 30
	Contadores del Sistema de Archivos
		FILE: NÃºmero de bytes leÃ­dos<span class="o">=</span>1204316
		FILE: NÃºmero de bytes <span class="nv">escritos</span><span class="o">=</span>3565480
		FILE: NÃºmero de operaciones de <span class="nv">lectura</span><span class="o">=</span>0
		FILE: NÃºmero de operaciones de lectura <span class="nv">grandes</span><span class="o">=</span>0
		FILE: NÃºmero de operaciones de <span class="nv">escritura</span><span class="o">=</span>0
	Marco de Map-Reduce
		Registros de entrada de <span class="nv">Map</span><span class="o">=</span>1
		Registros de salida de <span class="nv">Map</span><span class="o">=</span>1
		Bytes de salida de <span class="nv">Map</span><span class="o">=</span>17
		Bytes materializados de salida de <span class="nv">Map</span><span class="o">=</span>25
		Bytes de divisiÃ³n de <span class="nv">entrada</span><span class="o">=</span>141
		Registros de entrada de <span class="nv">Combine</span><span class="o">=</span>0
		Registros de salida de <span class="nv">Combine</span><span class="o">=</span>0
		Grupos de entrada de <span class="nv">Reduce</span><span class="o">=</span>1
		Bytes de shuffle de <span class="nv">Reduce</span><span class="o">=</span>25
		Registros de entrada de <span class="nv">Reduce</span><span class="o">=</span>1
		Registros de salida de <span class="nv">Reduce</span><span class="o">=</span>1
		Registros <span class="nv">derramados</span><span class="o">=</span>2
		Mapas <span class="nv">mezclados</span><span class="o">=</span>1
		Shuffles <span class="nv">fallidos</span><span class="o">=</span>0
		Salidas de Map <span class="nv">fusionadas</span><span class="o">=</span>1
		Tiempo de GC transcurrido <span class="o">(</span>ms<span class="o">)=</span>57
		Uso total de memoria heap comprometida <span class="o">(</span>bytes<span class="o">)=</span>772800512
	Errores de Shuffle
		<span class="nv">BAD_ID</span><span class="o">=</span>0
		<span class="nv">CONNECTION</span><span class="o">=</span>0
		<span class="nv">IO_ERROR</span><span class="o">=</span>0
		<span class="nv">WRONG_LENGTH</span><span class="o">=</span>0
		<span class="nv">WRONG_MAP</span><span class="o">=</span>0
		<span class="nv">WRONG_REDUCE</span><span class="o">=</span>0
	Contadores de Formato de Entrada de Archivo
		Bytes LeÃ­dos<span class="o">=</span>123
	Contadores de Formato de Salida de Archivo
		Bytes <span class="nv">Escritos</span><span class="o">=</span>23
</code></pre></div></div>

<p>Sigamos viendo.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>Â¿QuÃ© significa todo esto? No importa, lo importante es que hemos logrado poner en marcha <code class="language-plaintext highlighter-rouge">Hadoop</code> y hemos ejecutado el primer ejemplo de cÃ¡lculo en modo standalone.</p>

<h2 id="spark">Spark</h2>

<p>Volviendo a Spark. Veamos un ejemplo.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
</code></pre></div></div>

<p>AquÃ­ aparece un archivo <code class="language-plaintext highlighter-rouge">hdfs</code>. DespuÃ©s de investigar, descubrÃ­ que se puede crear un archivo <code class="language-plaintext highlighter-rouge">hdfs</code> de la siguiente manera:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-mkdir</span> /test
</code></pre></div></div>

<p>Vamos a echar un vistazo al comando <code class="language-plaintext highlighter-rouge">hdfs</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hdfs
Uso: hdfs <span class="o">[</span>OPCIONES] SUBCOMANDO <span class="o">[</span>OPCIONES DE SUBCOMANDO]
</code></pre></div></div>

<p>OPTIONS es ninguno o cualquiera de:</p>

<p>â€“buildpaths                       intentar agregar archivos de clase desde el Ã¡rbol de compilaciÃ³n
â€“config dir                       directorio de configuraciÃ³n de Hadoop
â€“daemon (start|status|stop)       operar sobre un demonio
â€“debug                            activar el modo de depuraciÃ³n del script de shell
â€“help                             informaciÃ³n de uso
â€“hostnames lista[,de,host,names]  hosts a usar en modo worker
â€“hosts nombre_de_archivo          lista de hosts a usar en modo worker
â€“loglevel nivel                   establecer el nivel de log4j para este comando
â€“workers                          activar el modo worker</p>

<p>SUBCOMMAND es uno de:
    Comandos de AdministraciÃ³n:</p>

<p>cacheadmin           configurar la cachÃ© de HDFS
crypto               configurar zonas de cifrado de HDFS
debug                ejecutar un Debug Admin para ejecutar comandos de depuraciÃ³n de HDFS
dfsadmin             ejecutar un cliente de administraciÃ³n de DFS
dfsrouteradmin       administrar la federaciÃ³n basada en Router
ec                   ejecutar una CLI de CodificaciÃ³n de Borrado de HDFS
fsck                 ejecutar una utilidad de verificaciÃ³n del sistema de archivos DFS
haadmin              ejecutar un cliente de administraciÃ³n de DFS HA
jmxget               obtener valores exportados de JMX desde el NameNode o DataNode
oev                  aplicar el visor de ediciones fuera de lÃ­nea a un archivo de ediciones
oiv                  aplicar el visor de imÃ¡genes de sistema de archivos fuera de lÃ­nea a una imagen de sistema de archivos
oiv_legacy           aplicar el visor de imÃ¡genes de sistema de archivos fuera de lÃ­nea a una imagen de sistema de archivos heredada
storagepolicies      listar/obtener/establecer/satisfacer polÃ­ticas de almacenamiento de bloques</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Comandos del Cliente:
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>classpath            imprime el classpath necesario para obtener el jar de Hadoop y las bibliotecas requeridas
dfs                  ejecuta un comando del sistema de archivos en el sistema de archivos
envvars              muestra las variables de entorno de Hadoop calculadas
fetchdt              obtiene un token de delegaciÃ³n del NameNode
getconf              obtiene valores de configuraciÃ³n desde la configuraciÃ³n
groups               obtiene los grupos a los que pertenecen los usuarios
lsSnapshottableDir   lista todos los directorios snapshottables propiedad del usuario actual
snapshotDiff         compara dos instantÃ¡neas de un directorio o compara el contenido actual del directorio con una instantÃ¡nea
version              imprime la versiÃ³n
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Comandos de Daemon:
</code></pre></div></div>

<p>balancer             ejecutar una utilidad de balanceo de clÃºster<br />
datanode             ejecutar un datanode DFS<br />
dfsrouter            ejecutar el enrutador DFS<br />
diskbalancer         distribuir datos de manera uniforme entre discos en un nodo dado<br />
httpfs               ejecutar el servidor HttpFS, la puerta de enlace HTTP de HDFS<br />
journalnode          ejecutar el journalnode DFS<br />
mover                ejecutar una utilidad para mover rÃ©plicas de bloques entre tipos de almacenamiento<br />
namenode             ejecutar el namenode DFS<br />
nfs3                 ejecutar una puerta de enlace NFS versiÃ³n 3<br />
portmap              ejecutar un servicio portmap<br />
secondarynamenode    ejecutar el secondary namenode DFS<br />
sps                  ejecutar el satisfactor de polÃ­ticas de almacenamiento externo<br />
zkfc                 ejecutar el daemon del Controlador de ConmutaciÃ³n por Error ZK</p>

<p>SUBCOMMAND puede mostrar ayuda cuando se invoca sin parÃ¡metros o con -h.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Continuar modificando el cÃ³digo.

```python
from pyspark.sql import SparkSession
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">master</span><span class="p">(</span><span class="s">"local[*]"</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">config</span><span class="p">(</span><span class="s">'spark.driver.bindAddress'</span><span class="p">,</span> <span class="s">'127.0.0.1'</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"a.txt"</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"b.txt"</span><span class="p">)</span>
</code></pre></div></div>

<p>Es importante notar <code class="language-plaintext highlighter-rouge">.config('spark.driver.bindAddress', '127.0.0.1')</code>. De lo contrario, se generarÃ¡ el error <code class="language-plaintext highlighter-rouge">Service 'sparkDriver' could not bind on a random free port. You may check whether configuring an appropriate binding address</code>.</p>

<p>Sin embargo, en este momento apareciÃ³ un error.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Causado por: org.apache.spark.api.python.PythonException: Traceback <span class="o">(</span>Ãºltima llamada mÃ¡s reciente<span class="o">)</span>:
  File <span class="s2">"/usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py"</span>, line 473, <span class="k">in </span>main
    raise Exception<span class="o">((</span><span class="s2">"Python en el worker tiene una versiÃ³n diferente %s que la del "</span> +
Exception: Python en el worker tiene una versiÃ³n diferente 3.8 que la del driver 3.9, PySpark no puede ejecutarse con versiones menores diferentes. Por favor, verifica que las variables de entorno PYSPARK_PYTHON y PYSPARK_DRIVER_PYTHON estÃ©n configuradas correctamente.
</code></pre></div></div>

<p>indica que se estÃ¡n ejecutando diferentes versiones de <code class="language-plaintext highlighter-rouge">Python</code>.</p>

<p>Modificar <code class="language-plaintext highlighter-rouge">.bash_profile</code>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
<span class="nv">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
</code></pre></div></div>

<p>Sin embargo, seguÃ­a apareciendo el mismo error. DespuÃ©s de investigar un poco, descubrÃ­ que podrÃ­a ser porque <code class="language-plaintext highlighter-rouge">spark</code> no carga esta variable de entorno cuando se ejecuta, y no utiliza las variables de entorno predeterminadas del terminal.</p>

<p>Necesitas configurar en el cÃ³digo:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
</code></pre></div></div>

<h1 id="configurar-entornos-de-spark">Configurar entornos de Spark</h1>
<p>os.environ[â€˜PYSPARK_PYTHONâ€™] = â€˜/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3â€™
os.environ[â€˜PYSPARK_DRIVER_PYTHONâ€™] = â€˜/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3â€™</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Esto se ejecutarÃ¡.

```shell
$ python sc.py
21/03/11 02:54:52 WARN NativeCodeLoader: No se pudo cargar la biblioteca nativa de Hadoop para su plataforma... utilizando clases Java integradas donde sea aplicable
Usando el perfil predeterminado de log4j de Spark: org/apache/spark/log4j-defaults.properties
Estableciendo el nivel de registro predeterminado en "WARN".
Para ajustar el nivel de registro, use sc.setLogLevel(newLevel). Para SparkR, use setLogLevel(newLevel).
PythonRDD[6] en RDD en PythonRDD.scala:53
</code></pre></div></div>

<p>En este momento se ha generado <code class="language-plaintext highlighter-rouge">b.txt</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>â”œâ”€â”€ b.txt
â”‚Â Â  â”œâ”€â”€ _SUCCESS
â”‚Â Â  â”œâ”€â”€ part-00000
â”‚Â Â  â””â”€â”€ part-00001
</code></pre></div></div>

<p>Ãbrelo.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>b.txt/part-00000
<span class="o">(</span><span class="s1">'college'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'two'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'things'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'worked'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'on,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'of'</span>, 8<span class="o">)</span>
<span class="o">(</span><span class="s1">'school,'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'writing'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'programming.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s2">"didn't"</span>, 4<span class="o">)</span>
<span class="o">(</span><span class="s1">'then,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'probably'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'are:'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'short'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'awful.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'They'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'plot,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'just'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'characters'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'them'</span>, 2<span class="o">)</span>
...
</code></pre></div></div>

<p>Â¡Ã‰xito! Â¿No te resulta familiar? Es como en el ejemplo de <code class="language-plaintext highlighter-rouge">Hadoop</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>Estos archivos se llaman <code class="language-plaintext highlighter-rouge">HDFS</code>. AquÃ­ se utiliza <code class="language-plaintext highlighter-rouge">Spark</code> para contar palabras. Con unas pocas lÃ­neas, parece muy conveniente.</p>

<h2 id="kubernetes">Kubernetes</h2>

<p>A continuaciÃ³n, vamos a explorar <code class="language-plaintext highlighter-rouge">Kubernetes</code>, tambiÃ©n conocido como <code class="language-plaintext highlighter-rouge">k8s</code>, donde el â€œ8â€ representa las 8 letras omitidas en la abreviatura. Es un sistema de cÃ³digo abierto diseÃ±ado para automatizar la implementaciÃ³n, escalado y gestiÃ³n de aplicaciones en contenedores.</p>

<p>La herramienta de lÃ­nea de comandos <code class="language-plaintext highlighter-rouge">kubectl</code> se utiliza para ejecutar comandos en un clÃºster de Kubernetes. Con ella, puedes desplegar aplicaciones, ver y gestionar recursos del clÃºster, asÃ­ como consultar registros (logs).</p>

<p>TambiÃ©n se puede instalar utilizando Homebrew.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>kubectl
</code></pre></div></div>

<p>Registro de salida:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">==&gt;</span> Descargando https://homebrew.bintray.com/bottles/kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Descargando desde https://d29vzk4ow07wi7.cloudfront.net/0b4f08bd1d47cb913d7cd4571e3394c6747dfbad7ff114c5589c8396c1085ecf?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Extrayendo kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Advertencias
La autocompletado de Bash se ha instalado en:
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Resumen
ğŸº  /usr/local/Cellar/kubernetes-cli/1.20.1: 246 archivos, 46.1MB
</code></pre></div></div>

<p>Se ha instalado correctamente.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl
kubectl controla el gestor del clÃºster de Kubernetes.
</code></pre></div></div>

<p>Encuentra mÃ¡s informaciÃ³n en: https://kubernetes.io/docs/reference/kubectl/overview/</p>

<p>Comandos BÃ¡sicos (Principiante):
  create        Crear un recurso desde un archivo o desde stdin.
  expose        Tomar un controlador de replicaciÃ³n, servicio, despliegue o pod y exponerlo como un nuevo Servicio de Kubernetes
  run           Ejecutar una imagen especÃ­fica en el clÃºster
  set           Establecer caracterÃ­sticas especÃ­ficas en objetos</p>

<p>Comandos BÃ¡sicos (Intermedios):
  explain       DocumentaciÃ³n de recursos
  get           Mostrar uno o varios recursos
  edit          Editar un recurso en el servidor
  delete        Eliminar recursos por nombres de archivo, stdin, recursos y nombres, o por recursos y selector de etiquetas</p>

<p>Comandos de Despliegue:
  rollout       Gestiona el despliegue de un recurso
  scale         Establece un nuevo tamaÃ±o para un Deployment, ReplicaSet o Replication Controller
  autoscale     Escala automÃ¡ticamente un Deployment, ReplicaSet o ReplicationController</p>

<p>Comandos de GestiÃ³n de ClÃºster:
  certificate   Modificar recursos de certificados.
  cluster-info  Mostrar informaciÃ³n del clÃºster.
  top           Mostrar el uso de recursos (CPU/Memoria/Almacenamiento).
  cordon        Marcar un nodo como no programable.
  uncordon      Marcar un nodo como programable.
  drain         Drenar un nodo en preparaciÃ³n para mantenimiento.
  taint         Actualizar los taints en uno o mÃ¡s nodos.</p>

<p>Comandos de ResoluciÃ³n de Problemas y DepuraciÃ³n:
  describe      Muestra detalles de un recurso especÃ­fico o un grupo de recursos
  logs          Imprime los registros (logs) de un contenedor en un pod
  attach        Conecta a un contenedor en ejecuciÃ³n
  exec          Ejecuta un comando en un contenedor
  port-forward  Redirige uno o mÃ¡s puertos locales a un pod
  proxy         Ejecuta un proxy hacia el servidor de la API de Kubernetes
  cp            Copia archivos y directorios hacia y desde contenedores
  auth          Inspecciona la autorizaciÃ³n
  debug         Crea sesiones de depuraciÃ³n para solucionar problemas en cargas de trabajo y nodos</p>

<p>Comandos avanzados:
  diff          Compara la versiÃ³n en vivo con la versiÃ³n que se aplicarÃ­a
  apply         Aplica una configuraciÃ³n a un recurso mediante un archivo o stdin
  patch         Actualiza campo(s) de un recurso
  replace       Reemplaza un recurso mediante un archivo o stdin
  wait          Experimental: Espera una condiciÃ³n especÃ­fica en uno o varios recursos.
  kustomize     Construye un objetivo de kustomization desde un directorio o una URL remota.</p>

<p>Comandos de ConfiguraciÃ³n:
  label         Actualiza las etiquetas en un recurso
  annotate      Actualiza las anotaciones en un recurso
  completion    Genera cÃ³digo de completado de shell para el shell especificado (bash o zsh)</p>

<p>Otros Comandos:
  api-resources Imprime los recursos de API soportados en el servidor
  api-versions  Imprime las versiones de API soportadas en el servidor, en el formato â€œgrupo/versiÃ³nâ€
  config        Modifica archivos de kubeconfig
  plugin        Proporciona utilidades para interactuar con plugins.
  version       Imprime la informaciÃ³n de la versiÃ³n del cliente y del servidor</p>

<p>Uso:
  kubectl [flags] [opciones]</p>

<p>Usa â€œkubectl <comando> --help" para obtener mÃ¡s informaciÃ³n sobre un comando especÃ­fico.
Usa "kubectl options" para ver una lista de opciones globales de lÃ­nea de comandos (aplicables a todos los comandos).</comando></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Vamos a crear un archivo de configuraciÃ³n.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  minReadySeconds: 5
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
</code></pre></div></div>

<p>El texto que has proporcionado es solo un bloque de cÃ³digo vacÃ­o. Si necesitas que traduzca algo mÃ¡s especÃ­fico o si hay mÃ¡s contenido que necesitas traducir, por favor, proporciÃ³nalo y estarÃ© encantado de ayudarte.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> simple_deployment.yaml
La conexiÃ³n al servidor localhost:8080 fue rechazada. Â¿Especificaste el host o puerto correcto?
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl cluster-info
</code></pre></div></div>

<p>Para depurar y diagnosticar mÃ¡s a fondo los problemas del clÃºster, utiliza â€˜kubectl cluster-info dumpâ€™.
La conexiÃ³n al servidor localhost:8080 fue rechazada - Â¿especificaste el host o puerto correcto?</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Cuando intentas ejecutarlo en el terminal de la pÃ¡gina oficial.

```shell
$ start.sh
Iniciando Kubernetes...minikube versiÃ³n: v1.8.1
commit: cbda04cf6bbe65e987ae52bb393c10099ab62014
* minikube v1.8.1 en Ubuntu 18.04
* Usando el controlador none basado en la configuraciÃ³n del usuario
* Ejecutando en localhost (CPUs=2, Memoria=2460MB, Disco=145651MB) ...
* La versiÃ³n del sistema operativo es Ubuntu 18.04.4 LTS
</code></pre></div></div>

<ul>
  <li>Preparando Kubernetes v1.17.3 en Docker 19.03.6 â€¦
    <ul>
      <li>kubelet.resolv-conf=/run/systemd/resolve/resolv.conf</li>
    </ul>
  </li>
  <li>Iniciando Kubernetes â€¦</li>
  <li>Habilitando complementos: default-storageclass, storage-provisioner</li>
  <li>Configurando el entorno del host local â€¦</li>
  <li>Â¡Listo! kubectl ahora estÃ¡ configurado para usar â€œminikubeâ€</li>
  <li>El complemento â€˜dashboardâ€™ estÃ¡ habilitado
Kubernetes Iniciado
```</li>
</ul>

<p>Continuemos de vuelta en nuestra terminal.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
<span class="nv">$ </span>kubectl version
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
La conexiÃ³n al servidor localhost:8080 fue rechazada - Â¿especificaste el host o puerto correcto?
</code></pre></div></div>

<p>Curiosamente, agregar la opciÃ³n <code class="language-plaintext highlighter-rouge">--client</code> no generÃ³ ningÃºn error.</p>

<p>La documentaciÃ³n dice que primero necesitas instalar <code class="language-plaintext highlighter-rouge">Minikube</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>minikube
<span class="o">==&gt;</span> Descargando https://homebrew.bintray.com/bottles/minikube-1.16.0.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Descargando desde https://d29vzk4ow07wi7.cloudfront.net/1b6d7d1b97b11b6b07e4fa531c2dc21770da290da9b2816f360fd923e00c85fc?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Extrayendo minikube-1.16.0.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Notas
La completaciÃ³n de Bash se ha instalado en:
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Resumen
ğŸº  /usr/local/Cellar/minikube/1.16.0: 8 archivos, 64.6MB
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube start
ğŸ˜„  minikube v1.16.0 en Darwin 11.2.2
ğŸ‰  Â¡minikube 1.18.1 estÃ¡ disponible! DescÃ¡rgalo: https://github.com/kubernetes/minikube/releases/tag/v1.18.1
ğŸ’¡  Para desactivar esta notificaciÃ³n, ejecuta: <span class="s1">'minikube config set WantUpdateNotification false'</span>
</code></pre></div></div>

<p>âœ¨  SelecciÃ³n automÃ¡tica del controlador virtualbox<br />
ğŸ’¿  Descargando la imagen de arranque de la VM â€¦<br />
    &gt; minikube-v1.16.0.iso.sha256: 65 B / 65 B [â€”â€”â€”â€”-] 100.00% ? p/s 0s<br />
    &gt; minikube-v1.16.0.iso: 212.62 MiB / 212.62 MiB [] 100.00% 5.32 MiB p/s 40s<br />
ğŸ‘  Iniciando el nodo del plano de control minikube en el clÃºster minikube<br />
ğŸ’¾  Descargando la precarga de Kubernetes v1.20.0 â€¦<br />
    &gt; preloaded-images-k8s-v8-v1â€¦.: 491.00 MiB / 491.00 MiB  100.00% 7.52 MiB<br />
ğŸ”¥  Creando la VM de virtualbox (CPUs=2, Memoria=4000MB, Disco=20000MB) â€¦<br />
â—  Esta VM estÃ¡ teniendo problemas para acceder a https://k8s.gcr.io<br />
ğŸ’¡  Para descargar nuevas imÃ¡genes externas, es posible que necesites configurar un proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/<br />
ğŸ³  Preparando Kubernetes v1.20.0 en Docker 20.10.0 â€¦<br />
    â–ª Generando certificados y claves â€¦<br />
    â–ª Iniciando el plano de control â€¦<br />
    â–ª Configurando reglas de RBAC â€¦<br />
ğŸ”  Verificando componentes de Kubernetesâ€¦<br />
ğŸŒŸ  Complementos habilitados: storage-provisioner, default-storageclass<br />
ğŸ„  Â¡Listo! kubectl ahora estÃ¡ configurado para usar el clÃºster â€œminikubeâ€ y el espacio de nombres â€œdefaultâ€ por defecto</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
A continuaciÃ³n, accedemos a este clÃºster.

```shell
$ kubectl get po -A
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
kube-system   coredns-74ff55c5b-ndbcr            1/1     Running   0          60s
kube-system   etcd-minikube                      0/1     Running   0          74s
kube-system   kube-apiserver-minikube            1/1     Running   0          74s
kube-system   kube-controller-manager-minikube   1/1     Running   0          74s
kube-system   kube-proxy-g2296                   1/1     Running   0          60s
kube-system   kube-scheduler-minikube            0/1     Running   0          74s
kube-system   storage-provisioner                1/1     Running   1          74s
</code></pre></div></div>

<p>Para abrir el panel de control de <code class="language-plaintext highlighter-rouge">minikube</code>, ejecuta el siguiente comando:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube dashboard
</code></pre></div></div>

<p>Esto abrirÃ¡ automÃ¡ticamente el panel de control de Kubernetes en tu navegador predeterminado.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube dashboard
ğŸ”Œ  Habilitando el panel de control ...
ğŸ¤”  Verificando la salud del panel de control ...
ğŸš€  Lanzando el proxy ...
ğŸ¤”  Verificando la salud del proxy ...
ğŸ‰  Abriendo http://127.0.0.1:50030/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ en tu navegador predeterminado...
</code></pre></div></div>

<p><img src="assets/images/distributed/k8s.png" alt="k8s" /></p>

<p>Â¿CÃ³mo apagarlo?</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube
minikube provisiona y gestiona clÃºsteres locales de Kubernetes optimizados para flujos de trabajo de desarrollo.
</code></pre></div></div>

<p>Comandos bÃ¡sicos:
  start          Inicia un clÃºster local de Kubernetes
  status         Obtiene el estado de un clÃºster local de Kubernetes
  stop           Detiene un clÃºster local de Kubernetes en ejecuciÃ³n
  delete         Elimina un clÃºster local de Kubernetes
  dashboard      Accede al panel de control de Kubernetes que se ejecuta dentro del clÃºster de minikube
  pause          Pausa Kubernetes
  unpause        Reanuda Kubernetes</p>

<p>Comandos de ImÃ¡genes:
  docker-env     Configura el entorno para usar el demonio Docker de minikube
  podman-env     Configura el entorno para usar el servicio Podman de minikube
  cache          Agrega, elimina o sube una imagen local a minikube</p>

<p>Comandos de ConfiguraciÃ³n y GestiÃ³n:
  addons         Habilitar o deshabilitar un complemento de minikube
  config         Modificar valores de configuraciÃ³n persistentes
  profile        Obtener o listar los perfiles actuales (clusters)
  update-context Actualizar kubeconfig en caso de un cambio de IP o puerto</p>

<p>Comandos de Red y Conectividad:
  service        Devuelve una URL para conectarse a un servicio
  tunnel         Conecta a servicios de tipo LoadBalancer</p>

<p>Comandos avanzados:
  mount          Monta el directorio especificado en minikube
  ssh            Inicia sesiÃ³n en el entorno de minikube (para depuraciÃ³n)
  kubectl        Ejecuta un binario de kubectl que coincida con la versiÃ³n del clÃºster
  node           Agrega, elimina o lista nodos adicionales</p>

<p>Comandos de ResoluciÃ³n de Problemas:
  ssh-key        Recupera la ruta de la clave de identidad ssh del nodo especificado
  ssh-host       Recupera la clave de host ssh del nodo especificado
  ip             Recupera la direcciÃ³n IP del nodo especificado
  logs           Devuelve los registros para depurar un clÃºster local de Kubernetes
  update-check   Imprime el nÃºmero de versiÃ³n actual y la Ãºltima versiÃ³n disponible
  version        Imprime la versiÃ³n de minikube</p>

<p>Otros Comandos:
  completion     Generar autocompletado de comandos para un shell</p>

<p>Usa â€œminikube <comando> --help" para obtener mÃ¡s informaciÃ³n sobre un comando especÃ­fico.</comando></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
El comando visible es `minikube stop`.

Volviendo a `kubernetes`, ahora funciona correctamente.

```shell
$ kubectl cluster-info
El plano de control de Kubernetes estÃ¡ ejecutÃ¡ndose en https://192.168.99.100:8443
KubeDNS estÃ¡ ejecutÃ¡ndose en https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
</code></pre></div></div>

<p>Para depurar y diagnosticar mÃ¡s a fondo los problemas del clÃºster, utiliza â€˜kubectl cluster-info dumpâ€™.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Cuando abrimos `https://192.168.99.100:8443`, el navegador muestra:

```json
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "Failure",
  "message": "prohibido: El usuario \"system:anonymous\" no puede acceder a la ruta \"/\"",
  "reason": "Prohibido",
  "details": {
    
  },
  "code": 403
}
</code></pre></div></div>

<p>Accede a <code class="language-plaintext highlighter-rouge">https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</code>:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Status"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"apiVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Fallo"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">"el servicio </span><span class="se">\"</span><span class="s2">kube-dns:dns</span><span class="se">\"</span><span class="s2"> estÃ¡ prohibido: El usuario </span><span class="se">\"</span><span class="s2">system:anonymous</span><span class="se">\"</span><span class="s2"> no puede obtener el recurso </span><span class="se">\"</span><span class="s2">services/proxy</span><span class="se">\"</span><span class="s2"> en el grupo de API </span><span class="se">\"\"</span><span class="s2"> en el espacio de nombres </span><span class="se">\"</span><span class="s2">kube-system</span><span class="se">\"</span><span class="s2">"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"reason"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Prohibido"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"details"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-dns:dns"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"services"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"code"</span><span class="p">:</span><span class="w"> </span><span class="mi">403</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Vamos a probar la configuraciÃ³n que acabamos de hacer.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> simple_deployment.yaml
deployment.apps/nginx-deployment creado
</code></pre></div></div>

<p>Hay un pequeÃ±o problema. Sin embargo, hasta este punto, ya hemos logrado ejecutar <code class="language-plaintext highlighter-rouge">kubernetes</code>. Vamos a detenerlo por ahora y seguiremos jugando con Ã©l mÃ¡s adelante.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube stop
âœ‹  Deteniendo el nodo <span class="s2">"minikube"</span>  ...
ğŸ›‘  1 nodo detenido.
</code></pre></div></div>

<p>Verificar si ha terminado.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>w<span class="nv">$ </span>minikube dashboard
ğŸ¤·  El nodo del plano de control debe estar en ejecuciÃ³n para este comando
ğŸ‘‰  Para iniciar un clÃºster, ejecuta: <span class="s2">"minikube start"</span>
</code></pre></div></div>

<h2 id="docker">Docker</h2>

<p><code class="language-plaintext highlighter-rouge">Docker</code> es tambiÃ©n una plataforma de contenedores que ayuda a acelerar la creaciÃ³n, el intercambio y la ejecuciÃ³n de aplicaciones modernas. Descarga la aplicaciÃ³n desde el sitio web oficial.</p>

<p><img src="assets/images/distributed/docker.png" alt="docker" /></p>

<p>El cliente se siente un poco lento. Usemos la lÃ­nea de comandos.</p>

<div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker
</code></pre></div></div>

<p>Uso: docker [OPCIONES] COMANDO</p>

<p>Un entorno de ejecuciÃ³n autosuficiente para contenedores</p>

<p>Opciones:
      â€“config string      UbicaciÃ³n de los archivos de configuraciÃ³n del cliente (por defecto â€œ/Users/lzw/.dockerâ€)
  -c, â€“context string     Nombre del contexto a utilizar para conectarse al daemon (sobrescribe la variable de entorno DOCKER_HOST y el contexto predeterminado establecido con â€œdocker context useâ€)
  -D, â€“debug              Habilita el modo de depuraciÃ³n
  -H, â€“host list          Socket(s) del daemon al que conectarse
  -l, â€“log-level string   Establece el nivel de registro (â€œdebugâ€|â€infoâ€|â€warnâ€|â€errorâ€|â€fatalâ€) (por defecto â€œinfoâ€)
      â€“tls                Usar TLS; implÃ­cito con â€“tlsverify
      â€“tlscacert string   Confiar solo en certificados firmados por esta CA (por defecto â€œ/Users/lzw/.docker/ca.pemâ€)
      â€“tlscert string     Ruta al archivo de certificado TLS (por defecto â€œ/Users/lzw/.docker/cert.pemâ€)
      â€“tlskey string      Ruta al archivo de clave TLS (por defecto â€œ/Users/lzw/.docker/key.pemâ€)
      â€“tlsverify          Usar TLS y verificar el remoto
  -v, â€“version            Imprime la informaciÃ³n de la versiÃ³n y sale</p>

<p>Comandos de GestiÃ³n:
  app*        Docker App (Docker Inc., v0.9.1-beta3)
  builder     Gestionar construcciones
  buildx*     Construir con BuildKit (Docker Inc., v0.5.1-docker)
  config      Gestionar configuraciones de Docker
  container   Gestionar contenedores
  context     Gestionar contextos
  image       Gestionar imÃ¡genes
  manifest    Gestionar manifiestos de imÃ¡genes de Docker y listas de manifiestos
  network     Gestionar redes
  node        Gestionar nodos de Swarm
  plugin      Gestionar plugins
  scan*       Docker Scan (Docker Inc., v0.5.0)
  secret      Gestionar secretos de Docker
  service     Gestionar servicios
  stack       Gestionar pilas de Docker
  swarm       Gestionar Swarm
  system      Gestionar Docker
  trust       Gestionar la confianza en las imÃ¡genes de Docker
  volume      Gestionar volÃºmenes</p>

<p>Comandos:
  attach      Conectar las entradas, salidas y flujos de error estÃ¡ndar locales a un contenedor en ejecuciÃ³n
  build       Construir una imagen a partir de un Dockerfile
  commit      Crear una nueva imagen a partir de los cambios de un contenedor
  cp          Copiar archivos/carpetas entre un contenedor y el sistema de archivos local
  create      Crear un nuevo contenedor
  diff        Inspeccionar cambios en archivos o directorios en el sistema de archivos de un contenedor
  events      Obtener eventos en tiempo real desde el servidor
  exec        Ejecutar un comando en un contenedor en ejecuciÃ³n
  export      Exportar el sistema de archivos de un contenedor como un archivo tar
  history     Mostrar el historial de una imagen
  images      Listar imÃ¡genes
  import      Importar el contenido de un archivo tar para crear una imagen del sistema de archivos
  info        Mostrar informaciÃ³n general del sistema
  inspect     Devolver informaciÃ³n de bajo nivel sobre objetos de Docker
  kill        Detener uno o mÃ¡s contenedores en ejecuciÃ³n
  load        Cargar una imagen desde un archivo tar o STDIN
  login       Iniciar sesiÃ³n en un registro de Docker
  logout      Cerrar sesiÃ³n de un registro de Docker
  logs        Obtener los registros de un contenedor
  pause       Pausar todos los procesos dentro de uno o mÃ¡s contenedores
  port        Listar mapeos de puertos o un mapeo especÃ­fico para el contenedor
  ps          Listar contenedores
  pull        Descargar una imagen o un repositorio desde un registro
  push        Subir una imagen o un repositorio a un registro
  rename      Renombrar un contenedor
  restart     Reiniciar uno o mÃ¡s contenedores
  rm          Eliminar uno o mÃ¡s contenedores
  rmi         Eliminar una o mÃ¡s imÃ¡genes
  run         Ejecutar un comando en un nuevo contenedor
  save        Guardar una o mÃ¡s imÃ¡genes en un archivo tar (transmitido a STDOUT por defecto)
  search      Buscar imÃ¡genes en Docker Hub
  start       Iniciar uno o mÃ¡s contenedores detenidos
  stats       Mostrar una transmisiÃ³n en vivo de las estadÃ­sticas de uso de recursos de los contenedores
  stop        Detener uno o mÃ¡s contenedores en ejecuciÃ³n
  tag         Crear una etiqueta TARGET_IMAGE que haga referencia a SOURCE_IMAGE
  top         Mostrar los procesos en ejecuciÃ³n de un contenedor
  unpause     Reanudar todos los procesos dentro de uno o mÃ¡s contenedores
  update      Actualizar la configuraciÃ³n de uno o mÃ¡s contenedores
  version     Mostrar la informaciÃ³n de la versiÃ³n de Docker
  wait        Bloquear hasta que uno o mÃ¡s contenedores se detengan, luego imprimir sus cÃ³digos de salida</p>

<p>Ejecuta â€˜docker COMANDO â€“helpâ€™ para obtener mÃ¡s informaciÃ³n sobre un comando.</p>

<p>Para obtener mÃ¡s ayuda con Docker, consulta nuestras guÃ­as en https://docs.docker.com/go/guides/</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Siguiendo el tutorial, vamos a intentarlo.

```shell
$ docker run -d -p 80:80 docker/getting-started
No se pudo encontrar la imagen 'docker/getting-started:latest' localmente
latest: Extrayendo de docker/getting-started
aad63a933944: ExtraÃ­do completamente
b14da7a62044: ExtraÃ­do completamente
343784d40d66: ExtraÃ­do completamente
6f617e610986: ExtraÃ­do completamente
Digest: sha256:d2c4fb0641519ea208f20ab03dc40ec2a5a53fdfbccca90bef14f870158ed577
Estado: Se descargÃ³ una imagen mÃ¡s reciente para docker/getting-started:latest
815f13fc8f99f6185257980f74c349e182842ca572fe60ff62cbb15641199eaf
docker: Error de respuesta del daemon: Los puertos no estÃ¡n disponibles: escuchar tcp 0.0.0.0:80: bind: la direcciÃ³n ya estÃ¡ en uso.
</code></pre></div></div>

<p>Cambiar el puerto.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:80 docker/getting-started
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p><img src="assets/images/distributed/docker_run.png" alt="docker_run" /></p>

<p>Al abrir el navegador, confirmamos que hemos logrado ejecutar <code class="language-plaintext highlighter-rouge">docker</code> correctamente.</p>

<p><img src="assets/images/distributed/browser.png" alt="navegador" /></p>

<p>DetÃ©n el contenedor. Usa el <code class="language-plaintext highlighter-rouge">ID</code> que acabas de obtener.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker stop 45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p>En ese momento, ya no se podÃ­a abrir el sitio web.</p>

<p>Esto indica que <code class="language-plaintext highlighter-rouge">docker</code> se asemeja a una mÃ¡quina virtual.</p>

<h2 id="flink">Flink</h2>

<p>Abre el sitio web oficial.</p>

<p><img src="assets/images/distributed/flink-home-graphic.png" alt="flink-home-graphic" /></p>

<p><code class="language-plaintext highlighter-rouge">Flink</code> se refiere al cÃ¡lculo <code class="language-plaintext highlighter-rouge">Stateful</code> de flujos de datos. Â¿QuÃ© significa <code class="language-plaintext highlighter-rouge">Stateful</code>? TodavÃ­a no lo tengo claro. La imagen anterior es bastante interesante. Vamos a intentarlo.</p>

<p>Se dice que se necesita un entorno Java.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>java <span class="nt">-version</span>
java version <span class="s2">"1.8.0_151"</span>
Java<span class="o">(</span>TM<span class="o">)</span> SE Runtime Environment <span class="o">(</span>build 1.8.0_151-b12<span class="o">)</span>
Java HotSpot<span class="o">(</span>TM<span class="o">)</span> 64-Bit Server VM <span class="o">(</span>build 25.151-b12, mixed mode<span class="o">)</span>
</code></pre></div></div>

<p>Descarga la Ãºltima versiÃ³n <code class="language-plaintext highlighter-rouge">flink-1.12.2-bin-scala_2.11.tar</code> desde el sitio web oficial.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/start-cluster.sh
Iniciando el clÃºster.
Iniciando el demonio standalonesession en el host lzwjava.
Iniciando el demonio taskexecutor en el host lzwjava.
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/flink run examples/streaming/WordCount.jar
Ejecutando el ejemplo WordCount con el conjunto de datos de entrada predeterminado.
Usa <span class="nt">--input</span> para especificar un archivo de entrada.
Imprimiendo el resultado en la salida estÃ¡ndar. Usa <span class="nt">--output</span> para especificar la ruta de salida.
El trabajo ha sido enviado con el JobID 60f37647c20c2a6654359bd34edab807
La ejecuciÃ³n del programa ha finalizado
El trabajo con JobID 60f37647c20c2a6654359bd34edab807 ha finalizado.
Tiempo de ejecuciÃ³n del trabajo: 757 ms
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">tail </span>log/flink-<span class="k">*</span><span class="nt">-taskexecutor-</span><span class="k">*</span>.out
<span class="o">(</span>nymph,1<span class="o">)</span>
<span class="o">(</span><span class="k">in</span>,3<span class="o">)</span>
<span class="o">(</span>thy,1<span class="o">)</span>
<span class="o">(</span>orisons,1<span class="o">)</span>
<span class="o">(</span>be,4<span class="o">)</span>
<span class="o">(</span>all,2<span class="o">)</span>
<span class="o">(</span>my,1<span class="o">)</span>
<span class="o">(</span>sins,1<span class="o">)</span>
<span class="o">(</span>remember,1<span class="o">)</span>
<span class="o">(</span>d,4<span class="o">)</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/stop-cluster.sh
Deteniendo el demonio taskexecutor <span class="o">(</span>pid: 41812<span class="o">)</span> en el host lzwjava.
</code></pre></div></div>

<p>Bueno, lo he conseguido. Se puede ver que es muy similar a <code class="language-plaintext highlighter-rouge">Spark</code>.</p>

<h2 id="kylin">Kylin</h2>

<p>Abre el sitio web oficial.</p>

<blockquote>
  <p>Apache Kylinâ„¢ es un AlmacÃ©n de Datos AnalÃ­ticos distribuido y de cÃ³digo abierto para Big Data; fue diseÃ±ado para proporcionar capacidades OLAP (Procesamiento AnalÃ­tico en LÃ­nea) en la era del big data. Al renovar la tecnologÃ­a de cubos multidimensionales y precÃ¡lculo en Hadoop y Spark, Kylin es capaz de lograr una velocidad de consulta casi constante, independientemente del volumen de datos en constante crecimiento. Al reducir la latencia de las consultas de minutos a fracciones de segundo, Kylin devuelve el anÃ¡lisis en lÃ­nea al big data.</p>
</blockquote>

<blockquote>
  <p>Apache Kylinâ„¢ te permite consultar miles de millones de filas con una latencia de menos de un segundo en 3 pasos.</p>

  <ol>
    <li>Identifica un esquema de estrella o copo de nieve en Hadoop.</li>
    <li>Construye un cubo a partir de las tablas identificadas.</li>
    <li>Consulta utilizando ANSI-SQL y obtÃ©n resultados en menos de un segundo, a travÃ©s de ODBC, JDBC o una API RESTful.</li>
  </ol>
</blockquote>

<p><img src="assets/images/distributed/kylin_diagram.png" alt="kylin_diagram" /></p>

<p>BÃ¡sicamente, es una capa para analizar grandes volÃºmenes de datos. Con ella, puedes realizar consultas de manera extremadamente rÃ¡pida. ActÃºa como un puente.</p>

<p>Lamentablemente, actualmente solo se puede usar en un entorno <code class="language-plaintext highlighter-rouge">Linux</code>. VolverÃ© a jugar con esto mÃ¡s adelante.</p>

<h2 id="mongodb">MongoDB</h2>

<p>Esto tambiÃ©n es una base de datos. Intenta instalarlo.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew tap mongodb/brew
<span class="o">==&gt;</span> Tapping mongodb/brew
Clonando en <span class="s1">'/usr/local/Homebrew/Library/Taps/mongodb/homebrew-brew'</span>...
remote: Enumerando objetos: 63, listo.
remote: Contando objetos: 100% <span class="o">(</span>63/63<span class="o">)</span>, listo.
remote: Comprimiendo objetos: 100% <span class="o">(</span>62/62<span class="o">)</span>, listo.
remote: Total 566 <span class="o">(</span>delta 21<span class="o">)</span>, reusados 6 <span class="o">(</span>delta 1<span class="o">)</span>, reusados del pack 503
Recibiendo objetos: 100% <span class="o">(</span>566/566<span class="o">)</span>, 121.78 KiB | 335.00 KiB/s, listo.
Resolviendo deltas: 100% <span class="o">(</span>259/259<span class="o">)</span>, listo.
Tapped 11 fÃ³rmulas <span class="o">(</span>39 archivos, 196.2KB<span class="o">)</span><span class="nb">.</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>mongodb-community@4.4
<span class="o">==&gt;</span> Instalando mongodb-community desde mongodb/brew
<span class="o">==&gt;</span> Descargando https://fastdl.mongodb.org/tools/db/mongodb-database-tools-macos-x86_64-100.3.0.zip
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Descargando https://fastdl.mongodb.org/osx/mongodb-macos-x86_64-4.4.3.tgz
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Instalando dependencias para mongodb/brew/mongodb-community: mongodb-database-tools
<span class="o">==&gt;</span> Instalando dependencia de mongodb/brew/mongodb-community: mongodb-database-tools
Error: El paso <span class="sb">`</span>brew <span class="nb">link</span><span class="sb">`</span> no se completÃ³ correctamente
La fÃ³rmula se construyÃ³, pero no se enlazÃ³ simbÃ³licamente en /usr/local
No se pudo crear el enlace simbÃ³lico para bin/bsondump
El objetivo /usr/local/bin/bsondump
es un enlace simbÃ³lico que pertenece a mongodb. Puedes desenlazarlo:
  brew <span class="nb">unlink </span>mongodb
</code></pre></div></div>

<p>Para forzar el enlace y sobrescribir todos los archivos en conflicto:
  brew link â€“overwrite mongodb-database-tools</p>

<p>Para listar todos los archivos que serÃ­an eliminados:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  brew <span class="nb">link</span> <span class="nt">--overwrite</span> <span class="nt">--dry-run</span> mongodb-database-tools
</code></pre></div></div>

<p>Los archivos que podrÃ­an estar en conflicto son:
/usr/local/bin/bsondump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/bsondump
/usr/local/bin/mongodump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongodump
/usr/local/bin/mongoexport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoexport
/usr/local/bin/mongofiles -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongofiles
/usr/local/bin/mongoimport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoimport
/usr/local/bin/mongorestore -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongorestore
/usr/local/bin/mongostat -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongostat
/usr/local/bin/mongotop -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongotop
==&gt; Resumen
ğŸº  /usr/local/Cellar/mongodb-database-tools/100.3.0: 13 archivos, 154MB, construidos en 11 segundos
==&gt; Instalando mongodb/brew/mongodb-community
Error: El paso <code class="language-plaintext highlighter-rouge">brew link</code> no se completÃ³ correctamente
La fÃ³rmula se construyÃ³, pero no se enlazÃ³ simbÃ³licamente en /usr/local
No se pudo crear el enlace simbÃ³lico para bin/mongo
El objetivo /usr/local/bin/mongo
es un enlace simbÃ³lico que pertenece a mongodb. Puedes desenlazarlo:
  brew unlink mongodb</p>

<p>Para forzar el enlace y sobrescribir todos los archivos en conflicto:
  brew link â€“overwrite mongodb-community</p>

<p>Para listar todos los archivos que se eliminarÃ­an:
  brew link â€“overwrite â€“dry-run mongodb-community</p>

<p>Los archivos que podrÃ­an estar en conflicto son:
/usr/local/bin/mongo -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongo
/usr/local/bin/mongod -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongod
/usr/local/bin/mongos -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongos
==&gt; Advertencias
Para iniciar mongodb/brew/mongodb-community con launchd ahora y reiniciar al iniciar sesiÃ³n:
  brew services start mongodb/brew/mongodb-community
O, si no deseas/necesitas un servicio en segundo plano, simplemente puedes ejecutar:
  mongod â€“config /usr/local/etc/mongod.conf
==&gt; Resumen
ğŸº  /usr/local/Cellar/mongodb-community/4.4.3: 11 archivos, 156.8MB, construido en 10 segundos
==&gt; Advertencias
==&gt; mongodb-community
Para iniciar mongodb/brew/mongodb-community con launchd ahora y reiniciar al iniciar sesiÃ³n:
  brew services start mongodb/brew/mongodb-community
O, si no deseas/necesitas un servicio en segundo plano, simplemente puedes ejecutar:
  mongod â€“config /usr/local/etc/mongod.conf</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Anteriormente instalÃ© una versiÃ³n antigua. DesvinculÃ© los siguientes enlaces.

```shell
$ brew unlink mongodb
Desvinculando /usr/local/Cellar/mongodb/3.0.7... 11 enlaces simbÃ³licos eliminados
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--version</span>
db version v4.4.3
Build Info: <span class="o">{</span>
    <span class="s2">"version"</span>: <span class="s2">"4.4.3"</span>,
    <span class="s2">"gitVersion"</span>: <span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span>,
    <span class="s2">"modules"</span>: <span class="o">[]</span>,
    <span class="s2">"allocator"</span>: <span class="s2">"system"</span>,
    <span class="s2">"environment"</span>: <span class="o">{</span>
        <span class="s2">"distarch"</span>: <span class="s2">"x86_64"</span>,
        <span class="s2">"target_arch"</span>: <span class="s2">"x86_64"</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Luego, ejecuta <code class="language-plaintext highlighter-rouge">mongod</code> para iniciar el servidor de la base de datos mongo. Sin embargo, la primera vez que lo intentÃ©, me indicÃ³ que <code class="language-plaintext highlighter-rouge">/data/db</code> no existÃ­a. AsÃ­ que creÃ© un directorio, <code class="language-plaintext highlighter-rouge">~/mongodb</code>, para guardar los archivos de la base de datos.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--dbpath</span> ~/mongodb
</code></pre></div></div>

<p>Salida como:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.838+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23285</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Deshabilitando automÃ¡ticamente TLS 1.0, para forzar la habilitaciÃ³n de TLS 1.0 especifique --sslDisabledProtocols 'none'"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"W"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"ASIO"</span><span class="p">,</span><span class="w">     </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">22601</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"No se configurÃ³ TransportLayer durante el inicio de NetworkInterface"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"NETWORK"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4648602</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"TCP FastOpen implÃ­cito en uso."</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"STORAGE"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4615611</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"MongoDB iniciando"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"pid"</span><span class="p">:</span><span class="mi">46256</span><span class="p">,</span><span class="nl">"port"</span><span class="p">:</span><span class="mi">27017</span><span class="p">,</span><span class="nl">"dbPath"</span><span class="p">:</span><span class="s2">"/Users/lzw/mongodb"</span><span class="p">,</span><span class="nl">"architecture"</span><span class="p">:</span><span class="s2">"64-bit"</span><span class="p">,</span><span class="nl">"host"</span><span class="p">:</span><span class="s2">"lzwjava"</span><span class="p">}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23403</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"InformaciÃ³n de compilaciÃ³n"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"buildInfo"</span><span class="p">:{</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"4.4.3"</span><span class="p">,</span><span class="nl">"gitVersion"</span><span class="p">:</span><span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span><span class="p">,</span><span class="nl">"modules"</span><span class="p">:[],</span><span class="nl">"allocator"</span><span class="p">:</span><span class="s2">"system"</span><span class="p">,</span><span class="nl">"environment"</span><span class="p">:{</span><span class="nl">"distarch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">,</span><span class="nl">"target_arch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">}}}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.843+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">51765</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Sistema Operativo"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"os"</span><span class="p">:{</span><span class="nl">"name"</span><span class="p">:</span><span class="s2">"Mac OS X"</span><span class="p">,</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"20.3.0"</span><span class="p">}}}</span><span class="w">
</span><span class="err">...</span><span class="w">
</span></code></pre></div></div>

<p>Se puede ver que todo estÃ¡ en formato <code class="language-plaintext highlighter-rouge">JSON</code>. MongoDB guarda todos los archivos de datos en formato <code class="language-plaintext highlighter-rouge">JSON</code>. Luego, abre otra pestaÃ±a del terminal.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongo
MongoDB shell version v4.4.3
conectando a: mongodb://127.0.0.1:27017/?compressors<span class="o">=</span>disabled&amp;gssapiServiceName<span class="o">=</span>mongodb
SesiÃ³n implÃ­cita: sesiÃ³n <span class="o">{</span> <span class="s2">"id"</span> : UUID<span class="o">(</span><span class="s2">"4f55c561-70d3-4289-938d-4b90a284891f"</span><span class="o">)</span> <span class="o">}</span>
VersiÃ³n del servidor MongoDB: 4.4.3
<span class="nt">---</span>
El servidor generÃ³ estas advertencias de inicio al arrancar:
        2021-03-11T18:17:33.743+08:00: El control de acceso no estÃ¡ habilitado para la base de datos. El acceso de lectura y escritura a los datos y la configuraciÃ³n no estÃ¡ restringido.
        2021-03-11T18:17:33.743+08:00: Este servidor estÃ¡ vinculado a localhost. Los sistemas remotos no podrÃ¡n conectarse a este servidor. Inicie el servidor con <span class="nt">--bind_ip</span> &lt;direcciÃ³n&gt; para especificar las direcciones IP desde las que debe responder, o con <span class="nt">--bind_ip_all</span> para vincularlo a todas las interfaces. Si este comportamiento es deseado, inicie el servidor con <span class="nt">--bind_ip</span> 127.0.0.1 para desactivar esta advertencia.
        2021-03-11T18:17:33.743+08:00: LÃ­mites suaves demasiado bajos.
        2021-03-11T18:17:33.743+08:00:         valor actual: 4864
        2021-03-11T18:17:33.743+08:00:         mÃ­nimo recomendado: 64000
<span class="nt">---</span>
<span class="nt">---</span>
        Habilite el servicio de monitoreo en la nube gratuito de MongoDB, que recibirÃ¡ y mostrarÃ¡
        mÃ©tricas sobre su implementaciÃ³n <span class="o">(</span>utilizaciÃ³n del disco, CPU, estadÃ­sticas de operaciones, etc.<span class="o">)</span><span class="nb">.</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Los datos de monitoreo estarÃ¡n disponibles en un sitio web de MongoDB con una URL Ãºnica a la que usted
    y cualquier persona con la que comparta la URL podrÃ¡n acceder. MongoDB puede utilizar esta informaciÃ³n para realizar mejoras en el producto
    y para sugerirle productos de MongoDB y opciones de implementaciÃ³n.
</code></pre></div></div>

<p>Para habilitar el monitoreo gratuito, ejecuta el siguiente comando: <code class="language-plaintext highlighter-rouge">db.enableFreeMonitoring()</code>
Para deshabilitar permanentemente este recordatorio, ejecuta el siguiente comando: <code class="language-plaintext highlighter-rouge">db.disableFreeMonitoring()</code></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
A continuaciÃ³n, puedes intentar insertar datos y consultar datos.

```shell
&gt; db.inventory.insertOne(
...    { item: "canvas", qty: 100, tags: ["cotton"], size: { h: 28, w: 35.5, uom: "cm" } }
... )
{
	"acknowledged" : true,
	"insertedId" : ObjectId("6049ef91b653541cf355facb")
}
&gt;
&gt; db.inventory.find()
{ "_id" : ObjectId("6049ef91b653541cf355facb"), "item" : "canvas", "qty" : 100, "tags" : [ "cotton" ], "size" : { "h" : 28, "w" : 35.5, "uom" : "cm" } }
</code></pre></div></div>

<h2 id="finalmente">Finalmente</h2>

<p>Hasta aquÃ­ por ahora. MÃ¡s adelante nos pondremos manos a la obra con otras herramientas. Â¿CuÃ¡l es el propÃ³sito de todo esto? Probablemente es tener primero una idea general. El comienzo siempre es lo mÃ¡s difÃ­cil, y nosotros hemos pasado por todo esto de una vez. Esto nos da confianza, y lo que sigue es seguir explorando mÃ¡s a fondo estos programas.</p>

<h2 id="prÃ¡ctica">PrÃ¡ctica</h2>

<ul>
  <li>Los estudiantes exploran de manera similar como se mencionÃ³ anteriormente.</li>
</ul>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-es" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
