<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Introducción a la Computación en la Nube y el Big Data</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Introducción a la Computación en la Nube y el Big Data | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Introducción a la Computación en la Nube y el Big Data" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="es" />
<meta name="description" content="Esta lección cubre los siguientes temas:" />
<meta property="og:description" content="Esta lección cubre los siguientes temas:" />
<link rel="canonical" href="https://lzwjava.github.io/distributed-es" />
<meta property="og:url" content="https://lzwjava.github.io/distributed-es" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-10T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Introducción a la Computación en la Nube y el Big Data" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2021-03-10T00:00:00+08:00","datePublished":"2021-03-10T00:00:00+08:00","description":"Esta lección cubre los siguientes temas:","headline":"Introducción a la Computación en la Nube y el Big Data","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/distributed-es"},"url":"https://lzwjava.github.io/distributed-es"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=fe13842666dd2631771e2916b70907f46ff54eb6">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=fe13842666dd2631771e2916b70907f46ff54eb6" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Introducción a la Computación en la Nube y el Big Data | Original, traducido por IA
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/es/2021-03-10-distributed-es.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postses2021-03-10-distributed-es.md</span> -->
      

      <!-- <span>2021-03-10-distributed-es.md</span> -->

      
        

        
          
          <a href="#" class="button">2021.03</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/distributed-en" >English</option>
        <option value="/distributed-zh" >中文</option>
        <option value="/distributed-ja" >日本語</option>
        <option value="/distributed-es" selected>Español</option>
        <option value="/distributed-hi" >हिंदी</option>
        <option value="/distributed-fr" >Français</option>
        <option value="/distributed-de" >Deutsch</option>
        <option value="/distributed-ar" >العربية</option>
        <option value="/distributed-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>Esta lección cubre los siguientes temas:</p>

<ul>
  <li>Spark</li>
  <li>Hadoop</li>
  <li>Kubernetes</li>
  <li>Docker</li>
  <li>Flink</li>
  <li>MongoDB</li>
</ul>

<p>Cuando se habla de computación en la nube, parece que no se puede evitar mencionar muchas herramientas: Hadoop, Hive, Hbase, ZooKeeper, Docker, Kubernetes, Spark, Kafka, MongoDB, Flink, Druid, Presto, Kylin, Elastic Search. ¿Has oído hablar de todas ellas? Algunas de estas herramientas las encontré en las descripciones de puestos como <code class="language-plaintext highlighter-rouge">ingeniero de big data</code> e <code class="language-plaintext highlighter-rouge">ingeniero backend distribuido</code>. Estos son puestos bien remunerados. Intentemos instalarlos todos y jugar un poco con ellos.</p>
<h2 id="primer-vistazo-a-spark">Primer vistazo a Spark</h2>

<p>El sitio web oficial dice que <code class="language-plaintext highlighter-rouge">Spark</code> es un motor de análisis utilizado para procesar datos a gran escala. <code class="language-plaintext highlighter-rouge">Spark</code> es esencialmente un conjunto de bibliotecas. Parece que no está dividido en servidor y cliente como <code class="language-plaintext highlighter-rouge">Redis</code>. <code class="language-plaintext highlighter-rouge">Spark</code> se utiliza únicamente en el lado del cliente. Descargué la última versión del sitio web, <code class="language-plaintext highlighter-rouge">spark-3.1.1-bin-hadoop3.2.tar</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
├── LICENSE
├── NOTICE
├── R
├── README.md
├── RELEASE
├── bin
├── conf
├── data
├── examples
├── jars
├── kubernetes
├── licenses
├── python
├── sbin
└── yarn
</code></pre></div></div>

<p>11 directorios, 4 archivos</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Parece ser una colección de bibliotecas de análisis escritas en varios lenguajes.

Al mismo tiempo, el sitio web oficial menciona que puedes instalar las dependencias directamente en Python. `pip install pyspark`

```shell
$ pip install pyspark
Collecting pyspark
  Descargando pyspark-3.1.1.tar.gz (212.3 MB)
     |████████████████████████████████| 212.3 MB 14 kB/s
Collecting py4j==0.10.9
  Descargando py4j-0.10.9-py2.py3-none-any.whl (198 kB)
     |████████████████████████████████| 198 kB 145 kB/s
Building wheels for collected packages: pyspark
  Building wheel for pyspark (setup.py) ... done
  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=0b8079e82f3a5bcadad99179902d8c8ff9f8eccad928a469c11b97abdc960b72
  Stored in directory: /Users/lzw/Library/Caches/pip/wheels/23/bf/e9/9f3500437422e2ab82246f25a51ee480a44d4efc6c27e50d33
Successfully built pyspark
Installing collected packages: py4j, pyspark
Successfully installed py4j-0.10.9 pyspark-3.1.1
</code></pre></div></div>

<p>Se ha instalado.</p>

<p>Esto se ve en el sitio web oficial, hay algunos ejemplos.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/run-ejemplo SparkPi 10
</code></pre></div></div>

<p>Ah, resulta que puedes ejecutar el programa del paquete de instalación que acabas de descargar. Pero ocurrió un error.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/run-example SparkPi 10
21/03/11 00:06:15 WARN NativeCodeLoader: No se pudo cargar la biblioteca nativa de Hadoop para su plataforma... utilizando clases integradas de Java donde sea aplicable
21/03/11 00:06:16 INFO ResourceUtils: No se han configurado recursos personalizados para spark.driver.
21/03/11 00:06:16 WARN Utils: El servicio <span class="s1">'sparkDriver'</span> no pudo vincularse a un puerto libre aleatorio. Puede verificar si se ha configurado una dirección de enlace adecuada.
</code></pre></div></div>

<blockquote>
  <p>Spark es un motor de procesamiento rápido y general compatible con datos de Hadoop. Puede ejecutarse en clústeres de Hadoop a través de YARN o en modo independiente de Spark, y puede procesar datos en HDFS, HBase, Cassandra, Hive y cualquier formato de entrada de Hadoop. Está diseñado para realizar tanto procesamiento por lotes (similar a MapReduce) como nuevas cargas de trabajo como transmisión en tiempo real, consultas interactivas y aprendizaje automático.</p>
</blockquote>

<p>Apareció varias veces la palabra <code class="language-plaintext highlighter-rouge">hadoop</code>. Después de buscar en Google <code class="language-plaintext highlighter-rouge">spark depends hadoop</code>, encontré este párrafo. Parece que esto depende de los datos en formato <code class="language-plaintext highlighter-rouge">Hadoop</code>. Primero, vamos a investigar <code class="language-plaintext highlighter-rouge">Hadoop</code>.</p>

<h2 id="hadoop">Hadoop</h2>

<p>Después de echar un vistazo rápido a la página oficial, procedí a instalarlo.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>hadoop
</code></pre></div></div>

<p>Durante el proceso de instalación, vamos a aprender un poco más.</p>

<blockquote>
  <p>La biblioteca de software Apache Hadoop es un marco que permite el procesamiento distribuido de grandes conjuntos de datos a través de clústeres de computadoras utilizando modelos de programación simples. Está diseñado para escalar desde servidores individuales hasta miles de máquinas, cada una ofreciendo capacidad de cálculo y almacenamiento local. En lugar de depender del hardware para ofrecer alta disponibilidad, la biblioteca en sí está diseñada para detectar y manejar fallos en la capa de aplicación, proporcionando así un servicio altamente disponible sobre un clúster de computadoras, cada una de las cuales puede ser propensa a fallos.</p>
</blockquote>

<p>En otras palabras, Hadoop es un conjunto de marcos de trabajo diseñados para procesar conjuntos de datos distribuidos. Estos conjuntos de datos pueden estar distribuidos en muchas computadoras. Se utiliza un modelo de programación muy simple para manejarlos. Está diseñado para escalar desde un solo servidor hasta miles de máquinas. En lugar de depender de la alta disponibilidad del hardware, esta biblioteca está diseñada para detectar y manejar errores en la capa de aplicación. Por lo tanto, permite implementar servicios de alta disponibilidad en un clúster, incluso si cada computadora en el clúster puede fallar.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>hadoop
Error:
  homebrew-core es un clon superficial.
  homebrew-cask es un clon superficial.
Para ejecutar <span class="sb">`</span>brew update<span class="sb">`</span>, primero ejecuta:
  git <span class="nt">-C</span> /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core fetch <span class="nt">--unshallow</span>
  git <span class="nt">-C</span> /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask fetch <span class="nt">--unshallow</span>
Estos comandos pueden tardar unos minutos en ejecutarse debido al gran tamaño de los repositorios.
Esta restricción se ha implementado a solicitud de GitHub porque actualizar clones superficiales
es una operación extremadamente costosa debido al diseño del árbol y al tráfico de
Homebrew/homebrew-core y Homebrew/homebrew-cask. No lo hacemos automáticamente para evitar
realizar repetidamente una operación costosa de <span class="s2">"unshallow"</span> en sistemas de CI <span class="o">(</span>que en su lugar
deberían corregirse para no usar clones superficiales<span class="o">)</span><span class="nb">.</span> ¡Lamentamos las molestias!
<span class="o">==&gt;</span> Descargando https://homebrew.bintray.com/bottles/openjdk-15.0.1.big_sur.bottle.tar.gz
Ya descargado: /Users/lzw/Library/Caches/Homebrew/downloads/d1e3ece4af1d225bc2607eaa4ce85a873d2c6d43757ae4415d195751bc431962--openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Descargando https://www.apache.org/dyn/closer.lua?path<span class="o">=</span>hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
Ya descargado: /Users/lzw/Library/Caches/Homebrew/downloads/764c6a0ea7352bb8bb505989feee1b36dc628c2dcd6b93fef1ca829d191b4e1e--hadoop-3.3.0.tar.gz
<span class="o">==&gt;</span> Instalando dependencias para hadoop: openjdk
<span class="o">==&gt;</span> Instalando dependencia de hadoop: openjdk
<span class="o">==&gt;</span> Vertiendo openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Advertencias
Para que los wrappers de Java del sistema encuentren este JDK, crea un enlace simbólico con
  <span class="nb">sudo ln</span> <span class="nt">-sfn</span> /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk
</code></pre></div></div>

<p>openjdk es keg-only, lo que significa que no se ha creado un enlace simbólico en /usr/local,
porque oscurece el wrapper <code class="language-plaintext highlighter-rouge">java</code> de macOS.</p>

<p>Si necesitas que openjdk esté primero en tu PATH, ejecuta:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>Para que los compiladores encuentren openjdk, es posible que necesites configurar:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">export </span><span class="nv">CPPFLAGS</span><span class="o">=</span><span class="s2">"-I/usr/local/opt/openjdk/include"</span>
</code></pre></div></div>

<p>==&gt; Resumen
🍺  /usr/local/Cellar/openjdk/15.0.1: 614 archivos, 324.9MB
==&gt; Instalando hadoop
🍺  /usr/local/Cellar/hadoop/3.3.0: 21,819 archivos, 954.7MB, construido en 2 minutos 15 segundos
==&gt; Actualizando 1 dependencia:
maven 3.3.3 -&gt; 3.6.3_1
==&gt; Actualizando maven 3.3.3 -&gt; 3.6.3_1
==&gt; Descargando https://www.apache.org/dyn/closer.lua?path=maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
==&gt; Descargando desde https://mirror.olnevhost.net/pub/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
######################################################################## 100.0%
Error: El paso <code class="language-plaintext highlighter-rouge">brew link</code> no se completó correctamente
La fórmula se construyó, pero no se enlazó simbólicamente en /usr/local
No se pudo crear el enlace simbólico bin/mvn
El objetivo /usr/local/bin/mvn
es un enlace simbólico que pertenece a maven. Puedes desenlazarlo:
  brew unlink maven</p>

<p>Para forzar el enlace y sobrescribir todos los archivos en conflicto:
  brew link –overwrite maven</p>

<p>Para listar todos los archivos que serían eliminados:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  brew <span class="nb">link</span> <span class="nt">--overwrite</span> <span class="nt">--dry-run</span> maven
</code></pre></div></div>

<p>Los archivos que podrían estar en conflicto son:
/usr/local/bin/mvn -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvn
/usr/local/bin/mvnDebug -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnDebug
/usr/local/bin/mvnyjp -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnyjp
==&gt; Resumen
🍺  /usr/local/Cellar/maven/3.6.3_1: 87 archivos, 10.7MB, construido en 7 segundos
Eliminando: /usr/local/Cellar/maven/3.3.3… (92 archivos, 9MB)
==&gt; Verificando dependientes de fórmulas actualizadas…
==&gt; ¡No se encontraron dependientes rotos!
==&gt; Advertencias
==&gt; openjdk
Para que los wrappers de Java del sistema encuentren este JDK, crea un enlace simbólico con
  sudo ln -sfn /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk</p>

<p>openjdk es keg-only, lo que significa que no se ha creado un enlace simbólico en /usr/local,
porque oculta el envoltorio <code class="language-plaintext highlighter-rouge">java</code> de macOS.</p>

<p>Si necesitas tener openjdk primero en tu PATH, ejecuta:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>Para que los compiladores encuentren openjdk, es posible que necesites configurar:
  export CPPFLAGS=”-I/usr/local/opt/openjdk/include”</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Noté en los registros de salida de `brew` que `maven` no estaba correctamente enlazado. A continuación, procedí a forzar el enlace a la versión `3.6.3_1`.

```shell
  brew link --overwrite maven
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Hadoop</code> se ha instalado correctamente.</p>

<blockquote>
  <h2 id="módulos">Módulos</h2>

  <p>El proyecto incluye los siguientes módulos:</p>

  <ul>
    <li><strong>Hadoop Common</strong>: Las utilidades comunes que soportan los otros módulos de Hadoop.</li>
    <li><strong>Hadoop Distributed File System (HDFS™)</strong>: Un sistema de archivos distribuido que proporciona acceso de alto rendimiento a los datos de las aplicaciones.</li>
    <li><strong>Hadoop YARN</strong>: Un marco de trabajo para la planificación de trabajos y la gestión de recursos del clúster.</li>
    <li><strong>Hadoop MapReduce</strong>: Un sistema basado en YARN para el procesamiento paralelo de grandes conjuntos de datos.</li>
    <li><strong>Hadoop Ozone</strong>: Un almacén de objetos para Hadoop.</li>
  </ul>
</blockquote>

<p>Dice que tiene estos módulos. Esto escribirá <code class="language-plaintext highlighter-rouge">hadoop</code> y aparecerá:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hadoop
Uso: hadoop <span class="o">[</span>OPCIONES] SUBCOMANDO <span class="o">[</span>OPCIONES DEL SUBCOMANDO]
 o     hadoop <span class="o">[</span>OPCIONES] NOMBRE_DE_CLASE <span class="o">[</span>OPCIONES DE NOMBRE_DE_CLASE]
  donde NOMBRE_DE_CLASE es una clase Java proporcionada por el usuario
</code></pre></div></div>

<p>OPTIONS es ninguno o cualquiera de:</p>

<p>–config dir                     Directorio de configuración de Hadoop
–debug                          Activar el modo de depuración de scripts de shell
–help                           Información de uso
buildpaths                       Intentar agregar archivos de clase desde el árbol de compilación
hostnames list[,of,host,names]   Lista de nombres de hosts para usar en modo esclavo
hosts filename                   Archivo con la lista de hosts para usar en modo esclavo
loglevel level                   Establecer el nivel de log4j para este comando
workers                          Activar el modo de trabajador</p>

<p>SUBCOMMAND es uno de:
    Comandos de Administración:</p>

<p>daemonlog     obtener/establecer el nivel de registro para cada daemon</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Comandos del Cliente:
</code></pre></div></div>

<p>archive       crear un archivo Hadoop
checknative   verificar la disponibilidad de las bibliotecas nativas de Hadoop y compresión
classpath     imprime la ruta de clase necesaria para obtener el archivo jar de Hadoop y las bibliotecas requeridas
conftest      validar archivos de configuración XML
credential    interactuar con proveedores de credenciales
distch        cambiador de metadatos distribuido
distcp        copiar archivos o directorios de forma recursiva
dtutil        operaciones relacionadas con tokens de delegación
envvars       mostrar las variables de entorno de Hadoop calculadas
fs            ejecutar un cliente de usuario genérico del sistema de archivos
gridmix       enviar una mezcla de trabajos sintéticos, modelando una carga de producción perfilada
jar <jar>     ejecutar un archivo jar. NOTA: por favor usa "yarn jar" para lanzar aplicaciones YARN, no este comando.
jnipath       imprime la ruta java.library.path
kdiag         diagnosticar problemas de Kerberos
kerbname      mostrar la conversión de principal auth_to_local
key           gestionar claves a través del KeyProvider
rumenfolder   escalar un rastro de entrada de rumen
rumentrace    convertir registros en un rastro de rumen
s3guard       gestionar metadatos en S3
trace         ver y modificar configuraciones de rastreo de Hadoop
version       imprimir la versión</jar></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Comandos de Daemon:
</code></pre></div></div>

<p>kms           ejecuta KMS, el servidor de gestión de claves
registrydns   ejecuta el servidor DNS del registro</p>

<p>SUBCOMMAND puede mostrar ayuda cuando se invoca sin parámetros o con -h.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
El sitio web oficial proporciona algunos ejemplos.

```shell
  $ mkdir input
  $ cp etc/hadoop/*.xml input
  $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'
  $ cat output/*
</code></pre></div></div>

<p>Noté que existe <code class="language-plaintext highlighter-rouge">share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar</code>. Esto significa que quizás algunos archivos de ejemplo no los obtuvimos. Supongo que al instalar con <code class="language-plaintext highlighter-rouge">Homebrew</code> no se incluyen estos archivos. Descargamos el paquete de instalación desde el sitio web oficial.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
├── LICENSE-binary
├── LICENSE.txt
├── NOTICE-binary
├── NOTICE.txt
├── README.txt
├── bin
├── etc
├── include
├── lib
├── libexec
├── licenses-binary
├── sbin
└── share
</code></pre></div></div>

<p>Apareció el directorio <code class="language-plaintext highlighter-rouge">share</code>. Sin embargo, ¿realmente <code class="language-plaintext highlighter-rouge">Homebrew</code> no tiene estos archivos adicionales? Encuentra el directorio de instalación de <code class="language-plaintext highlighter-rouge">Homebrew</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">type </span>hadoop
hadoop es /usr/local/bin/hadoop
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-alrt</span> /usr/local/bin/hadoop
lrwxr-xr-x  1 lzw  admin  33 Mar 11 00:48 /usr/local/bin/hadoop -&gt; ../Cellar/hadoop/3.3.0/bin/hadoop
<span class="nv">$ </span><span class="nb">cd</span> /usr/local/Cellar/hadoop/3.3.0
</code></pre></div></div>

<p>Este es el árbol de directorios impreso en <code class="language-plaintext highlighter-rouge">/usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 2
<span class="nb">.</span>
├── client
│   ├── hadoop-client-api-3.3.0.jar
│   ├── hadoop-client-minicluster-3.3.0.jar
│   └── hadoop-client-runtime-3.3.0.jar
├── common
│   ├── hadoop-common-3.3.0-tests.jar
│   ├── hadoop-common-3.3.0.jar
│   ├── hadoop-kms-3.3.0.jar
│   ├── hadoop-nfs-3.3.0.jar
│   ├── hadoop-registry-3.3.0.jar
│   ├── jdiff
│   ├── lib
│   ├── sources
│   └── webapps
├── hdfs
│   ├── hadoop-hdfs-3.3.0-tests.jar
│   ├── hadoop-hdfs-3.3.0.jar
│   ├── hadoop-hdfs-client-3.3.0-tests.jar
│   ├── hadoop-hdfs-client-3.3.0.jar
│   ├── hadoop-hdfs-httpfs-3.3.0.jar
│   ├── hadoop-hdfs-native-client-3.3.0-tests.jar
│   ├── hadoop-hdfs-native-client-3.3.0.jar
│   ├── hadoop-hdfs-nfs-3.3.0.jar
│   ├── hadoop-hdfs-rbf-3.3.0-tests.jar
│   ├── hadoop-hdfs-rbf-3.3.0.jar
│   ├── jdiff
│   ├── lib
│   ├── sources
│   └── webapps
├── mapreduce
│   ├── hadoop-mapreduce-client-app-3.3.0.jar
│   ├── hadoop-mapreduce-client-common-3.3.0.jar
│   ├── hadoop-mapreduce-client-core-3.3.0.jar
│   ├── hadoop-mapreduce-client-hs-3.3.0.jar
│   ├── hadoop-mapreduce-client-hs-plugins-3.3.0.jar
│   ├── hadoop-mapreduce-client-jobclient-3.3.0-tests.jar
│   ├── hadoop-mapreduce-client-jobclient-3.3.0.jar
│   ├── hadoop-mapreduce-client-nativetask-3.3.0.jar
│   ├── hadoop-mapreduce-client-shuffle-3.3.0.jar
│   ├── hadoop-mapreduce-client-uploader-3.3.0.jar
│   ├── hadoop-mapreduce-examples-3.3.0.jar
│   ├── jdiff
│   ├── lib-examples
│   └── sources
├── tools
│   ├── dynamometer
│   ├── lib
│   ├── resourceestimator
│   ├── sls
│   └── sources
└── yarn
    ├── csi
    ├── hadoop-yarn-api-3.3.0.jar
    ├── hadoop-yarn-applications-catalog-webapp-3.3.0.war
    ├── hadoop-yarn-applications-distributedshell-3.3.0.jar
    ├── hadoop-yarn-applications-mawo-core-3.3.0.jar
    ├── hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar
    ├── hadoop-yarn-client-3.3.0.jar
    ├── hadoop-yarn-common-3.3.0.jar
    ├── hadoop-yarn-registry-3.3.0.jar
    ├── hadoop-yarn-server-applicationhistoryservice-3.3.0.jar
    ├── hadoop-yarn-server-common-3.3.0.jar
    ├── hadoop-yarn-server-nodemanager-3.3.0.jar
    ├── hadoop-yarn-server-resourcemanager-3.3.0.jar
    ├── hadoop-yarn-server-router-3.3.0.jar
    ├── hadoop-yarn-server-sharedcachemanager-3.3.0.jar
    ├── hadoop-yarn-server-tests-3.3.0.jar
    ├── hadoop-yarn-server-timeline-pluginstorage-3.3.0.jar
    ├── hadoop-yarn-server-web-proxy-3.3.0.jar
    ├── hadoop-yarn-services-api-3.3.0.jar
    ├── hadoop-yarn-services-core-3.3.0.jar
    ├── lib
    ├── sources
    ├── <span class="nb">test</span>
    ├── timelineservice
    ├── webapps
    └── yarn-service-examples
</code></pre></div></div>

<p>Se pueden ver muchos archivos <code class="language-plaintext highlighter-rouge">jar</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>input
<span class="nv">$ </span><span class="nb">ls
</span>bin			hadoop-config.sh	hdfs-config.sh		libexec			sbin			yarn-config.sh
etc			hadoop-functions.sh	input			mapred-config.sh	share
<span class="nv">$ </span><span class="nb">cp </span>etc/hadoop/<span class="k">*</span>.xml input
<span class="nv">$ </span><span class="nb">cd </span>input/
<span class="nv">$ </span><span class="nb">ls
</span>capacity-scheduler.xml	hadoop-policy.xml	hdfs-site.xml		kms-acls.xml		mapred-site.xml
core-site.xml		hdfs-rbf-site.xml	httpfs-site.xml		kms-site.xml		yarn-site.xml
<span class="nv">$ </span><span class="nb">cd</span> ..
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
El archivo JAR no existe o no es un archivo normal: /usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar
<span class="err">$</span>
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
2021-03-11 01:54:30,791 WARN util.NativeCodeLoader: No se pudo cargar la biblioteca nativa de Hadoop para su plataforma... utilizando clases Java integradas donde sea aplicable
2021-03-11 01:54:31,115 INFO impl.MetricsConfig: Propiedades cargadas desde hadoop-metrics2.properties
2021-03-11 01:54:31,232 INFO impl.MetricsSystemImpl: Período de instantánea de métricas programado en 10 segundo<span class="o">(</span>s<span class="o">)</span><span class="nb">.</span>
...
</code></pre></div></div>

<p>Siguiendo el ejemplo de la página oficial. Noté que en <code class="language-plaintext highlighter-rouge">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input</code>, el paquete <code class="language-plaintext highlighter-rouge">jar</code> tiene un número de versión. Por lo tanto, debemos cambiarlo a nuestra versión <code class="language-plaintext highlighter-rouge">3.3.0</code>.</p>

<p>Final del registro:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2021-03-11 01:54:35,374 INFO mapreduce.Job:  map 100% reduce 100%
2021-03-11 01:54:35,374 INFO mapreduce.Job: El trabajo job_local2087514596_0002 se completó exitosamente
2021-03-11 01:54:35,377 INFO mapreduce.Job: Contadores: 30
	Contadores del Sistema de Archivos
		FILE: Número de bytes leídos<span class="o">=</span>1204316
		FILE: Número de bytes <span class="nv">escritos</span><span class="o">=</span>3565480
		FILE: Número de operaciones de <span class="nv">lectura</span><span class="o">=</span>0
		FILE: Número de operaciones de lectura <span class="nv">grandes</span><span class="o">=</span>0
		FILE: Número de operaciones de <span class="nv">escritura</span><span class="o">=</span>0
	Marco de Map-Reduce
		Registros de entrada de <span class="nv">Map</span><span class="o">=</span>1
		Registros de salida de <span class="nv">Map</span><span class="o">=</span>1
		Bytes de salida de <span class="nv">Map</span><span class="o">=</span>17
		Bytes materializados de salida de <span class="nv">Map</span><span class="o">=</span>25
		Bytes de división de <span class="nv">entrada</span><span class="o">=</span>141
		Registros de entrada de <span class="nv">Combine</span><span class="o">=</span>0
		Registros de salida de <span class="nv">Combine</span><span class="o">=</span>0
		Grupos de entrada de <span class="nv">Reduce</span><span class="o">=</span>1
		Bytes de shuffle de <span class="nv">Reduce</span><span class="o">=</span>25
		Registros de entrada de <span class="nv">Reduce</span><span class="o">=</span>1
		Registros de salida de <span class="nv">Reduce</span><span class="o">=</span>1
		Registros <span class="nv">derramados</span><span class="o">=</span>2
		Mapas <span class="nv">mezclados</span><span class="o">=</span>1
		Shuffles <span class="nv">fallidos</span><span class="o">=</span>0
		Salidas de Map <span class="nv">fusionadas</span><span class="o">=</span>1
		Tiempo de GC transcurrido <span class="o">(</span>ms<span class="o">)=</span>57
		Uso total de memoria heap comprometida <span class="o">(</span>bytes<span class="o">)=</span>772800512
	Errores de Shuffle
		<span class="nv">BAD_ID</span><span class="o">=</span>0
		<span class="nv">CONNECTION</span><span class="o">=</span>0
		<span class="nv">IO_ERROR</span><span class="o">=</span>0
		<span class="nv">WRONG_LENGTH</span><span class="o">=</span>0
		<span class="nv">WRONG_MAP</span><span class="o">=</span>0
		<span class="nv">WRONG_REDUCE</span><span class="o">=</span>0
	Contadores de Formato de Entrada de Archivo
		Bytes Leídos<span class="o">=</span>123
	Contadores de Formato de Salida de Archivo
		Bytes <span class="nv">Escritos</span><span class="o">=</span>23
</code></pre></div></div>

<p>Sigamos viendo.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>¿Qué significa todo esto? No importa, lo importante es que hemos logrado poner en marcha <code class="language-plaintext highlighter-rouge">Hadoop</code> y hemos ejecutado el primer ejemplo de cálculo en modo standalone.</p>

<h2 id="spark">Spark</h2>

<p>Volviendo a Spark. Veamos un ejemplo.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
</code></pre></div></div>

<p>Aquí aparece un archivo <code class="language-plaintext highlighter-rouge">hdfs</code>. Después de investigar, descubrí que se puede crear un archivo <code class="language-plaintext highlighter-rouge">hdfs</code> de la siguiente manera:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-mkdir</span> /test
</code></pre></div></div>

<p>Vamos a echar un vistazo al comando <code class="language-plaintext highlighter-rouge">hdfs</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hdfs
Uso: hdfs <span class="o">[</span>OPCIONES] SUBCOMANDO <span class="o">[</span>OPCIONES DE SUBCOMANDO]
</code></pre></div></div>

<p>OPTIONS es ninguno o cualquiera de:</p>

<p>–buildpaths                       intentar agregar archivos de clase desde el árbol de compilación
–config dir                       directorio de configuración de Hadoop
–daemon (start|status|stop)       operar sobre un demonio
–debug                            activar el modo de depuración del script de shell
–help                             información de uso
–hostnames lista[,de,host,names]  hosts a usar en modo worker
–hosts nombre_de_archivo          lista de hosts a usar en modo worker
–loglevel nivel                   establecer el nivel de log4j para este comando
–workers                          activar el modo worker</p>

<p>SUBCOMMAND es uno de:
    Comandos de Administración:</p>

<p>cacheadmin           configurar la caché de HDFS
crypto               configurar zonas de cifrado de HDFS
debug                ejecutar un Debug Admin para ejecutar comandos de depuración de HDFS
dfsadmin             ejecutar un cliente de administración de DFS
dfsrouteradmin       administrar la federación basada en Router
ec                   ejecutar una CLI de Codificación de Borrado de HDFS
fsck                 ejecutar una utilidad de verificación del sistema de archivos DFS
haadmin              ejecutar un cliente de administración de DFS HA
jmxget               obtener valores exportados de JMX desde el NameNode o DataNode
oev                  aplicar el visor de ediciones fuera de línea a un archivo de ediciones
oiv                  aplicar el visor de imágenes de sistema de archivos fuera de línea a una imagen de sistema de archivos
oiv_legacy           aplicar el visor de imágenes de sistema de archivos fuera de línea a una imagen de sistema de archivos heredada
storagepolicies      listar/obtener/establecer/satisfacer políticas de almacenamiento de bloques</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Comandos del Cliente:
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>classpath            imprime el classpath necesario para obtener el jar de Hadoop y las bibliotecas requeridas
dfs                  ejecuta un comando del sistema de archivos en el sistema de archivos
envvars              muestra las variables de entorno de Hadoop calculadas
fetchdt              obtiene un token de delegación del NameNode
getconf              obtiene valores de configuración desde la configuración
groups               obtiene los grupos a los que pertenecen los usuarios
lsSnapshottableDir   lista todos los directorios snapshottables propiedad del usuario actual
snapshotDiff         compara dos instantáneas de un directorio o compara el contenido actual del directorio con una instantánea
version              imprime la versión
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Comandos de Daemon:
</code></pre></div></div>

<p>balancer             ejecutar una utilidad de balanceo de clúster<br />
datanode             ejecutar un datanode DFS<br />
dfsrouter            ejecutar el enrutador DFS<br />
diskbalancer         distribuir datos de manera uniforme entre discos en un nodo dado<br />
httpfs               ejecutar el servidor HttpFS, la puerta de enlace HTTP de HDFS<br />
journalnode          ejecutar el journalnode DFS<br />
mover                ejecutar una utilidad para mover réplicas de bloques entre tipos de almacenamiento<br />
namenode             ejecutar el namenode DFS<br />
nfs3                 ejecutar una puerta de enlace NFS versión 3<br />
portmap              ejecutar un servicio portmap<br />
secondarynamenode    ejecutar el secondary namenode DFS<br />
sps                  ejecutar el satisfactor de políticas de almacenamiento externo<br />
zkfc                 ejecutar el daemon del Controlador de Conmutación por Error ZK</p>

<p>SUBCOMMAND puede mostrar ayuda cuando se invoca sin parámetros o con -h.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Continuar modificando el código.

```python
from pyspark.sql import SparkSession
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">master</span><span class="p">(</span><span class="s">"local[*]"</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">config</span><span class="p">(</span><span class="s">'spark.driver.bindAddress'</span><span class="p">,</span> <span class="s">'127.0.0.1'</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"a.txt"</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"b.txt"</span><span class="p">)</span>
</code></pre></div></div>

<p>Es importante notar <code class="language-plaintext highlighter-rouge">.config('spark.driver.bindAddress', '127.0.0.1')</code>. De lo contrario, se generará el error <code class="language-plaintext highlighter-rouge">Service 'sparkDriver' could not bind on a random free port. You may check whether configuring an appropriate binding address</code>.</p>

<p>Sin embargo, en este momento apareció un error.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Causado por: org.apache.spark.api.python.PythonException: Traceback <span class="o">(</span>última llamada más reciente<span class="o">)</span>:
  File <span class="s2">"/usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py"</span>, line 473, <span class="k">in </span>main
    raise Exception<span class="o">((</span><span class="s2">"Python en el worker tiene una versión diferente %s que la del "</span> +
Exception: Python en el worker tiene una versión diferente 3.8 que la del driver 3.9, PySpark no puede ejecutarse con versiones menores diferentes. Por favor, verifica que las variables de entorno PYSPARK_PYTHON y PYSPARK_DRIVER_PYTHON estén configuradas correctamente.
</code></pre></div></div>

<p>indica que se están ejecutando diferentes versiones de <code class="language-plaintext highlighter-rouge">Python</code>.</p>

<p>Modificar <code class="language-plaintext highlighter-rouge">.bash_profile</code>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
<span class="nv">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
</code></pre></div></div>

<p>Sin embargo, seguía apareciendo el mismo error. Después de investigar un poco, descubrí que podría ser porque <code class="language-plaintext highlighter-rouge">spark</code> no carga esta variable de entorno cuando se ejecuta, y no utiliza las variables de entorno predeterminadas del terminal.</p>

<p>Necesitas configurar en el código:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
</code></pre></div></div>

<h1 id="configurar-entornos-de-spark">Configurar entornos de Spark</h1>
<p>os.environ[‘PYSPARK_PYTHON’] = ‘/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3’
os.environ[‘PYSPARK_DRIVER_PYTHON’] = ‘/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3’</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Esto se ejecutará.

```shell
$ python sc.py
21/03/11 02:54:52 WARN NativeCodeLoader: No se pudo cargar la biblioteca nativa de Hadoop para su plataforma... utilizando clases Java integradas donde sea aplicable
Usando el perfil predeterminado de log4j de Spark: org/apache/spark/log4j-defaults.properties
Estableciendo el nivel de registro predeterminado en "WARN".
Para ajustar el nivel de registro, use sc.setLogLevel(newLevel). Para SparkR, use setLogLevel(newLevel).
PythonRDD[6] en RDD en PythonRDD.scala:53
</code></pre></div></div>

<p>En este momento se ha generado <code class="language-plaintext highlighter-rouge">b.txt</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── b.txt
│   ├── _SUCCESS
│   ├── part-00000
│   └── part-00001
</code></pre></div></div>

<p>Ábrelo.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>b.txt/part-00000
<span class="o">(</span><span class="s1">'college'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'two'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'things'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'worked'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'on,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'of'</span>, 8<span class="o">)</span>
<span class="o">(</span><span class="s1">'school,'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'writing'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'programming.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s2">"didn't"</span>, 4<span class="o">)</span>
<span class="o">(</span><span class="s1">'then,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'probably'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'are:'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'short'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'awful.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'They'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'plot,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'just'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'characters'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'them'</span>, 2<span class="o">)</span>
...
</code></pre></div></div>

<p>¡Éxito! ¿No te resulta familiar? Es como en el ejemplo de <code class="language-plaintext highlighter-rouge">Hadoop</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>Estos archivos se llaman <code class="language-plaintext highlighter-rouge">HDFS</code>. Aquí se utiliza <code class="language-plaintext highlighter-rouge">Spark</code> para contar palabras. Con unas pocas líneas, parece muy conveniente.</p>

<h2 id="kubernetes">Kubernetes</h2>

<p>A continuación, vamos a explorar <code class="language-plaintext highlighter-rouge">Kubernetes</code>, también conocido como <code class="language-plaintext highlighter-rouge">k8s</code>, donde el “8” representa las 8 letras omitidas en la abreviatura. Es un sistema de código abierto diseñado para automatizar la implementación, escalado y gestión de aplicaciones en contenedores.</p>

<p>La herramienta de línea de comandos <code class="language-plaintext highlighter-rouge">kubectl</code> se utiliza para ejecutar comandos en un clúster de Kubernetes. Con ella, puedes desplegar aplicaciones, ver y gestionar recursos del clúster, así como consultar registros (logs).</p>

<p>También se puede instalar utilizando Homebrew.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>kubectl
</code></pre></div></div>

<p>Registro de salida:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">==&gt;</span> Descargando https://homebrew.bintray.com/bottles/kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Descargando desde https://d29vzk4ow07wi7.cloudfront.net/0b4f08bd1d47cb913d7cd4571e3394c6747dfbad7ff114c5589c8396c1085ecf?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Extrayendo kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Advertencias
La autocompletado de Bash se ha instalado en:
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Resumen
🍺  /usr/local/Cellar/kubernetes-cli/1.20.1: 246 archivos, 46.1MB
</code></pre></div></div>

<p>Se ha instalado correctamente.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl
kubectl controla el gestor del clúster de Kubernetes.
</code></pre></div></div>

<p>Encuentra más información en: https://kubernetes.io/docs/reference/kubectl/overview/</p>

<p>Comandos Básicos (Principiante):
  create        Crear un recurso desde un archivo o desde stdin.
  expose        Tomar un controlador de replicación, servicio, despliegue o pod y exponerlo como un nuevo Servicio de Kubernetes
  run           Ejecutar una imagen específica en el clúster
  set           Establecer características específicas en objetos</p>

<p>Comandos Básicos (Intermedios):
  explain       Documentación de recursos
  get           Mostrar uno o varios recursos
  edit          Editar un recurso en el servidor
  delete        Eliminar recursos por nombres de archivo, stdin, recursos y nombres, o por recursos y selector de etiquetas</p>

<p>Comandos de Despliegue:
  rollout       Gestiona el despliegue de un recurso
  scale         Establece un nuevo tamaño para un Deployment, ReplicaSet o Replication Controller
  autoscale     Escala automáticamente un Deployment, ReplicaSet o ReplicationController</p>

<p>Comandos de Gestión de Clúster:
  certificate   Modificar recursos de certificados.
  cluster-info  Mostrar información del clúster.
  top           Mostrar el uso de recursos (CPU/Memoria/Almacenamiento).
  cordon        Marcar un nodo como no programable.
  uncordon      Marcar un nodo como programable.
  drain         Drenar un nodo en preparación para mantenimiento.
  taint         Actualizar los taints en uno o más nodos.</p>

<p>Comandos de Resolución de Problemas y Depuración:
  describe      Muestra detalles de un recurso específico o un grupo de recursos
  logs          Imprime los registros (logs) de un contenedor en un pod
  attach        Conecta a un contenedor en ejecución
  exec          Ejecuta un comando en un contenedor
  port-forward  Redirige uno o más puertos locales a un pod
  proxy         Ejecuta un proxy hacia el servidor de la API de Kubernetes
  cp            Copia archivos y directorios hacia y desde contenedores
  auth          Inspecciona la autorización
  debug         Crea sesiones de depuración para solucionar problemas en cargas de trabajo y nodos</p>

<p>Comandos avanzados:
  diff          Compara la versión en vivo con la versión que se aplicaría
  apply         Aplica una configuración a un recurso mediante un archivo o stdin
  patch         Actualiza campo(s) de un recurso
  replace       Reemplaza un recurso mediante un archivo o stdin
  wait          Experimental: Espera una condición específica en uno o varios recursos.
  kustomize     Construye un objetivo de kustomization desde un directorio o una URL remota.</p>

<p>Comandos de Configuración:
  label         Actualiza las etiquetas en un recurso
  annotate      Actualiza las anotaciones en un recurso
  completion    Genera código de completado de shell para el shell especificado (bash o zsh)</p>

<p>Otros Comandos:
  api-resources Imprime los recursos de API soportados en el servidor
  api-versions  Imprime las versiones de API soportadas en el servidor, en el formato “grupo/versión”
  config        Modifica archivos de kubeconfig
  plugin        Proporciona utilidades para interactuar con plugins.
  version       Imprime la información de la versión del cliente y del servidor</p>

<p>Uso:
  kubectl [flags] [opciones]</p>

<p>Usa “kubectl <comando> --help" para obtener más información sobre un comando específico.
Usa "kubectl options" para ver una lista de opciones globales de línea de comandos (aplicables a todos los comandos).</comando></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Vamos a crear un archivo de configuración.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  minReadySeconds: 5
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
</code></pre></div></div>

<p>El texto que has proporcionado es solo un bloque de código vacío. Si necesitas que traduzca algo más específico o si hay más contenido que necesitas traducir, por favor, proporciónalo y estaré encantado de ayudarte.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> simple_deployment.yaml
La conexión al servidor localhost:8080 fue rechazada. ¿Especificaste el host o puerto correcto?
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl cluster-info
</code></pre></div></div>

<p>Para depurar y diagnosticar más a fondo los problemas del clúster, utiliza ‘kubectl cluster-info dump’.
La conexión al servidor localhost:8080 fue rechazada - ¿especificaste el host o puerto correcto?</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Cuando intentas ejecutarlo en el terminal de la página oficial.

```shell
$ start.sh
Iniciando Kubernetes...minikube versión: v1.8.1
commit: cbda04cf6bbe65e987ae52bb393c10099ab62014
* minikube v1.8.1 en Ubuntu 18.04
* Usando el controlador none basado en la configuración del usuario
* Ejecutando en localhost (CPUs=2, Memoria=2460MB, Disco=145651MB) ...
* La versión del sistema operativo es Ubuntu 18.04.4 LTS
</code></pre></div></div>

<ul>
  <li>Preparando Kubernetes v1.17.3 en Docker 19.03.6 …
    <ul>
      <li>kubelet.resolv-conf=/run/systemd/resolve/resolv.conf</li>
    </ul>
  </li>
  <li>Iniciando Kubernetes …</li>
  <li>Habilitando complementos: default-storageclass, storage-provisioner</li>
  <li>Configurando el entorno del host local …</li>
  <li>¡Listo! kubectl ahora está configurado para usar “minikube”</li>
  <li>El complemento ‘dashboard’ está habilitado
Kubernetes Iniciado
```</li>
</ul>

<p>Continuemos de vuelta en nuestra terminal.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
<span class="nv">$ </span>kubectl version
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
La conexión al servidor localhost:8080 fue rechazada - ¿especificaste el host o puerto correcto?
</code></pre></div></div>

<p>Curiosamente, agregar la opción <code class="language-plaintext highlighter-rouge">--client</code> no generó ningún error.</p>

<p>La documentación dice que primero necesitas instalar <code class="language-plaintext highlighter-rouge">Minikube</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>minikube
<span class="o">==&gt;</span> Descargando https://homebrew.bintray.com/bottles/minikube-1.16.0.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Descargando desde https://d29vzk4ow07wi7.cloudfront.net/1b6d7d1b97b11b6b07e4fa531c2dc21770da290da9b2816f360fd923e00c85fc?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Extrayendo minikube-1.16.0.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Notas
La completación de Bash se ha instalado en:
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Resumen
🍺  /usr/local/Cellar/minikube/1.16.0: 8 archivos, 64.6MB
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube start
😄  minikube v1.16.0 en Darwin 11.2.2
🎉  ¡minikube 1.18.1 está disponible! Descárgalo: https://github.com/kubernetes/minikube/releases/tag/v1.18.1
💡  Para desactivar esta notificación, ejecuta: <span class="s1">'minikube config set WantUpdateNotification false'</span>
</code></pre></div></div>

<p>✨  Selección automática del controlador virtualbox<br />
💿  Descargando la imagen de arranque de la VM …<br />
    &gt; minikube-v1.16.0.iso.sha256: 65 B / 65 B [————-] 100.00% ? p/s 0s<br />
    &gt; minikube-v1.16.0.iso: 212.62 MiB / 212.62 MiB [] 100.00% 5.32 MiB p/s 40s<br />
👍  Iniciando el nodo del plano de control minikube en el clúster minikube<br />
💾  Descargando la precarga de Kubernetes v1.20.0 …<br />
    &gt; preloaded-images-k8s-v8-v1….: 491.00 MiB / 491.00 MiB  100.00% 7.52 MiB<br />
🔥  Creando la VM de virtualbox (CPUs=2, Memoria=4000MB, Disco=20000MB) …<br />
❗  Esta VM está teniendo problemas para acceder a https://k8s.gcr.io<br />
💡  Para descargar nuevas imágenes externas, es posible que necesites configurar un proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/<br />
🐳  Preparando Kubernetes v1.20.0 en Docker 20.10.0 …<br />
    ▪ Generando certificados y claves …<br />
    ▪ Iniciando el plano de control …<br />
    ▪ Configurando reglas de RBAC …<br />
🔎  Verificando componentes de Kubernetes…<br />
🌟  Complementos habilitados: storage-provisioner, default-storageclass<br />
🏄  ¡Listo! kubectl ahora está configurado para usar el clúster “minikube” y el espacio de nombres “default” por defecto</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
A continuación, accedemos a este clúster.

```shell
$ kubectl get po -A
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
kube-system   coredns-74ff55c5b-ndbcr            1/1     Running   0          60s
kube-system   etcd-minikube                      0/1     Running   0          74s
kube-system   kube-apiserver-minikube            1/1     Running   0          74s
kube-system   kube-controller-manager-minikube   1/1     Running   0          74s
kube-system   kube-proxy-g2296                   1/1     Running   0          60s
kube-system   kube-scheduler-minikube            0/1     Running   0          74s
kube-system   storage-provisioner                1/1     Running   1          74s
</code></pre></div></div>

<p>Para abrir el panel de control de <code class="language-plaintext highlighter-rouge">minikube</code>, ejecuta el siguiente comando:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube dashboard
</code></pre></div></div>

<p>Esto abrirá automáticamente el panel de control de Kubernetes en tu navegador predeterminado.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube dashboard
🔌  Habilitando el panel de control ...
🤔  Verificando la salud del panel de control ...
🚀  Lanzando el proxy ...
🤔  Verificando la salud del proxy ...
🎉  Abriendo http://127.0.0.1:50030/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ en tu navegador predeterminado...
</code></pre></div></div>

<p><img src="assets/images/distributed/k8s.png" alt="k8s" /></p>

<p>¿Cómo apagarlo?</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube
minikube provisiona y gestiona clústeres locales de Kubernetes optimizados para flujos de trabajo de desarrollo.
</code></pre></div></div>

<p>Comandos básicos:
  start          Inicia un clúster local de Kubernetes
  status         Obtiene el estado de un clúster local de Kubernetes
  stop           Detiene un clúster local de Kubernetes en ejecución
  delete         Elimina un clúster local de Kubernetes
  dashboard      Accede al panel de control de Kubernetes que se ejecuta dentro del clúster de minikube
  pause          Pausa Kubernetes
  unpause        Reanuda Kubernetes</p>

<p>Comandos de Imágenes:
  docker-env     Configura el entorno para usar el demonio Docker de minikube
  podman-env     Configura el entorno para usar el servicio Podman de minikube
  cache          Agrega, elimina o sube una imagen local a minikube</p>

<p>Comandos de Configuración y Gestión:
  addons         Habilitar o deshabilitar un complemento de minikube
  config         Modificar valores de configuración persistentes
  profile        Obtener o listar los perfiles actuales (clusters)
  update-context Actualizar kubeconfig en caso de un cambio de IP o puerto</p>

<p>Comandos de Red y Conectividad:
  service        Devuelve una URL para conectarse a un servicio
  tunnel         Conecta a servicios de tipo LoadBalancer</p>

<p>Comandos avanzados:
  mount          Monta el directorio especificado en minikube
  ssh            Inicia sesión en el entorno de minikube (para depuración)
  kubectl        Ejecuta un binario de kubectl que coincida con la versión del clúster
  node           Agrega, elimina o lista nodos adicionales</p>

<p>Comandos de Resolución de Problemas:
  ssh-key        Recupera la ruta de la clave de identidad ssh del nodo especificado
  ssh-host       Recupera la clave de host ssh del nodo especificado
  ip             Recupera la dirección IP del nodo especificado
  logs           Devuelve los registros para depurar un clúster local de Kubernetes
  update-check   Imprime el número de versión actual y la última versión disponible
  version        Imprime la versión de minikube</p>

<p>Otros Comandos:
  completion     Generar autocompletado de comandos para un shell</p>

<p>Usa “minikube <comando> --help" para obtener más información sobre un comando específico.</comando></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
El comando visible es `minikube stop`.

Volviendo a `kubernetes`, ahora funciona correctamente.

```shell
$ kubectl cluster-info
El plano de control de Kubernetes está ejecutándose en https://192.168.99.100:8443
KubeDNS está ejecutándose en https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
</code></pre></div></div>

<p>Para depurar y diagnosticar más a fondo los problemas del clúster, utiliza ‘kubectl cluster-info dump’.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Cuando abrimos `https://192.168.99.100:8443`, el navegador muestra:

```json
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "Failure",
  "message": "prohibido: El usuario \"system:anonymous\" no puede acceder a la ruta \"/\"",
  "reason": "Prohibido",
  "details": {
    
  },
  "code": 403
}
</code></pre></div></div>

<p>Accede a <code class="language-plaintext highlighter-rouge">https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</code>:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Status"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"apiVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Fallo"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">"el servicio </span><span class="se">\"</span><span class="s2">kube-dns:dns</span><span class="se">\"</span><span class="s2"> está prohibido: El usuario </span><span class="se">\"</span><span class="s2">system:anonymous</span><span class="se">\"</span><span class="s2"> no puede obtener el recurso </span><span class="se">\"</span><span class="s2">services/proxy</span><span class="se">\"</span><span class="s2"> en el grupo de API </span><span class="se">\"\"</span><span class="s2"> en el espacio de nombres </span><span class="se">\"</span><span class="s2">kube-system</span><span class="se">\"</span><span class="s2">"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"reason"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Prohibido"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"details"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-dns:dns"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"services"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"code"</span><span class="p">:</span><span class="w"> </span><span class="mi">403</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Vamos a probar la configuración que acabamos de hacer.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> simple_deployment.yaml
deployment.apps/nginx-deployment creado
</code></pre></div></div>

<p>Hay un pequeño problema. Sin embargo, hasta este punto, ya hemos logrado ejecutar <code class="language-plaintext highlighter-rouge">kubernetes</code>. Vamos a detenerlo por ahora y seguiremos jugando con él más adelante.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube stop
✋  Deteniendo el nodo <span class="s2">"minikube"</span>  ...
🛑  1 nodo detenido.
</code></pre></div></div>

<p>Verificar si ha terminado.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>w<span class="nv">$ </span>minikube dashboard
🤷  El nodo del plano de control debe estar en ejecución para este comando
👉  Para iniciar un clúster, ejecuta: <span class="s2">"minikube start"</span>
</code></pre></div></div>

<h2 id="docker">Docker</h2>

<p><code class="language-plaintext highlighter-rouge">Docker</code> es también una plataforma de contenedores que ayuda a acelerar la creación, el intercambio y la ejecución de aplicaciones modernas. Descarga la aplicación desde el sitio web oficial.</p>

<p><img src="assets/images/distributed/docker.png" alt="docker" /></p>

<p>El cliente se siente un poco lento. Usemos la línea de comandos.</p>

<div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker
</code></pre></div></div>

<p>Uso: docker [OPCIONES] COMANDO</p>

<p>Un entorno de ejecución autosuficiente para contenedores</p>

<p>Opciones:
      –config string      Ubicación de los archivos de configuración del cliente (por defecto “/Users/lzw/.docker”)
  -c, –context string     Nombre del contexto a utilizar para conectarse al daemon (sobrescribe la variable de entorno DOCKER_HOST y el contexto predeterminado establecido con “docker context use”)
  -D, –debug              Habilita el modo de depuración
  -H, –host list          Socket(s) del daemon al que conectarse
  -l, –log-level string   Establece el nivel de registro (“debug”|”info”|”warn”|”error”|”fatal”) (por defecto “info”)
      –tls                Usar TLS; implícito con –tlsverify
      –tlscacert string   Confiar solo en certificados firmados por esta CA (por defecto “/Users/lzw/.docker/ca.pem”)
      –tlscert string     Ruta al archivo de certificado TLS (por defecto “/Users/lzw/.docker/cert.pem”)
      –tlskey string      Ruta al archivo de clave TLS (por defecto “/Users/lzw/.docker/key.pem”)
      –tlsverify          Usar TLS y verificar el remoto
  -v, –version            Imprime la información de la versión y sale</p>

<p>Comandos de Gestión:
  app*        Docker App (Docker Inc., v0.9.1-beta3)
  builder     Gestionar construcciones
  buildx*     Construir con BuildKit (Docker Inc., v0.5.1-docker)
  config      Gestionar configuraciones de Docker
  container   Gestionar contenedores
  context     Gestionar contextos
  image       Gestionar imágenes
  manifest    Gestionar manifiestos de imágenes de Docker y listas de manifiestos
  network     Gestionar redes
  node        Gestionar nodos de Swarm
  plugin      Gestionar plugins
  scan*       Docker Scan (Docker Inc., v0.5.0)
  secret      Gestionar secretos de Docker
  service     Gestionar servicios
  stack       Gestionar pilas de Docker
  swarm       Gestionar Swarm
  system      Gestionar Docker
  trust       Gestionar la confianza en las imágenes de Docker
  volume      Gestionar volúmenes</p>

<p>Comandos:
  attach      Conectar las entradas, salidas y flujos de error estándar locales a un contenedor en ejecución
  build       Construir una imagen a partir de un Dockerfile
  commit      Crear una nueva imagen a partir de los cambios de un contenedor
  cp          Copiar archivos/carpetas entre un contenedor y el sistema de archivos local
  create      Crear un nuevo contenedor
  diff        Inspeccionar cambios en archivos o directorios en el sistema de archivos de un contenedor
  events      Obtener eventos en tiempo real desde el servidor
  exec        Ejecutar un comando en un contenedor en ejecución
  export      Exportar el sistema de archivos de un contenedor como un archivo tar
  history     Mostrar el historial de una imagen
  images      Listar imágenes
  import      Importar el contenido de un archivo tar para crear una imagen del sistema de archivos
  info        Mostrar información general del sistema
  inspect     Devolver información de bajo nivel sobre objetos de Docker
  kill        Detener uno o más contenedores en ejecución
  load        Cargar una imagen desde un archivo tar o STDIN
  login       Iniciar sesión en un registro de Docker
  logout      Cerrar sesión de un registro de Docker
  logs        Obtener los registros de un contenedor
  pause       Pausar todos los procesos dentro de uno o más contenedores
  port        Listar mapeos de puertos o un mapeo específico para el contenedor
  ps          Listar contenedores
  pull        Descargar una imagen o un repositorio desde un registro
  push        Subir una imagen o un repositorio a un registro
  rename      Renombrar un contenedor
  restart     Reiniciar uno o más contenedores
  rm          Eliminar uno o más contenedores
  rmi         Eliminar una o más imágenes
  run         Ejecutar un comando en un nuevo contenedor
  save        Guardar una o más imágenes en un archivo tar (transmitido a STDOUT por defecto)
  search      Buscar imágenes en Docker Hub
  start       Iniciar uno o más contenedores detenidos
  stats       Mostrar una transmisión en vivo de las estadísticas de uso de recursos de los contenedores
  stop        Detener uno o más contenedores en ejecución
  tag         Crear una etiqueta TARGET_IMAGE que haga referencia a SOURCE_IMAGE
  top         Mostrar los procesos en ejecución de un contenedor
  unpause     Reanudar todos los procesos dentro de uno o más contenedores
  update      Actualizar la configuración de uno o más contenedores
  version     Mostrar la información de la versión de Docker
  wait        Bloquear hasta que uno o más contenedores se detengan, luego imprimir sus códigos de salida</p>

<p>Ejecuta ‘docker COMANDO –help’ para obtener más información sobre un comando.</p>

<p>Para obtener más ayuda con Docker, consulta nuestras guías en https://docs.docker.com/go/guides/</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Siguiendo el tutorial, vamos a intentarlo.

```shell
$ docker run -d -p 80:80 docker/getting-started
No se pudo encontrar la imagen 'docker/getting-started:latest' localmente
latest: Extrayendo de docker/getting-started
aad63a933944: Extraído completamente
b14da7a62044: Extraído completamente
343784d40d66: Extraído completamente
6f617e610986: Extraído completamente
Digest: sha256:d2c4fb0641519ea208f20ab03dc40ec2a5a53fdfbccca90bef14f870158ed577
Estado: Se descargó una imagen más reciente para docker/getting-started:latest
815f13fc8f99f6185257980f74c349e182842ca572fe60ff62cbb15641199eaf
docker: Error de respuesta del daemon: Los puertos no están disponibles: escuchar tcp 0.0.0.0:80: bind: la dirección ya está en uso.
</code></pre></div></div>

<p>Cambiar el puerto.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:80 docker/getting-started
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p><img src="assets/images/distributed/docker_run.png" alt="docker_run" /></p>

<p>Al abrir el navegador, confirmamos que hemos logrado ejecutar <code class="language-plaintext highlighter-rouge">docker</code> correctamente.</p>

<p><img src="assets/images/distributed/browser.png" alt="navegador" /></p>

<p>Detén el contenedor. Usa el <code class="language-plaintext highlighter-rouge">ID</code> que acabas de obtener.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker stop 45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p>En ese momento, ya no se podía abrir el sitio web.</p>

<p>Esto indica que <code class="language-plaintext highlighter-rouge">docker</code> se asemeja a una máquina virtual.</p>

<h2 id="flink">Flink</h2>

<p>Abre el sitio web oficial.</p>

<p><img src="assets/images/distributed/flink-home-graphic.png" alt="flink-home-graphic" /></p>

<p><code class="language-plaintext highlighter-rouge">Flink</code> se refiere al cálculo <code class="language-plaintext highlighter-rouge">Stateful</code> de flujos de datos. ¿Qué significa <code class="language-plaintext highlighter-rouge">Stateful</code>? Todavía no lo tengo claro. La imagen anterior es bastante interesante. Vamos a intentarlo.</p>

<p>Se dice que se necesita un entorno Java.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>java <span class="nt">-version</span>
java version <span class="s2">"1.8.0_151"</span>
Java<span class="o">(</span>TM<span class="o">)</span> SE Runtime Environment <span class="o">(</span>build 1.8.0_151-b12<span class="o">)</span>
Java HotSpot<span class="o">(</span>TM<span class="o">)</span> 64-Bit Server VM <span class="o">(</span>build 25.151-b12, mixed mode<span class="o">)</span>
</code></pre></div></div>

<p>Descarga la última versión <code class="language-plaintext highlighter-rouge">flink-1.12.2-bin-scala_2.11.tar</code> desde el sitio web oficial.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/start-cluster.sh
Iniciando el clúster.
Iniciando el demonio standalonesession en el host lzwjava.
Iniciando el demonio taskexecutor en el host lzwjava.
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/flink run examples/streaming/WordCount.jar
Ejecutando el ejemplo WordCount con el conjunto de datos de entrada predeterminado.
Usa <span class="nt">--input</span> para especificar un archivo de entrada.
Imprimiendo el resultado en la salida estándar. Usa <span class="nt">--output</span> para especificar la ruta de salida.
El trabajo ha sido enviado con el JobID 60f37647c20c2a6654359bd34edab807
La ejecución del programa ha finalizado
El trabajo con JobID 60f37647c20c2a6654359bd34edab807 ha finalizado.
Tiempo de ejecución del trabajo: 757 ms
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">tail </span>log/flink-<span class="k">*</span><span class="nt">-taskexecutor-</span><span class="k">*</span>.out
<span class="o">(</span>nymph,1<span class="o">)</span>
<span class="o">(</span><span class="k">in</span>,3<span class="o">)</span>
<span class="o">(</span>thy,1<span class="o">)</span>
<span class="o">(</span>orisons,1<span class="o">)</span>
<span class="o">(</span>be,4<span class="o">)</span>
<span class="o">(</span>all,2<span class="o">)</span>
<span class="o">(</span>my,1<span class="o">)</span>
<span class="o">(</span>sins,1<span class="o">)</span>
<span class="o">(</span>remember,1<span class="o">)</span>
<span class="o">(</span>d,4<span class="o">)</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/stop-cluster.sh
Deteniendo el demonio taskexecutor <span class="o">(</span>pid: 41812<span class="o">)</span> en el host lzwjava.
</code></pre></div></div>

<p>Bueno, lo he conseguido. Se puede ver que es muy similar a <code class="language-plaintext highlighter-rouge">Spark</code>.</p>

<h2 id="kylin">Kylin</h2>

<p>Abre el sitio web oficial.</p>

<blockquote>
  <p>Apache Kylin™ es un Almacén de Datos Analíticos distribuido y de código abierto para Big Data; fue diseñado para proporcionar capacidades OLAP (Procesamiento Analítico en Línea) en la era del big data. Al renovar la tecnología de cubos multidimensionales y precálculo en Hadoop y Spark, Kylin es capaz de lograr una velocidad de consulta casi constante, independientemente del volumen de datos en constante crecimiento. Al reducir la latencia de las consultas de minutos a fracciones de segundo, Kylin devuelve el análisis en línea al big data.</p>
</blockquote>

<blockquote>
  <p>Apache Kylin™ te permite consultar miles de millones de filas con una latencia de menos de un segundo en 3 pasos.</p>

  <ol>
    <li>Identifica un esquema de estrella o copo de nieve en Hadoop.</li>
    <li>Construye un cubo a partir de las tablas identificadas.</li>
    <li>Consulta utilizando ANSI-SQL y obtén resultados en menos de un segundo, a través de ODBC, JDBC o una API RESTful.</li>
  </ol>
</blockquote>

<p><img src="assets/images/distributed/kylin_diagram.png" alt="kylin_diagram" /></p>

<p>Básicamente, es una capa para analizar grandes volúmenes de datos. Con ella, puedes realizar consultas de manera extremadamente rápida. Actúa como un puente.</p>

<p>Lamentablemente, actualmente solo se puede usar en un entorno <code class="language-plaintext highlighter-rouge">Linux</code>. Volveré a jugar con esto más adelante.</p>

<h2 id="mongodb">MongoDB</h2>

<p>Esto también es una base de datos. Intenta instalarlo.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew tap mongodb/brew
<span class="o">==&gt;</span> Tapping mongodb/brew
Clonando en <span class="s1">'/usr/local/Homebrew/Library/Taps/mongodb/homebrew-brew'</span>...
remote: Enumerando objetos: 63, listo.
remote: Contando objetos: 100% <span class="o">(</span>63/63<span class="o">)</span>, listo.
remote: Comprimiendo objetos: 100% <span class="o">(</span>62/62<span class="o">)</span>, listo.
remote: Total 566 <span class="o">(</span>delta 21<span class="o">)</span>, reusados 6 <span class="o">(</span>delta 1<span class="o">)</span>, reusados del pack 503
Recibiendo objetos: 100% <span class="o">(</span>566/566<span class="o">)</span>, 121.78 KiB | 335.00 KiB/s, listo.
Resolviendo deltas: 100% <span class="o">(</span>259/259<span class="o">)</span>, listo.
Tapped 11 fórmulas <span class="o">(</span>39 archivos, 196.2KB<span class="o">)</span><span class="nb">.</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>mongodb-community@4.4
<span class="o">==&gt;</span> Instalando mongodb-community desde mongodb/brew
<span class="o">==&gt;</span> Descargando https://fastdl.mongodb.org/tools/db/mongodb-database-tools-macos-x86_64-100.3.0.zip
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Descargando https://fastdl.mongodb.org/osx/mongodb-macos-x86_64-4.4.3.tgz
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Instalando dependencias para mongodb/brew/mongodb-community: mongodb-database-tools
<span class="o">==&gt;</span> Instalando dependencia de mongodb/brew/mongodb-community: mongodb-database-tools
Error: El paso <span class="sb">`</span>brew <span class="nb">link</span><span class="sb">`</span> no se completó correctamente
La fórmula se construyó, pero no se enlazó simbólicamente en /usr/local
No se pudo crear el enlace simbólico para bin/bsondump
El objetivo /usr/local/bin/bsondump
es un enlace simbólico que pertenece a mongodb. Puedes desenlazarlo:
  brew <span class="nb">unlink </span>mongodb
</code></pre></div></div>

<p>Para forzar el enlace y sobrescribir todos los archivos en conflicto:
  brew link –overwrite mongodb-database-tools</p>

<p>Para listar todos los archivos que serían eliminados:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  brew <span class="nb">link</span> <span class="nt">--overwrite</span> <span class="nt">--dry-run</span> mongodb-database-tools
</code></pre></div></div>

<p>Los archivos que podrían estar en conflicto son:
/usr/local/bin/bsondump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/bsondump
/usr/local/bin/mongodump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongodump
/usr/local/bin/mongoexport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoexport
/usr/local/bin/mongofiles -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongofiles
/usr/local/bin/mongoimport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoimport
/usr/local/bin/mongorestore -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongorestore
/usr/local/bin/mongostat -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongostat
/usr/local/bin/mongotop -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongotop
==&gt; Resumen
🍺  /usr/local/Cellar/mongodb-database-tools/100.3.0: 13 archivos, 154MB, construidos en 11 segundos
==&gt; Instalando mongodb/brew/mongodb-community
Error: El paso <code class="language-plaintext highlighter-rouge">brew link</code> no se completó correctamente
La fórmula se construyó, pero no se enlazó simbólicamente en /usr/local
No se pudo crear el enlace simbólico para bin/mongo
El objetivo /usr/local/bin/mongo
es un enlace simbólico que pertenece a mongodb. Puedes desenlazarlo:
  brew unlink mongodb</p>

<p>Para forzar el enlace y sobrescribir todos los archivos en conflicto:
  brew link –overwrite mongodb-community</p>

<p>Para listar todos los archivos que se eliminarían:
  brew link –overwrite –dry-run mongodb-community</p>

<p>Los archivos que podrían estar en conflicto son:
/usr/local/bin/mongo -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongo
/usr/local/bin/mongod -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongod
/usr/local/bin/mongos -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongos
==&gt; Advertencias
Para iniciar mongodb/brew/mongodb-community con launchd ahora y reiniciar al iniciar sesión:
  brew services start mongodb/brew/mongodb-community
O, si no deseas/necesitas un servicio en segundo plano, simplemente puedes ejecutar:
  mongod –config /usr/local/etc/mongod.conf
==&gt; Resumen
🍺  /usr/local/Cellar/mongodb-community/4.4.3: 11 archivos, 156.8MB, construido en 10 segundos
==&gt; Advertencias
==&gt; mongodb-community
Para iniciar mongodb/brew/mongodb-community con launchd ahora y reiniciar al iniciar sesión:
  brew services start mongodb/brew/mongodb-community
O, si no deseas/necesitas un servicio en segundo plano, simplemente puedes ejecutar:
  mongod –config /usr/local/etc/mongod.conf</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Anteriormente instalé una versión antigua. Desvinculé los siguientes enlaces.

```shell
$ brew unlink mongodb
Desvinculando /usr/local/Cellar/mongodb/3.0.7... 11 enlaces simbólicos eliminados
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--version</span>
db version v4.4.3
Build Info: <span class="o">{</span>
    <span class="s2">"version"</span>: <span class="s2">"4.4.3"</span>,
    <span class="s2">"gitVersion"</span>: <span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span>,
    <span class="s2">"modules"</span>: <span class="o">[]</span>,
    <span class="s2">"allocator"</span>: <span class="s2">"system"</span>,
    <span class="s2">"environment"</span>: <span class="o">{</span>
        <span class="s2">"distarch"</span>: <span class="s2">"x86_64"</span>,
        <span class="s2">"target_arch"</span>: <span class="s2">"x86_64"</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Luego, ejecuta <code class="language-plaintext highlighter-rouge">mongod</code> para iniciar el servidor de la base de datos mongo. Sin embargo, la primera vez que lo intenté, me indicó que <code class="language-plaintext highlighter-rouge">/data/db</code> no existía. Así que creé un directorio, <code class="language-plaintext highlighter-rouge">~/mongodb</code>, para guardar los archivos de la base de datos.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--dbpath</span> ~/mongodb
</code></pre></div></div>

<p>Salida como:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.838+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23285</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Deshabilitando automáticamente TLS 1.0, para forzar la habilitación de TLS 1.0 especifique --sslDisabledProtocols 'none'"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"W"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"ASIO"</span><span class="p">,</span><span class="w">     </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">22601</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"No se configuró TransportLayer durante el inicio de NetworkInterface"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"NETWORK"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4648602</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"TCP FastOpen implícito en uso."</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"STORAGE"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4615611</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"MongoDB iniciando"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"pid"</span><span class="p">:</span><span class="mi">46256</span><span class="p">,</span><span class="nl">"port"</span><span class="p">:</span><span class="mi">27017</span><span class="p">,</span><span class="nl">"dbPath"</span><span class="p">:</span><span class="s2">"/Users/lzw/mongodb"</span><span class="p">,</span><span class="nl">"architecture"</span><span class="p">:</span><span class="s2">"64-bit"</span><span class="p">,</span><span class="nl">"host"</span><span class="p">:</span><span class="s2">"lzwjava"</span><span class="p">}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23403</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Información de compilación"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"buildInfo"</span><span class="p">:{</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"4.4.3"</span><span class="p">,</span><span class="nl">"gitVersion"</span><span class="p">:</span><span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span><span class="p">,</span><span class="nl">"modules"</span><span class="p">:[],</span><span class="nl">"allocator"</span><span class="p">:</span><span class="s2">"system"</span><span class="p">,</span><span class="nl">"environment"</span><span class="p">:{</span><span class="nl">"distarch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">,</span><span class="nl">"target_arch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">}}}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.843+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">51765</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Sistema Operativo"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"os"</span><span class="p">:{</span><span class="nl">"name"</span><span class="p">:</span><span class="s2">"Mac OS X"</span><span class="p">,</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"20.3.0"</span><span class="p">}}}</span><span class="w">
</span><span class="err">...</span><span class="w">
</span></code></pre></div></div>

<p>Se puede ver que todo está en formato <code class="language-plaintext highlighter-rouge">JSON</code>. MongoDB guarda todos los archivos de datos en formato <code class="language-plaintext highlighter-rouge">JSON</code>. Luego, abre otra pestaña del terminal.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongo
MongoDB shell version v4.4.3
conectando a: mongodb://127.0.0.1:27017/?compressors<span class="o">=</span>disabled&amp;gssapiServiceName<span class="o">=</span>mongodb
Sesión implícita: sesión <span class="o">{</span> <span class="s2">"id"</span> : UUID<span class="o">(</span><span class="s2">"4f55c561-70d3-4289-938d-4b90a284891f"</span><span class="o">)</span> <span class="o">}</span>
Versión del servidor MongoDB: 4.4.3
<span class="nt">---</span>
El servidor generó estas advertencias de inicio al arrancar:
        2021-03-11T18:17:33.743+08:00: El control de acceso no está habilitado para la base de datos. El acceso de lectura y escritura a los datos y la configuración no está restringido.
        2021-03-11T18:17:33.743+08:00: Este servidor está vinculado a localhost. Los sistemas remotos no podrán conectarse a este servidor. Inicie el servidor con <span class="nt">--bind_ip</span> &lt;dirección&gt; para especificar las direcciones IP desde las que debe responder, o con <span class="nt">--bind_ip_all</span> para vincularlo a todas las interfaces. Si este comportamiento es deseado, inicie el servidor con <span class="nt">--bind_ip</span> 127.0.0.1 para desactivar esta advertencia.
        2021-03-11T18:17:33.743+08:00: Límites suaves demasiado bajos.
        2021-03-11T18:17:33.743+08:00:         valor actual: 4864
        2021-03-11T18:17:33.743+08:00:         mínimo recomendado: 64000
<span class="nt">---</span>
<span class="nt">---</span>
        Habilite el servicio de monitoreo en la nube gratuito de MongoDB, que recibirá y mostrará
        métricas sobre su implementación <span class="o">(</span>utilización del disco, CPU, estadísticas de operaciones, etc.<span class="o">)</span><span class="nb">.</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Los datos de monitoreo estarán disponibles en un sitio web de MongoDB con una URL única a la que usted
    y cualquier persona con la que comparta la URL podrán acceder. MongoDB puede utilizar esta información para realizar mejoras en el producto
    y para sugerirle productos de MongoDB y opciones de implementación.
</code></pre></div></div>

<p>Para habilitar el monitoreo gratuito, ejecuta el siguiente comando: <code class="language-plaintext highlighter-rouge">db.enableFreeMonitoring()</code>
Para deshabilitar permanentemente este recordatorio, ejecuta el siguiente comando: <code class="language-plaintext highlighter-rouge">db.disableFreeMonitoring()</code></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
A continuación, puedes intentar insertar datos y consultar datos.

```shell
&gt; db.inventory.insertOne(
...    { item: "canvas", qty: 100, tags: ["cotton"], size: { h: 28, w: 35.5, uom: "cm" } }
... )
{
	"acknowledged" : true,
	"insertedId" : ObjectId("6049ef91b653541cf355facb")
}
&gt;
&gt; db.inventory.find()
{ "_id" : ObjectId("6049ef91b653541cf355facb"), "item" : "canvas", "qty" : 100, "tags" : [ "cotton" ], "size" : { "h" : 28, "w" : 35.5, "uom" : "cm" } }
</code></pre></div></div>

<h2 id="finalmente">Finalmente</h2>

<p>Hasta aquí por ahora. Más adelante nos pondremos manos a la obra con otras herramientas. ¿Cuál es el propósito de todo esto? Probablemente es tener primero una idea general. El comienzo siempre es lo más difícil, y nosotros hemos pasado por todo esto de una vez. Esto nos da confianza, y lo que sigue es seguir explorando más a fondo estos programas.</p>

<h2 id="práctica">Práctica</h2>

<ul>
  <li>Los estudiantes exploran de manera similar como se mencionó anteriormente.</li>
</ul>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-es" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
