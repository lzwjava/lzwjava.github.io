<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>EinfÃ¼hrung in Cloud Computing und Big Data</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>EinfÃ¼hrung in Cloud Computing und Big Data | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="EinfÃ¼hrung in Cloud Computing und Big Data" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="de" />
<meta name="description" content="Diese Lektion behandelt die folgenden Themen:" />
<meta property="og:description" content="Diese Lektion behandelt die folgenden Themen:" />
<link rel="canonical" href="https://lzwjava.github.io/distributed-de" />
<meta property="og:url" content="https://lzwjava.github.io/distributed-de" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-10T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="EinfÃ¼hrung in Cloud Computing und Big Data" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2021-03-10T00:00:00+08:00","datePublished":"2021-03-10T00:00:00+08:00","description":"Diese Lektion behandelt die folgenden Themen:","headline":"EinfÃ¼hrung in Cloud Computing und Big Data","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/distributed-de"},"url":"https://lzwjava.github.io/distributed-de"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=7098a57ecee3641d358bc8eb96400bb82ad66f00">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=7098a57ecee3641d358bc8eb96400bb82ad66f00" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       EinfÃ¼hrung in Cloud Computing und Big Data | Original, von KI Ã¼bersetzt
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/de/2021-03-10-distributed-de.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postsde2021-03-10-distributed-de.md</span> -->
      

      <!-- <span>2021-03-10-distributed-de.md</span> -->

      
        

        
          
          <a href="#" class="button">2021.03</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/distributed-en" >English</option>
        <option value="/distributed-zh" >ä¸­æ–‡</option>
        <option value="/distributed-ja" >æ—¥æœ¬èª</option>
        <option value="/distributed-es" >EspaÃ±ol</option>
        <option value="/distributed-hi" >à¤¹à¤¿à¤‚à¤¦à¥€</option>
        <option value="/distributed-fr" >FranÃ§ais</option>
        <option value="/distributed-de" selected>Deutsch</option>
        <option value="/distributed-ar" >Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</option>
        <option value="/distributed-hant" >ç¹é«”ä¸­æ–‡</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>Diese Lektion behandelt die folgenden Themen:</p>

<ul>
  <li>Spark</li>
  <li>Hadoop</li>
  <li>Kubernetes</li>
  <li>Docker</li>
  <li>Flink</li>
  <li>MongoDB</li>
</ul>

<p>Wenn es um Cloud Computing geht, scheint es unvermeidlich, viele Tools zu erwÃ¤hnen: Hadoop, Hive, Hbase, ZooKeeper, Docker, Kubernetes, Spark, Kafka, MongoDB, Flink, Druid, Presto, Kylin, Elastic Search. Haben Sie schon von all diesen gehÃ¶rt? Einige dieser Tools habe ich aus den Stellenbeschreibungen von <code class="language-plaintext highlighter-rouge">Big Data Engineers</code> und <code class="language-plaintext highlighter-rouge">Distributed Backend Engineers</code> gefunden. Dies sind alles gut bezahlte Positionen. Versuchen wir, sie alle zu installieren und ein wenig damit zu spielen.</p>
<h2 id="erste-schritte-mit-spark">Erste Schritte mit Spark</h2>

<p>Die offizielle Website besagt, dass <code class="language-plaintext highlighter-rouge">Spark</code> ein Analyse-Engine zur Verarbeitung von Massendaten ist. <code class="language-plaintext highlighter-rouge">Spark</code> ist im Wesentlichen eine Sammlung von Bibliotheken. Es scheint nicht wie <code class="language-plaintext highlighter-rouge">Redis</code> in Server- und Client-Komponenten unterteilt zu sein. <code class="language-plaintext highlighter-rouge">Spark</code> wird ausschlieÃŸlich auf der Client-Seite verwendet. Von der offiziellen Website habe ich die neueste Version heruntergeladen, <code class="language-plaintext highlighter-rouge">spark-3.1.1-bin-hadoop3.2.tar</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
â”œâ”€â”€ LICENSE
â”œâ”€â”€ NOTICE
â”œâ”€â”€ R
â”œâ”€â”€ README.md
â”œâ”€â”€ RELEASE
â”œâ”€â”€ bin
â”œâ”€â”€ conf
â”œâ”€â”€ data
â”œâ”€â”€ examples
â”œâ”€â”€ jars
â”œâ”€â”€ kubernetes
â”œâ”€â”€ licenses
â”œâ”€â”€ python
â”œâ”€â”€ sbin
â””â”€â”€ yarn
</code></pre></div></div>

<p>11 Verzeichnisse, 4 Dateien</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Es scheint sich um einige Analysebibliotheken zu handeln, die in verschiedenen Sprachen geschrieben sind.

Gleichzeitig sagt die offizielle Website, dass man die AbhÃ¤ngigkeiten direkt in Python installieren kann. `pip install pyspark`

```shell
$ pip install pyspark
Collecting pyspark
  Downloading pyspark-3.1.1.tar.gz (212,3 MB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212,3 MB 14 kB/s
Collecting py4j==0.10.9
  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198 kB 145 kB/s
Building wheels for collected packages: pyspark
  Building wheel for pyspark (setup.py) ... done
  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=0b8079e82f3a5bcadad99179902d8c8ff9f8eccad928a469c11b97abdc960b72
  Stored in directory: /Users/lzw/Library/Caches/pip/wheels/23/bf/e9/9f3500437422e2ab82246f25a51ee480a44d4efc6c27e50d33
Successfully built pyspark
Installing collected packages: py4j, pyspark
Successfully installed py4j-0.10.9 pyspark-3.1.1
</code></pre></div></div>

<p>Installiert.</p>

<p>Ich habe mir die offizielle Website angesehen und einige Beispiele gefunden.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/run-example SparkPi 10
</code></pre></div></div>

<p>Oh, ich sehe, du kannst das Programm aus dem gerade heruntergeladenen Installationspaket ausfÃ¼hren, aber es ist ein Fehler aufgetreten.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/run-example SparkPi 10
21/03/11 00:06:15 WARN NativeCodeLoader: Native-Hadoop-Bibliothek konnte fÃ¼r Ihre Plattform nicht geladen werden... Es werden integrierte Java-Klassen verwendet, wo zutreffend.
21/03/11 00:06:16 INFO ResourceUtils: Keine benutzerdefinierten Ressourcen fÃ¼r spark.driver konfiguriert.
21/03/11 00:06:16 WARN Utils: Der Dienst <span class="s1">'sparkDriver'</span> konnte keinen zufÃ¤lligen freien Port binden. ÃœberprÃ¼fen Sie, ob eine geeignete Bindungsadresse konfiguriert ist.
</code></pre></div></div>

<blockquote>
  <p>Spark ist eine schnelle und vielseitige Verarbeitungs-Engine, die mit Hadoop-Daten kompatibel ist. Es kann in Hadoop-Clustern Ã¼ber YARN oder im eigenstÃ¤ndigen Modus von Spark ausgefÃ¼hrt werden und kann Daten in HDFS, HBase, Cassandra, Hive und jedem Hadoop InputFormat verarbeiten. Es wurde entwickelt, um sowohl Batch-Verarbeitung (Ã¤hnlich wie MapReduce) als auch neue Workloads wie Streaming, interaktive Abfragen und maschinelles Lernen zu unterstÃ¼tzen.</p>
</blockquote>

<p>Es ist mehrmals <code class="language-plaintext highlighter-rouge">hadoop</code> aufgetaucht. Nachdem ich <code class="language-plaintext highlighter-rouge">spark depends hadoop</code> gegoogelt habe, bin ich auf folgenden Absatz gestoÃŸen. Es scheint, dass dies von Daten im <code class="language-plaintext highlighter-rouge">Hadoop</code>-Format abhÃ¤ngt. Lassen Sie uns zunÃ¤chst <code class="language-plaintext highlighter-rouge">Hadoop</code> untersuchen.</p>

<h2 id="hadoop">Hadoop</h2>

<p>Nachdem ich die offizielle Website kurz Ã¼berflogen habe, werde ich es jetzt installieren.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>hadoop
</code></pre></div></div>

<p>WÃ¤hrend des Installationsprozesses lass uns etwas darÃ¼ber lernen.</p>

<blockquote>
  <p>Die Apache Hadoop-Softwarebibliothek ist ein Framework, das die verteilte Verarbeitung groÃŸer Datenmengen Ã¼ber Computercluster hinweg mithilfe einfacher Programmiermodelle ermÃ¶glicht. Es ist darauf ausgelegt, sich von einzelnen Servern auf Tausende von Maschinen zu skalieren, wobei jede lokale Berechnungen und Speicherung bietet. Anstatt sich auf Hardware zu verlassen, um HochverfÃ¼gbarkeit zu gewÃ¤hrleisten, ist die Bibliothek selbst so konzipiert, dass sie Fehler auf der Anwendungsebene erkennt und behandelt. Dadurch bietet sie einen hochverfÃ¼gbaren Dienst auf Basis eines Computerclusters, bei dem jede einzelne Maschine anfÃ¤llig fÃ¼r AusfÃ¤lle sein kann.</p>
</blockquote>

<p>Hadoop ist ein Framework, das entwickelt wurde, um verteilte DatensÃ¤tze zu verarbeiten. Diese DatensÃ¤tze kÃ¶nnen auf vielen Computern verteilt sein. Es verwendet ein sehr einfaches Programmiermodell. Es ist darauf ausgelegt, sich von einem einzelnen Server auf Tausende von Maschinen zu skalieren. Anstatt sich auf die hohe VerfÃ¼gbarkeit von Hardware zu verlassen, ist diese Bibliothek so konzipiert, dass sie Fehler auf der Anwendungsebene erkennen und behandeln kann. Dadurch kann ein hochverfÃ¼gbarer Dienst in einem Cluster bereitgestellt werden, obwohl jede einzelne Maschine im Cluster potenziell ausfallen kÃ¶nnte.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>hadoop
Fehler:
  homebrew-core ist ein flacher Klon.
  homebrew-cask ist ein flacher Klon.
Um <span class="sb">`</span>brew update<span class="sb">`</span> auszufÃ¼hren, fÃ¼hren Sie zuerst folgende Befehle aus:
  git <span class="nt">-C</span> /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core fetch <span class="nt">--unshallow</span>
  git <span class="nt">-C</span> /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask fetch <span class="nt">--unshallow</span>
Diese Befehle kÃ¶nnen einige Minuten dauern, da die Repositorys sehr groÃŸ sind.
Diese EinschrÃ¤nkung wurde auf Anfrage von GitHub vorgenommen, da das Aktualisieren von flachen Klonen aufgrund der Baumstruktur und des Datenverkehrs von Homebrew/homebrew-core und Homebrew/homebrew-cask eine Ã¤uÃŸerst aufwÃ¤ndige Operation ist. Wir fÃ¼hren dies nicht automatisch fÃ¼r Sie durch, um zu vermeiden, dass <span class="k">in </span>CI-Systemen wiederholt eine aufwÃ¤ndige Unshallow-Operation durchgefÃ¼hrt wird <span class="o">(</span>die stattdessen so angepasst werden sollten, dass sie keine flachen Klone verwenden<span class="o">)</span><span class="nb">.</span> Entschuldigung fÃ¼r die Unannehmlichkeiten!
<span class="o">==&gt;</span> Lade https://homebrew.bintray.com/bottles/openjdk-15.0.1.big_sur.bottle.tar.gz herunter
Bereits heruntergeladen: /Users/lzw/Library/Caches/Homebrew/downloads/d1e3ece4af1d225bc2607eaa4ce85a873d2c6d43757ae4415d195751bc431962--openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Lade https://www.apache.org/dyn/closer.lua?path<span class="o">=</span>hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz herunter
Bereits heruntergeladen: /Users/lzw/Library/Caches/Homebrew/downloads/764c6a0ea7352bb8bb505989feee1b36dc628c2dcd6b93fef1ca829d191b4e1e--hadoop-3.3.0.tar.gz
<span class="o">==&gt;</span> Installiere AbhÃ¤ngigkeiten fÃ¼r hadoop: openjdk
<span class="o">==&gt;</span> Installiere hadoop-AbhÃ¤ngigkeit: openjdk
<span class="o">==&gt;</span> GieÃŸe openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Hinweise
Damit die System-Java-Wrapper dieses JDK finden, verlinken Sie es mit
  <span class="nb">sudo ln</span> <span class="nt">-sfn</span> /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk
</code></pre></div></div>

<p>openjdk ist keg-only, was bedeutet, dass es nicht nach /usr/local symbolisch verlinkt wurde,
weil es den macOS <code class="language-plaintext highlighter-rouge">java</code>-Wrapper Ã¼berschattet.</p>

<p>Wenn Sie openjdk zuerst in Ihrem PATH haben mÃ¼ssen, fÃ¼hren Sie den folgenden Befehl aus:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>Damit Compiler OpenJDK finden kÃ¶nnen, mÃ¼ssen Sie mÃ¶glicherweise Folgendes setzen:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">export </span><span class="nv">CPPFLAGS</span><span class="o">=</span><span class="s2">"-I/usr/local/opt/openjdk/include"</span>
</code></pre></div></div>

<p>==&gt; Zusammenfassung
ğŸº  /usr/local/Cellar/openjdk/15.0.1: 614 Dateien, 324,9 MB
==&gt; Installiere hadoop
ğŸº  /usr/local/Cellar/hadoop/3.3.0: 21.819 Dateien, 954,7 MB, gebaut in 2 Minuten 15 Sekunden
==&gt; Aktualisiere 1 AbhÃ¤ngigkeit:
maven 3.3.3 -&gt; 3.6.3_1
==&gt; Aktualisiere maven 3.3.3 -&gt; 3.6.3_1
==&gt; Lade https://www.apache.org/dyn/closer.lua?path=maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz herunter
==&gt; Lade von https://mirror.olnevhost.net/pub/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz herunter
######################################################################## 100,0%
Fehler: Der <code class="language-plaintext highlighter-rouge">brew link</code> Schritt wurde nicht erfolgreich abgeschlossen
Die Formel wurde gebaut, aber nicht in /usr/local verlinkt
Konnte bin/mvn nicht verlinken
Ziel /usr/local/bin/mvn
ist ein Symlink, der zu maven gehÃ¶rt. Sie kÃ¶nnen ihn entlinken:
  brew unlink maven</p>

<p>Um den Link zu erzwingen und alle konfligierenden Dateien zu Ã¼berschreiben:
  brew link â€“overwrite maven</p>

<p>Um alle Dateien aufzulisten, die gelÃ¶scht wÃ¼rden:
  brew link â€“overwrite â€“dry-run maven</p>

<p>MÃ¶gliche konflikttrÃ¤chtige Dateien sind:
/usr/local/bin/mvn -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvn
/usr/local/bin/mvnDebug -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnDebug
/usr/local/bin/mvnyjp -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnyjp
==&gt; Zusammenfassung
ğŸº  /usr/local/Cellar/maven/3.6.3_1: 87 Dateien, 10,7MB, in 7 Sekunden erstellt
Entferne: /usr/local/Cellar/maven/3.3.3â€¦ (92 Dateien, 9MB)
==&gt; ÃœberprÃ¼fe AbhÃ¤ngigkeiten der aktualisierten Formelnâ€¦
==&gt; Keine defekten AbhÃ¤ngigkeiten gefunden!
==&gt; Hinweise
==&gt; openjdk
Damit die System-Java-Wrapper dieses JDK finden, verlinken Sie es mit
  sudo ln -sfn /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk</p>

<p>openjdk ist keg-only, was bedeutet, dass es nicht in /usr/local symbolisch verlinkt wurde,
weil es den macOS <code class="language-plaintext highlighter-rouge">java</code>-Wrapper Ã¼berschattet.</p>

<p>Wenn Sie sicherstellen mÃ¶chten, dass openjdk in Ihrem PATH an erster Stelle steht, fÃ¼hren Sie den folgenden Befehl aus:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>Damit Compiler OpenJDK finden kÃ¶nnen, mÃ¼ssen Sie mÃ¶glicherweise folgendes setzen:
  export CPPFLAGS=â€-I/usr/local/opt/openjdk/includeâ€</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Beachten Sie, dass in den Ausgabelogs von `brew` `maven` nicht korrekt verlinkt wurde. FÃ¼hren Sie als NÃ¤chstes eine erzwungene Verlinkung zur Version `3.6.3_1` durch.

```shell
  brew link --overwrite maven
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Hadoop</code> wurde erfolgreich installiert.</p>

<blockquote>
  <h2 id="module">Module</h2>

  <p>Das Projekt umfasst folgende Module:</p>

  <ul>
    <li><strong>Hadoop Common</strong>: Die allgemeinen Hilfsprogramme, die die anderen Hadoop-Module unterstÃ¼tzen.</li>
    <li><strong>Hadoop Distributed File System (HDFSâ„¢)</strong>: Ein verteiltes Dateisystem, das einen hohen Durchsatz fÃ¼r den Zugriff auf Anwendungsdaten bietet.</li>
    <li><strong>Hadoop YARN</strong>: Ein Framework fÃ¼r die Jobplanung und die Verwaltung von Clusterressourcen.</li>
    <li><strong>Hadoop MapReduce</strong>: Ein YARN-basiertes System zur parallelen Verarbeitung groÃŸer Datenmengen.</li>
    <li><strong>Hadoop Ozone</strong>: Ein Objektspeicher fÃ¼r Hadoop.</li>
  </ul>
</blockquote>

<p>Es gibt diese Module. Wenn Sie <code class="language-plaintext highlighter-rouge">hadoop</code> eingeben, erscheint:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hadoop
Verwendung: hadoop <span class="o">[</span>OPTIONEN] UNTERBEFEHL <span class="o">[</span>UNTERBEFEHL-OPTIONEN]
 oder    hadoop <span class="o">[</span>OPTIONEN] KLASSENNAME <span class="o">[</span>KLASSENNAME-OPTIONEN]
  wobei KLASSENNAME eine vom Benutzer bereitgestellte Java-Klasse ist

OPTIONS ist keine oder eine der folgenden Optionen:

<span class="nt">--config</span> <span class="nb">dir                     </span>Hadoop-Konfigurationsverzeichnis
<span class="nt">--debug</span>                          Debug-Modus fÃ¼r Shell-Skripte aktivieren
<span class="nt">--help</span>                           Nutzungsinformationen
buildpaths                       Versuch, Klassendateien aus dem Build-Verzeichnis hinzuzufÃ¼gen
hostnames list[,of,host,names]   Hosts, die im Slave-Modus verwendet werden sollen
hosts filename                   Liste der Hosts, die im Slave-Modus verwendet werden sollen
loglevel level                   Log4j-Level fÃ¼r diesen Befehl festlegen
workers                          Worker-Modus aktivieren

  SUBCOMMAND ist eines der folgenden:
    Admin-Befehle:

daemonlog     Protokollstufe fÃ¼r jeden Daemon abrufen/festlegen

    Client-Befehle:

</code></pre></div></div>
<p>archive       Erstellt ein Hadoop-Archiv
checknative   ÃœberprÃ¼ft die VerfÃ¼gbarkeit nativer Hadoop- und Kompressionsbibliotheken
classpath     Gibt den Klassenpfad aus, der benÃ¶tigt wird, um das Hadoop-JAR und die erforderlichen Bibliotheken zu erhalten
conftest      Validiert Konfigurations-XML-Dateien
credential    Interagiert mit Anmeldeinformationsanbietern
distch        Verteilter MetadatenÃ¤nderer
distcp        Kopiert Dateien oder Verzeichnisse rekursiv
dtutil        Operationen im Zusammenhang mit Delegationstokens
envvars       Zeigt die berechneten Hadoop-Umgebungsvariablen an
fs            FÃ¼hrt einen generischen Dateisystem-Client aus
gridmix       Sendet eine Mischung aus synthetischen Jobs, die ein Profil aus der Produktionslast modellieren
jar <jar>     FÃ¼hrt eine JAR-Datei aus. HINWEIS: Bitte verwenden Sie "yarn jar", um YARN-Anwendungen zu starten, nicht diesen Befehl.
jnipath       Gibt den java.library.path aus
kdiag         Diagnostiziert Kerberos-Probleme
kerbname      Zeigt die auth_to_local Principal-Konvertierung an
key           Verwaltet SchlÃ¼ssel Ã¼ber den KeyProvider
rumenfolder   Skaliert eine Rumen-Eingabespur
rumentrace    Konvertiert Protokolle in eine Rumen-Spur
s3guard       Verwaltet Metadaten auf S3
trace         Zeigt und modifiziert Hadoop-Tracing-Einstellungen
version       Gibt die Version aus</jar></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
    Daemon-Befehle:

kms           KMS ausfÃ¼hren, den Key Management Server
registrydns   den Registry-DNS-Server ausfÃ¼hren

SUBCOMMAND kann Hilfe anzeigen, wenn es ohne Parameter oder mit -h aufgerufen wird.
</code></pre></div></div>

<p>Die offizielle Website bietet einige Beispiele.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span><span class="nb">mkdir </span>input
  <span class="nv">$ </span><span class="nb">cp </span>etc/hadoop/<span class="k">*</span>.xml input
  <span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
  <span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
</code></pre></div></div>

<p>Beachte, dass es <code class="language-plaintext highlighter-rouge">share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar</code> gibt. Dies bedeutet, dass mÃ¶glicherweise einige Beispiel-Dateien fehlen, die wir nicht erhalten haben. Es wird vermutet, dass bei der Installation mit <code class="language-plaintext highlighter-rouge">Homebrew</code> diese Dateien nicht enthalten sind. Wir haben das Installationspaket von der offiziellen Website heruntergeladen.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
â”œâ”€â”€ LICENSE-binary
â”œâ”€â”€ LICENSE.txt
â”œâ”€â”€ NOTICE-binary
â”œâ”€â”€ NOTICE.txt
â”œâ”€â”€ README.txt
â”œâ”€â”€ bin
â”œâ”€â”€ etc
â”œâ”€â”€ include
â”œâ”€â”€ lib
â”œâ”€â”€ libexec
â”œâ”€â”€ licenses-binary
â”œâ”€â”€ sbin
â””â”€â”€ share
</code></pre></div></div>

<p>Es scheint, dass ein <code class="language-plaintext highlighter-rouge">share</code>-Verzeichnis vorhanden ist. Aber hat <code class="language-plaintext highlighter-rouge">Homebrew</code> wirklich keine dieser zusÃ¤tzlichen Dateien? Finde das Verzeichnis, in dem <code class="language-plaintext highlighter-rouge">Homebrew</code> installiert ist.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">type </span>hadoop
hadoop ist /usr/local/bin/hadoop
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-alrt</span> /usr/local/bin/hadoop
lrwxr-xr-x  1 lzw  admin  33 Mar 11 00:48 /usr/local/bin/hadoop -&gt; ../Cellar/hadoop/3.3.0/bin/hadoop
<span class="nv">$ </span><span class="nb">cd</span> /usr/local/Cellar/hadoop/3.3.0
</code></pre></div></div>

<p>Dies ist das Verzeichnisbaum, das unter <code class="language-plaintext highlighter-rouge">/usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop</code> gedruckt wurde.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 2
<span class="nb">.</span>
â”œâ”€â”€ client
â”‚Â Â  â”œâ”€â”€ hadoop-client-api-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-client-minicluster-3.3.0.jar
â”‚Â Â  â””â”€â”€ hadoop-client-runtime-3.3.0.jar
â”œâ”€â”€ common
â”‚Â Â  â”œâ”€â”€ hadoop-common-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-common-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-kms-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-nfs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-registry-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ jdiff
â”‚Â Â  â”œâ”€â”€ lib
â”‚Â Â  â”œâ”€â”€ sources
â”‚Â Â  â””â”€â”€ webapps
â”œâ”€â”€ hdfs
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-client-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-client-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-httpfs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-native-client-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-native-client-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-nfs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-rbf-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-rbf-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ jdiff
â”‚Â Â  â”œâ”€â”€ lib
â”‚Â Â  â”œâ”€â”€ sources
â”‚Â Â  â””â”€â”€ webapps
â”œâ”€â”€ mapreduce
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-app-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-common-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-core-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-hs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-hs-plugins-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-jobclient-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-jobclient-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-nativetask-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-shuffle-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-uploader-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-examples-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ jdiff
â”‚Â Â  â”œâ”€â”€ lib-examples
â”‚Â Â  â””â”€â”€ sources
â”œâ”€â”€ tools
â”‚Â Â  â”œâ”€â”€ dynamometer
â”‚Â Â  â”œâ”€â”€ lib
â”‚Â Â  â”œâ”€â”€ resourceestimator
â”‚Â Â  â”œâ”€â”€ sls
â”‚Â Â  â””â”€â”€ sources
â””â”€â”€ yarn
    â”œâ”€â”€ csi
    â”œâ”€â”€ hadoop-yarn-api-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-applications-catalog-webapp-3.3.0.war
    â”œâ”€â”€ hadoop-yarn-applications-distributedshell-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-applications-mawo-core-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-client-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-common-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-registry-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-applicationhistoryservice-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-common-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-nodemanager-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-resourcemanager-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-router-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-sharedcachemanager-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-tests-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-timeline-pluginstorage-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-web-proxy-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-services-api-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-services-core-3.3.0.jar
    â”œâ”€â”€ lib
    â”œâ”€â”€ sources
    â”œâ”€â”€ <span class="nb">test</span>
    â”œâ”€â”€ timelineservice
    â”œâ”€â”€ webapps
    â””â”€â”€ yarn-service-examples
</code></pre></div></div>

<p>Man kann viele <code class="language-plaintext highlighter-rouge">jar</code>-Pakete sehen.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>input
<span class="nv">$ </span><span class="nb">ls
</span>bin			hadoop-config.sh	hdfs-config.sh		libexec			sbin			yarn-config.sh
etc			hadoop-functions.sh	input			mapred-config.sh	share
<span class="nv">$ </span><span class="nb">cp </span>etc/hadoop/<span class="k">*</span>.xml input
<span class="nv">$ </span><span class="nb">cd </span>input/
<span class="nv">$ </span><span class="nb">ls
</span>capacity-scheduler.xml	hadoop-policy.xml	hdfs-site.xml		kms-acls.xml		mapred-site.xml
core-site.xml		hdfs-rbf-site.xml	httpfs-site.xml		kms-site.xml		yarn-site.xml
<span class="nv">$ </span><span class="nb">cd</span> ..
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
JAR existiert nicht oder ist keine normale Datei: /usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar
<span class="err">$</span>
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
2021-03-11 01:54:30,791 WARN util.NativeCodeLoader: Native-Hadoop-Bibliothek konnte fÃ¼r Ihre Plattform nicht geladen werden... Es werden eingebaute Java-Klassen verwendet, wo zutreffend
2021-03-11 01:54:31,115 INFO impl.MetricsConfig: Eigenschaften aus hadoop-metrics2.properties geladen
2021-03-11 01:54:31,232 INFO impl.MetricsSystemImpl: Metrik-Snapshot-Intervall auf 10 Sekunden festgelegt.
...
</code></pre></div></div>

<p>Folgen Sie dem Beispiel auf der offiziellen Website. Beachten Sie, dass in <code class="language-plaintext highlighter-rouge">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input</code> die <code class="language-plaintext highlighter-rouge">jar</code>-Datei eine Versionsnummer enthÃ¤lt. Daher mÃ¼ssen wir diese durch unsere Version <code class="language-plaintext highlighter-rouge">3.3.0</code> ersetzen.</p>

<p>Ende des Logs:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2021-03-11 01:54:35,374 INFO mapreduce.Job:  map 100% reduce 100%
2021-03-11 01:54:35,374 INFO mapreduce.Job: Job job_local2087514596_0002 erfolgreich abgeschlossen
2021-03-11 01:54:35,377 INFO mapreduce.Job: ZÃ¤hler: 30
	Dateisystem-ZÃ¤hler
		FILE: Anzahl der gelesenen <span class="nv">Bytes</span><span class="o">=</span>1204316
		FILE: Anzahl der geschriebenen <span class="nv">Bytes</span><span class="o">=</span>3565480
		FILE: Anzahl der LesevorgÃ¤nge<span class="o">=</span>0
		FILE: Anzahl der groÃŸen LesevorgÃ¤nge<span class="o">=</span>0
		FILE: Anzahl der SchreibvorgÃ¤nge<span class="o">=</span>0
	Map-Reduce-Framework
		Map-EingabedatensÃ¤tze<span class="o">=</span>1
		Map-AusgabedatensÃ¤tze<span class="o">=</span>1
		Map-Ausgabebytes<span class="o">=</span>17
		Map-Ausgabematerialisierte <span class="nv">Bytes</span><span class="o">=</span>25
		Eingabe-Split-Bytes<span class="o">=</span>141
		Combine-EingabedatensÃ¤tze<span class="o">=</span>0
		Combine-AusgabedatensÃ¤tze<span class="o">=</span>0
		Reduce-Eingabegruppen<span class="o">=</span>1
		Reduce-Shuffle-Bytes<span class="o">=</span>25
		Reduce-EingabedatensÃ¤tze<span class="o">=</span>1
		Reduce-AusgabedatensÃ¤tze<span class="o">=</span>1
		Verlorene DatensÃ¤tze<span class="o">=</span>2
		Shuffled <span class="nv">Maps</span><span class="o">=</span>1
		Fehlgeschlagene <span class="nv">Shuffles</span><span class="o">=</span>0
		ZusammengefÃ¼hrte Map-Ausgaben<span class="o">=</span>1
		GC-Zeit verstrichen <span class="o">(</span>ms<span class="o">)=</span>57
		Gesamter belegter Heap-Speicher <span class="o">(</span>Bytes<span class="o">)=</span>772800512
	Shuffle-Fehler
		<span class="nv">BAD_ID</span><span class="o">=</span>0
		<span class="nv">CONNECTION</span><span class="o">=</span>0
		<span class="nv">IO_ERROR</span><span class="o">=</span>0
		<span class="nv">WRONG_LENGTH</span><span class="o">=</span>0
		<span class="nv">WRONG_MAP</span><span class="o">=</span>0
		<span class="nv">WRONG_REDUCE</span><span class="o">=</span>0
	Datei-Eingabeformat-ZÃ¤hler
		Gelesene <span class="nv">Bytes</span><span class="o">=</span>123
	Datei-Ausgabeformat-ZÃ¤hler
		Geschriebene <span class="nv">Bytes</span><span class="o">=</span>23
</code></pre></div></div>

<p>Weiter schauen.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>Was bedeutet das nun? Keine Sorge, jedenfalls haben wir <code class="language-plaintext highlighter-rouge">Hadoop</code> zum Laufen gebracht. Und wir haben das erste Beispiel fÃ¼r eine lokale Berechnung ausgefÃ¼hrt.</p>

<h2 id="spark">Spark</h2>

<p>ZurÃ¼ck zu Spark. Schauen wir uns ein Beispiel an.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
</code></pre></div></div>

<p>Hier ist eine <code class="language-plaintext highlighter-rouge">hdfs</code>-Datei aufgetaucht. Nach einiger Recherche habe ich herausgefunden, dass man eine <code class="language-plaintext highlighter-rouge">hdfs</code>-Datei auf folgende Weise erstellen kann:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-mkdir</span> /test
</code></pre></div></div>

<p>Schauen wir uns den <code class="language-plaintext highlighter-rouge">hdfs</code>-Befehl an.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hdfs
Verwendung: hdfs <span class="o">[</span>OPTIONEN] UNTERBEFEHL <span class="o">[</span>UNTERBEFEHLSOPTIONEN]
</code></pre></div></div>

<p>OPTIONS ist keine oder eine der folgenden:</p>

<p>â€“buildpaths                       versucht, Klassendateien aus dem Build-Verzeichnis hinzuzufÃ¼gen
â€“config dir                       Hadoop-Konfigurationsverzeichnis
â€“daemon (start|status|stop)       fÃ¼hrt eine Aktion auf einem Daemon aus
â€“debug                            aktiviert den Debug-Modus fÃ¼r Shell-Skripte
â€“help                             zeigt Nutzungsinformationen an
â€“hostnames list[,of,host,names]   Hosts, die im Worker-Modus verwendet werden sollen
â€“hosts filename                   Liste der Hosts, die im Worker-Modus verwendet werden sollen
â€“loglevel level                   setzt den Log4j-Level fÃ¼r diesen Befehl
â€“workers                          aktiviert den Worker-Modus</p>

<p>SUBCOMMAND ist eines der folgenden:
    Admin-Befehle:</p>

<p>cacheadmin           Konfigurieren des HDFS-Caches
crypto               Konfigurieren von HDFS-VerschlÃ¼sselungszonen
debug                AusfÃ¼hren eines Debug-Administrators zur AusfÃ¼hrung von HDFS-Debug-Befehlen
dfsadmin             AusfÃ¼hren eines DFS-Administrator-Clients
dfsrouteradmin       Verwalten der Router-basierten FÃ¶deration
ec                   AusfÃ¼hren eines HDFS-ErasureCoding-CLI
fsck                 AusfÃ¼hren eines DFS-Dateisystem-PrÃ¼fprogramms
haadmin              AusfÃ¼hren eines DFS-HA-Administrator-Clients
jmxget               Abrufen von JMX-exportierten Werten vom NameNode oder DataNode
oev                  Anwenden des Offline-Edits-Viewers auf eine Edits-Datei
oiv                  Anwenden des Offline-Fsimage-Viewers auf ein Fsimage
oiv_legacy           Anwenden des Offline-Fsimage-Viewers auf ein Legacy-Fsimage
storagepolicies      Auflisten/Abrufen/Setzen/ErfÃ¼llen von Block-Speicherrichtlinien</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Client-Befehle:
</code></pre></div></div>

<p>classpath            gibt den Klassenpfad aus, der benÃ¶tigt wird, um das Hadoop-JAR und die erforderlichen Bibliotheken zu erhalten
dfs                  fÃ¼hrt einen Dateisystembefehl auf dem Dateisystem aus
envvars              zeigt die berechneten Hadoop-Umgebungsvariablen an
fetchdt              holt ein Delegation-Token vom NameNode
getconf              ruft Konfigurationswerte aus der Konfiguration ab
groups               zeigt die Gruppen an, zu denen Benutzer gehÃ¶ren
lsSnapshottableDir   listet alle vom aktuellen Benutzer besessenen Snapshottable-Verzeichnisse auf
snapshotDiff         vergleicht zwei Snapshots eines Verzeichnisses oder vergleicht die aktuellen Verzeichnisinhalte mit einem Snapshot
version              gibt die Version aus</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Daemon-Befehle:
</code></pre></div></div>

<p>balancer             FÃ¼hrt ein Cluster-Balancing-Utility aus<br />
datanode             FÃ¼hrt einen DFS-Datanode aus<br />
dfsrouter            FÃ¼hrt den DFS-Router aus<br />
diskbalancer         Verteilt Daten gleichmÃ¤ÃŸig auf Festplatten eines bestimmten Knotens<br />
httpfs               FÃ¼hrt den HttpFS-Server aus, das HDFS-HTTP-Gateway<br />
journalnode          FÃ¼hrt den DFS-Journalnode aus<br />
mover                FÃ¼hrt ein Utility aus, um Blockreplikate Ã¼ber Speichertypen hinweg zu verschieben<br />
namenode             FÃ¼hrt den DFS-Namenode aus<br />
nfs3                 FÃ¼hrt ein NFS-Version-3-Gateway aus<br />
portmap              FÃ¼hrt einen Portmap-Dienst aus<br />
secondarynamenode    FÃ¼hrt den sekundÃ¤ren DFS-Namenode aus<br />
sps                  FÃ¼hrt den externen StoragePolicySatisfier aus<br />
zkfc                 FÃ¼hrt den ZK-Failover-Controller-Daemon aus</p>

<p>SUBCOMMAND kann Hilfe anzeigen, wenn es ohne Parameter oder mit -h aufgerufen wird.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
ç»§ç»­ä¿®æ”¹ä»£ç ã€‚

```python
from pyspark.sql import SparkSession
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">master</span><span class="p">(</span><span class="s">"local[*]"</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">config</span><span class="p">(</span><span class="s">'spark.driver.bindAddress'</span><span class="p">,</span> <span class="s">'127.0.0.1'</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"a.txt"</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"b.txt"</span><span class="p">)</span>
</code></pre></div></div>

<p>Es ist wichtig, <code class="language-plaintext highlighter-rouge">.config('spark.driver.bindAddress', '127.0.0.1')</code> zu beachten. Andernfalls wird der Fehler <code class="language-plaintext highlighter-rouge">Service 'sparkDriver' could not bind on a random free port. You may check whether configuring an appropriate binding address</code> auftreten.</p>

<p>Allerdings trat zu diesem Zeitpunkt erneut ein Fehler auf.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Caused by: org.apache.spark.api.python.PythonException: Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
  File <span class="s2">"/usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py"</span>, line 473, <span class="k">in </span>main
    raise Exception<span class="o">((</span><span class="s2">"Python in worker has different version %s than that in "</span> +
Exception: Python im Worker hat eine andere Version 3.8 als im Driver 3.9. PySpark kann nicht mit unterschiedlichen Nebenversionen ausgefÃ¼hrt werden. Bitte Ã¼berprÃ¼fen Sie, ob die Umgebungsvariablen PYSPARK_PYTHON und PYSPARK_DRIVER_PYTHON korrekt gesetzt sind.
</code></pre></div></div>

<p>zeigt an, dass verschiedene Versionen von <code class="language-plaintext highlighter-rouge">Python</code> ausgefÃ¼hrt wurden.</p>

<p>Ã„ndern der <code class="language-plaintext highlighter-rouge">.bash_profile</code>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
<span class="nv">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
</code></pre></div></div>

<p>Es wird jedoch weiterhin der gleiche Fehler gemeldet. Nach einiger Recherche kÃ¶nnte der Grund dafÃ¼r sein, dass <code class="language-plaintext highlighter-rouge">spark</code> beim AusfÃ¼hren diese Umgebungsvariable nicht geladen hat und nicht die Standard-Umgebungsvariablen des Terminals verwendet.</p>

<p>In der Code mÃ¼ssen Sie folgendes einstellen:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
</code></pre></div></div>

<h1 id="spark-umgebungen-setzen">Spark-Umgebungen setzen</h1>
<p>os.environ[â€˜PYSPARK_PYTHONâ€™] = â€˜/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3â€™
os.environ[â€˜PYSPARK_DRIVER_PYTHONâ€™] = â€˜/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3â€™</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Das wird ausgefÃ¼hrt.

```shell
$ python sc.py
21/03/11 02:54:52 WARN NativeCodeLoader: Native-Hadoop-Bibliothek konnte fÃ¼r Ihre Plattform nicht geladen werden... Es werden integrierte Java-Klassen verwendet, wo zutreffend.
Verwende Sparks Standard-Log4j-Profil: org/apache/spark/log4j-defaults.properties
Standard-Log-Level auf "WARN" gesetzt.
Um das Logging-Level anzupassen, verwenden Sie sc.setLogLevel(newLevel). FÃ¼r SparkR verwenden Sie setLogLevel(newLevel).
PythonRDD[6] at RDD at PythonRDD.scala:53
</code></pre></div></div>

<p>Zu diesem Zeitpunkt wurde <code class="language-plaintext highlighter-rouge">b.txt</code> erstellt.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>â”œâ”€â”€ b.txt
â”‚Â Â  â”œâ”€â”€ _SUCCESS
â”‚Â Â  â”œâ”€â”€ part-00000
â”‚Â Â  â””â”€â”€ part-00001
</code></pre></div></div>

<p>Ã–ffne es.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>b.txt/part-00000
<span class="o">(</span><span class="s1">'college'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'two'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'things'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'worked'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'on,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'of'</span>, 8<span class="o">)</span>
<span class="o">(</span><span class="s1">'school,'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'writing'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'programming.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s2">"didn't"</span>, 4<span class="o">)</span>
<span class="o">(</span><span class="s1">'then,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'probably'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'are:'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'short'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'awful.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'They'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'plot,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'just'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'characters'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'them'</span>, 2<span class="o">)</span>
...
</code></pre></div></div>

<p>Erfolg! Kommt dir das bekannt vor? Es ist genau wie im <code class="language-plaintext highlighter-rouge">Hadoop</code>-Beispiel.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>Diese Dateien werden <code class="language-plaintext highlighter-rouge">HDFS</code> genannt. Hier wird <code class="language-plaintext highlighter-rouge">Spark</code> verwendet, um WÃ¶rter zu zÃ¤hlen. Mit nur wenigen Zeilen sieht es sehr praktisch aus.</p>

<h2 id="kubernetes">Kubernetes</h2>

<p>Als nÃ¤chstes beschÃ¤ftige ich mich mit <code class="language-plaintext highlighter-rouge">Kubernetes</code>, auch bekannt als <code class="language-plaintext highlighter-rouge">k8s</code>, wobei die 8 die acht ausgelassenen Buchstaben in der Mitte darstellt. Es handelt sich um ein Open-Source-System, das die Automatisierung der Bereitstellung, Skalierung und Verwaltung von Containeranwendungen ermÃ¶glicht.</p>

<p>Das <code class="language-plaintext highlighter-rouge">kubectl</code>-Befehlszeilentool wird verwendet, um Befehle auf einem Kubernetes-Cluster auszufÃ¼hren. Es kann verwendet werden, um Anwendungen bereitzustellen, Cluster-Ressourcen anzuzeigen und zu verwalten sowie Protokolle einzusehen.</p>

<p>Man kann es auch mit Homebrew installieren.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>kubectl
</code></pre></div></div>

<p>Protokollausgabe:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">==&gt;</span> Herunterladen von https://homebrew.bintray.com/bottles/kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Herunterladen von https://d29vzk4ow07wi7.cloudfront.net/0b4f08bd1d47cb913d7cd4571e3394c6747dfbad7ff114c5589c8396c1085ecf?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Entpacken von kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Hinweise
Die Bash-VervollstÃ¤ndigung wurde installiert <span class="k">in</span>:
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Zusammenfassung
ğŸº  /usr/local/Cellar/kubernetes-cli/1.20.1: 246 Dateien, 46,1MB
</code></pre></div></div>

<p>Installation abgeschlossen.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl
kubectl steuert den Kubernetes-Cluster-Manager.
</code></pre></div></div>

<p>Weitere Informationen finden Sie unter: https://kubernetes.io/docs/reference/kubectl/overview/</p>

<p>Grundlegende Befehle (AnfÃ¤nger):
  create        Erstellt eine Ressource aus einer Datei oder von stdin.
  expose        Nimmt einen Replication Controller, Service, Deployment oder Pod und macht ihn als neuen Kubernetes Service verfÃ¼gbar.
  run           FÃ¼hrt ein bestimmtes Image im Cluster aus.
  set           Legt spezifische Funktionen fÃ¼r Objekte fest.</p>

<p>Grundlegende Befehle (Fortgeschrittene):
  explain       Dokumentation von Ressourcen
  get           Eine oder mehrere Ressourcen anzeigen
  edit          Eine Ressource auf dem Server bearbeiten
  delete        Ressourcen lÃ¶schen anhand von Dateinamen, stdin, Ressourcen und Namen oder durch Ressourcen und Label-Selektor</p>

<p>Befehle fÃ¼r die Bereitstellung:
  rollout       Verwaltet das Rollout einer Ressource
  scale         Legt eine neue GrÃ¶ÃŸe fÃ¼r eine Deployment, ReplicaSet oder Replication Controller fest
  autoscale     Skaliert automatisch ein Deployment, ReplicaSet oder ReplicationController</p>

<p>Cluster Management Befehle:
  certificate   Zertifikatsressourcen Ã¤ndern.
  cluster-info  Cluster-Informationen anzeigen
  top           Ressourcenverbrauch (CPU/Speicher/Speicherplatz) anzeigen.
  cordon        Knoten als nicht planbar markieren
  uncordon      Knoten als planbar markieren
  drain         Knoten fÃ¼r Wartungsarbeiten vorbereiten
  taint         Taints auf einem oder mehreren Knoten aktualisieren</p>

<p>Fehlerbehebung und Debugging-Befehle:
  describe      Zeigt Details einer bestimmten Ressource oder einer Gruppe von Ressourcen an
  logs          Gibt die Protokolle eines Containers in einem Pod aus
  attach        Verbindet sich mit einem laufenden Container
  exec          FÃ¼hrt einen Befehl in einem Container aus
  port-forward  Leitet einen oder mehrere lokale Ports an einen Pod weiter
  proxy         Startet einen Proxy zum Kubernetes API-Server
  cp            Kopiert Dateien und Verzeichnisse zu und von Containern
  auth          ÃœberprÃ¼ft die Autorisierung
  debug         Erstellt Debugging-Sitzungen zur Fehlerbehebung von Workloads und Knoten</p>

<p>Erweiterte Befehle:
  diff          Vergleicht die Live-Version mit der Version, die angewendet werden wÃ¼rde
  apply         Wendet eine Konfiguration auf eine Ressource an, basierend auf einem Dateinamen oder stdin
  patch         Aktualisiert Feld(er) einer Ressource
  replace       Ersetzt eine Ressource basierend auf einem Dateinamen oder stdin
  wait          Experimentell: Wartet auf eine bestimmte Bedingung fÃ¼r eine oder mehrere Ressourcen.
  kustomize     Erstellt ein Kustomization-Ziel aus einem Verzeichnis oder einer Remote-URL.</p>

<p>Einstellungsbefehle:
  label         Aktualisiert die Labels einer Ressource
  annotate      Aktualisiert die Annotationen einer Ressource
  completion    Gibt den Shell-VervollstÃ¤ndigungscode fÃ¼r die angegebene Shell aus (bash oder zsh)</p>

<p>Weitere Befehle:
  api-resources Zeigt die unterstÃ¼tzten API-Ressourcen auf dem Server an
  api-versions  Zeigt die unterstÃ¼tzten API-Versionen auf dem Server in der Form â€œGruppe/Versionâ€ an
  config        Bearbeitet kubeconfig-Dateien
  plugin        Bietet Hilfsmittel fÃ¼r die Interaktion mit Plugins.
  version       Zeigt die Versionsinformationen des Clients und des Servers an</p>

<p>Verwendung:
  kubectl [flags] [options]</p>

<p>Verwenden Sie â€œkubectl <Befehl> --help", um weitere Informationen zu einem bestimmten Befehl zu erhalten.
Verwenden Sie "kubectl options", um eine Liste globaler Befehlszeilenoptionen anzuzeigen (gilt fÃ¼r alle Befehle).</Befehl></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Erstellen wir eine Konfigurationsdatei.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  minReadySeconds: 5
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Der obige Codeblock enthÃ¤lt keine spezifischen Anweisungen oder Inhalte, die Ã¼bersetzt werden mÃ¼ssen. Es handelt sich lediglich um einen leeren Codeblock, der in Markdown verwendet wird, um Codeabschnitte zu kennzeichnen. Wenn Sie spezifische Inhalte oder Anweisungen haben, die Ã¼bersetzt werden sollen, geben Sie diese bitte an.

```shell
$ kubectl apply -f simple_deployment.yaml
Die Verbindung zum Server localhost:8080 wurde abgelehnt â€“ haben Sie den richtigen Host oder Port angegeben?
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl cluster-info
</code></pre></div></div>

<p>Um Cluster-Probleme weiter zu debuggen und zu diagnostizieren, verwenden Sie <code class="language-plaintext highlighter-rouge">kubectl cluster-info dump</code>.
Die Verbindung zum Server localhost:8080 wurde abgelehnt â€“ haben Sie den richtigen Host oder Port angegeben?</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Wenn Sie es versuchen, im Terminal der offiziellen Website auszufÃ¼hren.

```shell
$ start.sh
Starte Kubernetes...minikube Version: v1.8.1
Commit: cbda04cf6bbe65e987ae52bb393c10099ab62014
* minikube v1.8.1 auf Ubuntu 18.04
* Verwendung des none-Treibers basierend auf Benutzerkonfiguration
* LÃ¤uft auf localhost (CPUs=2, Speicher=2460MB, Festplatte=145651MB) ...
* Betriebssystemversion ist Ubuntu 18.04.4 LTS
</code></pre></div></div>

<ul>
  <li>Vorbereitung von Kubernetes v1.17.3 auf Docker 19.03.6 â€¦
    <ul>
      <li>kubelet.resolv-conf=/run/systemd/resolve/resolv.conf</li>
    </ul>
  </li>
  <li>Starten von Kubernetes â€¦</li>
  <li>Aktivieren von Addons: default-storageclass, storage-provisioner</li>
  <li>Konfiguration der lokalen Host-Umgebung â€¦</li>
  <li>Fertig! kubectl ist nun so konfiguriert, dass es â€œminikubeâ€ verwendet</li>
  <li>Das â€˜dashboardâ€™-Addon ist aktiviert
Kubernetes gestartet
```</li>
</ul>

<p>Kehren wir zurÃ¼ck zu unserem Terminal.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
<span class="nv">$ </span>kubectl version
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
Die Verbindung zum Server localhost:8080 wurde abgelehnt â€“ haben Sie den richtigen Host oder Port angegeben?
</code></pre></div></div>

<p>Interessanterweise fÃ¼hrt das HinzufÃ¼gen der Option <code class="language-plaintext highlighter-rouge">--client</code> nicht zu einem Fehler.</p>

<p>Die Dokumentation besagt, dass zuerst <code class="language-plaintext highlighter-rouge">Minikube</code> installiert werden muss.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>minikube
<span class="o">==&gt;</span> Lade https://homebrew.bintray.com/bottles/minikube-1.16.0.big_sur.bottle.tar.gz herunter
<span class="o">==&gt;</span> Lade von https://d29vzk4ow07wi7.cloudfront.net/1b6d7d1b97b11b6b07e4fa531c2dc21770da290da9b2816f360fd923e00c85fc?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> GieÃŸe minikube-1.16.0.big_sur.bottle.tar.gz ein
<span class="o">==&gt;</span> Hinweise
Die Bash-VervollstÃ¤ndigung wurde installiert <span class="k">in</span>:
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Zusammenfassung
ğŸº  /usr/local/Cellar/minikube/1.16.0: 8 Dateien, 64.6MB
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube start
ğŸ˜„  minikube v1.16.0 auf Darwin 11.2.2
ğŸ‰  minikube 1.18.1 ist verfÃ¼gbar! Lade es herunter: https://github.com/kubernetes/minikube/releases/tag/v1.18.1
ğŸ’¡  Um diese Benachrichtigung zu deaktivieren, fÃ¼hre aus: <span class="s1">'minikube config set WantUpdateNotification false'</span>
</code></pre></div></div>

<p>âœ¨  Automatisch den Virtualbox-Treiber ausgewÃ¤hlt
ğŸ’¿  VM-Boot-Image wird heruntergeladen â€¦
    &gt; minikube-v1.16.0.iso.sha256: 65 B / 65 B [â€”â€”â€”â€”-] 100.00% ? p/s 0s
    &gt; minikube-v1.16.0.iso: 212.62 MiB / 212.62 MiB [] 100.00% 5.32 MiB p/s 40s
ğŸ‘  Starte den Control-Plane-Knoten minikube im Cluster minikube
ğŸ’¾  Kubernetes v1.20.0 Preload wird heruntergeladen â€¦
    &gt; preloaded-images-k8s-v8-v1â€¦.: 491.00 MiB / 491.00 MiB  100.00% 7.52 MiB
ğŸ”¥  Erstelle Virtualbox-VM (CPUs=2, Speicher=4000MB, Festplatte=20000MB) â€¦
â—  Diese VM hat Probleme, auf https://k8s.gcr.io zuzugreifen
ğŸ’¡  Um neue externe Images zu pullen, mÃ¼ssen Sie mÃ¶glicherweise einen Proxy konfigurieren: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
ğŸ³  Bereite Kubernetes v1.20.0 auf Docker 20.10.0 vor â€¦
    â–ª Zertifikate und SchlÃ¼ssel werden generiert â€¦
    â–ª Control Plane wird hochgefahren â€¦
    â–ª RBAC-Regeln werden konfiguriert â€¦
ğŸ”  ÃœberprÃ¼fe Kubernetes-Komponentenâ€¦
ğŸŒŸ  Aktivierte Addons: storage-provisioner, default-storageclass
ğŸ„  Fertig! kubectl ist nun standardmÃ¤ÃŸig fÃ¼r die Verwendung des Clusters â€œminikubeâ€ und des Namespace â€œdefaultâ€ konfiguriert</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Als NÃ¤chstes greifen wir auf diesen Cluster zu.

```shell
$ kubectl get po -A
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
kube-system   coredns-74ff55c5b-ndbcr            1/1     Running   0          60s
kube-system   etcd-minikube                      0/1     Running   0          74s
kube-system   kube-apiserver-minikube            1/1     Running   0          74s
kube-system   kube-controller-manager-minikube   1/1     Running   0          74s
kube-system   kube-proxy-g2296                   1/1     Running   0          60s
kube-system   kube-scheduler-minikube            0/1     Running   0          74s
kube-system   storage-provisioner                1/1     Running   1          74s
</code></pre></div></div>

<p>Um das Dashboard von <code class="language-plaintext highlighter-rouge">minikube</code> zu Ã¶ffnen, fÃ¼hren Sie den folgenden Befehl aus:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube dashboard
</code></pre></div></div>

<p>Dieser Befehl startet das Kubernetes-Dashboard und Ã¶ffnet es in Ihrem Standard-Webbrowser.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube dashboard
ğŸ”Œ  Dashboard wird aktiviert ...
ğŸ¤”  ÃœberprÃ¼fung der Dashboard-IntegritÃ¤t ...
ğŸš€  Proxy wird gestartet ...
ğŸ¤”  ÃœberprÃ¼fung der Proxy-IntegritÃ¤t ...
ğŸ‰  Ã–ffnen von http://127.0.0.1:50030/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ <span class="k">in </span>Ihrem Standardbrowser...
</code></pre></div></div>

<p><img src="assets/images/distributed/k8s.png" alt="k8s" /></p>

<p>Wie schaltet man es aus?</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube
minikube stellt lokale Kubernetes-Cluster bereit und verwaltet sie, die fÃ¼r Entwicklungs-Workflows optimiert sind.
</code></pre></div></div>

<p>Grundlegende Befehle:
  start          Startet einen lokalen Kubernetes-Cluster
  status         Ruft den Status eines lokalen Kubernetes-Clusters ab
  stop           Stoppt einen laufenden lokalen Kubernetes-Cluster
  delete         LÃ¶scht einen lokalen Kubernetes-Cluster
  dashboard      Greift auf das Kubernetes-Dashboard zu, das im Minikube-Cluster lÃ¤uft
  pause          Pausiert Kubernetes
  unpause        Setzt Kubernetes fort</p>

<p>Bilder-Befehle:
  docker-env     Konfiguriert die Umgebung, um den Docker-Daemon von minikube zu verwenden
  podman-env     Konfiguriert die Umgebung, um den Podman-Dienst von minikube zu verwenden
  cache          FÃ¼gt ein lokales Bild hinzu, lÃ¶scht es oder lÃ¤dt es in minikube hoch</p>

<p>Konfigurations- und Verwaltungsbefehle:
  addons         Aktivieren oder deaktivieren Sie ein Minikube-Addon
  config         Ã„ndern Sie persistente Konfigurationswerte
  profile        Abrufen oder Auflisten der aktuellen Profile (Cluster)
  update-context Aktualisieren Sie kubeconfig im Falle einer IP- oder PortÃ¤nderung</p>

<p>Netzwerk- und KonnektivitÃ¤tsbefehle:
  service        Gibt eine URL zurÃ¼ck, um eine Verbindung zu einem Dienst herzustellen
  tunnel         Verbindung zu LoadBalancer-Diensten herstellen</p>

<p>Erweiterte Befehle:
  mount          Bindet das angegebene Verzeichnis in minikube ein
  ssh            Loggt sich in die minikube-Umgebung ein (fÃ¼r Debugging-Zwecke)
  kubectl        FÃ¼hrt eine kubectl-BinÃ¤rdatei aus, die der Cluster-Version entspricht
  node           FÃ¼gt zusÃ¤tzliche Knoten hinzu, entfernt sie oder listet sie auf</p>

<p>Fehlerbehebungsbefehle:
  ssh-key        Ruft den Pfad des SSH-IdentitÃ¤tsschlÃ¼ssels des angegebenen Knotens ab
  ssh-host       Ruft den SSH-HostschlÃ¼ssel des angegebenen Knotens ab
  ip             Ruft die IP-Adresse des angegebenen Knotens ab
  logs           Gibt Protokolle zurÃ¼ck, um einen lokalen Kubernetes-Cluster zu debuggen
  update-check   Druckt die aktuelle und die neueste Versionsnummer
  version        Druckt die Version von minikube</p>

<p>Andere Befehle:
  completion     Generiert BefehlsvervollstÃ¤ndigung fÃ¼r eine Shell</p>

<p>Verwenden Sie <code class="language-plaintext highlighter-rouge">minikube &lt;Befehl&gt; --help</code>, um weitere Informationen zu einem bestimmten Befehl zu erhalten.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Es scheint, dass es sich um `minikube stop` handelt.

ZurÃ¼ck zu `kubernetes`, jetzt funktioniert alles einwandfrei.

```shell
$ kubectl cluster-info
Kubernetes Control Plane lÃ¤uft unter https://192.168.99.100:8443
KubeDNS lÃ¤uft unter https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
</code></pre></div></div>

<p>Um Cluster-Probleme weiter zu debuggen und zu diagnostizieren, verwenden Sie <code class="language-plaintext highlighter-rouge">kubectl cluster-info dump</code>.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Wenn wir `https://192.168.99.100:8443` Ã¶ffnen, zeigt der Browser:

```json
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "Failure",
  "message": "verboten: Benutzer \"system:anonymous\" kann den Pfad \"/\" nicht abrufen",
  "reason": "Forbidden",
  "details": {
    
  },
  "code": 403
}
</code></pre></div></div>

<p>è®¿é—®<code class="language-plaintext highlighter-rouge">https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</code>ï¼š</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Status"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"apiVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Fehler"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Dienste </span><span class="se">\"</span><span class="s2">kube-dns:dns</span><span class="se">\"</span><span class="s2"> sind verboten: Benutzer </span><span class="se">\"</span><span class="s2">system:anonymous</span><span class="se">\"</span><span class="s2"> kann die Ressource </span><span class="se">\"</span><span class="s2">services/proxy</span><span class="se">\"</span><span class="s2"> in der API-Gruppe </span><span class="se">\"\"</span><span class="s2"> im Namespace </span><span class="se">\"</span><span class="s2">kube-system</span><span class="se">\"</span><span class="s2"> nicht abrufen"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"reason"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Verboten"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"details"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-dns:dns"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"services"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"code"</span><span class="p">:</span><span class="w"> </span><span class="mi">403</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Probieren wir die gerade besprochene Konfiguration aus.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> simple_deployment.yaml
deployment.apps/nginx-deployment erstellt
</code></pre></div></div>

<p>Es gab ein kleines Problem. Aber bis hierher haben wir <code class="language-plaintext highlighter-rouge">Kubernetes</code> zum Laufen gebracht. Beenden wir es erstmal. Wir werden spÃ¤ter weiter damit spielen.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube stop
âœ‹  Stoppe den Knoten <span class="s2">"minikube"</span>  ...
ğŸ›‘  1 Knoten gestoppt.
</code></pre></div></div>

<p>ÃœberprÃ¼fen, ob beendet ist.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>w<span class="nv">$ </span>minikube dashboard
ğŸ¤·  Der Control-Plane-Knoten muss ausgefÃ¼hrt werden, um diesen Befehl auszufÃ¼hren
ğŸ‘‰  Um einen Cluster zu starten, fÃ¼hren Sie aus: <span class="s2">"minikube start"</span>
</code></pre></div></div>

<h2 id="docker">Docker</h2>

<p><code class="language-plaintext highlighter-rouge">Docker</code> ist ebenfalls eine Container-Plattform, die dazu beitrÃ¤gt, die Erstellung, Freigabe und AusfÃ¼hrung moderner Anwendungen zu beschleunigen. Laden Sie die Anwendung von der offiziellen Website herunter.</p>

<p><img src="assets/images/distributed/docker.png" alt="docker" /></p>

<p>Die Verwendung des Clients ist etwas langsam. Lass uns die Befehlszeile verwenden.</p>

<div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker
</code></pre></div></div>

<p>Verwendung:  docker [OPTIONEN] BEFEHL</p>

<p>Eine eigenstÃ¤ndige Laufzeitumgebung fÃ¼r Container</p>

<p>Optionen:
      â€“config string      Speicherort der Client-Konfigurationsdateien (Standard â€œ/Users/lzw/.dockerâ€)
  -c, â€“context string     Name des Kontexts, der fÃ¼r die Verbindung zum Daemon verwendet werden soll (Ã¼berschreibt die DOCKER_HOST-Umgebungsvariable und den Standardkontext, der mit â€œdocker context useâ€ festgelegt wurde)
  -D, â€“debug              Debug-Modus aktivieren
  -H, â€“host list          Daemon-Socket(s), zu dem/denen eine Verbindung hergestellt werden soll
  -l, â€“log-level string   Legt das Log-Level fest (â€œdebugâ€|â€infoâ€|â€warnâ€|â€errorâ€|â€fatalâ€) (Standard â€œinfoâ€)
      â€“tls                TLS verwenden; impliziert durch â€“tlsverify
      â€“tlscacert string   Nur Zertifikate vertrauen, die von dieser CA signiert wurden (Standard â€œ/Users/lzw/.docker/ca.pemâ€)
      â€“tlscert string     Pfad zur TLS-Zertifikatsdatei (Standard â€œ/Users/lzw/.docker/cert.pemâ€)
      â€“tlskey string      Pfad zur TLS-SchlÃ¼sseldatei (Standard â€œ/Users/lzw/.docker/key.pemâ€)
      â€“tlsverify          TLS verwenden und die Remote-Verbindung Ã¼berprÃ¼fen
  -v, â€“version            Versionsinformationen anzeigen und beenden</p>

<p>Management-Befehle:
  app*        Docker App (Docker Inc., v0.9.1-beta3)
  builder     Builds verwalten
  buildx*     Mit BuildKit bauen (Docker Inc., v0.5.1-docker)
  config      Docker-Konfigurationen verwalten
  container   Container verwalten
  context     Kontexte verwalten
  image       Images verwalten
  manifest    Docker-Image-Manifeste und Manifest-Listen verwalten
  network     Netzwerke verwalten
  node        Swarm-Knoten verwalten
  plugin      Plugins verwalten
  scan*       Docker Scan (Docker Inc., v0.5.0)
  secret      Docker-Geheimnisse verwalten
  service     Dienste verwalten
  stack       Docker-Stacks verwalten
  swarm       Swarm verwalten
  system      Docker verwalten
  trust       VertrauenswÃ¼rdigkeit von Docker-Images verwalten
  volume      Volumes verwalten</p>

<p>Befehle:
  attach      Lokale Standard-Eingabe-, Ausgabe- und FehlerstrÃ¶me an einen laufenden Container anhÃ¤ngen
  build       Ein Image aus einer Dockerfile erstellen
  commit      Ein neues Image aus den Ã„nderungen eines Containers erstellen
  cp          Dateien/Ordner zwischen einem Container und dem lokalen Dateisystem kopieren
  create      Einen neuen Container erstellen
  diff        Ã„nderungen an Dateien oder Verzeichnissen im Dateisystem eines Containers Ã¼berprÃ¼fen
  events      Echtzeit-Ereignisse vom Server abrufen
  exec        Einen Befehl in einem laufenden Container ausfÃ¼hren
  export      Das Dateisystem eines Containers als tar-Archiv exportieren
  history     Die Historie eines Images anzeigen
  images      Images auflisten
  import      Den Inhalt eines tar-Archivs importieren, um ein Dateisystem-Image zu erstellen
  info        Systemweite Informationen anzeigen
  inspect     Niedrigstufige Informationen zu Docker-Objekten zurÃ¼ckgeben
  kill        Einen oder mehrere laufende Container beenden
  load        Ein Image aus einem tar-Archiv oder STDIN laden
  login       Bei einer Docker-Registry anmelden
  logout      Von einer Docker-Registry abmelden
  logs        Die Protokolle eines Containers abrufen
  pause       Alle Prozesse in einem oder mehreren Containern anhalten
  port        Port-Zuordnungen oder eine spezifische Zuordnung fÃ¼r den Container auflisten
  ps          Container auflisten
  pull        Ein Image oder ein Repository aus einer Registry herunterladen
  push        Ein Image oder ein Repository in eine Registry hochladen
  rename      Einen Container umbenennen
  restart     Einen oder mehrere Container neu starten
  rm          Einen oder mehrere Container entfernen
  rmi         Einen oder mehrere Images entfernen
  run         Einen Befehl in einem neuen Container ausfÃ¼hren
  save        Ein oder mehrere Images in ein tar-Archiv speichern (standardmÃ¤ÃŸig nach STDOUT gestreamt)
  search      Im Docker Hub nach Images suchen
  start       Einen oder mehrere gestoppte Container starten
  stats       Einen Live-Stream der Ressourcennutzungsstatistiken von Container(n) anzeigen
  stop        Einen oder mehrere laufende Container stoppen
  tag         Ein Tag TARGET_IMAGE erstellen, das auf SOURCE_IMAGE verweist
  top         Die laufenden Prozesse eines Containers anzeigen
  unpause     Alle Prozesse in einem oder mehreren Containern fortsetzen
  update      Die Konfiguration eines oder mehrerer Container aktualisieren
  version     Die Docker-Versionsinformationen anzeigen
  wait        Blockieren, bis ein oder mehrere Container stoppen, und dann deren Exit-Codes ausgeben</p>

<p>FÃ¼hren Sie <code class="language-plaintext highlighter-rouge">docker COMMAND --help</code> aus, um weitere Informationen zu einem Befehl zu erhalten.</p>

<p>Um mehr Hilfe zu Docker zu erhalten, schauen Sie sich unsere Anleitungen unter https://docs.docker.com/go/guides/ an.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Folgen Sie dem Tutorial und probieren Sie es aus.

```shell
$ docker run -d -p 80:80 docker/getting-started
Unable to find image 'docker/getting-started:latest' locally
latest: Pulling from docker/getting-started
aad63a933944: Pull complete
b14da7a62044: Pull complete
343784d40d66: Pull complete
6f617e610986: Pull complete
Digest: sha256:d2c4fb0641519ea208f20ab03dc40ec2a5a53fdfbccca90bef14f870158ed577
Status: Downloaded newer image for docker/getting-started:latest
815f13fc8f99f6185257980f74c349e182842ca572fe60ff62cbb15641199eaf
docker: Error response from daemon: Ports are not available: listen tcp 0.0.0.0:80: bind: address already in use.
</code></pre></div></div>

<p>Ãœbersetzung:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 80:80 docker/getting-started
Das Image <span class="s1">'docker/getting-started:latest'</span> wurde lokal nicht gefunden.
latest: Wird von docker/getting-started gezogen
aad63a933944: Pull <span class="nb">complete
</span>b14da7a62044: Pull <span class="nb">complete
</span>343784d40d66: Pull <span class="nb">complete
</span>6f617e610986: Pull <span class="nb">complete
</span>Digest: sha256:d2c4fb0641519ea208f20ab03dc40ec2a5a53fdfbccca90bef14f870158ed577
Status: Neueres Image fÃ¼r docker/getting-started wurde heruntergeladen.
815f13fc8f99f6185257980f74c349e182842ca572fe60ff62cbb15641199eaf
docker: Fehlerantwort vom Daemon: Ports sind nicht verfÃ¼gbar: listen tcp 0.0.0.0:80: <span class="nb">bind</span>: Adresse wird bereits verwendet.
</code></pre></div></div>

<p>Ã„ndere den Port.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:80 docker/getting-started
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p><img src="assets/images/distributed/docker_run.png" alt="docker_run" /></p>

<p>Ã–ffnen Sie den Browser, um zu zeigen, dass wir <code class="language-plaintext highlighter-rouge">docker</code> erfolgreich gestartet haben.</p>

<p><img src="assets/images/distributed/browser.png" alt="Browser" /></p>

<p>Stoppe den Container. Verwende die zuvor zurÃ¼ckgegebene <code class="language-plaintext highlighter-rouge">ID</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker stop 45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p>Zu diesem Zeitpunkt war die Website bereits nicht mehr erreichbar.</p>

<p>Das deutet darauf hin, dass <code class="language-plaintext highlighter-rouge">docker</code> wie eine virtuelle Maschine funktioniert.</p>

<h2 id="flink">Flink</h2>

<p>Ã–ffnen Sie die offizielle Website.</p>

<p><img src="assets/images/distributed/flink-home-graphic.png" alt="flink-home-graphic" /></p>

<p><code class="language-plaintext highlighter-rouge">Flink</code> spricht von <code class="language-plaintext highlighter-rouge">Stateful</code>-Berechnungen fÃ¼r DatenstrÃ¶me. Was bedeutet <code class="language-plaintext highlighter-rouge">Stateful</code>? Das ist mir noch nicht ganz klar. Das obige Diagramm ist jedoch sehr interessant. Lass es uns ausprobieren.</p>

<p>Es wird eine Java-Umgebung benÃ¶tigt.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>java <span class="nt">-version</span>
java version <span class="s2">"1.8.0_151"</span>
Java<span class="o">(</span>TM<span class="o">)</span> SE Runtime Environment <span class="o">(</span>Build 1.8.0_151-b12<span class="o">)</span>
Java HotSpot<span class="o">(</span>TM<span class="o">)</span> 64-Bit Server VM <span class="o">(</span>Build 25.151-b12, gemischter Modus<span class="o">)</span>
</code></pre></div></div>

<p>Laden Sie die neueste Version <code class="language-plaintext highlighter-rouge">flink-1.12.2-bin-scala_2.11.tar</code> von der offiziellen Website herunter.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/start-cluster.sh
Cluster wird gestartet.
Standalonesession-Daemon wird auf Host lzwjava gestartet.
Taskexecutor-Daemon wird auf Host lzwjava gestartet.
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/flink run examples/streaming/WordCount.jar
AusfÃ¼hrung des WordCount-Beispiels mit dem Standard-Eingabedatensatz.
Verwenden Sie <span class="nt">--input</span>, um eine Dateieingabe anzugeben.
Das Ergebnis wird auf stdout ausgegeben. Verwenden Sie <span class="nt">--output</span>, um einen Ausgabepfad anzugeben.
Der Job wurde mit der JobID 60f37647c20c2a6654359bd34edab807 Ã¼bermittelt.
ProgrammausfÃ¼hrung abgeschlossen
Der Job mit der JobID 60f37647c20c2a6654359bd34edab807 ist abgeschlossen.
Job-Laufzeit: 757 ms
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">tail </span>log/flink-<span class="k">*</span><span class="nt">-taskexecutor-</span><span class="k">*</span>.out
<span class="o">(</span>nymph,1<span class="o">)</span>
<span class="o">(</span><span class="k">in</span>,3<span class="o">)</span>
<span class="o">(</span>thy,1<span class="o">)</span>
<span class="o">(</span>orisons,1<span class="o">)</span>
<span class="o">(</span>be,4<span class="o">)</span>
<span class="o">(</span>all,2<span class="o">)</span>
<span class="o">(</span>my,1<span class="o">)</span>
<span class="o">(</span>sins,1<span class="o">)</span>
<span class="o">(</span>remember,1<span class="o">)</span>
<span class="o">(</span>d,4<span class="o">)</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/stop-cluster.sh
Taskexecutor-Daemon wird gestoppt <span class="o">(</span>pid: 41812<span class="o">)</span> auf Host lzwjava.
</code></pre></div></div>

<p>Ja, der Einstieg war erfolgreich. Man kann sehen, dass dies <code class="language-plaintext highlighter-rouge">Spark</code> sehr Ã¤hnlich ist.</p>

<h2 id="kylin">Kylin</h2>

<p>Ã–ffnen Sie die offizielle Website.</p>

<blockquote>
  <p>Apache Kylinâ„¢ ist ein Open-Source, verteiltes Analytisches Data Warehouse fÃ¼r Big Data; es wurde entwickelt, um OLAP-FÃ¤higkeiten (Online Analytical Processing) im Zeitalter von Big Data bereitzustellen. Durch die Modernisierung der Multi-Dimensional-Cube- und Vorberechnungstechnologie auf Hadoop und Spark ist Kylin in der Lage, nahezu konstante Abfragegeschwindigkeiten zu erreichen, unabhÃ¤ngig vom stetig wachsenden Datenvolumen. Indem Kylin die Abfragelatenz von Minuten auf unter eine Sekunde reduziert, bringt es Online-Analysen zurÃ¼ck zu Big Data.</p>
</blockquote>

<blockquote>
  <p>Apache Kylinâ„¢ ermÃ¶glicht es Ihnen, Milliarden von Zeilen in weniger als einer Sekunde in 3 Schritten abzufragen.</p>

  <ol>
    <li>Identifizieren Sie ein Stern- oder Schneeflockenschema auf Hadoop.</li>
    <li>Erstellen Sie einen Cube aus den identifizierten Tabellen.</li>
    <li>FÃ¼hren Sie Abfragen mit ANSI-SQL durch und erhalten Sie Ergebnisse in weniger als einer Sekunde Ã¼ber ODBC, JDBC oder eine RESTful API.</li>
  </ol>
</blockquote>

<p><img src="assets/images/distributed/kylin_diagram.png" alt="kylin_diagram" /></p>

<p>Es handelt sich im Wesentlichen um eine Ebene zur Analyse von Big Data. Mit ihr kann man sehr schnell suchen. Sie dient als BrÃ¼cke.</p>

<p>Leider ist die Nutzung derzeit nur in einer <code class="language-plaintext highlighter-rouge">Linux</code>-Umgebung mÃ¶glich. Ich werde spÃ¤ter noch einmal daran herumspielen.</p>

<h2 id="mongodb">MongoDB</h2>

<p>Das ist auch eine Art von Datenbank. Versuchen Sie, es zu installieren.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew tap mongodb/brew
<span class="o">==&gt;</span> Tapping mongodb/brew
Klone nach <span class="s1">'/usr/local/Homebrew/Library/Taps/mongodb/homebrew-brew'</span>...
remote: Enumerating objects: 63, <span class="k">done</span><span class="nb">.</span>
remote: Counting objects: 100% <span class="o">(</span>63/63<span class="o">)</span>, <span class="k">done</span><span class="nb">.</span>
remote: Compressing objects: 100% <span class="o">(</span>62/62<span class="o">)</span>, <span class="k">done</span><span class="nb">.</span>
remote: Total 566 <span class="o">(</span>delta 21<span class="o">)</span>, reused 6 <span class="o">(</span>delta 1<span class="o">)</span>, pack-reused 503
Empfange Objekte: 100% <span class="o">(</span>566/566<span class="o">)</span>, 121.78 KiB | 335.00 KiB/s, <span class="k">done</span><span class="nb">.</span>
LÃ¶se Deltas auf: 100% <span class="o">(</span>259/259<span class="o">)</span>, <span class="k">done</span><span class="nb">.</span>
11 Formeln angezapft <span class="o">(</span>39 Dateien, 196.2KB<span class="o">)</span><span class="nb">.</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>mongodb-community@4.4
<span class="o">==&gt;</span> Installation von mongodb-community aus mongodb/brew
<span class="o">==&gt;</span> Herunterladen von https://fastdl.mongodb.org/tools/db/mongodb-database-tools-macos-x86_64-100.3.0.zip
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Herunterladen von https://fastdl.mongodb.org/osx/mongodb-macos-x86_64-4.4.3.tgz
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Installation der AbhÃ¤ngigkeiten fÃ¼r mongodb/brew/mongodb-community: mongodb-database-tools
<span class="o">==&gt;</span> Installation der AbhÃ¤ngigkeit mongodb/brew/mongodb-community: mongodb-database-tools
Fehler: Der <span class="sb">`</span>brew <span class="nb">link</span><span class="sb">`</span><span class="nt">-Schritt</span> wurde nicht erfolgreich abgeschlossen
Die Formel wurde gebaut, ist aber nicht <span class="k">in</span> /usr/local verlinkt
Konnte bin/bsondump nicht verlinken
Ziel /usr/local/bin/bsondump
ist ein Symlink, der zu mongodb gehÃ¶rt. Sie kÃ¶nnen ihn entlinken:
  brew <span class="nb">unlink </span>mongodb
</code></pre></div></div>

<p>Um den Link zu erzwingen und alle konfligierenden Dateien zu Ã¼berschreiben:
  brew link â€“overwrite mongodb-database-tools</p>

<p>Um alle Dateien aufzulisten, die gelÃ¶scht wÃ¼rden:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  brew <span class="nb">link</span> <span class="nt">--overwrite</span> <span class="nt">--dry-run</span> mongodb-database-tools
</code></pre></div></div>

<p>MÃ¶gliche konfliktierende Dateien sind:
/usr/local/bin/bsondump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/bsondump
/usr/local/bin/mongodump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongodump
/usr/local/bin/mongoexport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoexport
/usr/local/bin/mongofiles -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongofiles
/usr/local/bin/mongoimport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoimport
/usr/local/bin/mongorestore -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongorestore
/usr/local/bin/mongostat -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongostat
/usr/local/bin/mongotop -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongotop
==&gt; Zusammenfassung
ğŸº  /usr/local/Cellar/mongodb-database-tools/100.3.0: 13 Dateien, 154MB, in 11 Sekunden erstellt
==&gt; Installation von mongodb/brew/mongodb-community
Fehler: Der <code class="language-plaintext highlighter-rouge">brew link</code> Schritt wurde nicht erfolgreich abgeschlossen
Die Formel wurde erstellt, ist jedoch nicht in /usr/local verlinkt
Konnte bin/mongo nicht verlinken
Ziel /usr/local/bin/mongo
ist ein Symlink, der zu mongodb gehÃ¶rt. Sie kÃ¶nnen ihn entlinken:
  brew unlink mongodb</p>

<p>Um den Link zu erzwingen und alle konfligierenden Dateien zu Ã¼berschreiben:
  brew link â€“overwrite mongodb-community</p>

<p>Um alle Dateien aufzulisten, die gelÃ¶scht wÃ¼rden:
  brew link â€“overwrite â€“dry-run mongodb-community</p>

<p>MÃ¶gliche konfliktierende Dateien sind:
/usr/local/bin/mongo -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongo
/usr/local/bin/mongod -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongod
/usr/local/bin/mongos -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongos
==&gt; Hinweise
Um launchd zu veranlassen, mongodb/brew/mongodb-community jetzt zu starten und bei der Anmeldung neu zu starten:
  brew services start mongodb/brew/mongodb-community
Oder, wenn Sie keinen Hintergrunddienst benÃ¶tigen/wollen, kÃ¶nnen Sie einfach ausfÃ¼hren:
  mongod â€“config /usr/local/etc/mongod.conf
==&gt; Zusammenfassung
ğŸº  /usr/local/Cellar/mongodb-community/4.4.3: 11 Dateien, 156,8 MB, in 10 Sekunden erstellt
==&gt; Hinweise
==&gt; mongodb-community
Um launchd zu veranlassen, mongodb/brew/mongodb-community jetzt zu starten und bei der Anmeldung neu zu starten:
  brew services start mongodb/brew/mongodb-community
Oder, wenn Sie keinen Hintergrunddienst benÃ¶tigen/wollen, kÃ¶nnen Sie einfach ausfÃ¼hren:
  mongod â€“config /usr/local/etc/mongod.conf</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Zuvor hatte ich eine Ã¤ltere Version installiert. Ich werde die VerknÃ¼pfungen aufheben.

```shell
$ brew unlink mongodb
Unlinking /usr/local/Cellar/mongodb/3.0.7... 11 Symlinks entfernt
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--version</span>
db version v4.4.3
Build Info: <span class="o">{</span>
    <span class="s2">"version"</span>: <span class="s2">"4.4.3"</span>,
    <span class="s2">"gitVersion"</span>: <span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span>,
    <span class="s2">"modules"</span>: <span class="o">[]</span>,
    <span class="s2">"allocator"</span>: <span class="s2">"system"</span>,
    <span class="s2">"environment"</span>: <span class="o">{</span>
        <span class="s2">"distarch"</span>: <span class="s2">"x86_64"</span>,
        <span class="s2">"target_arch"</span>: <span class="s2">"x86_64"</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>FÃ¼hren Sie dann <code class="language-plaintext highlighter-rouge">mongod</code> aus, um den MongoDB-Server zu starten. Beim ersten Start wurde jedoch gemeldet, dass <code class="language-plaintext highlighter-rouge">/data/db</code> nicht existiert. Wir erstellen ein Verzeichnis, <code class="language-plaintext highlighter-rouge">~/mongodb</code>, um die Datenbankdateien dort zu speichern.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--dbpath</span> ~/mongodb
</code></pre></div></div>

<p>Ausgabe:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.838+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23285</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"TLS 1.0 wird automatisch deaktiviert. Um TLS 1.0 zu erzwingen, geben Sie --sslDisabledProtocols 'none' an"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"W"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"ASIO"</span><span class="p">,</span><span class="w">     </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">22601</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Keine TransportLayer wÃ¤hrend des NetworkInterface-Starts konfiguriert"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"NETWORK"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4648602</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Implizites TCP FastOpen wird verwendet."</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"STORAGE"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4615611</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"MongoDB startet"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"pid"</span><span class="p">:</span><span class="mi">46256</span><span class="p">,</span><span class="nl">"port"</span><span class="p">:</span><span class="mi">27017</span><span class="p">,</span><span class="nl">"dbPath"</span><span class="p">:</span><span class="s2">"/Users/lzw/mongodb"</span><span class="p">,</span><span class="nl">"architecture"</span><span class="p">:</span><span class="s2">"64-bit"</span><span class="p">,</span><span class="nl">"host"</span><span class="p">:</span><span class="s2">"lzwjava"</span><span class="p">}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23403</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Build-Informationen"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"buildInfo"</span><span class="p">:{</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"4.4.3"</span><span class="p">,</span><span class="nl">"gitVersion"</span><span class="p">:</span><span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span><span class="p">,</span><span class="nl">"modules"</span><span class="p">:[],</span><span class="nl">"allocator"</span><span class="p">:</span><span class="s2">"system"</span><span class="p">,</span><span class="nl">"environment"</span><span class="p">:{</span><span class="nl">"distarch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">,</span><span class="nl">"target_arch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">}}}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.843+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">51765</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Betriebssystem"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"os"</span><span class="p">:{</span><span class="nl">"name"</span><span class="p">:</span><span class="s2">"Mac OS X"</span><span class="p">,</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"20.3.0"</span><span class="p">}}}</span><span class="w">
</span><span class="err">...</span><span class="w">
</span></code></pre></div></div>

<p>Es ist ersichtlich, dass alles im <code class="language-plaintext highlighter-rouge">JSON</code>-Format vorliegt. MongoDB speichert alle Daten in <code class="language-plaintext highlighter-rouge">JSON</code>-Format. Ã–ffnen Sie anschlieÃŸend einen weiteren Terminal-Tab.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongo
MongoDB Shell Version v4.4.3
Verbindung zu: mongodb://127.0.0.1:27017/?compressors<span class="o">=</span>disabled&amp;gssapiServiceName<span class="o">=</span>mongodb
Implizite Sitzung: Sitzung <span class="o">{</span> <span class="s2">"id"</span> : UUID<span class="o">(</span><span class="s2">"4f55c561-70d3-4289-938d-4b90a284891f"</span><span class="o">)</span> <span class="o">}</span>
MongoDB Server Version: 4.4.3
<span class="nt">---</span>
Der Server hat beim Starten diese Warnungen generiert:
        2021-03-11T18:17:33.743+08:00: Zugriffskontrolle ist fÃ¼r die Datenbank nicht aktiviert. Lese- und Schreibzugriff auf Daten und Konfiguration sind uneingeschrÃ¤nkt
        2021-03-11T18:17:33.743+08:00: Dieser Server ist an localhost gebunden. Externe Systeme kÃ¶nnen keine Verbindung zu diesem Server herstellen. Starten Sie den Server mit <span class="nt">--bind_ip</span> &lt;Adresse&gt;, um anzugeben, von welchen IP-Adressen er Antworten bereitstellen soll, oder mit <span class="nt">--bind_ip_all</span>, um an alle Schnittstellen zu binden. Wenn dieses Verhalten gewÃ¼nscht ist, starten Sie den Server mit <span class="nt">--bind_ip</span> 127.0.0.1, um diese Warnung zu deaktivieren
        2021-03-11T18:17:33.743+08:00: Soft rlimits zu niedrig
        2021-03-11T18:17:33.743+08:00:         aktueller Wert: 4864
        2021-03-11T18:17:33.743+08:00:         empfohlenes Minimum: 64000
<span class="nt">---</span>
<span class="nt">---</span>
        Aktivieren Sie den kostenlosen cloud-basierten Ãœberwachungsdienst von MongoDB, der dann Metriken Ã¼ber Ihre Bereitstellung <span class="o">(</span>DatentrÃ¤gerauslastung, CPU, Betriebsstatistiken usw.<span class="o">)</span> empfÃ¤ngt und anzeigt.

        Die Ãœberwachungsdaten werden auf einer MongoDB-Website mit einer eindeutigen URL verfÃ¼gbar sein, auf die Sie und alle, mit denen Sie die URL teilen, zugreifen kÃ¶nnen. MongoDB kann diese Informationen verwenden, um Produktverbesserungen vorzunehmen und Ihnen MongoDB-Produkte sowie Bereitstellungsoptionen vorzuschlagen.

Um die kostenlose Ãœberwachung zu aktivieren, fÃ¼hren Sie den folgenden Befehl aus: <span class="sb">`</span>db.enableFreeMonitoring<span class="o">()</span><span class="sb">`</span>
Um diese Erinnerung dauerhaft zu deaktivieren, fÃ¼hren Sie den folgenden Befehl aus: <span class="sb">`</span>db.disableFreeMonitoring<span class="o">()</span><span class="sb">`</span>
</code></pre></div></div>

<p>AnschlieÃŸend kÃ¶nnen Sie versuchen, Daten einzufÃ¼gen und abzufragen.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> db.inventory.insertOne<span class="o">(</span>
...    <span class="o">{</span> item: <span class="s2">"canvas"</span>, qty: 100, tags: <span class="o">[</span><span class="s2">"cotton"</span><span class="o">]</span>, size: <span class="o">{</span> h: 28, w: 35.5, uom: <span class="s2">"cm"</span> <span class="o">}</span> <span class="o">}</span>
... <span class="o">)</span>
<span class="o">{</span>
	<span class="s2">"acknowledged"</span> : <span class="nb">true</span>,
	<span class="s2">"insertedId"</span> : ObjectId<span class="o">(</span><span class="s2">"6049ef91b653541cf355facb"</span><span class="o">)</span>
<span class="o">}</span>
<span class="o">&gt;</span>
<span class="o">&gt;</span> db.inventory.find<span class="o">()</span>
<span class="o">{</span> <span class="s2">"_id"</span> : ObjectId<span class="o">(</span><span class="s2">"6049ef91b653541cf355facb"</span><span class="o">)</span>, <span class="s2">"item"</span> : <span class="s2">"canvas"</span>, <span class="s2">"qty"</span> : 100, <span class="s2">"tags"</span> : <span class="o">[</span> <span class="s2">"cotton"</span> <span class="o">]</span>, <span class="s2">"size"</span> : <span class="o">{</span> <span class="s2">"h"</span> : 28, <span class="s2">"w"</span> : 35.5, <span class="s2">"uom"</span> : <span class="s2">"cm"</span> <span class="o">}</span> <span class="o">}</span>
</code></pre></div></div>

<h2 id="fazit">Fazit</h2>

<p>Das warâ€™s erstmal. SpÃ¤ter werden wir noch andere Tools ausprobieren. Was ist der Sinn hinter all dem? Wahrscheinlich, um zunÃ¤chst eine Struktur zu haben. Der Anfang ist immer schwer, und wir haben gleich alles auf einmal durchgearbeitet. Das gibt uns das Vertrauen, dass wir in der Lage sind, und jetzt geht es darum, noch mehr mit diesen Programmen herumzuspielen.</p>

<h2 id="Ã¼bung">Ãœbung</h2>

<ul>
  <li>Die SchÃ¼ler erkunden Ã¤hnlich wie oben.</li>
</ul>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-de" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
