<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Einführung in Cloud Computing und Big Data</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Einführung in Cloud Computing und Big Data | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Einführung in Cloud Computing und Big Data" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="de" />
<meta name="description" content="Diese Lektion behandelt die folgenden Themen:" />
<meta property="og:description" content="Diese Lektion behandelt die folgenden Themen:" />
<link rel="canonical" href="https://lzwjava.github.io/distributed-de" />
<meta property="og:url" content="https://lzwjava.github.io/distributed-de" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-10T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Einführung in Cloud Computing und Big Data" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2021-03-10T00:00:00+08:00","datePublished":"2021-03-10T00:00:00+08:00","description":"Diese Lektion behandelt die folgenden Themen:","headline":"Einführung in Cloud Computing und Big Data","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/distributed-de"},"url":"https://lzwjava.github.io/distributed-de"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=7098a57ecee3641d358bc8eb96400bb82ad66f00">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=7098a57ecee3641d358bc8eb96400bb82ad66f00" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Einführung in Cloud Computing und Big Data | Original, von KI übersetzt
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/de/2021-03-10-distributed-de.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postsde2021-03-10-distributed-de.md</span> -->
      

      <!-- <span>2021-03-10-distributed-de.md</span> -->

      
        

        
          
          <a href="#" class="button">2021.03</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/distributed-en" >English</option>
        <option value="/distributed-zh" >中文</option>
        <option value="/distributed-ja" >日本語</option>
        <option value="/distributed-es" >Español</option>
        <option value="/distributed-hi" >हिंदी</option>
        <option value="/distributed-fr" >Français</option>
        <option value="/distributed-de" selected>Deutsch</option>
        <option value="/distributed-ar" >العربية</option>
        <option value="/distributed-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>Diese Lektion behandelt die folgenden Themen:</p>

<ul>
  <li>Spark</li>
  <li>Hadoop</li>
  <li>Kubernetes</li>
  <li>Docker</li>
  <li>Flink</li>
  <li>MongoDB</li>
</ul>

<p>Wenn es um Cloud Computing geht, scheint es unvermeidlich, viele Tools zu erwähnen: Hadoop, Hive, Hbase, ZooKeeper, Docker, Kubernetes, Spark, Kafka, MongoDB, Flink, Druid, Presto, Kylin, Elastic Search. Haben Sie schon von all diesen gehört? Einige dieser Tools habe ich aus den Stellenbeschreibungen von <code class="language-plaintext highlighter-rouge">Big Data Engineers</code> und <code class="language-plaintext highlighter-rouge">Distributed Backend Engineers</code> gefunden. Dies sind alles gut bezahlte Positionen. Versuchen wir, sie alle zu installieren und ein wenig damit zu spielen.</p>
<h2 id="erste-schritte-mit-spark">Erste Schritte mit Spark</h2>

<p>Die offizielle Website besagt, dass <code class="language-plaintext highlighter-rouge">Spark</code> ein Analyse-Engine zur Verarbeitung von Massendaten ist. <code class="language-plaintext highlighter-rouge">Spark</code> ist im Wesentlichen eine Sammlung von Bibliotheken. Es scheint nicht wie <code class="language-plaintext highlighter-rouge">Redis</code> in Server- und Client-Komponenten unterteilt zu sein. <code class="language-plaintext highlighter-rouge">Spark</code> wird ausschließlich auf der Client-Seite verwendet. Von der offiziellen Website habe ich die neueste Version heruntergeladen, <code class="language-plaintext highlighter-rouge">spark-3.1.1-bin-hadoop3.2.tar</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
├── LICENSE
├── NOTICE
├── R
├── README.md
├── RELEASE
├── bin
├── conf
├── data
├── examples
├── jars
├── kubernetes
├── licenses
├── python
├── sbin
└── yarn
</code></pre></div></div>

<p>11 Verzeichnisse, 4 Dateien</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Es scheint sich um einige Analysebibliotheken zu handeln, die in verschiedenen Sprachen geschrieben sind.

Gleichzeitig sagt die offizielle Website, dass man die Abhängigkeiten direkt in Python installieren kann. `pip install pyspark`

```shell
$ pip install pyspark
Collecting pyspark
  Downloading pyspark-3.1.1.tar.gz (212,3 MB)
     |████████████████████████████████| 212,3 MB 14 kB/s
Collecting py4j==0.10.9
  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)
     |████████████████████████████████| 198 kB 145 kB/s
Building wheels for collected packages: pyspark
  Building wheel for pyspark (setup.py) ... done
  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=0b8079e82f3a5bcadad99179902d8c8ff9f8eccad928a469c11b97abdc960b72
  Stored in directory: /Users/lzw/Library/Caches/pip/wheels/23/bf/e9/9f3500437422e2ab82246f25a51ee480a44d4efc6c27e50d33
Successfully built pyspark
Installing collected packages: py4j, pyspark
Successfully installed py4j-0.10.9 pyspark-3.1.1
</code></pre></div></div>

<p>Installiert.</p>

<p>Ich habe mir die offizielle Website angesehen und einige Beispiele gefunden.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/run-example SparkPi 10
</code></pre></div></div>

<p>Oh, ich sehe, du kannst das Programm aus dem gerade heruntergeladenen Installationspaket ausführen, aber es ist ein Fehler aufgetreten.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/run-example SparkPi 10
21/03/11 00:06:15 WARN NativeCodeLoader: Native-Hadoop-Bibliothek konnte für Ihre Plattform nicht geladen werden... Es werden integrierte Java-Klassen verwendet, wo zutreffend.
21/03/11 00:06:16 INFO ResourceUtils: Keine benutzerdefinierten Ressourcen für spark.driver konfiguriert.
21/03/11 00:06:16 WARN Utils: Der Dienst <span class="s1">'sparkDriver'</span> konnte keinen zufälligen freien Port binden. Überprüfen Sie, ob eine geeignete Bindungsadresse konfiguriert ist.
</code></pre></div></div>

<blockquote>
  <p>Spark ist eine schnelle und vielseitige Verarbeitungs-Engine, die mit Hadoop-Daten kompatibel ist. Es kann in Hadoop-Clustern über YARN oder im eigenständigen Modus von Spark ausgeführt werden und kann Daten in HDFS, HBase, Cassandra, Hive und jedem Hadoop InputFormat verarbeiten. Es wurde entwickelt, um sowohl Batch-Verarbeitung (ähnlich wie MapReduce) als auch neue Workloads wie Streaming, interaktive Abfragen und maschinelles Lernen zu unterstützen.</p>
</blockquote>

<p>Es ist mehrmals <code class="language-plaintext highlighter-rouge">hadoop</code> aufgetaucht. Nachdem ich <code class="language-plaintext highlighter-rouge">spark depends hadoop</code> gegoogelt habe, bin ich auf folgenden Absatz gestoßen. Es scheint, dass dies von Daten im <code class="language-plaintext highlighter-rouge">Hadoop</code>-Format abhängt. Lassen Sie uns zunächst <code class="language-plaintext highlighter-rouge">Hadoop</code> untersuchen.</p>

<h2 id="hadoop">Hadoop</h2>

<p>Nachdem ich die offizielle Website kurz überflogen habe, werde ich es jetzt installieren.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>hadoop
</code></pre></div></div>

<p>Während des Installationsprozesses lass uns etwas darüber lernen.</p>

<blockquote>
  <p>Die Apache Hadoop-Softwarebibliothek ist ein Framework, das die verteilte Verarbeitung großer Datenmengen über Computercluster hinweg mithilfe einfacher Programmiermodelle ermöglicht. Es ist darauf ausgelegt, sich von einzelnen Servern auf Tausende von Maschinen zu skalieren, wobei jede lokale Berechnungen und Speicherung bietet. Anstatt sich auf Hardware zu verlassen, um Hochverfügbarkeit zu gewährleisten, ist die Bibliothek selbst so konzipiert, dass sie Fehler auf der Anwendungsebene erkennt und behandelt. Dadurch bietet sie einen hochverfügbaren Dienst auf Basis eines Computerclusters, bei dem jede einzelne Maschine anfällig für Ausfälle sein kann.</p>
</blockquote>

<p>Hadoop ist ein Framework, das entwickelt wurde, um verteilte Datensätze zu verarbeiten. Diese Datensätze können auf vielen Computern verteilt sein. Es verwendet ein sehr einfaches Programmiermodell. Es ist darauf ausgelegt, sich von einem einzelnen Server auf Tausende von Maschinen zu skalieren. Anstatt sich auf die hohe Verfügbarkeit von Hardware zu verlassen, ist diese Bibliothek so konzipiert, dass sie Fehler auf der Anwendungsebene erkennen und behandeln kann. Dadurch kann ein hochverfügbarer Dienst in einem Cluster bereitgestellt werden, obwohl jede einzelne Maschine im Cluster potenziell ausfallen könnte.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>hadoop
Fehler:
  homebrew-core ist ein flacher Klon.
  homebrew-cask ist ein flacher Klon.
Um <span class="sb">`</span>brew update<span class="sb">`</span> auszuführen, führen Sie zuerst folgende Befehle aus:
  git <span class="nt">-C</span> /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core fetch <span class="nt">--unshallow</span>
  git <span class="nt">-C</span> /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask fetch <span class="nt">--unshallow</span>
Diese Befehle können einige Minuten dauern, da die Repositorys sehr groß sind.
Diese Einschränkung wurde auf Anfrage von GitHub vorgenommen, da das Aktualisieren von flachen Klonen aufgrund der Baumstruktur und des Datenverkehrs von Homebrew/homebrew-core und Homebrew/homebrew-cask eine äußerst aufwändige Operation ist. Wir führen dies nicht automatisch für Sie durch, um zu vermeiden, dass <span class="k">in </span>CI-Systemen wiederholt eine aufwändige Unshallow-Operation durchgeführt wird <span class="o">(</span>die stattdessen so angepasst werden sollten, dass sie keine flachen Klone verwenden<span class="o">)</span><span class="nb">.</span> Entschuldigung für die Unannehmlichkeiten!
<span class="o">==&gt;</span> Lade https://homebrew.bintray.com/bottles/openjdk-15.0.1.big_sur.bottle.tar.gz herunter
Bereits heruntergeladen: /Users/lzw/Library/Caches/Homebrew/downloads/d1e3ece4af1d225bc2607eaa4ce85a873d2c6d43757ae4415d195751bc431962--openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Lade https://www.apache.org/dyn/closer.lua?path<span class="o">=</span>hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz herunter
Bereits heruntergeladen: /Users/lzw/Library/Caches/Homebrew/downloads/764c6a0ea7352bb8bb505989feee1b36dc628c2dcd6b93fef1ca829d191b4e1e--hadoop-3.3.0.tar.gz
<span class="o">==&gt;</span> Installiere Abhängigkeiten für hadoop: openjdk
<span class="o">==&gt;</span> Installiere hadoop-Abhängigkeit: openjdk
<span class="o">==&gt;</span> Gieße openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Hinweise
Damit die System-Java-Wrapper dieses JDK finden, verlinken Sie es mit
  <span class="nb">sudo ln</span> <span class="nt">-sfn</span> /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk
</code></pre></div></div>

<p>openjdk ist keg-only, was bedeutet, dass es nicht nach /usr/local symbolisch verlinkt wurde,
weil es den macOS <code class="language-plaintext highlighter-rouge">java</code>-Wrapper überschattet.</p>

<p>Wenn Sie openjdk zuerst in Ihrem PATH haben müssen, führen Sie den folgenden Befehl aus:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>Damit Compiler OpenJDK finden können, müssen Sie möglicherweise Folgendes setzen:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">export </span><span class="nv">CPPFLAGS</span><span class="o">=</span><span class="s2">"-I/usr/local/opt/openjdk/include"</span>
</code></pre></div></div>

<p>==&gt; Zusammenfassung
🍺  /usr/local/Cellar/openjdk/15.0.1: 614 Dateien, 324,9 MB
==&gt; Installiere hadoop
🍺  /usr/local/Cellar/hadoop/3.3.0: 21.819 Dateien, 954,7 MB, gebaut in 2 Minuten 15 Sekunden
==&gt; Aktualisiere 1 Abhängigkeit:
maven 3.3.3 -&gt; 3.6.3_1
==&gt; Aktualisiere maven 3.3.3 -&gt; 3.6.3_1
==&gt; Lade https://www.apache.org/dyn/closer.lua?path=maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz herunter
==&gt; Lade von https://mirror.olnevhost.net/pub/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz herunter
######################################################################## 100,0%
Fehler: Der <code class="language-plaintext highlighter-rouge">brew link</code> Schritt wurde nicht erfolgreich abgeschlossen
Die Formel wurde gebaut, aber nicht in /usr/local verlinkt
Konnte bin/mvn nicht verlinken
Ziel /usr/local/bin/mvn
ist ein Symlink, der zu maven gehört. Sie können ihn entlinken:
  brew unlink maven</p>

<p>Um den Link zu erzwingen und alle konfligierenden Dateien zu überschreiben:
  brew link –overwrite maven</p>

<p>Um alle Dateien aufzulisten, die gelöscht würden:
  brew link –overwrite –dry-run maven</p>

<p>Mögliche konfliktträchtige Dateien sind:
/usr/local/bin/mvn -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvn
/usr/local/bin/mvnDebug -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnDebug
/usr/local/bin/mvnyjp -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnyjp
==&gt; Zusammenfassung
🍺  /usr/local/Cellar/maven/3.6.3_1: 87 Dateien, 10,7MB, in 7 Sekunden erstellt
Entferne: /usr/local/Cellar/maven/3.3.3… (92 Dateien, 9MB)
==&gt; Überprüfe Abhängigkeiten der aktualisierten Formeln…
==&gt; Keine defekten Abhängigkeiten gefunden!
==&gt; Hinweise
==&gt; openjdk
Damit die System-Java-Wrapper dieses JDK finden, verlinken Sie es mit
  sudo ln -sfn /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk</p>

<p>openjdk ist keg-only, was bedeutet, dass es nicht in /usr/local symbolisch verlinkt wurde,
weil es den macOS <code class="language-plaintext highlighter-rouge">java</code>-Wrapper überschattet.</p>

<p>Wenn Sie sicherstellen möchten, dass openjdk in Ihrem PATH an erster Stelle steht, führen Sie den folgenden Befehl aus:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>Damit Compiler OpenJDK finden können, müssen Sie möglicherweise folgendes setzen:
  export CPPFLAGS=”-I/usr/local/opt/openjdk/include”</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Beachten Sie, dass in den Ausgabelogs von `brew` `maven` nicht korrekt verlinkt wurde. Führen Sie als Nächstes eine erzwungene Verlinkung zur Version `3.6.3_1` durch.

```shell
  brew link --overwrite maven
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Hadoop</code> wurde erfolgreich installiert.</p>

<blockquote>
  <h2 id="module">Module</h2>

  <p>Das Projekt umfasst folgende Module:</p>

  <ul>
    <li><strong>Hadoop Common</strong>: Die allgemeinen Hilfsprogramme, die die anderen Hadoop-Module unterstützen.</li>
    <li><strong>Hadoop Distributed File System (HDFS™)</strong>: Ein verteiltes Dateisystem, das einen hohen Durchsatz für den Zugriff auf Anwendungsdaten bietet.</li>
    <li><strong>Hadoop YARN</strong>: Ein Framework für die Jobplanung und die Verwaltung von Clusterressourcen.</li>
    <li><strong>Hadoop MapReduce</strong>: Ein YARN-basiertes System zur parallelen Verarbeitung großer Datenmengen.</li>
    <li><strong>Hadoop Ozone</strong>: Ein Objektspeicher für Hadoop.</li>
  </ul>
</blockquote>

<p>Es gibt diese Module. Wenn Sie <code class="language-plaintext highlighter-rouge">hadoop</code> eingeben, erscheint:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hadoop
Verwendung: hadoop <span class="o">[</span>OPTIONEN] UNTERBEFEHL <span class="o">[</span>UNTERBEFEHL-OPTIONEN]
 oder    hadoop <span class="o">[</span>OPTIONEN] KLASSENNAME <span class="o">[</span>KLASSENNAME-OPTIONEN]
  wobei KLASSENNAME eine vom Benutzer bereitgestellte Java-Klasse ist

OPTIONS ist keine oder eine der folgenden Optionen:

<span class="nt">--config</span> <span class="nb">dir                     </span>Hadoop-Konfigurationsverzeichnis
<span class="nt">--debug</span>                          Debug-Modus für Shell-Skripte aktivieren
<span class="nt">--help</span>                           Nutzungsinformationen
buildpaths                       Versuch, Klassendateien aus dem Build-Verzeichnis hinzuzufügen
hostnames list[,of,host,names]   Hosts, die im Slave-Modus verwendet werden sollen
hosts filename                   Liste der Hosts, die im Slave-Modus verwendet werden sollen
loglevel level                   Log4j-Level für diesen Befehl festlegen
workers                          Worker-Modus aktivieren

  SUBCOMMAND ist eines der folgenden:
    Admin-Befehle:

daemonlog     Protokollstufe für jeden Daemon abrufen/festlegen

    Client-Befehle:

</code></pre></div></div>
<p>archive       Erstellt ein Hadoop-Archiv
checknative   Überprüft die Verfügbarkeit nativer Hadoop- und Kompressionsbibliotheken
classpath     Gibt den Klassenpfad aus, der benötigt wird, um das Hadoop-JAR und die erforderlichen Bibliotheken zu erhalten
conftest      Validiert Konfigurations-XML-Dateien
credential    Interagiert mit Anmeldeinformationsanbietern
distch        Verteilter Metadatenänderer
distcp        Kopiert Dateien oder Verzeichnisse rekursiv
dtutil        Operationen im Zusammenhang mit Delegationstokens
envvars       Zeigt die berechneten Hadoop-Umgebungsvariablen an
fs            Führt einen generischen Dateisystem-Client aus
gridmix       Sendet eine Mischung aus synthetischen Jobs, die ein Profil aus der Produktionslast modellieren
jar <jar>     Führt eine JAR-Datei aus. HINWEIS: Bitte verwenden Sie "yarn jar", um YARN-Anwendungen zu starten, nicht diesen Befehl.
jnipath       Gibt den java.library.path aus
kdiag         Diagnostiziert Kerberos-Probleme
kerbname      Zeigt die auth_to_local Principal-Konvertierung an
key           Verwaltet Schlüssel über den KeyProvider
rumenfolder   Skaliert eine Rumen-Eingabespur
rumentrace    Konvertiert Protokolle in eine Rumen-Spur
s3guard       Verwaltet Metadaten auf S3
trace         Zeigt und modifiziert Hadoop-Tracing-Einstellungen
version       Gibt die Version aus</jar></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
    Daemon-Befehle:

kms           KMS ausführen, den Key Management Server
registrydns   den Registry-DNS-Server ausführen

SUBCOMMAND kann Hilfe anzeigen, wenn es ohne Parameter oder mit -h aufgerufen wird.
</code></pre></div></div>

<p>Die offizielle Website bietet einige Beispiele.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span><span class="nb">mkdir </span>input
  <span class="nv">$ </span><span class="nb">cp </span>etc/hadoop/<span class="k">*</span>.xml input
  <span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
  <span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
</code></pre></div></div>

<p>Beachte, dass es <code class="language-plaintext highlighter-rouge">share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar</code> gibt. Dies bedeutet, dass möglicherweise einige Beispiel-Dateien fehlen, die wir nicht erhalten haben. Es wird vermutet, dass bei der Installation mit <code class="language-plaintext highlighter-rouge">Homebrew</code> diese Dateien nicht enthalten sind. Wir haben das Installationspaket von der offiziellen Website heruntergeladen.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
├── LICENSE-binary
├── LICENSE.txt
├── NOTICE-binary
├── NOTICE.txt
├── README.txt
├── bin
├── etc
├── include
├── lib
├── libexec
├── licenses-binary
├── sbin
└── share
</code></pre></div></div>

<p>Es scheint, dass ein <code class="language-plaintext highlighter-rouge">share</code>-Verzeichnis vorhanden ist. Aber hat <code class="language-plaintext highlighter-rouge">Homebrew</code> wirklich keine dieser zusätzlichen Dateien? Finde das Verzeichnis, in dem <code class="language-plaintext highlighter-rouge">Homebrew</code> installiert ist.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">type </span>hadoop
hadoop ist /usr/local/bin/hadoop
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-alrt</span> /usr/local/bin/hadoop
lrwxr-xr-x  1 lzw  admin  33 Mar 11 00:48 /usr/local/bin/hadoop -&gt; ../Cellar/hadoop/3.3.0/bin/hadoop
<span class="nv">$ </span><span class="nb">cd</span> /usr/local/Cellar/hadoop/3.3.0
</code></pre></div></div>

<p>Dies ist das Verzeichnisbaum, das unter <code class="language-plaintext highlighter-rouge">/usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop</code> gedruckt wurde.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 2
<span class="nb">.</span>
├── client
│   ├── hadoop-client-api-3.3.0.jar
│   ├── hadoop-client-minicluster-3.3.0.jar
│   └── hadoop-client-runtime-3.3.0.jar
├── common
│   ├── hadoop-common-3.3.0-tests.jar
│   ├── hadoop-common-3.3.0.jar
│   ├── hadoop-kms-3.3.0.jar
│   ├── hadoop-nfs-3.3.0.jar
│   ├── hadoop-registry-3.3.0.jar
│   ├── jdiff
│   ├── lib
│   ├── sources
│   └── webapps
├── hdfs
│   ├── hadoop-hdfs-3.3.0-tests.jar
│   ├── hadoop-hdfs-3.3.0.jar
│   ├── hadoop-hdfs-client-3.3.0-tests.jar
│   ├── hadoop-hdfs-client-3.3.0.jar
│   ├── hadoop-hdfs-httpfs-3.3.0.jar
│   ├── hadoop-hdfs-native-client-3.3.0-tests.jar
│   ├── hadoop-hdfs-native-client-3.3.0.jar
│   ├── hadoop-hdfs-nfs-3.3.0.jar
│   ├── hadoop-hdfs-rbf-3.3.0-tests.jar
│   ├── hadoop-hdfs-rbf-3.3.0.jar
│   ├── jdiff
│   ├── lib
│   ├── sources
│   └── webapps
├── mapreduce
│   ├── hadoop-mapreduce-client-app-3.3.0.jar
│   ├── hadoop-mapreduce-client-common-3.3.0.jar
│   ├── hadoop-mapreduce-client-core-3.3.0.jar
│   ├── hadoop-mapreduce-client-hs-3.3.0.jar
│   ├── hadoop-mapreduce-client-hs-plugins-3.3.0.jar
│   ├── hadoop-mapreduce-client-jobclient-3.3.0-tests.jar
│   ├── hadoop-mapreduce-client-jobclient-3.3.0.jar
│   ├── hadoop-mapreduce-client-nativetask-3.3.0.jar
│   ├── hadoop-mapreduce-client-shuffle-3.3.0.jar
│   ├── hadoop-mapreduce-client-uploader-3.3.0.jar
│   ├── hadoop-mapreduce-examples-3.3.0.jar
│   ├── jdiff
│   ├── lib-examples
│   └── sources
├── tools
│   ├── dynamometer
│   ├── lib
│   ├── resourceestimator
│   ├── sls
│   └── sources
└── yarn
    ├── csi
    ├── hadoop-yarn-api-3.3.0.jar
    ├── hadoop-yarn-applications-catalog-webapp-3.3.0.war
    ├── hadoop-yarn-applications-distributedshell-3.3.0.jar
    ├── hadoop-yarn-applications-mawo-core-3.3.0.jar
    ├── hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar
    ├── hadoop-yarn-client-3.3.0.jar
    ├── hadoop-yarn-common-3.3.0.jar
    ├── hadoop-yarn-registry-3.3.0.jar
    ├── hadoop-yarn-server-applicationhistoryservice-3.3.0.jar
    ├── hadoop-yarn-server-common-3.3.0.jar
    ├── hadoop-yarn-server-nodemanager-3.3.0.jar
    ├── hadoop-yarn-server-resourcemanager-3.3.0.jar
    ├── hadoop-yarn-server-router-3.3.0.jar
    ├── hadoop-yarn-server-sharedcachemanager-3.3.0.jar
    ├── hadoop-yarn-server-tests-3.3.0.jar
    ├── hadoop-yarn-server-timeline-pluginstorage-3.3.0.jar
    ├── hadoop-yarn-server-web-proxy-3.3.0.jar
    ├── hadoop-yarn-services-api-3.3.0.jar
    ├── hadoop-yarn-services-core-3.3.0.jar
    ├── lib
    ├── sources
    ├── <span class="nb">test</span>
    ├── timelineservice
    ├── webapps
    └── yarn-service-examples
</code></pre></div></div>

<p>Man kann viele <code class="language-plaintext highlighter-rouge">jar</code>-Pakete sehen.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>input
<span class="nv">$ </span><span class="nb">ls
</span>bin			hadoop-config.sh	hdfs-config.sh		libexec			sbin			yarn-config.sh
etc			hadoop-functions.sh	input			mapred-config.sh	share
<span class="nv">$ </span><span class="nb">cp </span>etc/hadoop/<span class="k">*</span>.xml input
<span class="nv">$ </span><span class="nb">cd </span>input/
<span class="nv">$ </span><span class="nb">ls
</span>capacity-scheduler.xml	hadoop-policy.xml	hdfs-site.xml		kms-acls.xml		mapred-site.xml
core-site.xml		hdfs-rbf-site.xml	httpfs-site.xml		kms-site.xml		yarn-site.xml
<span class="nv">$ </span><span class="nb">cd</span> ..
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
JAR existiert nicht oder ist keine normale Datei: /usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar
<span class="err">$</span>
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
2021-03-11 01:54:30,791 WARN util.NativeCodeLoader: Native-Hadoop-Bibliothek konnte für Ihre Plattform nicht geladen werden... Es werden eingebaute Java-Klassen verwendet, wo zutreffend
2021-03-11 01:54:31,115 INFO impl.MetricsConfig: Eigenschaften aus hadoop-metrics2.properties geladen
2021-03-11 01:54:31,232 INFO impl.MetricsSystemImpl: Metrik-Snapshot-Intervall auf 10 Sekunden festgelegt.
...
</code></pre></div></div>

<p>Folgen Sie dem Beispiel auf der offiziellen Website. Beachten Sie, dass in <code class="language-plaintext highlighter-rouge">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input</code> die <code class="language-plaintext highlighter-rouge">jar</code>-Datei eine Versionsnummer enthält. Daher müssen wir diese durch unsere Version <code class="language-plaintext highlighter-rouge">3.3.0</code> ersetzen.</p>

<p>Ende des Logs:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2021-03-11 01:54:35,374 INFO mapreduce.Job:  map 100% reduce 100%
2021-03-11 01:54:35,374 INFO mapreduce.Job: Job job_local2087514596_0002 erfolgreich abgeschlossen
2021-03-11 01:54:35,377 INFO mapreduce.Job: Zähler: 30
	Dateisystem-Zähler
		FILE: Anzahl der gelesenen <span class="nv">Bytes</span><span class="o">=</span>1204316
		FILE: Anzahl der geschriebenen <span class="nv">Bytes</span><span class="o">=</span>3565480
		FILE: Anzahl der Lesevorgänge<span class="o">=</span>0
		FILE: Anzahl der großen Lesevorgänge<span class="o">=</span>0
		FILE: Anzahl der Schreibvorgänge<span class="o">=</span>0
	Map-Reduce-Framework
		Map-Eingabedatensätze<span class="o">=</span>1
		Map-Ausgabedatensätze<span class="o">=</span>1
		Map-Ausgabebytes<span class="o">=</span>17
		Map-Ausgabematerialisierte <span class="nv">Bytes</span><span class="o">=</span>25
		Eingabe-Split-Bytes<span class="o">=</span>141
		Combine-Eingabedatensätze<span class="o">=</span>0
		Combine-Ausgabedatensätze<span class="o">=</span>0
		Reduce-Eingabegruppen<span class="o">=</span>1
		Reduce-Shuffle-Bytes<span class="o">=</span>25
		Reduce-Eingabedatensätze<span class="o">=</span>1
		Reduce-Ausgabedatensätze<span class="o">=</span>1
		Verlorene Datensätze<span class="o">=</span>2
		Shuffled <span class="nv">Maps</span><span class="o">=</span>1
		Fehlgeschlagene <span class="nv">Shuffles</span><span class="o">=</span>0
		Zusammengeführte Map-Ausgaben<span class="o">=</span>1
		GC-Zeit verstrichen <span class="o">(</span>ms<span class="o">)=</span>57
		Gesamter belegter Heap-Speicher <span class="o">(</span>Bytes<span class="o">)=</span>772800512
	Shuffle-Fehler
		<span class="nv">BAD_ID</span><span class="o">=</span>0
		<span class="nv">CONNECTION</span><span class="o">=</span>0
		<span class="nv">IO_ERROR</span><span class="o">=</span>0
		<span class="nv">WRONG_LENGTH</span><span class="o">=</span>0
		<span class="nv">WRONG_MAP</span><span class="o">=</span>0
		<span class="nv">WRONG_REDUCE</span><span class="o">=</span>0
	Datei-Eingabeformat-Zähler
		Gelesene <span class="nv">Bytes</span><span class="o">=</span>123
	Datei-Ausgabeformat-Zähler
		Geschriebene <span class="nv">Bytes</span><span class="o">=</span>23
</code></pre></div></div>

<p>Weiter schauen.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>Was bedeutet das nun? Keine Sorge, jedenfalls haben wir <code class="language-plaintext highlighter-rouge">Hadoop</code> zum Laufen gebracht. Und wir haben das erste Beispiel für eine lokale Berechnung ausgeführt.</p>

<h2 id="spark">Spark</h2>

<p>Zurück zu Spark. Schauen wir uns ein Beispiel an.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
</code></pre></div></div>

<p>Hier ist eine <code class="language-plaintext highlighter-rouge">hdfs</code>-Datei aufgetaucht. Nach einiger Recherche habe ich herausgefunden, dass man eine <code class="language-plaintext highlighter-rouge">hdfs</code>-Datei auf folgende Weise erstellen kann:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-mkdir</span> /test
</code></pre></div></div>

<p>Schauen wir uns den <code class="language-plaintext highlighter-rouge">hdfs</code>-Befehl an.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hdfs
Verwendung: hdfs <span class="o">[</span>OPTIONEN] UNTERBEFEHL <span class="o">[</span>UNTERBEFEHLSOPTIONEN]
</code></pre></div></div>

<p>OPTIONS ist keine oder eine der folgenden:</p>

<p>–buildpaths                       versucht, Klassendateien aus dem Build-Verzeichnis hinzuzufügen
–config dir                       Hadoop-Konfigurationsverzeichnis
–daemon (start|status|stop)       führt eine Aktion auf einem Daemon aus
–debug                            aktiviert den Debug-Modus für Shell-Skripte
–help                             zeigt Nutzungsinformationen an
–hostnames list[,of,host,names]   Hosts, die im Worker-Modus verwendet werden sollen
–hosts filename                   Liste der Hosts, die im Worker-Modus verwendet werden sollen
–loglevel level                   setzt den Log4j-Level für diesen Befehl
–workers                          aktiviert den Worker-Modus</p>

<p>SUBCOMMAND ist eines der folgenden:
    Admin-Befehle:</p>

<p>cacheadmin           Konfigurieren des HDFS-Caches
crypto               Konfigurieren von HDFS-Verschlüsselungszonen
debug                Ausführen eines Debug-Administrators zur Ausführung von HDFS-Debug-Befehlen
dfsadmin             Ausführen eines DFS-Administrator-Clients
dfsrouteradmin       Verwalten der Router-basierten Föderation
ec                   Ausführen eines HDFS-ErasureCoding-CLI
fsck                 Ausführen eines DFS-Dateisystem-Prüfprogramms
haadmin              Ausführen eines DFS-HA-Administrator-Clients
jmxget               Abrufen von JMX-exportierten Werten vom NameNode oder DataNode
oev                  Anwenden des Offline-Edits-Viewers auf eine Edits-Datei
oiv                  Anwenden des Offline-Fsimage-Viewers auf ein Fsimage
oiv_legacy           Anwenden des Offline-Fsimage-Viewers auf ein Legacy-Fsimage
storagepolicies      Auflisten/Abrufen/Setzen/Erfüllen von Block-Speicherrichtlinien</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Client-Befehle:
</code></pre></div></div>

<p>classpath            gibt den Klassenpfad aus, der benötigt wird, um das Hadoop-JAR und die erforderlichen Bibliotheken zu erhalten
dfs                  führt einen Dateisystembefehl auf dem Dateisystem aus
envvars              zeigt die berechneten Hadoop-Umgebungsvariablen an
fetchdt              holt ein Delegation-Token vom NameNode
getconf              ruft Konfigurationswerte aus der Konfiguration ab
groups               zeigt die Gruppen an, zu denen Benutzer gehören
lsSnapshottableDir   listet alle vom aktuellen Benutzer besessenen Snapshottable-Verzeichnisse auf
snapshotDiff         vergleicht zwei Snapshots eines Verzeichnisses oder vergleicht die aktuellen Verzeichnisinhalte mit einem Snapshot
version              gibt die Version aus</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Daemon-Befehle:
</code></pre></div></div>

<p>balancer             Führt ein Cluster-Balancing-Utility aus<br />
datanode             Führt einen DFS-Datanode aus<br />
dfsrouter            Führt den DFS-Router aus<br />
diskbalancer         Verteilt Daten gleichmäßig auf Festplatten eines bestimmten Knotens<br />
httpfs               Führt den HttpFS-Server aus, das HDFS-HTTP-Gateway<br />
journalnode          Führt den DFS-Journalnode aus<br />
mover                Führt ein Utility aus, um Blockreplikate über Speichertypen hinweg zu verschieben<br />
namenode             Führt den DFS-Namenode aus<br />
nfs3                 Führt ein NFS-Version-3-Gateway aus<br />
portmap              Führt einen Portmap-Dienst aus<br />
secondarynamenode    Führt den sekundären DFS-Namenode aus<br />
sps                  Führt den externen StoragePolicySatisfier aus<br />
zkfc                 Führt den ZK-Failover-Controller-Daemon aus</p>

<p>SUBCOMMAND kann Hilfe anzeigen, wenn es ohne Parameter oder mit -h aufgerufen wird.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
继续修改代码。

```python
from pyspark.sql import SparkSession
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">master</span><span class="p">(</span><span class="s">"local[*]"</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">config</span><span class="p">(</span><span class="s">'spark.driver.bindAddress'</span><span class="p">,</span> <span class="s">'127.0.0.1'</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"a.txt"</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"b.txt"</span><span class="p">)</span>
</code></pre></div></div>

<p>Es ist wichtig, <code class="language-plaintext highlighter-rouge">.config('spark.driver.bindAddress', '127.0.0.1')</code> zu beachten. Andernfalls wird der Fehler <code class="language-plaintext highlighter-rouge">Service 'sparkDriver' could not bind on a random free port. You may check whether configuring an appropriate binding address</code> auftreten.</p>

<p>Allerdings trat zu diesem Zeitpunkt erneut ein Fehler auf.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Caused by: org.apache.spark.api.python.PythonException: Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
  File <span class="s2">"/usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py"</span>, line 473, <span class="k">in </span>main
    raise Exception<span class="o">((</span><span class="s2">"Python in worker has different version %s than that in "</span> +
Exception: Python im Worker hat eine andere Version 3.8 als im Driver 3.9. PySpark kann nicht mit unterschiedlichen Nebenversionen ausgeführt werden. Bitte überprüfen Sie, ob die Umgebungsvariablen PYSPARK_PYTHON und PYSPARK_DRIVER_PYTHON korrekt gesetzt sind.
</code></pre></div></div>

<p>zeigt an, dass verschiedene Versionen von <code class="language-plaintext highlighter-rouge">Python</code> ausgeführt wurden.</p>

<p>Ändern der <code class="language-plaintext highlighter-rouge">.bash_profile</code>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
<span class="nv">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
</code></pre></div></div>

<p>Es wird jedoch weiterhin der gleiche Fehler gemeldet. Nach einiger Recherche könnte der Grund dafür sein, dass <code class="language-plaintext highlighter-rouge">spark</code> beim Ausführen diese Umgebungsvariable nicht geladen hat und nicht die Standard-Umgebungsvariablen des Terminals verwendet.</p>

<p>In der Code müssen Sie folgendes einstellen:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
</code></pre></div></div>

<h1 id="spark-umgebungen-setzen">Spark-Umgebungen setzen</h1>
<p>os.environ[‘PYSPARK_PYTHON’] = ‘/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3’
os.environ[‘PYSPARK_DRIVER_PYTHON’] = ‘/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3’</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Das wird ausgeführt.

```shell
$ python sc.py
21/03/11 02:54:52 WARN NativeCodeLoader: Native-Hadoop-Bibliothek konnte für Ihre Plattform nicht geladen werden... Es werden integrierte Java-Klassen verwendet, wo zutreffend.
Verwende Sparks Standard-Log4j-Profil: org/apache/spark/log4j-defaults.properties
Standard-Log-Level auf "WARN" gesetzt.
Um das Logging-Level anzupassen, verwenden Sie sc.setLogLevel(newLevel). Für SparkR verwenden Sie setLogLevel(newLevel).
PythonRDD[6] at RDD at PythonRDD.scala:53
</code></pre></div></div>

<p>Zu diesem Zeitpunkt wurde <code class="language-plaintext highlighter-rouge">b.txt</code> erstellt.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── b.txt
│   ├── _SUCCESS
│   ├── part-00000
│   └── part-00001
</code></pre></div></div>

<p>Öffne es.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>b.txt/part-00000
<span class="o">(</span><span class="s1">'college'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'two'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'things'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'worked'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'on,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'of'</span>, 8<span class="o">)</span>
<span class="o">(</span><span class="s1">'school,'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'writing'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'programming.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s2">"didn't"</span>, 4<span class="o">)</span>
<span class="o">(</span><span class="s1">'then,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'probably'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'are:'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'short'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'awful.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'They'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'plot,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'just'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'characters'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'them'</span>, 2<span class="o">)</span>
...
</code></pre></div></div>

<p>Erfolg! Kommt dir das bekannt vor? Es ist genau wie im <code class="language-plaintext highlighter-rouge">Hadoop</code>-Beispiel.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>Diese Dateien werden <code class="language-plaintext highlighter-rouge">HDFS</code> genannt. Hier wird <code class="language-plaintext highlighter-rouge">Spark</code> verwendet, um Wörter zu zählen. Mit nur wenigen Zeilen sieht es sehr praktisch aus.</p>

<h2 id="kubernetes">Kubernetes</h2>

<p>Als nächstes beschäftige ich mich mit <code class="language-plaintext highlighter-rouge">Kubernetes</code>, auch bekannt als <code class="language-plaintext highlighter-rouge">k8s</code>, wobei die 8 die acht ausgelassenen Buchstaben in der Mitte darstellt. Es handelt sich um ein Open-Source-System, das die Automatisierung der Bereitstellung, Skalierung und Verwaltung von Containeranwendungen ermöglicht.</p>

<p>Das <code class="language-plaintext highlighter-rouge">kubectl</code>-Befehlszeilentool wird verwendet, um Befehle auf einem Kubernetes-Cluster auszuführen. Es kann verwendet werden, um Anwendungen bereitzustellen, Cluster-Ressourcen anzuzeigen und zu verwalten sowie Protokolle einzusehen.</p>

<p>Man kann es auch mit Homebrew installieren.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>kubectl
</code></pre></div></div>

<p>Protokollausgabe:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">==&gt;</span> Herunterladen von https://homebrew.bintray.com/bottles/kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Herunterladen von https://d29vzk4ow07wi7.cloudfront.net/0b4f08bd1d47cb913d7cd4571e3394c6747dfbad7ff114c5589c8396c1085ecf?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Entpacken von kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Hinweise
Die Bash-Vervollständigung wurde installiert <span class="k">in</span>:
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Zusammenfassung
🍺  /usr/local/Cellar/kubernetes-cli/1.20.1: 246 Dateien, 46,1MB
</code></pre></div></div>

<p>Installation abgeschlossen.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl
kubectl steuert den Kubernetes-Cluster-Manager.
</code></pre></div></div>

<p>Weitere Informationen finden Sie unter: https://kubernetes.io/docs/reference/kubectl/overview/</p>

<p>Grundlegende Befehle (Anfänger):
  create        Erstellt eine Ressource aus einer Datei oder von stdin.
  expose        Nimmt einen Replication Controller, Service, Deployment oder Pod und macht ihn als neuen Kubernetes Service verfügbar.
  run           Führt ein bestimmtes Image im Cluster aus.
  set           Legt spezifische Funktionen für Objekte fest.</p>

<p>Grundlegende Befehle (Fortgeschrittene):
  explain       Dokumentation von Ressourcen
  get           Eine oder mehrere Ressourcen anzeigen
  edit          Eine Ressource auf dem Server bearbeiten
  delete        Ressourcen löschen anhand von Dateinamen, stdin, Ressourcen und Namen oder durch Ressourcen und Label-Selektor</p>

<p>Befehle für die Bereitstellung:
  rollout       Verwaltet das Rollout einer Ressource
  scale         Legt eine neue Größe für eine Deployment, ReplicaSet oder Replication Controller fest
  autoscale     Skaliert automatisch ein Deployment, ReplicaSet oder ReplicationController</p>

<p>Cluster Management Befehle:
  certificate   Zertifikatsressourcen ändern.
  cluster-info  Cluster-Informationen anzeigen
  top           Ressourcenverbrauch (CPU/Speicher/Speicherplatz) anzeigen.
  cordon        Knoten als nicht planbar markieren
  uncordon      Knoten als planbar markieren
  drain         Knoten für Wartungsarbeiten vorbereiten
  taint         Taints auf einem oder mehreren Knoten aktualisieren</p>

<p>Fehlerbehebung und Debugging-Befehle:
  describe      Zeigt Details einer bestimmten Ressource oder einer Gruppe von Ressourcen an
  logs          Gibt die Protokolle eines Containers in einem Pod aus
  attach        Verbindet sich mit einem laufenden Container
  exec          Führt einen Befehl in einem Container aus
  port-forward  Leitet einen oder mehrere lokale Ports an einen Pod weiter
  proxy         Startet einen Proxy zum Kubernetes API-Server
  cp            Kopiert Dateien und Verzeichnisse zu und von Containern
  auth          Überprüft die Autorisierung
  debug         Erstellt Debugging-Sitzungen zur Fehlerbehebung von Workloads und Knoten</p>

<p>Erweiterte Befehle:
  diff          Vergleicht die Live-Version mit der Version, die angewendet werden würde
  apply         Wendet eine Konfiguration auf eine Ressource an, basierend auf einem Dateinamen oder stdin
  patch         Aktualisiert Feld(er) einer Ressource
  replace       Ersetzt eine Ressource basierend auf einem Dateinamen oder stdin
  wait          Experimentell: Wartet auf eine bestimmte Bedingung für eine oder mehrere Ressourcen.
  kustomize     Erstellt ein Kustomization-Ziel aus einem Verzeichnis oder einer Remote-URL.</p>

<p>Einstellungsbefehle:
  label         Aktualisiert die Labels einer Ressource
  annotate      Aktualisiert die Annotationen einer Ressource
  completion    Gibt den Shell-Vervollständigungscode für die angegebene Shell aus (bash oder zsh)</p>

<p>Weitere Befehle:
  api-resources Zeigt die unterstützten API-Ressourcen auf dem Server an
  api-versions  Zeigt die unterstützten API-Versionen auf dem Server in der Form “Gruppe/Version” an
  config        Bearbeitet kubeconfig-Dateien
  plugin        Bietet Hilfsmittel für die Interaktion mit Plugins.
  version       Zeigt die Versionsinformationen des Clients und des Servers an</p>

<p>Verwendung:
  kubectl [flags] [options]</p>

<p>Verwenden Sie “kubectl <Befehl> --help", um weitere Informationen zu einem bestimmten Befehl zu erhalten.
Verwenden Sie "kubectl options", um eine Liste globaler Befehlszeilenoptionen anzuzeigen (gilt für alle Befehle).</Befehl></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Erstellen wir eine Konfigurationsdatei.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  minReadySeconds: 5
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Der obige Codeblock enthält keine spezifischen Anweisungen oder Inhalte, die übersetzt werden müssen. Es handelt sich lediglich um einen leeren Codeblock, der in Markdown verwendet wird, um Codeabschnitte zu kennzeichnen. Wenn Sie spezifische Inhalte oder Anweisungen haben, die übersetzt werden sollen, geben Sie diese bitte an.

```shell
$ kubectl apply -f simple_deployment.yaml
Die Verbindung zum Server localhost:8080 wurde abgelehnt – haben Sie den richtigen Host oder Port angegeben?
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl cluster-info
</code></pre></div></div>

<p>Um Cluster-Probleme weiter zu debuggen und zu diagnostizieren, verwenden Sie <code class="language-plaintext highlighter-rouge">kubectl cluster-info dump</code>.
Die Verbindung zum Server localhost:8080 wurde abgelehnt – haben Sie den richtigen Host oder Port angegeben?</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Wenn Sie es versuchen, im Terminal der offiziellen Website auszuführen.

```shell
$ start.sh
Starte Kubernetes...minikube Version: v1.8.1
Commit: cbda04cf6bbe65e987ae52bb393c10099ab62014
* minikube v1.8.1 auf Ubuntu 18.04
* Verwendung des none-Treibers basierend auf Benutzerkonfiguration
* Läuft auf localhost (CPUs=2, Speicher=2460MB, Festplatte=145651MB) ...
* Betriebssystemversion ist Ubuntu 18.04.4 LTS
</code></pre></div></div>

<ul>
  <li>Vorbereitung von Kubernetes v1.17.3 auf Docker 19.03.6 …
    <ul>
      <li>kubelet.resolv-conf=/run/systemd/resolve/resolv.conf</li>
    </ul>
  </li>
  <li>Starten von Kubernetes …</li>
  <li>Aktivieren von Addons: default-storageclass, storage-provisioner</li>
  <li>Konfiguration der lokalen Host-Umgebung …</li>
  <li>Fertig! kubectl ist nun so konfiguriert, dass es “minikube” verwendet</li>
  <li>Das ‘dashboard’-Addon ist aktiviert
Kubernetes gestartet
```</li>
</ul>

<p>Kehren wir zurück zu unserem Terminal.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
<span class="nv">$ </span>kubectl version
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
Die Verbindung zum Server localhost:8080 wurde abgelehnt – haben Sie den richtigen Host oder Port angegeben?
</code></pre></div></div>

<p>Interessanterweise führt das Hinzufügen der Option <code class="language-plaintext highlighter-rouge">--client</code> nicht zu einem Fehler.</p>

<p>Die Dokumentation besagt, dass zuerst <code class="language-plaintext highlighter-rouge">Minikube</code> installiert werden muss.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>minikube
<span class="o">==&gt;</span> Lade https://homebrew.bintray.com/bottles/minikube-1.16.0.big_sur.bottle.tar.gz herunter
<span class="o">==&gt;</span> Lade von https://d29vzk4ow07wi7.cloudfront.net/1b6d7d1b97b11b6b07e4fa531c2dc21770da290da9b2816f360fd923e00c85fc?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Gieße minikube-1.16.0.big_sur.bottle.tar.gz ein
<span class="o">==&gt;</span> Hinweise
Die Bash-Vervollständigung wurde installiert <span class="k">in</span>:
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Zusammenfassung
🍺  /usr/local/Cellar/minikube/1.16.0: 8 Dateien, 64.6MB
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube start
😄  minikube v1.16.0 auf Darwin 11.2.2
🎉  minikube 1.18.1 ist verfügbar! Lade es herunter: https://github.com/kubernetes/minikube/releases/tag/v1.18.1
💡  Um diese Benachrichtigung zu deaktivieren, führe aus: <span class="s1">'minikube config set WantUpdateNotification false'</span>
</code></pre></div></div>

<p>✨  Automatisch den Virtualbox-Treiber ausgewählt
💿  VM-Boot-Image wird heruntergeladen …
    &gt; minikube-v1.16.0.iso.sha256: 65 B / 65 B [————-] 100.00% ? p/s 0s
    &gt; minikube-v1.16.0.iso: 212.62 MiB / 212.62 MiB [] 100.00% 5.32 MiB p/s 40s
👍  Starte den Control-Plane-Knoten minikube im Cluster minikube
💾  Kubernetes v1.20.0 Preload wird heruntergeladen …
    &gt; preloaded-images-k8s-v8-v1….: 491.00 MiB / 491.00 MiB  100.00% 7.52 MiB
🔥  Erstelle Virtualbox-VM (CPUs=2, Speicher=4000MB, Festplatte=20000MB) …
❗  Diese VM hat Probleme, auf https://k8s.gcr.io zuzugreifen
💡  Um neue externe Images zu pullen, müssen Sie möglicherweise einen Proxy konfigurieren: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
🐳  Bereite Kubernetes v1.20.0 auf Docker 20.10.0 vor …
    ▪ Zertifikate und Schlüssel werden generiert …
    ▪ Control Plane wird hochgefahren …
    ▪ RBAC-Regeln werden konfiguriert …
🔎  Überprüfe Kubernetes-Komponenten…
🌟  Aktivierte Addons: storage-provisioner, default-storageclass
🏄  Fertig! kubectl ist nun standardmäßig für die Verwendung des Clusters “minikube” und des Namespace “default” konfiguriert</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Als Nächstes greifen wir auf diesen Cluster zu.

```shell
$ kubectl get po -A
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
kube-system   coredns-74ff55c5b-ndbcr            1/1     Running   0          60s
kube-system   etcd-minikube                      0/1     Running   0          74s
kube-system   kube-apiserver-minikube            1/1     Running   0          74s
kube-system   kube-controller-manager-minikube   1/1     Running   0          74s
kube-system   kube-proxy-g2296                   1/1     Running   0          60s
kube-system   kube-scheduler-minikube            0/1     Running   0          74s
kube-system   storage-provisioner                1/1     Running   1          74s
</code></pre></div></div>

<p>Um das Dashboard von <code class="language-plaintext highlighter-rouge">minikube</code> zu öffnen, führen Sie den folgenden Befehl aus:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube dashboard
</code></pre></div></div>

<p>Dieser Befehl startet das Kubernetes-Dashboard und öffnet es in Ihrem Standard-Webbrowser.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube dashboard
🔌  Dashboard wird aktiviert ...
🤔  Überprüfung der Dashboard-Integrität ...
🚀  Proxy wird gestartet ...
🤔  Überprüfung der Proxy-Integrität ...
🎉  Öffnen von http://127.0.0.1:50030/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ <span class="k">in </span>Ihrem Standardbrowser...
</code></pre></div></div>

<p><img src="assets/images/distributed/k8s.png" alt="k8s" /></p>

<p>Wie schaltet man es aus?</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube
minikube stellt lokale Kubernetes-Cluster bereit und verwaltet sie, die für Entwicklungs-Workflows optimiert sind.
</code></pre></div></div>

<p>Grundlegende Befehle:
  start          Startet einen lokalen Kubernetes-Cluster
  status         Ruft den Status eines lokalen Kubernetes-Clusters ab
  stop           Stoppt einen laufenden lokalen Kubernetes-Cluster
  delete         Löscht einen lokalen Kubernetes-Cluster
  dashboard      Greift auf das Kubernetes-Dashboard zu, das im Minikube-Cluster läuft
  pause          Pausiert Kubernetes
  unpause        Setzt Kubernetes fort</p>

<p>Bilder-Befehle:
  docker-env     Konfiguriert die Umgebung, um den Docker-Daemon von minikube zu verwenden
  podman-env     Konfiguriert die Umgebung, um den Podman-Dienst von minikube zu verwenden
  cache          Fügt ein lokales Bild hinzu, löscht es oder lädt es in minikube hoch</p>

<p>Konfigurations- und Verwaltungsbefehle:
  addons         Aktivieren oder deaktivieren Sie ein Minikube-Addon
  config         Ändern Sie persistente Konfigurationswerte
  profile        Abrufen oder Auflisten der aktuellen Profile (Cluster)
  update-context Aktualisieren Sie kubeconfig im Falle einer IP- oder Portänderung</p>

<p>Netzwerk- und Konnektivitätsbefehle:
  service        Gibt eine URL zurück, um eine Verbindung zu einem Dienst herzustellen
  tunnel         Verbindung zu LoadBalancer-Diensten herstellen</p>

<p>Erweiterte Befehle:
  mount          Bindet das angegebene Verzeichnis in minikube ein
  ssh            Loggt sich in die minikube-Umgebung ein (für Debugging-Zwecke)
  kubectl        Führt eine kubectl-Binärdatei aus, die der Cluster-Version entspricht
  node           Fügt zusätzliche Knoten hinzu, entfernt sie oder listet sie auf</p>

<p>Fehlerbehebungsbefehle:
  ssh-key        Ruft den Pfad des SSH-Identitätsschlüssels des angegebenen Knotens ab
  ssh-host       Ruft den SSH-Hostschlüssel des angegebenen Knotens ab
  ip             Ruft die IP-Adresse des angegebenen Knotens ab
  logs           Gibt Protokolle zurück, um einen lokalen Kubernetes-Cluster zu debuggen
  update-check   Druckt die aktuelle und die neueste Versionsnummer
  version        Druckt die Version von minikube</p>

<p>Andere Befehle:
  completion     Generiert Befehlsvervollständigung für eine Shell</p>

<p>Verwenden Sie <code class="language-plaintext highlighter-rouge">minikube &lt;Befehl&gt; --help</code>, um weitere Informationen zu einem bestimmten Befehl zu erhalten.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Es scheint, dass es sich um `minikube stop` handelt.

Zurück zu `kubernetes`, jetzt funktioniert alles einwandfrei.

```shell
$ kubectl cluster-info
Kubernetes Control Plane läuft unter https://192.168.99.100:8443
KubeDNS läuft unter https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
</code></pre></div></div>

<p>Um Cluster-Probleme weiter zu debuggen und zu diagnostizieren, verwenden Sie <code class="language-plaintext highlighter-rouge">kubectl cluster-info dump</code>.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Wenn wir `https://192.168.99.100:8443` öffnen, zeigt der Browser:

```json
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "Failure",
  "message": "verboten: Benutzer \"system:anonymous\" kann den Pfad \"/\" nicht abrufen",
  "reason": "Forbidden",
  "details": {
    
  },
  "code": 403
}
</code></pre></div></div>

<p>访问<code class="language-plaintext highlighter-rouge">https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</code>：</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Status"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"apiVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Fehler"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Dienste </span><span class="se">\"</span><span class="s2">kube-dns:dns</span><span class="se">\"</span><span class="s2"> sind verboten: Benutzer </span><span class="se">\"</span><span class="s2">system:anonymous</span><span class="se">\"</span><span class="s2"> kann die Ressource </span><span class="se">\"</span><span class="s2">services/proxy</span><span class="se">\"</span><span class="s2"> in der API-Gruppe </span><span class="se">\"\"</span><span class="s2"> im Namespace </span><span class="se">\"</span><span class="s2">kube-system</span><span class="se">\"</span><span class="s2"> nicht abrufen"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"reason"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Verboten"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"details"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-dns:dns"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"services"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"code"</span><span class="p">:</span><span class="w"> </span><span class="mi">403</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Probieren wir die gerade besprochene Konfiguration aus.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> simple_deployment.yaml
deployment.apps/nginx-deployment erstellt
</code></pre></div></div>

<p>Es gab ein kleines Problem. Aber bis hierher haben wir <code class="language-plaintext highlighter-rouge">Kubernetes</code> zum Laufen gebracht. Beenden wir es erstmal. Wir werden später weiter damit spielen.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube stop
✋  Stoppe den Knoten <span class="s2">"minikube"</span>  ...
🛑  1 Knoten gestoppt.
</code></pre></div></div>

<p>Überprüfen, ob beendet ist.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>w<span class="nv">$ </span>minikube dashboard
🤷  Der Control-Plane-Knoten muss ausgeführt werden, um diesen Befehl auszuführen
👉  Um einen Cluster zu starten, führen Sie aus: <span class="s2">"minikube start"</span>
</code></pre></div></div>

<h2 id="docker">Docker</h2>

<p><code class="language-plaintext highlighter-rouge">Docker</code> ist ebenfalls eine Container-Plattform, die dazu beiträgt, die Erstellung, Freigabe und Ausführung moderner Anwendungen zu beschleunigen. Laden Sie die Anwendung von der offiziellen Website herunter.</p>

<p><img src="assets/images/distributed/docker.png" alt="docker" /></p>

<p>Die Verwendung des Clients ist etwas langsam. Lass uns die Befehlszeile verwenden.</p>

<div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker
</code></pre></div></div>

<p>Verwendung:  docker [OPTIONEN] BEFEHL</p>

<p>Eine eigenständige Laufzeitumgebung für Container</p>

<p>Optionen:
      –config string      Speicherort der Client-Konfigurationsdateien (Standard “/Users/lzw/.docker”)
  -c, –context string     Name des Kontexts, der für die Verbindung zum Daemon verwendet werden soll (überschreibt die DOCKER_HOST-Umgebungsvariable und den Standardkontext, der mit “docker context use” festgelegt wurde)
  -D, –debug              Debug-Modus aktivieren
  -H, –host list          Daemon-Socket(s), zu dem/denen eine Verbindung hergestellt werden soll
  -l, –log-level string   Legt das Log-Level fest (“debug”|”info”|”warn”|”error”|”fatal”) (Standard “info”)
      –tls                TLS verwenden; impliziert durch –tlsverify
      –tlscacert string   Nur Zertifikate vertrauen, die von dieser CA signiert wurden (Standard “/Users/lzw/.docker/ca.pem”)
      –tlscert string     Pfad zur TLS-Zertifikatsdatei (Standard “/Users/lzw/.docker/cert.pem”)
      –tlskey string      Pfad zur TLS-Schlüsseldatei (Standard “/Users/lzw/.docker/key.pem”)
      –tlsverify          TLS verwenden und die Remote-Verbindung überprüfen
  -v, –version            Versionsinformationen anzeigen und beenden</p>

<p>Management-Befehle:
  app*        Docker App (Docker Inc., v0.9.1-beta3)
  builder     Builds verwalten
  buildx*     Mit BuildKit bauen (Docker Inc., v0.5.1-docker)
  config      Docker-Konfigurationen verwalten
  container   Container verwalten
  context     Kontexte verwalten
  image       Images verwalten
  manifest    Docker-Image-Manifeste und Manifest-Listen verwalten
  network     Netzwerke verwalten
  node        Swarm-Knoten verwalten
  plugin      Plugins verwalten
  scan*       Docker Scan (Docker Inc., v0.5.0)
  secret      Docker-Geheimnisse verwalten
  service     Dienste verwalten
  stack       Docker-Stacks verwalten
  swarm       Swarm verwalten
  system      Docker verwalten
  trust       Vertrauenswürdigkeit von Docker-Images verwalten
  volume      Volumes verwalten</p>

<p>Befehle:
  attach      Lokale Standard-Eingabe-, Ausgabe- und Fehlerströme an einen laufenden Container anhängen
  build       Ein Image aus einer Dockerfile erstellen
  commit      Ein neues Image aus den Änderungen eines Containers erstellen
  cp          Dateien/Ordner zwischen einem Container und dem lokalen Dateisystem kopieren
  create      Einen neuen Container erstellen
  diff        Änderungen an Dateien oder Verzeichnissen im Dateisystem eines Containers überprüfen
  events      Echtzeit-Ereignisse vom Server abrufen
  exec        Einen Befehl in einem laufenden Container ausführen
  export      Das Dateisystem eines Containers als tar-Archiv exportieren
  history     Die Historie eines Images anzeigen
  images      Images auflisten
  import      Den Inhalt eines tar-Archivs importieren, um ein Dateisystem-Image zu erstellen
  info        Systemweite Informationen anzeigen
  inspect     Niedrigstufige Informationen zu Docker-Objekten zurückgeben
  kill        Einen oder mehrere laufende Container beenden
  load        Ein Image aus einem tar-Archiv oder STDIN laden
  login       Bei einer Docker-Registry anmelden
  logout      Von einer Docker-Registry abmelden
  logs        Die Protokolle eines Containers abrufen
  pause       Alle Prozesse in einem oder mehreren Containern anhalten
  port        Port-Zuordnungen oder eine spezifische Zuordnung für den Container auflisten
  ps          Container auflisten
  pull        Ein Image oder ein Repository aus einer Registry herunterladen
  push        Ein Image oder ein Repository in eine Registry hochladen
  rename      Einen Container umbenennen
  restart     Einen oder mehrere Container neu starten
  rm          Einen oder mehrere Container entfernen
  rmi         Einen oder mehrere Images entfernen
  run         Einen Befehl in einem neuen Container ausführen
  save        Ein oder mehrere Images in ein tar-Archiv speichern (standardmäßig nach STDOUT gestreamt)
  search      Im Docker Hub nach Images suchen
  start       Einen oder mehrere gestoppte Container starten
  stats       Einen Live-Stream der Ressourcennutzungsstatistiken von Container(n) anzeigen
  stop        Einen oder mehrere laufende Container stoppen
  tag         Ein Tag TARGET_IMAGE erstellen, das auf SOURCE_IMAGE verweist
  top         Die laufenden Prozesse eines Containers anzeigen
  unpause     Alle Prozesse in einem oder mehreren Containern fortsetzen
  update      Die Konfiguration eines oder mehrerer Container aktualisieren
  version     Die Docker-Versionsinformationen anzeigen
  wait        Blockieren, bis ein oder mehrere Container stoppen, und dann deren Exit-Codes ausgeben</p>

<p>Führen Sie <code class="language-plaintext highlighter-rouge">docker COMMAND --help</code> aus, um weitere Informationen zu einem Befehl zu erhalten.</p>

<p>Um mehr Hilfe zu Docker zu erhalten, schauen Sie sich unsere Anleitungen unter https://docs.docker.com/go/guides/ an.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Folgen Sie dem Tutorial und probieren Sie es aus.

```shell
$ docker run -d -p 80:80 docker/getting-started
Unable to find image 'docker/getting-started:latest' locally
latest: Pulling from docker/getting-started
aad63a933944: Pull complete
b14da7a62044: Pull complete
343784d40d66: Pull complete
6f617e610986: Pull complete
Digest: sha256:d2c4fb0641519ea208f20ab03dc40ec2a5a53fdfbccca90bef14f870158ed577
Status: Downloaded newer image for docker/getting-started:latest
815f13fc8f99f6185257980f74c349e182842ca572fe60ff62cbb15641199eaf
docker: Error response from daemon: Ports are not available: listen tcp 0.0.0.0:80: bind: address already in use.
</code></pre></div></div>

<p>Übersetzung:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 80:80 docker/getting-started
Das Image <span class="s1">'docker/getting-started:latest'</span> wurde lokal nicht gefunden.
latest: Wird von docker/getting-started gezogen
aad63a933944: Pull <span class="nb">complete
</span>b14da7a62044: Pull <span class="nb">complete
</span>343784d40d66: Pull <span class="nb">complete
</span>6f617e610986: Pull <span class="nb">complete
</span>Digest: sha256:d2c4fb0641519ea208f20ab03dc40ec2a5a53fdfbccca90bef14f870158ed577
Status: Neueres Image für docker/getting-started wurde heruntergeladen.
815f13fc8f99f6185257980f74c349e182842ca572fe60ff62cbb15641199eaf
docker: Fehlerantwort vom Daemon: Ports sind nicht verfügbar: listen tcp 0.0.0.0:80: <span class="nb">bind</span>: Adresse wird bereits verwendet.
</code></pre></div></div>

<p>Ändere den Port.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:80 docker/getting-started
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p><img src="assets/images/distributed/docker_run.png" alt="docker_run" /></p>

<p>Öffnen Sie den Browser, um zu zeigen, dass wir <code class="language-plaintext highlighter-rouge">docker</code> erfolgreich gestartet haben.</p>

<p><img src="assets/images/distributed/browser.png" alt="Browser" /></p>

<p>Stoppe den Container. Verwende die zuvor zurückgegebene <code class="language-plaintext highlighter-rouge">ID</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker stop 45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p>Zu diesem Zeitpunkt war die Website bereits nicht mehr erreichbar.</p>

<p>Das deutet darauf hin, dass <code class="language-plaintext highlighter-rouge">docker</code> wie eine virtuelle Maschine funktioniert.</p>

<h2 id="flink">Flink</h2>

<p>Öffnen Sie die offizielle Website.</p>

<p><img src="assets/images/distributed/flink-home-graphic.png" alt="flink-home-graphic" /></p>

<p><code class="language-plaintext highlighter-rouge">Flink</code> spricht von <code class="language-plaintext highlighter-rouge">Stateful</code>-Berechnungen für Datenströme. Was bedeutet <code class="language-plaintext highlighter-rouge">Stateful</code>? Das ist mir noch nicht ganz klar. Das obige Diagramm ist jedoch sehr interessant. Lass es uns ausprobieren.</p>

<p>Es wird eine Java-Umgebung benötigt.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>java <span class="nt">-version</span>
java version <span class="s2">"1.8.0_151"</span>
Java<span class="o">(</span>TM<span class="o">)</span> SE Runtime Environment <span class="o">(</span>Build 1.8.0_151-b12<span class="o">)</span>
Java HotSpot<span class="o">(</span>TM<span class="o">)</span> 64-Bit Server VM <span class="o">(</span>Build 25.151-b12, gemischter Modus<span class="o">)</span>
</code></pre></div></div>

<p>Laden Sie die neueste Version <code class="language-plaintext highlighter-rouge">flink-1.12.2-bin-scala_2.11.tar</code> von der offiziellen Website herunter.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/start-cluster.sh
Cluster wird gestartet.
Standalonesession-Daemon wird auf Host lzwjava gestartet.
Taskexecutor-Daemon wird auf Host lzwjava gestartet.
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/flink run examples/streaming/WordCount.jar
Ausführung des WordCount-Beispiels mit dem Standard-Eingabedatensatz.
Verwenden Sie <span class="nt">--input</span>, um eine Dateieingabe anzugeben.
Das Ergebnis wird auf stdout ausgegeben. Verwenden Sie <span class="nt">--output</span>, um einen Ausgabepfad anzugeben.
Der Job wurde mit der JobID 60f37647c20c2a6654359bd34edab807 übermittelt.
Programmausführung abgeschlossen
Der Job mit der JobID 60f37647c20c2a6654359bd34edab807 ist abgeschlossen.
Job-Laufzeit: 757 ms
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">tail </span>log/flink-<span class="k">*</span><span class="nt">-taskexecutor-</span><span class="k">*</span>.out
<span class="o">(</span>nymph,1<span class="o">)</span>
<span class="o">(</span><span class="k">in</span>,3<span class="o">)</span>
<span class="o">(</span>thy,1<span class="o">)</span>
<span class="o">(</span>orisons,1<span class="o">)</span>
<span class="o">(</span>be,4<span class="o">)</span>
<span class="o">(</span>all,2<span class="o">)</span>
<span class="o">(</span>my,1<span class="o">)</span>
<span class="o">(</span>sins,1<span class="o">)</span>
<span class="o">(</span>remember,1<span class="o">)</span>
<span class="o">(</span>d,4<span class="o">)</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/stop-cluster.sh
Taskexecutor-Daemon wird gestoppt <span class="o">(</span>pid: 41812<span class="o">)</span> auf Host lzwjava.
</code></pre></div></div>

<p>Ja, der Einstieg war erfolgreich. Man kann sehen, dass dies <code class="language-plaintext highlighter-rouge">Spark</code> sehr ähnlich ist.</p>

<h2 id="kylin">Kylin</h2>

<p>Öffnen Sie die offizielle Website.</p>

<blockquote>
  <p>Apache Kylin™ ist ein Open-Source, verteiltes Analytisches Data Warehouse für Big Data; es wurde entwickelt, um OLAP-Fähigkeiten (Online Analytical Processing) im Zeitalter von Big Data bereitzustellen. Durch die Modernisierung der Multi-Dimensional-Cube- und Vorberechnungstechnologie auf Hadoop und Spark ist Kylin in der Lage, nahezu konstante Abfragegeschwindigkeiten zu erreichen, unabhängig vom stetig wachsenden Datenvolumen. Indem Kylin die Abfragelatenz von Minuten auf unter eine Sekunde reduziert, bringt es Online-Analysen zurück zu Big Data.</p>
</blockquote>

<blockquote>
  <p>Apache Kylin™ ermöglicht es Ihnen, Milliarden von Zeilen in weniger als einer Sekunde in 3 Schritten abzufragen.</p>

  <ol>
    <li>Identifizieren Sie ein Stern- oder Schneeflockenschema auf Hadoop.</li>
    <li>Erstellen Sie einen Cube aus den identifizierten Tabellen.</li>
    <li>Führen Sie Abfragen mit ANSI-SQL durch und erhalten Sie Ergebnisse in weniger als einer Sekunde über ODBC, JDBC oder eine RESTful API.</li>
  </ol>
</blockquote>

<p><img src="assets/images/distributed/kylin_diagram.png" alt="kylin_diagram" /></p>

<p>Es handelt sich im Wesentlichen um eine Ebene zur Analyse von Big Data. Mit ihr kann man sehr schnell suchen. Sie dient als Brücke.</p>

<p>Leider ist die Nutzung derzeit nur in einer <code class="language-plaintext highlighter-rouge">Linux</code>-Umgebung möglich. Ich werde später noch einmal daran herumspielen.</p>

<h2 id="mongodb">MongoDB</h2>

<p>Das ist auch eine Art von Datenbank. Versuchen Sie, es zu installieren.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew tap mongodb/brew
<span class="o">==&gt;</span> Tapping mongodb/brew
Klone nach <span class="s1">'/usr/local/Homebrew/Library/Taps/mongodb/homebrew-brew'</span>...
remote: Enumerating objects: 63, <span class="k">done</span><span class="nb">.</span>
remote: Counting objects: 100% <span class="o">(</span>63/63<span class="o">)</span>, <span class="k">done</span><span class="nb">.</span>
remote: Compressing objects: 100% <span class="o">(</span>62/62<span class="o">)</span>, <span class="k">done</span><span class="nb">.</span>
remote: Total 566 <span class="o">(</span>delta 21<span class="o">)</span>, reused 6 <span class="o">(</span>delta 1<span class="o">)</span>, pack-reused 503
Empfange Objekte: 100% <span class="o">(</span>566/566<span class="o">)</span>, 121.78 KiB | 335.00 KiB/s, <span class="k">done</span><span class="nb">.</span>
Löse Deltas auf: 100% <span class="o">(</span>259/259<span class="o">)</span>, <span class="k">done</span><span class="nb">.</span>
11 Formeln angezapft <span class="o">(</span>39 Dateien, 196.2KB<span class="o">)</span><span class="nb">.</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>mongodb-community@4.4
<span class="o">==&gt;</span> Installation von mongodb-community aus mongodb/brew
<span class="o">==&gt;</span> Herunterladen von https://fastdl.mongodb.org/tools/db/mongodb-database-tools-macos-x86_64-100.3.0.zip
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Herunterladen von https://fastdl.mongodb.org/osx/mongodb-macos-x86_64-4.4.3.tgz
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Installation der Abhängigkeiten für mongodb/brew/mongodb-community: mongodb-database-tools
<span class="o">==&gt;</span> Installation der Abhängigkeit mongodb/brew/mongodb-community: mongodb-database-tools
Fehler: Der <span class="sb">`</span>brew <span class="nb">link</span><span class="sb">`</span><span class="nt">-Schritt</span> wurde nicht erfolgreich abgeschlossen
Die Formel wurde gebaut, ist aber nicht <span class="k">in</span> /usr/local verlinkt
Konnte bin/bsondump nicht verlinken
Ziel /usr/local/bin/bsondump
ist ein Symlink, der zu mongodb gehört. Sie können ihn entlinken:
  brew <span class="nb">unlink </span>mongodb
</code></pre></div></div>

<p>Um den Link zu erzwingen und alle konfligierenden Dateien zu überschreiben:
  brew link –overwrite mongodb-database-tools</p>

<p>Um alle Dateien aufzulisten, die gelöscht würden:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  brew <span class="nb">link</span> <span class="nt">--overwrite</span> <span class="nt">--dry-run</span> mongodb-database-tools
</code></pre></div></div>

<p>Mögliche konfliktierende Dateien sind:
/usr/local/bin/bsondump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/bsondump
/usr/local/bin/mongodump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongodump
/usr/local/bin/mongoexport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoexport
/usr/local/bin/mongofiles -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongofiles
/usr/local/bin/mongoimport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoimport
/usr/local/bin/mongorestore -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongorestore
/usr/local/bin/mongostat -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongostat
/usr/local/bin/mongotop -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongotop
==&gt; Zusammenfassung
🍺  /usr/local/Cellar/mongodb-database-tools/100.3.0: 13 Dateien, 154MB, in 11 Sekunden erstellt
==&gt; Installation von mongodb/brew/mongodb-community
Fehler: Der <code class="language-plaintext highlighter-rouge">brew link</code> Schritt wurde nicht erfolgreich abgeschlossen
Die Formel wurde erstellt, ist jedoch nicht in /usr/local verlinkt
Konnte bin/mongo nicht verlinken
Ziel /usr/local/bin/mongo
ist ein Symlink, der zu mongodb gehört. Sie können ihn entlinken:
  brew unlink mongodb</p>

<p>Um den Link zu erzwingen und alle konfligierenden Dateien zu überschreiben:
  brew link –overwrite mongodb-community</p>

<p>Um alle Dateien aufzulisten, die gelöscht würden:
  brew link –overwrite –dry-run mongodb-community</p>

<p>Mögliche konfliktierende Dateien sind:
/usr/local/bin/mongo -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongo
/usr/local/bin/mongod -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongod
/usr/local/bin/mongos -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongos
==&gt; Hinweise
Um launchd zu veranlassen, mongodb/brew/mongodb-community jetzt zu starten und bei der Anmeldung neu zu starten:
  brew services start mongodb/brew/mongodb-community
Oder, wenn Sie keinen Hintergrunddienst benötigen/wollen, können Sie einfach ausführen:
  mongod –config /usr/local/etc/mongod.conf
==&gt; Zusammenfassung
🍺  /usr/local/Cellar/mongodb-community/4.4.3: 11 Dateien, 156,8 MB, in 10 Sekunden erstellt
==&gt; Hinweise
==&gt; mongodb-community
Um launchd zu veranlassen, mongodb/brew/mongodb-community jetzt zu starten und bei der Anmeldung neu zu starten:
  brew services start mongodb/brew/mongodb-community
Oder, wenn Sie keinen Hintergrunddienst benötigen/wollen, können Sie einfach ausführen:
  mongod –config /usr/local/etc/mongod.conf</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Zuvor hatte ich eine ältere Version installiert. Ich werde die Verknüpfungen aufheben.

```shell
$ brew unlink mongodb
Unlinking /usr/local/Cellar/mongodb/3.0.7... 11 Symlinks entfernt
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--version</span>
db version v4.4.3
Build Info: <span class="o">{</span>
    <span class="s2">"version"</span>: <span class="s2">"4.4.3"</span>,
    <span class="s2">"gitVersion"</span>: <span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span>,
    <span class="s2">"modules"</span>: <span class="o">[]</span>,
    <span class="s2">"allocator"</span>: <span class="s2">"system"</span>,
    <span class="s2">"environment"</span>: <span class="o">{</span>
        <span class="s2">"distarch"</span>: <span class="s2">"x86_64"</span>,
        <span class="s2">"target_arch"</span>: <span class="s2">"x86_64"</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Führen Sie dann <code class="language-plaintext highlighter-rouge">mongod</code> aus, um den MongoDB-Server zu starten. Beim ersten Start wurde jedoch gemeldet, dass <code class="language-plaintext highlighter-rouge">/data/db</code> nicht existiert. Wir erstellen ein Verzeichnis, <code class="language-plaintext highlighter-rouge">~/mongodb</code>, um die Datenbankdateien dort zu speichern.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--dbpath</span> ~/mongodb
</code></pre></div></div>

<p>Ausgabe:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.838+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23285</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"TLS 1.0 wird automatisch deaktiviert. Um TLS 1.0 zu erzwingen, geben Sie --sslDisabledProtocols 'none' an"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"W"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"ASIO"</span><span class="p">,</span><span class="w">     </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">22601</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Keine TransportLayer während des NetworkInterface-Starts konfiguriert"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"NETWORK"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4648602</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Implizites TCP FastOpen wird verwendet."</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"STORAGE"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4615611</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"MongoDB startet"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"pid"</span><span class="p">:</span><span class="mi">46256</span><span class="p">,</span><span class="nl">"port"</span><span class="p">:</span><span class="mi">27017</span><span class="p">,</span><span class="nl">"dbPath"</span><span class="p">:</span><span class="s2">"/Users/lzw/mongodb"</span><span class="p">,</span><span class="nl">"architecture"</span><span class="p">:</span><span class="s2">"64-bit"</span><span class="p">,</span><span class="nl">"host"</span><span class="p">:</span><span class="s2">"lzwjava"</span><span class="p">}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23403</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Build-Informationen"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"buildInfo"</span><span class="p">:{</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"4.4.3"</span><span class="p">,</span><span class="nl">"gitVersion"</span><span class="p">:</span><span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span><span class="p">,</span><span class="nl">"modules"</span><span class="p">:[],</span><span class="nl">"allocator"</span><span class="p">:</span><span class="s2">"system"</span><span class="p">,</span><span class="nl">"environment"</span><span class="p">:{</span><span class="nl">"distarch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">,</span><span class="nl">"target_arch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">}}}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.843+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">51765</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Betriebssystem"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"os"</span><span class="p">:{</span><span class="nl">"name"</span><span class="p">:</span><span class="s2">"Mac OS X"</span><span class="p">,</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"20.3.0"</span><span class="p">}}}</span><span class="w">
</span><span class="err">...</span><span class="w">
</span></code></pre></div></div>

<p>Es ist ersichtlich, dass alles im <code class="language-plaintext highlighter-rouge">JSON</code>-Format vorliegt. MongoDB speichert alle Daten in <code class="language-plaintext highlighter-rouge">JSON</code>-Format. Öffnen Sie anschließend einen weiteren Terminal-Tab.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongo
MongoDB Shell Version v4.4.3
Verbindung zu: mongodb://127.0.0.1:27017/?compressors<span class="o">=</span>disabled&amp;gssapiServiceName<span class="o">=</span>mongodb
Implizite Sitzung: Sitzung <span class="o">{</span> <span class="s2">"id"</span> : UUID<span class="o">(</span><span class="s2">"4f55c561-70d3-4289-938d-4b90a284891f"</span><span class="o">)</span> <span class="o">}</span>
MongoDB Server Version: 4.4.3
<span class="nt">---</span>
Der Server hat beim Starten diese Warnungen generiert:
        2021-03-11T18:17:33.743+08:00: Zugriffskontrolle ist für die Datenbank nicht aktiviert. Lese- und Schreibzugriff auf Daten und Konfiguration sind uneingeschränkt
        2021-03-11T18:17:33.743+08:00: Dieser Server ist an localhost gebunden. Externe Systeme können keine Verbindung zu diesem Server herstellen. Starten Sie den Server mit <span class="nt">--bind_ip</span> &lt;Adresse&gt;, um anzugeben, von welchen IP-Adressen er Antworten bereitstellen soll, oder mit <span class="nt">--bind_ip_all</span>, um an alle Schnittstellen zu binden. Wenn dieses Verhalten gewünscht ist, starten Sie den Server mit <span class="nt">--bind_ip</span> 127.0.0.1, um diese Warnung zu deaktivieren
        2021-03-11T18:17:33.743+08:00: Soft rlimits zu niedrig
        2021-03-11T18:17:33.743+08:00:         aktueller Wert: 4864
        2021-03-11T18:17:33.743+08:00:         empfohlenes Minimum: 64000
<span class="nt">---</span>
<span class="nt">---</span>
        Aktivieren Sie den kostenlosen cloud-basierten Überwachungsdienst von MongoDB, der dann Metriken über Ihre Bereitstellung <span class="o">(</span>Datenträgerauslastung, CPU, Betriebsstatistiken usw.<span class="o">)</span> empfängt und anzeigt.

        Die Überwachungsdaten werden auf einer MongoDB-Website mit einer eindeutigen URL verfügbar sein, auf die Sie und alle, mit denen Sie die URL teilen, zugreifen können. MongoDB kann diese Informationen verwenden, um Produktverbesserungen vorzunehmen und Ihnen MongoDB-Produkte sowie Bereitstellungsoptionen vorzuschlagen.

Um die kostenlose Überwachung zu aktivieren, führen Sie den folgenden Befehl aus: <span class="sb">`</span>db.enableFreeMonitoring<span class="o">()</span><span class="sb">`</span>
Um diese Erinnerung dauerhaft zu deaktivieren, führen Sie den folgenden Befehl aus: <span class="sb">`</span>db.disableFreeMonitoring<span class="o">()</span><span class="sb">`</span>
</code></pre></div></div>

<p>Anschließend können Sie versuchen, Daten einzufügen und abzufragen.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> db.inventory.insertOne<span class="o">(</span>
...    <span class="o">{</span> item: <span class="s2">"canvas"</span>, qty: 100, tags: <span class="o">[</span><span class="s2">"cotton"</span><span class="o">]</span>, size: <span class="o">{</span> h: 28, w: 35.5, uom: <span class="s2">"cm"</span> <span class="o">}</span> <span class="o">}</span>
... <span class="o">)</span>
<span class="o">{</span>
	<span class="s2">"acknowledged"</span> : <span class="nb">true</span>,
	<span class="s2">"insertedId"</span> : ObjectId<span class="o">(</span><span class="s2">"6049ef91b653541cf355facb"</span><span class="o">)</span>
<span class="o">}</span>
<span class="o">&gt;</span>
<span class="o">&gt;</span> db.inventory.find<span class="o">()</span>
<span class="o">{</span> <span class="s2">"_id"</span> : ObjectId<span class="o">(</span><span class="s2">"6049ef91b653541cf355facb"</span><span class="o">)</span>, <span class="s2">"item"</span> : <span class="s2">"canvas"</span>, <span class="s2">"qty"</span> : 100, <span class="s2">"tags"</span> : <span class="o">[</span> <span class="s2">"cotton"</span> <span class="o">]</span>, <span class="s2">"size"</span> : <span class="o">{</span> <span class="s2">"h"</span> : 28, <span class="s2">"w"</span> : 35.5, <span class="s2">"uom"</span> : <span class="s2">"cm"</span> <span class="o">}</span> <span class="o">}</span>
</code></pre></div></div>

<h2 id="fazit">Fazit</h2>

<p>Das war’s erstmal. Später werden wir noch andere Tools ausprobieren. Was ist der Sinn hinter all dem? Wahrscheinlich, um zunächst eine Struktur zu haben. Der Anfang ist immer schwer, und wir haben gleich alles auf einmal durchgearbeitet. Das gibt uns das Vertrauen, dass wir in der Lage sind, und jetzt geht es darum, noch mehr mit diesen Programmen herumzuspielen.</p>

<h2 id="übung">Übung</h2>

<ul>
  <li>Die Schüler erkunden ähnlich wie oben.</li>
</ul>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-de" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
