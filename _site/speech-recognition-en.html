<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Real-time Speech Recognition</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Real-time Speech Recognition | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Real-time Speech Recognition" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="en" />
<meta name="description" content="This Python code implements real-time speech recognition using Google Cloud Speech-to-Text API and the PyAudio library. It captures audio from the microphone, streams it to the Speech-to-Text API, and prints the transcribed text. The MicrophoneStream class handles audio input, and the main function sets up the speech recognition client and processes the audio stream." />
<meta property="og:description" content="This Python code implements real-time speech recognition using Google Cloud Speech-to-Text API and the PyAudio library. It captures audio from the microphone, streams it to the Speech-to-Text API, and prints the transcribed text. The MicrophoneStream class handles audio input, and the main function sets up the speech recognition client and processes the audio stream." />
<link rel="canonical" href="https://lzwjava.github.io/speech-recognition-en" />
<meta property="og:url" content="https://lzwjava.github.io/speech-recognition-en" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-02-04T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Real-time Speech Recognition" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2025-02-04T00:00:00+08:00","datePublished":"2025-02-04T00:00:00+08:00","description":"This Python code implements real-time speech recognition using Google Cloud Speech-to-Text API and the PyAudio library. It captures audio from the microphone, streams it to the Speech-to-Text API, and prints the transcribed text. The MicrophoneStream class handles audio input, and the main function sets up the speech recognition client and processes the audio stream.","headline":"Real-time Speech Recognition","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/speech-recognition-en"},"url":"https://lzwjava.github.io/speech-recognition-en"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=d6d7cbcdf53c15b273c2759997eccbbc90238339">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=d6d7cbcdf53c15b273c2759997eccbbc90238339" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Real-time Speech Recognition | Original
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/en/2025-02-04-speech-recognition-en.md">PDF</a> -->

    <!-- Audio Button -->



    <!-- 
    <a href="#" id="playAudioButton" class="button audio-button" data-file-path="_posts/en/2025-02-04-speech-recognition-en.md">Audio</a>
     -->

        <!-- Date Button -->
    
      
      <!-- <span>_postsen2025-02-04-speech-recognition-en.md</span> -->
      

      <!-- <span>2025-02-04-speech-recognition-en.md</span> -->

      
        

        
          
          <a href="#" class="button">2025.02</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/speech-recognition-en" selected>English</option>
        <option value="/speech-recognition-zh" >中文</option>
        <option value="/speech-recognition-ja" >日本語</option>
        <option value="/speech-recognition-es" >Español</option>
        <option value="/speech-recognition-hi" >हिंदी</option>
        <option value="/speech-recognition-fr" >Français</option>
        <option value="/speech-recognition-de" >Deutsch</option>
        <option value="/speech-recognition-ar" >العربية</option>
        <option value="/speech-recognition-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>This Python code implements real-time speech recognition using Google Cloud Speech-to-Text API and the PyAudio library. It captures audio from the microphone, streams it to the Speech-to-Text API, and prints the transcribed text. The <code class="language-plaintext highlighter-rouge">MicrophoneStream</code> class handles audio input, and the <code class="language-plaintext highlighter-rouge">main</code> function sets up the speech recognition client and processes the audio stream.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">from</span> <span class="nn">google.cloud</span> <span class="kn">import</span> <span class="n">speech</span>

<span class="kn">import</span> <span class="nn">pyaudio</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="kn">import</span> <span class="n">queue</span>


<span class="c1"># Audio recording parameters
</span><span class="n">RATE</span> <span class="o">=</span> <span class="mi">16000</span>
<span class="n">CHUNK</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">RATE</span> <span class="o">/</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># 100ms
</span>

<span class="k">class</span> <span class="nc">MicrophoneStream</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="s">"""Opens a recording stream as a generator yielding the audio chunks."""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">chunk</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_rate</span> <span class="o">=</span> <span class="n">rate</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_chunk</span> <span class="o">=</span> <span class="n">chunk</span>

        <span class="c1"># Create a audio interface using PyAudio
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">_audio_interface</span> <span class="o">=</span> <span class="n">pyaudio</span><span class="p">.</span><span class="n">PyAudio</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_audio_stream</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_audio_interface</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span>
            <span class="nb">format</span><span class="o">=</span><span class="n">pyaudio</span><span class="p">.</span><span class="n">paInt16</span><span class="p">,</span>
            <span class="c1"># The API currently only supports 1-channel (mono) audio
</span>            <span class="c1"># https://goo.gl/z726ff
</span>            <span class="n">channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">_rate</span><span class="p">,</span>
            <span class="nb">input</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">frames_per_buffer</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">_chunk</span><span class="p">,</span>
            <span class="c1"># Run the audio stream asynchronously to fill the buffer object.
</span>            <span class="c1"># This is necessary so that the input device's buffer doesn't
</span>            <span class="c1"># overflow while the calling thread makes network requests, etc.
</span>            <span class="n">stream_callback</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">_fill_buffer</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">closed</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_buff</span> <span class="o">=</span> <span class="n">queue</span><span class="p">.</span><span class="n">Queue</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_fill_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_data</span><span class="p">,</span> <span class="n">frame_count</span><span class="p">,</span> <span class="n">time_info</span><span class="p">,</span> <span class="n">status_flags</span><span class="p">):</span>
        <span class="s">"""Continuously collect data from the audio stream, into the buffer."""</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_buff</span><span class="p">.</span><span class="n">put</span><span class="p">(</span><span class="n">in_data</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">None</span><span class="p">,</span> <span class="n">pyaudio</span><span class="p">.</span><span class="n">paContinue</span>

    <span class="k">def</span> <span class="nf">generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">record_seconds</span><span class="p">):</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">closed</span> <span class="ow">and</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span> <span class="o">&lt;</span> <span class="n">record_seconds</span><span class="p">:</span>
            <span class="c1"># Use a blocking get() to ensure there's at least one chunk of
</span>            <span class="c1"># data, and stop iteration if the chunk is None, indicating the
</span>            <span class="c1"># end of the audio stream.
</span>            <span class="n">chunk</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_buff</span><span class="p">.</span><span class="n">get</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">chunk</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">return</span>
            <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">chunk</span><span class="p">]</span>

            <span class="c1"># Now consume whatever other data's still buffered.
</span>            <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">chunk</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_buff</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">chunk</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                        <span class="k">return</span>
                    <span class="n">data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
                <span class="k">except</span> <span class="n">queue</span><span class="p">.</span><span class="n">Empty</span><span class="p">:</span>
                    <span class="k">break</span>

            <span class="k">yield</span> <span class="sa">b</span><span class="s">''</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">closed</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="c1"># Signal the generator to terminate so that the client's
</span>        <span class="c1"># streaming recognize method will not block the process termination.
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">_buff</span><span class="p">.</span><span class="n">put</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_audio_stream</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_audio_interface</span><span class="p">.</span><span class="n">terminate</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">traceback</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">record_seconds</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">language_code</span><span class="o">=</span><span class="s">'en-US'</span><span class="p">):</span>
    <span class="c1"># See http://g.co/cloud/speech/docs/languages
</span>    <span class="c1"># for a list of supported languages.
</span>    <span class="c1"># language_code = 'en-US'  # a BCP-47 language tag
</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">speech</span><span class="p">.</span><span class="n">SpeechClient</span><span class="p">()</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">speech</span><span class="p">.</span><span class="n">RecognitionConfig</span><span class="p">(</span>
        <span class="n">encoding</span><span class="o">=</span><span class="n">speech</span><span class="p">.</span><span class="n">RecognitionConfig</span><span class="p">.</span><span class="n">AudioEncoding</span><span class="p">.</span><span class="n">LINEAR16</span><span class="p">,</span>
        <span class="n">sample_rate_hertz</span><span class="o">=</span><span class="n">RATE</span><span class="p">,</span>
        <span class="n">language_code</span><span class="o">=</span><span class="n">language_code</span><span class="p">,</span>
        <span class="n">model</span><span class="o">=</span><span class="s">"latest_long"</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">streaming_config</span> <span class="o">=</span> <span class="n">speech</span><span class="p">.</span><span class="n">StreamingRecognitionConfig</span><span class="p">(</span>
        <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
        <span class="n">interim_results</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">MicrophoneStream</span><span class="p">(</span><span class="n">RATE</span><span class="p">,</span> <span class="n">CHUNK</span><span class="p">)</span> <span class="k">as</span> <span class="n">stream</span><span class="p">:</span>
        <span class="n">audio_generator</span> <span class="o">=</span> <span class="n">stream</span><span class="p">.</span><span class="n">generator</span><span class="p">(</span><span class="n">record_seconds</span><span class="p">)</span>
        <span class="n">requests</span> <span class="o">=</span> <span class="p">(</span><span class="n">speech</span><span class="p">.</span><span class="n">StreamingRecognizeRequest</span><span class="p">(</span><span class="n">audio_content</span><span class="o">=</span><span class="n">content</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">audio_generator</span><span class="p">)</span>

        <span class="n">responses</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="n">streaming_recognize</span><span class="p">(</span><span class="n">streaming_config</span><span class="p">,</span> <span class="n">requests</span><span class="p">)</span>
        

        <span class="c1"># Now, put the transcription responses to use.
</span>        <span class="n">transcript</span> <span class="o">=</span> <span class="s">""</span>
        <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">responses</span><span class="p">:</span>            
            <span class="k">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
            <span class="c1"># Once the transcription is done, print the result.
</span>            <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">response</span><span class="p">.</span><span class="n">results</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">is_final</span><span class="p">:</span>
                    <span class="n">alternative</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">alternatives</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">transcript</span> <span class="o">+=</span> <span class="n">alternative</span><span class="p">.</span><span class="n">transcript</span> <span class="o">+</span> <span class="s">" "</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">u</span><span class="s">'Transcript: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">transcript</span><span class="p">))</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="p">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s">"Real-time speech recognition with adjustable duration."</span><span class="p">)</span>
    <span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--duration'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">"Duration of recording in seconds."</span><span class="p">)</span>
    <span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--language_code'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s">'en-US'</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">"Language code for transcription."</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="p">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Please speak..."</span><span class="p">)</span>
    <span class="n">main</span><span class="p">(</span><span class="n">record_seconds</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">duration</span><span class="p">,</span> <span class="n">language_code</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">language_code</span><span class="p">)</span>

</code></pre></div></div>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-en" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
