<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>云计算和大数据入门</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>云计算和大数据入门 | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="云计算和大数据入门" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="zh" />
<meta name="description" content="这节课包含以下话题：" />
<meta property="og:description" content="这节课包含以下话题：" />
<link rel="canonical" href="https://lzwjava.github.io/distributed-zh" />
<meta property="og:url" content="https://lzwjava.github.io/distributed-zh" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-10T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="云计算和大数据入门" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2021-03-10T00:00:00+08:00","datePublished":"2021-03-10T00:00:00+08:00","description":"这节课包含以下话题：","headline":"云计算和大数据入门","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/distributed-zh"},"url":"https://lzwjava.github.io/distributed-zh"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=64a50048a82785e569a4f5bd5eb4f71353cc37bb">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=64a50048a82785e569a4f5bd5eb4f71353cc37bb" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       云计算和大数据入门 | 原创
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/zh/2021-03-10-distributed-zh.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postszh2021-03-10-distributed-zh.md</span> -->
      

      <!-- <span>2021-03-10-distributed-zh.md</span> -->

      
        

        
          
          <a href="#" class="button">2021.03</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/distributed-en" >English</option>
        <option value="/distributed-zh" selected>中文</option>
        <option value="/distributed-ja" >日本語</option>
        <option value="/distributed-es" >Español</option>
        <option value="/distributed-hi" >हिंदी</option>
        <option value="/distributed-fr" >Français</option>
        <option value="/distributed-de" >Deutsch</option>
        <option value="/distributed-ar" >العربية</option>
        <option value="/distributed-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>这节课包含以下话题：</p>

<ul>
  <li>Spark</li>
  <li>Hadoop</li>
  <li>Kubernetes</li>
  <li>Docker</li>
  <li>Flink</li>
  <li>MongoDB</li>
</ul>

<p>说起云计算，似乎离不开很多的工具，Hadoop、Hive、Hbase、ZooKeeper、Docker、Kubernetes、Spark、Kafka、MongoDB、Flink、Druid、Presto、Kylin、Elastic Search。都有听过吗。这些工具有些我是从<code class="language-plaintext highlighter-rouge">大数据工程师</code>、<code class="language-plaintext highlighter-rouge">分布式后端工程师</code>的职位描述上找到的。这些都是高薪职位。我们试着把他们都安装上，试着把玩两下。</p>
<h2 id="初探-spark">初探 Spark</h2>

<p>官网说，<code class="language-plaintext highlighter-rouge">Spark</code>用来处理大规模数据的分析引擎。<code class="language-plaintext highlighter-rouge">spark</code>就是一套库。它似乎不像<code class="language-plaintext highlighter-rouge">Redis</code>那样分成服务端和客户端。<code class="language-plaintext highlighter-rouge">spark</code>就是只在客户端使用的。从官网下载了最新的版本，<code class="language-plaintext highlighter-rouge">spark-3.1.1-bin-hadoop3.2.tar</code>。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
├── LICENSE
├── NOTICE
├── R
├── README.md
├── RELEASE
├── bin
├── conf
├── data
├── examples
├── jars
├── kubernetes
├── licenses
├── python
├── sbin
└── yarn

11 directories, 4 files
</code></pre></div></div>

<p>似乎就是各语言编写的一些分析库。</p>

<p>同时官网说可以在Python上直接装依赖库。<code class="language-plaintext highlighter-rouge">pip install pyspark</code></p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>pip <span class="nb">install </span>pyspark
Collecting pyspark
  Downloading pyspark-3.1.1.tar.gz <span class="o">(</span>212.3 MB<span class="o">)</span>
     |████████████████████████████████| 212.3 MB 14 kB/s
Collecting <span class="nv">py4j</span><span class="o">==</span>0.10.9
  Downloading py4j-0.10.9-py2.py3-none-any.whl <span class="o">(</span>198 kB<span class="o">)</span>
     |████████████████████████████████| 198 kB 145 kB/s
Building wheels <span class="k">for </span>collected packages: pyspark
  Building wheel <span class="k">for </span>pyspark <span class="o">(</span>setup.py<span class="o">)</span> ... <span class="k">done
  </span>Created wheel <span class="k">for </span>pyspark: <span class="nv">filename</span><span class="o">=</span>pyspark-3.1.1-py2.py3-none-any.whl <span class="nv">size</span><span class="o">=</span>212767604 <span class="nv">sha256</span><span class="o">=</span>0b8079e82f3a5bcadad99179902d8c8ff9f8eccad928a469c11b97abdc960b72
  Stored <span class="k">in </span>directory: /Users/lzw/Library/Caches/pip/wheels/23/bf/e9/9f3500437422e2ab82246f25a51ee480a44d4efc6c27e50d33
Successfully built pyspark
Installing collected packages: py4j, pyspark
Successfully installed py4j-0.10.9 pyspark-3.1.1
</code></pre></div></div>

<p>装上了。</p>

<p>这会看官网，有些例子</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/run-example SparkPi 10
</code></pre></div></div>

<p>哦，原来可以运行刚刚下载的安装包里的程序。但出错了。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/run-example SparkPi 10
21/03/11 00:06:15 WARN NativeCodeLoader: Unable to load native-hadoop library <span class="k">for </span>your platform... using builtin-java classes where applicable
21/03/11 00:06:16 INFO ResourceUtils: No custom resources configured <span class="k">for </span>spark.driver.
21/03/11 00:06:16 WARN Utils: Service <span class="s1">'sparkDriver'</span> could not <span class="nb">bind </span>on a random free port. You may check whether configuring an appropriate binding address.
</code></pre></div></div>

<blockquote>
  <p>Spark is a fast and general processing engine compatible with Hadoop data. It can run in Hadoop clusters through YARN or Spark’s standalone mode, and it can process data in HDFS, HBase, Cassandra, Hive, and any Hadoop InputFormat. It is designed to perform both batch processing (similar to MapReduce) and new workloads like streaming, interactive queries, and machine learning.</p>
</blockquote>

<p>出现了好几次<code class="language-plaintext highlighter-rouge">hadoop</code>。谷歌了<code class="language-plaintext highlighter-rouge">spark depends hadoop </code>之后，找到这样一段话。看来这依赖于<code class="language-plaintext highlighter-rouge">Hadoop</code>格式的数据。让我们先研究 <code class="language-plaintext highlighter-rouge">Hadoop</code>。</p>

<h2 id="hadoop">Hadoop</h2>

<p>简单看了官网后。来安装一下。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>hadoop
</code></pre></div></div>

<p>安装的过程中，来了解一下。</p>

<blockquote>
  <p>The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures.</p>
</blockquote>

<p>就是说 Hadoop 是一套框架，来处理分布式的数据集。这些数据集可能分部在很多计算机上。用很简单的编程模型来处理。它是设计来从单一服务器扩展到千台机器的。与其依赖于硬件的高可用，这个库则设计来在应用层就能检查和处理错误。因此能将高可用的服务部署到集群中，虽然集群中的每台电脑都可能导致失败。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>hadoop
Error:
  homebrew-core is a shallow clone.
  homebrew-cask is a shallow clone.
To <span class="sb">`</span>brew update<span class="sb">`</span>, first run:
  git <span class="nt">-C</span> /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core fetch <span class="nt">--unshallow</span>
  git <span class="nt">-C</span> /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask fetch <span class="nt">--unshallow</span>
These commands may take a few minutes to run due to the large size of the repositories.
This restriction has been made on GitHub<span class="s1">'s request because updating shallow
clones is an extremely expensive operation due to the tree layout and traffic of
Homebrew/homebrew-core and Homebrew/homebrew-cask. We don'</span>t <span class="k">do </span>this <span class="k">for </span>you
automatically to avoid repeatedly performing an expensive unshallow operation <span class="k">in
</span>CI systems <span class="o">(</span>which should instead be fixed to not use shallow clones<span class="o">)</span><span class="nb">.</span> Sorry <span class="k">for
</span>the inconvenience!
<span class="o">==&gt;</span> Downloading https://homebrew.bintray.com/bottles/openjdk-15.0.1.big_sur.bottle.tar.gz
Already downloaded: /Users/lzw/Library/Caches/Homebrew/downloads/d1e3ece4af1d225bc2607eaa4ce85a873d2c6d43757ae4415d195751bc431962--openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Downloading https://www.apache.org/dyn/closer.lua?path<span class="o">=</span>hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
Already downloaded: /Users/lzw/Library/Caches/Homebrew/downloads/764c6a0ea7352bb8bb505989feee1b36dc628c2dcd6b93fef1ca829d191b4e1e--hadoop-3.3.0.tar.gz
<span class="o">==&gt;</span> Installing dependencies <span class="k">for </span>hadoop: openjdk
<span class="o">==&gt;</span> Installing hadoop dependency: openjdk
<span class="o">==&gt;</span> Pouring openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Caveats
For the system Java wrappers to find this JDK, symlink it with
  <span class="nb">sudo ln</span> <span class="nt">-sfn</span> /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk

openjdk is keg-only, which means it was not symlinked into /usr/local,
because it shadows the macOS <span class="sb">`</span>java<span class="sb">`</span> wrapper.

If you need to have openjdk first <span class="k">in </span>your PATH run:
  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile

For compilers to find openjdk you may need to <span class="nb">set</span>:
  <span class="nb">export </span><span class="nv">CPPFLAGS</span><span class="o">=</span><span class="s2">"-I/usr/local/opt/openjdk/include"</span>

<span class="o">==&gt;</span> Summary
🍺  /usr/local/Cellar/openjdk/15.0.1: 614 files, 324.9MB
<span class="o">==&gt;</span> Installing hadoop
🍺  /usr/local/Cellar/hadoop/3.3.0: 21,819 files, 954.7MB, built <span class="k">in </span>2 minutes 15 seconds
<span class="o">==&gt;</span> Upgrading 1 dependent:
maven 3.3.3 -&gt; 3.6.3_1
<span class="o">==&gt;</span> Upgrading maven 3.3.3 -&gt; 3.6.3_1
<span class="o">==&gt;</span> Downloading https://www.apache.org/dyn/closer.lua?path<span class="o">=</span>maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
<span class="o">==&gt;</span> Downloading from https://mirror.olnevhost.net/pub/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
<span class="c">######################################################################## 100.0%</span>
Error: The <span class="sb">`</span>brew <span class="nb">link</span><span class="sb">`</span> step did not <span class="nb">complete </span>successfully
The formula built, but is not symlinked into /usr/local
Could not symlink bin/mvn
Target /usr/local/bin/mvn
is a symlink belonging to maven. You can <span class="nb">unlink </span>it:
  brew <span class="nb">unlink </span>maven

To force the <span class="nb">link </span>and overwrite all conflicting files:
  brew <span class="nb">link</span> <span class="nt">--overwrite</span> maven

To list all files that would be deleted:
  brew <span class="nb">link</span> <span class="nt">--overwrite</span> <span class="nt">--dry-run</span> maven

Possible conflicting files are:
/usr/local/bin/mvn -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvn
/usr/local/bin/mvnDebug -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnDebug
/usr/local/bin/mvnyjp -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnyjp
<span class="o">==&gt;</span> Summary
🍺  /usr/local/Cellar/maven/3.6.3_1: 87 files, 10.7MB, built <span class="k">in </span>7 seconds
Removing: /usr/local/Cellar/maven/3.3.3... <span class="o">(</span>92 files, 9MB<span class="o">)</span>
<span class="o">==&gt;</span> Checking <span class="k">for </span>dependents of upgraded formulae...
<span class="o">==&gt;</span> No broken dependents found!
<span class="o">==&gt;</span> Caveats
<span class="o">==&gt;</span> openjdk
For the system Java wrappers to find this JDK, symlink it with
  <span class="nb">sudo ln</span> <span class="nt">-sfn</span> /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk

openjdk is keg-only, which means it was not symlinked into /usr/local,
because it shadows the macOS <span class="sb">`</span>java<span class="sb">`</span> wrapper.

If you need to have openjdk first <span class="k">in </span>your PATH run:
  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile

For compilers to find openjdk you may need to <span class="nb">set</span>:
  <span class="nb">export </span><span class="nv">CPPFLAGS</span><span class="o">=</span><span class="s2">"-I/usr/local/opt/openjdk/include"</span>
</code></pre></div></div>

<p>注意到<code class="language-plaintext highlighter-rouge">brew</code>的输出日志中<code class="language-plaintext highlighter-rouge">maven</code>没有很好地被链接。接下来，进行强制链接到<code class="language-plaintext highlighter-rouge">3.6.3_1</code>版本。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  brew <span class="nb">link</span> <span class="nt">--overwrite</span> maven
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Hadoop</code>就安装成功了。</p>

<blockquote>
  <h2 id="modules">Modules</h2>

  <p>The project includes these modules:</p>

  <ul>
    <li><strong>Hadoop Common</strong>: The common utilities that support the other Hadoop modules.</li>
    <li><strong>Hadoop Distributed File System (HDFS™)</strong>: A distributed file system that provides high-throughput access to application data.</li>
    <li><strong>Hadoop YARN</strong>: A framework for job scheduling and cluster resource management.</li>
    <li><strong>Hadoop MapReduce</strong>: A YARN-based system for parallel processing of large data sets.</li>
    <li><strong>Hadoop Ozone</strong>: An object store for Hadoop.</li>
  </ul>
</blockquote>

<p>说有这些模块。这会敲入<code class="language-plaintext highlighter-rouge">hadoop</code>出现了：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hadoop
Usage: hadoop <span class="o">[</span>OPTIONS] SUBCOMMAND <span class="o">[</span>SUBCOMMAND OPTIONS]
 or    hadoop <span class="o">[</span>OPTIONS] CLASSNAME <span class="o">[</span>CLASSNAME OPTIONS]
  where CLASSNAME is a user-provided Java class

  OPTIONS is none or any of:

<span class="nt">--config</span> <span class="nb">dir                     </span>Hadoop config directory
<span class="nt">--debug</span>                          turn on shell script debug mode
<span class="nt">--help</span>                           usage information
buildpaths                       attempt to add class files from build tree
hostnames list[,of,host,names]   hosts to use <span class="k">in </span>slave mode
hosts filename                   list of hosts to use <span class="k">in </span>slave mode
loglevel level                   <span class="nb">set </span>the log4j level <span class="k">for </span>this <span class="nb">command
</span>workers                          turn on worker mode

  SUBCOMMAND is one of:
    Admin Commands:

daemonlog     get/set the log level <span class="k">for </span>each daemon

    Client Commands:

archive       create a Hadoop archive
checknative   check native Hadoop and compression libraries availability
classpath     prints the class path needed to get the Hadoop jar and the required libraries
conftest      validate configuration XML files
credential    interact with credential providers
distch        distributed metadata changer
distcp        copy file or directories recursively
dtutil        operations related to delegation tokens
envvars       display computed Hadoop environment variables
fs            run a generic filesystem user client
gridmix       submit a mix of synthetic job, modeling a profiled from production load
jar &lt;jar&gt;     run a jar file. NOTE: please use <span class="s2">"yarn jar"</span> to launch YARN applications, not this command.
jnipath       prints the java.library.path
kdiag         Diagnose Kerberos Problems
kerbname      show auth_to_local principal conversion
key           manage keys via the KeyProvider
rumenfolder   scale a rumen input trace
rumentrace    convert logs into a rumen trace
s3guard       manage metadata on S3
trace         view and modify Hadoop tracing settings
version       print the version

    Daemon Commands:

kms           run KMS, the Key Management Server
registrydns   run the registry DNS server

SUBCOMMAND may print <span class="nb">help </span>when invoked w/o parameters or with <span class="nt">-h</span><span class="nb">.</span>
</code></pre></div></div>

<p>官网给了些例子。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span><span class="nb">mkdir </span>input
  <span class="nv">$ </span><span class="nb">cp </span>etc/hadoop/<span class="k">*</span>.xml input
  <span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
  <span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
</code></pre></div></div>

<p>注意到有<code class="language-plaintext highlighter-rouge">share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar</code>。这意味着也许有些样例文件我们没有得到。猜测用<code class="language-plaintext highlighter-rouge">Homebrew</code>安装会没有这些文件。我们从官网下载了安装文件包。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
├── LICENSE-binary
├── LICENSE.txt
├── NOTICE-binary
├── NOTICE.txt
├── README.txt
├── bin
├── etc
├── include
├── lib
├── libexec
├── licenses-binary
├── sbin
└── share
</code></pre></div></div>

<p>出现了<code class="language-plaintext highlighter-rouge">share</code>目录。然而<code class="language-plaintext highlighter-rouge">Homebrew</code>真的没有附加的这些文件吗。找到<code class="language-plaintext highlighter-rouge">Homebrew</code>安装的目录。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">type </span>hadoop
hadoop is /usr/local/bin/hadoop
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-alrt</span> /usr/local/bin/hadoop
lrwxr-xr-x  1 lzw  admin  33 Mar 11 00:48 /usr/local/bin/hadoop -&gt; ../Cellar/hadoop/3.3.0/bin/hadoop
<span class="nv">$ </span><span class="nb">cd</span> /usr/local/Cellar/hadoop/3.3.0
</code></pre></div></div>

<p>这是在<code class="language-plaintext highlighter-rouge">/usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop</code>下打印的目录树</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 2
<span class="nb">.</span>
├── client
│   ├── hadoop-client-api-3.3.0.jar
│   ├── hadoop-client-minicluster-3.3.0.jar
│   └── hadoop-client-runtime-3.3.0.jar
├── common
│   ├── hadoop-common-3.3.0-tests.jar
│   ├── hadoop-common-3.3.0.jar
│   ├── hadoop-kms-3.3.0.jar
│   ├── hadoop-nfs-3.3.0.jar
│   ├── hadoop-registry-3.3.0.jar
│   ├── jdiff
│   ├── lib
│   ├── sources
│   └── webapps
├── hdfs
│   ├── hadoop-hdfs-3.3.0-tests.jar
│   ├── hadoop-hdfs-3.3.0.jar
│   ├── hadoop-hdfs-client-3.3.0-tests.jar
│   ├── hadoop-hdfs-client-3.3.0.jar
│   ├── hadoop-hdfs-httpfs-3.3.0.jar
│   ├── hadoop-hdfs-native-client-3.3.0-tests.jar
│   ├── hadoop-hdfs-native-client-3.3.0.jar
│   ├── hadoop-hdfs-nfs-3.3.0.jar
│   ├── hadoop-hdfs-rbf-3.3.0-tests.jar
│   ├── hadoop-hdfs-rbf-3.3.0.jar
│   ├── jdiff
│   ├── lib
│   ├── sources
│   └── webapps
├── mapreduce
│   ├── hadoop-mapreduce-client-app-3.3.0.jar
│   ├── hadoop-mapreduce-client-common-3.3.0.jar
│   ├── hadoop-mapreduce-client-core-3.3.0.jar
│   ├── hadoop-mapreduce-client-hs-3.3.0.jar
│   ├── hadoop-mapreduce-client-hs-plugins-3.3.0.jar
│   ├── hadoop-mapreduce-client-jobclient-3.3.0-tests.jar
│   ├── hadoop-mapreduce-client-jobclient-3.3.0.jar
│   ├── hadoop-mapreduce-client-nativetask-3.3.0.jar
│   ├── hadoop-mapreduce-client-shuffle-3.3.0.jar
│   ├── hadoop-mapreduce-client-uploader-3.3.0.jar
│   ├── hadoop-mapreduce-examples-3.3.0.jar
│   ├── jdiff
│   ├── lib-examples
│   └── sources
├── tools
│   ├── dynamometer
│   ├── lib
│   ├── resourceestimator
│   ├── sls
│   └── sources
└── yarn
    ├── csi
    ├── hadoop-yarn-api-3.3.0.jar
    ├── hadoop-yarn-applications-catalog-webapp-3.3.0.war
    ├── hadoop-yarn-applications-distributedshell-3.3.0.jar
    ├── hadoop-yarn-applications-mawo-core-3.3.0.jar
    ├── hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar
    ├── hadoop-yarn-client-3.3.0.jar
    ├── hadoop-yarn-common-3.3.0.jar
    ├── hadoop-yarn-registry-3.3.0.jar
    ├── hadoop-yarn-server-applicationhistoryservice-3.3.0.jar
    ├── hadoop-yarn-server-common-3.3.0.jar
    ├── hadoop-yarn-server-nodemanager-3.3.0.jar
    ├── hadoop-yarn-server-resourcemanager-3.3.0.jar
    ├── hadoop-yarn-server-router-3.3.0.jar
    ├── hadoop-yarn-server-sharedcachemanager-3.3.0.jar
    ├── hadoop-yarn-server-tests-3.3.0.jar
    ├── hadoop-yarn-server-timeline-pluginstorage-3.3.0.jar
    ├── hadoop-yarn-server-web-proxy-3.3.0.jar
    ├── hadoop-yarn-services-api-3.3.0.jar
    ├── hadoop-yarn-services-core-3.3.0.jar
    ├── lib
    ├── sources
    ├── <span class="nb">test</span>
    ├── timelineservice
    ├── webapps
    └── yarn-service-examples
</code></pre></div></div>

<p>可以看到有很多的<code class="language-plaintext highlighter-rouge">jar</code>包。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>input
<span class="nv">$ </span><span class="nb">ls
</span>bin			hadoop-config.sh	hdfs-config.sh		libexec			sbin			yarn-config.sh
etc			hadoop-functions.sh	input			mapred-config.sh	share
<span class="nv">$ </span><span class="nb">cp </span>etc/hadoop/<span class="k">*</span>.xml input
<span class="nv">$ </span><span class="nb">cd </span>input/
<span class="nv">$ </span><span class="nb">ls
</span>capacity-scheduler.xml	hadoop-policy.xml	hdfs-site.xml		kms-acls.xml		mapred-site.xml
core-site.xml		hdfs-rbf-site.xml	httpfs-site.xml		kms-site.xml		yarn-site.xml
<span class="nv">$ </span><span class="nb">cd</span> ..
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
JAR does not exist or is not a normal file: /usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar
<span class="err">$</span>
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
2021-03-11 01:54:30,791 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="k">for </span>your platform... using builtin-java classes where applicable
2021-03-11 01:54:31,115 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-03-11 01:54:31,232 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second<span class="o">(</span>s<span class="o">)</span><span class="nb">.</span>
...
</code></pre></div></div>

<p>照着官网的例子敲。注意到<code class="language-plaintext highlighter-rouge">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input </code>，这里是的<code class="language-plaintext highlighter-rouge">jar</code>包前有版本号。因此要换成我们的<code class="language-plaintext highlighter-rouge">3.3.0</code>。</p>

<p>日志的最后：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2021-03-11 01:54:35,374 INFO mapreduce.Job:  map 100% reduce 100%
2021-03-11 01:54:35,374 INFO mapreduce.Job: Job job_local2087514596_0002 completed successfully
2021-03-11 01:54:35,377 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes <span class="nb">read</span><span class="o">=</span>1204316
		FILE: Number of bytes <span class="nv">written</span><span class="o">=</span>3565480
		FILE: Number of <span class="nb">read </span><span class="nv">operations</span><span class="o">=</span>0
		FILE: Number of large <span class="nb">read </span><span class="nv">operations</span><span class="o">=</span>0
		FILE: Number of write <span class="nv">operations</span><span class="o">=</span>0
	Map-Reduce Framework
		Map input <span class="nv">records</span><span class="o">=</span>1
		Map output <span class="nv">records</span><span class="o">=</span>1
		Map output <span class="nv">bytes</span><span class="o">=</span>17
		Map output materialized <span class="nv">bytes</span><span class="o">=</span>25
		Input <span class="nb">split </span><span class="nv">bytes</span><span class="o">=</span>141
		Combine input <span class="nv">records</span><span class="o">=</span>0
		Combine output <span class="nv">records</span><span class="o">=</span>0
		Reduce input <span class="nb">groups</span><span class="o">=</span>1
		Reduce shuffle <span class="nv">bytes</span><span class="o">=</span>25
		Reduce input <span class="nv">records</span><span class="o">=</span>1
		Reduce output <span class="nv">records</span><span class="o">=</span>1
		Spilled <span class="nv">Records</span><span class="o">=</span>2
		Shuffled Maps <span class="o">=</span>1
		Failed <span class="nv">Shuffles</span><span class="o">=</span>0
		Merged Map <span class="nv">outputs</span><span class="o">=</span>1
		GC <span class="nb">time </span>elapsed <span class="o">(</span>ms<span class="o">)=</span>57
		Total committed heap usage <span class="o">(</span>bytes<span class="o">)=</span>772800512
	Shuffle Errors
		<span class="nv">BAD_ID</span><span class="o">=</span>0
		<span class="nv">CONNECTION</span><span class="o">=</span>0
		<span class="nv">IO_ERROR</span><span class="o">=</span>0
		<span class="nv">WRONG_LENGTH</span><span class="o">=</span>0
		<span class="nv">WRONG_MAP</span><span class="o">=</span>0
		<span class="nv">WRONG_REDUCE</span><span class="o">=</span>0
	File Input Format Counters
		Bytes <span class="nv">Read</span><span class="o">=</span>123
	File Output Format Counters
		Bytes <span class="nv">Written</span><span class="o">=</span>23
</code></pre></div></div>

<p>继续看看。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>这到底是什么意思呢。不要紧，总之我们把<code class="language-plaintext highlighter-rouge">Hadoop</code>跑起来了。并且运行了第一个单机版的计算例子。</p>

<h2 id="spark">Spark</h2>

<p>回到 Spark 上。看一个例子。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
</code></pre></div></div>

<p>这里出现了<code class="language-plaintext highlighter-rouge">hdfs</code>文件。查阅后，得知可以这样创建<code class="language-plaintext highlighter-rouge">hdfs</code>文件：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-mkdir</span> /test
</code></pre></div></div>

<p>来看看<code class="language-plaintext highlighter-rouge">hdfs</code>命令。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hdfs
Usage: hdfs <span class="o">[</span>OPTIONS] SUBCOMMAND <span class="o">[</span>SUBCOMMAND OPTIONS]

  OPTIONS is none or any of:

<span class="nt">--buildpaths</span>                       attempt to add class files from build tree
<span class="nt">--config</span> <span class="nb">dir                       </span>Hadoop config directory
<span class="nt">--daemon</span> <span class="o">(</span>start|status|stop<span class="o">)</span>       operate on a daemon
<span class="nt">--debug</span>                            turn on shell script debug mode
<span class="nt">--help</span>                             usage information
<span class="nt">--hostnames</span> list[,of,host,names]   hosts to use <span class="k">in </span>worker mode
<span class="nt">--hosts</span> filename                   list of hosts to use <span class="k">in </span>worker mode
<span class="nt">--loglevel</span> level                   <span class="nb">set </span>the log4j level <span class="k">for </span>this <span class="nb">command</span>
<span class="nt">--workers</span>                          turn on worker mode

  SUBCOMMAND is one of:
    Admin Commands:

cacheadmin           configure the HDFS cache
crypto               configure HDFS encryption zones
debug                run a Debug Admin to execute HDFS debug commands
dfsadmin             run a DFS admin client
dfsrouteradmin       manage Router-based federation
ec                   run a HDFS ErasureCoding CLI
fsck                 run a DFS filesystem checking utility
haadmin              run a DFS HA admin client
jmxget               get JMX exported values from NameNode or DataNode.
oev                  apply the offline edits viewer to an edits file
oiv                  apply the offline fsimage viewer to an fsimage
oiv_legacy           apply the offline fsimage viewer to a legacy fsimage
storagepolicies      list/get/set/satisfyStoragePolicy block storage policies

    Client Commands:

classpath            prints the class path needed to get the hadoop jar and the required libraries
dfs                  run a filesystem <span class="nb">command </span>on the file system
envvars              display computed Hadoop environment variables
fetchdt              fetch a delegation token from the NameNode
getconf              get config values from configuration
<span class="nb">groups               </span>get the <span class="nb">groups </span>which <span class="nb">users </span>belong to
lsSnapshottableDir   list all snapshottable <span class="nb">dirs </span>owned by the current user
snapshotDiff         diff two snapshots of a directory or diff the current directory contents with a snapshot
version              print the version

    Daemon Commands:

balancer             run a cluster balancing utility
datanode             run a DFS datanode
dfsrouter            run the DFS router
diskbalancer         Distributes data evenly among disks on a given node
httpfs               run HttpFS server, the HDFS HTTP Gateway
journalnode          run the DFS journalnode
mover                run a utility to move block replicas across storage types
namenode             run the DFS namenode
nfs3                 run an NFS version 3 gateway
portmap              run a portmap service
secondarynamenode    run the DFS secondary namenode
sps                  run external storagepolicysatisfier
zkfc                 run the ZK Failover Controller daemon

SUBCOMMAND may print <span class="nb">help </span>when invoked w/o parameters or with <span class="nt">-h</span><span class="nb">.</span>
</code></pre></div></div>

<p>继续修改代码。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">master</span><span class="p">(</span><span class="s">"local[*]"</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">config</span><span class="p">(</span><span class="s">'spark.driver.bindAddress'</span><span class="p">,</span> <span class="s">'127.0.0.1'</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span>

<span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"a.txt"</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"b.txt"</span><span class="p">)</span>
</code></pre></div></div>

<p>注意到<code class="language-plaintext highlighter-rouge">.config('spark.driver.bindAddress', '127.0.0.1')</code>很重要。否则会报错误<code class="language-plaintext highlighter-rouge">Service 'sparkDriver' could not bind on a random free port. You may check whether configuring an appropriate binding address</code>。</p>

<p>然而，这时又出现了错误。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Caused by: org.apache.spark.api.python.PythonException: Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
  File <span class="s2">"/usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py"</span>, line 473, <span class="k">in </span>main
    raise Exception<span class="o">((</span><span class="s2">"Python in worker has different version %s than that in "</span> +
Exception: Python <span class="k">in </span>worker has different version 3.8 than that <span class="k">in </span>driver 3.9, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.
</code></pre></div></div>

<p>表示运行了不同版本的<code class="language-plaintext highlighter-rouge">Python</code>。</p>

<p>修改<code class="language-plaintext highlighter-rouge">.bash_profile</code>：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
<span class="nv">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
</code></pre></div></div>

<p>然而还是报同样的错。了解一番后，可能是因为<code class="language-plaintext highlighter-rouge">spark</code>运行的时候，没有载入这个环境变量，没有使用终端默认的环境变量。</p>

<p>需要在代码里设置：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Set spark environments
</span><span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYSPARK_PYTHON'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'</span>
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYSPARK_DRIVER_PYTHON'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'</span>
</code></pre></div></div>

<p>这会运行。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python sc.py
21/03/11 02:54:52 WARN NativeCodeLoader: Unable to load native-hadoop library <span class="k">for </span>your platform... using builtin-java classes where applicable
Using Spark<span class="s1">'s default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
PythonRDD[6] at RDD at PythonRDD.scala:53
</span></code></pre></div></div>

<p>这时生成了<code class="language-plaintext highlighter-rouge">b.txt</code>。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── b.txt
│   ├── _SUCCESS
│   ├── part-00000
│   └── part-00001
</code></pre></div></div>

<p>打开一下。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>b.txt/part-00000
<span class="o">(</span><span class="s1">'college'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'two'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'things'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'worked'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'on,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'of'</span>, 8<span class="o">)</span>
<span class="o">(</span><span class="s1">'school,'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'writing'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'programming.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s2">"didn't"</span>, 4<span class="o">)</span>
<span class="o">(</span><span class="s1">'then,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'probably'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'are:'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'short'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'awful.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'They'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'plot,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'just'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'characters'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'them'</span>, 2<span class="o">)</span>
...
</code></pre></div></div>

<p>成功了！这是不是很熟悉。这就像在<code class="language-plaintext highlighter-rouge">Hadoop</code>例子里的。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>这些文件就叫<code class="language-plaintext highlighter-rouge">HDFS</code>。可见这里用<code class="language-plaintext highlighter-rouge">Spark</code>来统计单词。短短几句，很方便的样子。</p>

<h2 id="kubernetes">Kubernetes</h2>

<p>接下来捣鼓一下<code class="language-plaintext highlighter-rouge">Kubernetes</code>，也叫<code class="language-plaintext highlighter-rouge">k8s</code>，中间的8个字母简写为8。它是一套开源系统，来自动化部署、扩增和管理容器程序的。</p>

<p><code class="language-plaintext highlighter-rouge">kubectl</code>命令行工具是用来运行一些命令操作k8s集群。可以用它来部署应用、查看和管理集群资源，来查看日志。</p>

<p>同样可以用Homebrew来安装。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>kubectl 
</code></pre></div></div>

<p>输出日志：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">==&gt;</span> Downloading https://homebrew.bintray.com/bottles/kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Downloading from https://d29vzk4ow07wi7.cloudfront.net/0b4f08bd1d47cb913d7cd4571e3394c6747dfbad7ff114c5589c8396c1085ecf?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Pouring kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Caveats
Bash completion has been installed to:
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Summary
🍺  /usr/local/Cellar/kubernetes-cli/1.20.1: 246 files, 46.1MB
</code></pre></div></div>

<p>装好了。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl
kubectl controls the Kubernetes cluster manager.

 Find more information at: https://kubernetes.io/docs/reference/kubectl/overview/

Basic Commands <span class="o">(</span>Beginner<span class="o">)</span>:
  create        Create a resource from a file or from stdin.
  expose        Take a replication controller, service, deployment or pod and expose it as a new Kubernetes Service
  run           Run a particular image on the cluster
  <span class="nb">set           </span>Set specific features on objects

Basic Commands <span class="o">(</span>Intermediate<span class="o">)</span>:
  explain       Documentation of resources
  get           Display one or many resources
  edit          Edit a resource on the server
  delete        Delete resources by filenames, stdin, resources and names, or by resources and label selector

Deploy Commands:
  rollout       Manage the rollout of a resource
  scale         Set a new size <span class="k">for </span>a Deployment, ReplicaSet or Replication Controller
  autoscale     Auto-scale a Deployment, ReplicaSet, or ReplicationController

Cluster Management Commands:
  certificate   Modify certificate resources.
  cluster-info  Display cluster info
  top           Display Resource <span class="o">(</span>CPU/Memory/Storage<span class="o">)</span> usage.
  cordon        Mark node as unschedulable
  uncordon      Mark node as schedulable
  drain         Drain node <span class="k">in </span>preparation <span class="k">for </span>maintenance
  taint         Update the taints on one or more nodes

Troubleshooting and Debugging Commands:
  describe      Show details of a specific resource or group of resources
  logs          Print the logs <span class="k">for </span>a container <span class="k">in </span>a pod
  attach        Attach to a running container
  <span class="nb">exec          </span>Execute a <span class="nb">command </span><span class="k">in </span>a container
  port-forward  Forward one or more <span class="nb">local </span>ports to a pod
  proxy         Run a proxy to the Kubernetes API server
  <span class="nb">cp            </span>Copy files and directories to and from containers.
  auth          Inspect authorization
  debug         Create debugging sessions <span class="k">for </span>troubleshooting workloads and nodes

Advanced Commands:
  diff          Diff live version against would-be applied version
  apply         Apply a configuration to a resource by filename or stdin
  patch         Update field<span class="o">(</span>s<span class="o">)</span> of a resource
  replace       Replace a resource by filename or stdin
  <span class="nb">wait          </span>Experimental: Wait <span class="k">for </span>a specific condition on one or many resources.
  kustomize     Build a kustomization target from a directory or a remote url.

Settings Commands:
  label         Update the labels on a resource
  annotate      Update the annotations on a resource
  completion    Output shell completion code <span class="k">for </span>the specified shell <span class="o">(</span>bash or zsh<span class="o">)</span>

Other Commands:
  api-resources Print the supported API resources on the server
  api-versions  Print the supported API versions on the server, <span class="k">in </span>the form of <span class="s2">"group/version"</span>
  config        Modify kubeconfig files
  plugin        Provides utilities <span class="k">for </span>interacting with plugins.
  version       Print the client and server version information

Usage:
  kubectl <span class="o">[</span>flags] <span class="o">[</span>options]

Use <span class="s2">"kubectl &lt;command&gt; --help"</span> <span class="k">for </span>more information about a given command.
Use <span class="s2">"kubectl options"</span> <span class="k">for </span>a list of global command-line options <span class="o">(</span>applies to all commands<span class="o">)</span><span class="nb">.</span>
</code></pre></div></div>

<p>来创建一个配置文件。</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">nginx-deployment</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
  <span class="na">minReadySeconds</span><span class="pi">:</span> <span class="m">5</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">nginx:1.14.2</span>
        <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">80</span>

</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> simple_deployment.yaml
The connection to the server localhost:8080 was refused - did you specify the right host or port?
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl cluster-info

To further debug and diagnose cluster problems, use <span class="s1">'kubectl cluster-info dump'</span><span class="nb">.</span>
The connection to the server localhost:8080 was refused - did you specify the right host or port?
</code></pre></div></div>

<p>当用官网的终端试着运行下。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>start.sh
Starting Kubernetes...minikube version: v1.8.1
commit: cbda04cf6bbe65e987ae52bb393c10099ab62014
<span class="k">*</span> minikube v1.8.1 on Ubuntu 18.04
<span class="k">*</span> Using the none driver based on user configuration
<span class="k">*</span> Running on localhost <span class="o">(</span><span class="nv">CPUs</span><span class="o">=</span>2, <span class="nv">Memory</span><span class="o">=</span>2460MB, <span class="nv">Disk</span><span class="o">=</span>145651MB<span class="o">)</span> ...
<span class="k">*</span> OS release is Ubuntu 18.04.4 LTS

<span class="k">*</span> Preparing Kubernetes v1.17.3 on Docker 19.03.6 ...
  - kubelet.resolv-conf<span class="o">=</span>/run/systemd/resolve/resolv.conf
<span class="k">*</span> Launching Kubernetes ... 
<span class="k">*</span> Enabling addons: default-storageclass, storage-provisioner
<span class="k">*</span> Configuring <span class="nb">local </span>host environment ...
<span class="k">*</span> Done! kubectl is now configured to use <span class="s2">"minikube"</span>
<span class="k">*</span> The <span class="s1">'dashboard'</span> addon is enabled
Kubernetes Started
</code></pre></div></div>

<p>继续回到我们的终端。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
<span class="nv">$ </span>kubectl version
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
The connection to the server localhost:8080 was refused - did you specify the right host or port?
</code></pre></div></div>

<p>有意思的是加上<code class="language-plaintext highlighter-rouge">--client</code> 选项并没有报错。</p>

<p>文档说，需要先安装<code class="language-plaintext highlighter-rouge">Minikube</code>。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>minikube
<span class="o">==&gt;</span> Downloading https://homebrew.bintray.com/bottles/minikube-1.16.0.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Downloading from https://d29vzk4ow07wi7.cloudfront.net/1b6d7d1b97b11b6b07e4fa531c2dc21770da290da9b2816f360fd923e00c85fc?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Pouring minikube-1.16.0.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Caveats
Bash completion has been installed to:
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Summary
🍺  /usr/local/Cellar/minikube/1.16.0: 8 files, 64.6MB
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube start
😄  minikube v1.16.0 on Darwin 11.2.2
🎉  minikube 1.18.1 is available! Download it: https://github.com/kubernetes/minikube/releases/tag/v1.18.1
💡  To disable this notice, run: <span class="s1">'minikube config set WantUpdateNotification false'</span>

✨  Automatically selected the virtualbox driver
💿  Downloading VM boot image ...
    <span class="o">&gt;</span> minikube-v1.16.0.iso.sha256: 65 B / 65 B <span class="o">[</span><span class="nt">-------------</span><span class="o">]</span> 100.00% ? p/s 0s
    <span class="o">&gt;</span> minikube-v1.16.0.iso: 212.62 MiB / 212.62 MiB <span class="o">[]</span> 100.00% 5.32 MiB p/s 40s
👍  Starting control plane node minikube <span class="k">in </span>cluster minikube
💾  Downloading Kubernetes v1.20.0 preload ...
    <span class="o">&gt;</span> preloaded-images-k8s-v8-v1....: 491.00 MiB / 491.00 MiB  100.00% 7.52 MiB
🔥  Creating virtualbox VM <span class="o">(</span><span class="nv">CPUs</span><span class="o">=</span>2, <span class="nv">Memory</span><span class="o">=</span>4000MB, <span class="nv">Disk</span><span class="o">=</span>20000MB<span class="o">)</span> ...
❗  This VM is having trouble accessing https://k8s.gcr.io
💡  To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
🐳  Preparing Kubernetes v1.20.0 on Docker 20.10.0 ...
    ▪ Generating certificates and keys ...
    ▪ Booting up control plane ...
    ▪ Configuring RBAC rules ...
🔎  Verifying Kubernetes components...
🌟  Enabled addons: storage-provisioner, default-storageclass
🏄  Done! kubectl is now configured to use <span class="s2">"minikube"</span> cluster and <span class="s2">"default"</span> namespace by default
</code></pre></div></div>

<p>接着来访问这个集群。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get po <span class="nt">-A</span>
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
kube-system   coredns-74ff55c5b-ndbcr            1/1     Running   0          60s
kube-system   etcd-minikube                      0/1     Running   0          74s
kube-system   kube-apiserver-minikube            1/1     Running   0          74s
kube-system   kube-controller-manager-minikube   1/1     Running   0          74s
kube-system   kube-proxy-g2296                   1/1     Running   0          60s
kube-system   kube-scheduler-minikube            0/1     Running   0          74s
kube-system   storage-provisioner                1/1     Running   1          74s
</code></pre></div></div>

<p>来打开<code class="language-plaintext highlighter-rouge">minikube</code>的控制板。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube dashboard
🔌  Enabling dashboard ...
🤔  Verifying dashboard health ...
🚀  Launching proxy ...
🤔  Verifying proxy health ...
🎉  Opening http://127.0.0.1:50030/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ <span class="k">in </span>your default browser...
</code></pre></div></div>

<p><img src="assets/images/distributed/k8s.png" alt="k8s" /></p>

<p>如何关掉呢。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube
minikube provisions and manages <span class="nb">local </span>Kubernetes clusters optimized <span class="k">for </span>development workflows.

Basic Commands:
  start          Starts a <span class="nb">local </span>Kubernetes cluster
  status         Gets the status of a <span class="nb">local </span>Kubernetes cluster
  stop           Stops a running <span class="nb">local </span>Kubernetes cluster
  delete         Deletes a <span class="nb">local </span>Kubernetes cluster
  dashboard      Access the Kubernetes dashboard running within the minikube cluster
  pause          pause Kubernetes
  unpause        unpause Kubernetes

Images Commands:
  docker-env     Configure environment to use minikube<span class="s1">'s Docker daemon
  podman-env     Configure environment to use minikube'</span>s Podman service
  cache          Add, delete, or push a <span class="nb">local </span>image into minikube

Configuration and Management Commands:
  addons         Enable or disable a minikube addon
  config         Modify persistent configuration values
  profile        Get or list the current profiles <span class="o">(</span>clusters<span class="o">)</span>
  update-context Update kubeconfig <span class="k">in case</span> of an IP or port change

Networking and Connectivity Commands:
  service        Returns a URL to connect to a service
  tunnel         Connect to LoadBalancer services

Advanced Commands:
  mount          Mounts the specified directory into minikube
  ssh            Log into the minikube environment <span class="o">(</span><span class="k">for </span>debugging<span class="p">)</span>
  kubectl        Run a kubectl binary matching the cluster version
  node           Add, remove, or list additional nodes

Troubleshooting Commands:
  ssh-key        Retrieve the ssh identity key path of the specified node
  ssh-host       Retrieve the ssh host key of the specified node
  ip             Retrieves the IP address of the specified node
  logs           Returns logs to debug a <span class="nb">local </span>Kubernetes cluster
  update-check   Print current and latest version number
  version        Print the version of minikube

Other Commands:
  completion     Generate <span class="nb">command </span>completion <span class="k">for </span>a shell

Use <span class="s2">"minikube &lt;command&gt; --help"</span> <span class="k">for </span>more information about a given command.
</code></pre></div></div>

<p>可见是<code class="language-plaintext highlighter-rouge">minikube stop</code>。</p>

<p>回到<code class="language-plaintext highlighter-rouge">kuberntes</code>，现在工作正常了。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl cluster-info
Kubernetes control plane is running at https://192.168.99.100:8443
KubeDNS is running at https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use <span class="s1">'kubectl cluster-info dump'</span><span class="nb">.</span>
</code></pre></div></div>

<p>当我们打开<code class="language-plaintext highlighter-rouge">https://192.168.99.100:8443</code>时，浏览器显示：</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Status"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"apiVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Failure"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">"forbidden: User </span><span class="se">\"</span><span class="s2">system:anonymous</span><span class="se">\"</span><span class="s2"> cannot get path </span><span class="se">\"</span><span class="s2">/</span><span class="se">\"</span><span class="s2">"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"reason"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Forbidden"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"details"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"code"</span><span class="p">:</span><span class="w"> </span><span class="mi">403</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>访问<code class="language-plaintext highlighter-rouge">https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</code>：</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Status"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"apiVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Failure"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">"services </span><span class="se">\"</span><span class="s2">kube-dns:dns</span><span class="se">\"</span><span class="s2"> is forbidden: User </span><span class="se">\"</span><span class="s2">system:anonymous</span><span class="se">\"</span><span class="s2"> cannot get resource </span><span class="se">\"</span><span class="s2">services/proxy</span><span class="se">\"</span><span class="s2"> in API group </span><span class="se">\"\"</span><span class="s2"> in the namespace </span><span class="se">\"</span><span class="s2">kube-system</span><span class="se">\"</span><span class="s2">"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"reason"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Forbidden"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"details"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-dns:dns"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"services"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"code"</span><span class="p">:</span><span class="w"> </span><span class="mi">403</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>来试试刚刚那个配置。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> simple_deployment.yaml
deployment.apps/nginx-deployment created
</code></pre></div></div>

<p>有点问题。然而到这里，我们已经把<code class="language-plaintext highlighter-rouge">kubernetes</code>跑起来了。先结束掉。后续再玩。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube stop
✋  Stopping node <span class="s2">"minikube"</span>  ...
🛑  1 nodes stopped.
</code></pre></div></div>

<p>检查是否结束。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>w<span class="nv">$ </span>minikube dashboard
🤷  The control plane node must be running <span class="k">for </span>this <span class="nb">command</span>
👉  To start a cluster, run: <span class="s2">"minikube start"</span>
</code></pre></div></div>

<h2 id="docker">Docker</h2>

<p><code class="language-plaintext highlighter-rouge">Docker</code>也是一种容器平台，来帮助加速创建、分享、运行现代应用。从官网下载应用。</p>

<p><img src="assets/images/distributed/docker.png" alt="docker" /></p>

<p>用客户端有点卡。让我们用命令行。</p>

<div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker

Usage:  docker [OPTIONS] COMMAND

A self-sufficient runtime for containers

Options:
      --config string      Location of client config files (default "/Users/lzw/.docker")
  -c, --context string     Name of the context to use to connect to the daemon (overrides DOCKER_HOST env var and default context set with "docker
                           context use")
  -D, --debug              Enable debug mode
  -H, --host list          Daemon socket(s) to connect to
  -l, --log-level string   Set the logging level ("debug"|"info"|"warn"|"error"|"fatal") (default "info")
      --tls                Use TLS; implied by --tlsverify
      --tlscacert string   Trust certs signed only by this CA (default "/Users/lzw/.docker/ca.pem")
      --tlscert string     Path to TLS certificate file (default "/Users/lzw/.docker/cert.pem")
      --tlskey string      Path to TLS key file (default "/Users/lzw/.docker/key.pem")
      --tlsverify          Use TLS and verify the remote
  -v, --version            Print version information and quit

Management Commands:
  app*        Docker App (Docker Inc., v0.9.1-beta3)
  builder     Manage builds
  buildx*     Build with BuildKit (Docker Inc., v0.5.1-docker)
  config      Manage Docker configs
  container   Manage containers
  context     Manage contexts
  image       Manage images
  manifest    Manage Docker image manifests and manifest lists
  network     Manage networks
  node        Manage Swarm nodes
  plugin      Manage plugins
  scan*       Docker Scan (Docker Inc., v0.5.0)
  secret      Manage Docker secrets
  service     Manage services
  stack       Manage Docker stacks
  swarm       Manage Swarm
  system      Manage Docker
  trust       Manage trust on Docker images
  volume      Manage volumes

Commands:
  attach      Attach local standard input, output, and error streams to a running container
  build       Build an image from a Dockerfile
  commit      Create a new image from a container's changes
  cp          Copy files/folders between a container and the local filesystem
  create      Create a new container
  diff        Inspect changes to files or directories on a container's filesystem
  events      Get real time events from the server
  exec        Run a command in a running container
  export      Export a container's filesystem as a tar archive
  history     Show the history of an image
  images      List images
  import      Import the contents from a tarball to create a filesystem image
  info        Display system-wide information
  inspect     Return low-level information on Docker objects
  kill        Kill one or more running containers
  load        Load an image from a tar archive or STDIN
  login       Log in to a Docker registry
  logout      Log out from a Docker registry
  logs        Fetch the logs of a container
  pause       Pause all processes within one or more containers
  port        List port mappings or a specific mapping for the container
  ps          List containers
  pull        Pull an image or a repository from a registry
  push        Push an image or a repository to a registry
  rename      Rename a container
  restart     Restart one or more containers
  rm          Remove one or more containers
  rmi         Remove one or more images
  run         Run a command in a new container
  save        Save one or more images to a tar archive (streamed to STDOUT by default)
  search      Search the Docker Hub for images
  start       Start one or more stopped containers
  stats       Display a live stream of container(s) resource usage statistics
  stop        Stop one or more running containers
  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE
  top         Display the running processes of a container
  unpause     Unpause all processes within one or more containers
  update      Update configuration of one or more containers
  version     Show the Docker version information
  wait        Block until one or more containers stop, then print their exit codes

<span class="k">Run </span><span class="s1">'docker COMMAND --help'</span> <span class="k">for </span>more information on a command.

To get more help with docker, check out our guides at https://docs.docker.com/go/guides/
</code></pre></div></div>

<p>照着教程试试。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 80:80 docker/getting-started
Unable to find image <span class="s1">'docker/getting-started:latest'</span> locally
latest: Pulling from docker/getting-started
aad63a933944: Pull <span class="nb">complete
</span>b14da7a62044: Pull <span class="nb">complete
</span>343784d40d66: Pull <span class="nb">complete
</span>6f617e610986: Pull <span class="nb">complete
</span>Digest: sha256:d2c4fb0641519ea208f20ab03dc40ec2a5a53fdfbccca90bef14f870158ed577
Status: Downloaded newer image <span class="k">for </span>docker/getting-started:latest
815f13fc8f99f6185257980f74c349e182842ca572fe60ff62cbb15641199eaf
docker: Error response from daemon: Ports are not available: listen tcp 0.0.0.0:80: <span class="nb">bind</span>: address already <span class="k">in </span>use.
</code></pre></div></div>

<p>改个端口。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:80 docker/getting-started
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p><img src="assets/images/distributed/docker_run.png" alt="docker_run" /></p>

<p>打开浏览器，说明我们把<code class="language-plaintext highlighter-rouge">docker</code>运行起来了。</p>

<p><img src="assets/images/distributed/browser.png" alt="browser" /></p>

<p>停掉容器。用上刚刚返回的<code class="language-plaintext highlighter-rouge">ID</code>。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker stop 45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p>这时已经打不开网址了。</p>

<p>这说明<code class="language-plaintext highlighter-rouge">docker</code>像是虚拟机。</p>

<h2 id="flink">Flink</h2>

<p>打开官网。</p>

<p><img src="assets/images/distributed/flink-home-graphic.png" alt="flink-home-graphic" /></p>

<p><code class="language-plaintext highlighter-rouge">Flink</code>是说数据流的<code class="language-plaintext highlighter-rouge">Stateful</code>计算。<code class="language-plaintext highlighter-rouge">Stateful</code>指的是什么？暂时还不明白。上面这个图还是很有趣的。来试试看。</p>

<p>说是需要Java环境。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>java <span class="nt">-version</span>
java version <span class="s2">"1.8.0_151"</span>
Java<span class="o">(</span>TM<span class="o">)</span> SE Runtime Environment <span class="o">(</span>build 1.8.0_151-b12<span class="o">)</span>
Java HotSpot<span class="o">(</span>TM<span class="o">)</span> 64-Bit Server VM <span class="o">(</span>build 25.151-b12, mixed mode<span class="o">)</span>
</code></pre></div></div>

<p>从官网下载最新版本 <code class="language-plaintext highlighter-rouge">flink-1.12.2-bin-scala_2.11.tar</code>。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/start-cluster.sh
Starting cluster.
Starting standalonesession daemon on host lzwjava.
Starting taskexecutor daemon on host lzwjava.
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/flink run examples/streaming/WordCount.jar
Executing WordCount example with default input data set.
Use <span class="nt">--input</span> to specify file input.
Printing result to stdout. Use <span class="nt">--output</span> to specify output path.
Job has been submitted with JobID 60f37647c20c2a6654359bd34edab807
Program execution finished
Job with JobID 60f37647c20c2a6654359bd34edab807 has finished.
Job Runtime: 757 ms
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">tail </span>log/flink-<span class="k">*</span><span class="nt">-taskexecutor-</span><span class="k">*</span>.out
<span class="o">(</span>nymph,1<span class="o">)</span>
<span class="o">(</span><span class="k">in</span>,3<span class="o">)</span>
<span class="o">(</span>thy,1<span class="o">)</span>
<span class="o">(</span>orisons,1<span class="o">)</span>
<span class="o">(</span>be,4<span class="o">)</span>
<span class="o">(</span>all,2<span class="o">)</span>
<span class="o">(</span>my,1<span class="o">)</span>
<span class="o">(</span>sins,1<span class="o">)</span>
<span class="o">(</span>remember,1<span class="o">)</span>
<span class="o">(</span>d,4<span class="o">)</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/stop-cluster.sh
Stopping taskexecutor daemon <span class="o">(</span>pid: 41812<span class="o">)</span> on host lzwjava.
</code></pre></div></div>

<p>嗯，上手成功。可见这跟<code class="language-plaintext highlighter-rouge">Spark</code>很像。</p>

<h2 id="kylin">Kylin</h2>

<p>来打开官网。</p>

<blockquote>
  <p>Apache Kylin™ is an open source, distributed Analytical Data Warehouse for Big Data; it was designed to provide OLAP (Online Analytical Processing) capability in the big data era. By renovating the multi-dimensional cube and precalculation technology on Hadoop and Spark, Kylin is able to achieve near constant query speed regardless of the ever-growing data volume. Reducing query latency from minutes to sub-second, Kylin brings online analytics back to big data.</p>
</blockquote>

<blockquote>
  <p>Apache Kylin™ lets you query billions of rows at sub-second latency in 3 steps.</p>

  <ol>
    <li>Identify a Star/Snowflake Schema on Hadoop.</li>
    <li>Build Cube from the identified tables.</li>
    <li>Query using ANSI-SQL and get results in sub-second, via ODBC, JDBC or RESTful API.</li>
  </ol>
</blockquote>

<p><img src="assets/images/distributed/kylin_diagram.png" alt="kylin_diagram" /></p>

<p>大概就是分析大数据的一层。用它可以查得非常快。作为桥梁。</p>

<p>可惜当前只能在<code class="language-plaintext highlighter-rouge">Linux</code>环境下使用。回头再来折腾。</p>

<h2 id="mongodb">MongoDB</h2>

<p>这也是一种数据库。试试安装。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew tap mongodb/brew
<span class="o">==&gt;</span> Tapping mongodb/brew
Cloning into <span class="s1">'/usr/local/Homebrew/Library/Taps/mongodb/homebrew-brew'</span>...
remote: Enumerating objects: 63, <span class="k">done</span><span class="nb">.</span>
remote: Counting objects: 100% <span class="o">(</span>63/63<span class="o">)</span>, <span class="k">done</span><span class="nb">.</span>
remote: Compressing objects: 100% <span class="o">(</span>62/62<span class="o">)</span>, <span class="k">done</span><span class="nb">.</span>
remote: Total 566 <span class="o">(</span>delta 21<span class="o">)</span>, reused 6 <span class="o">(</span>delta 1<span class="o">)</span>, pack-reused 503
Receiving objects: 100% <span class="o">(</span>566/566<span class="o">)</span>, 121.78 KiB | 335.00 KiB/s, <span class="k">done</span><span class="nb">.</span>
Resolving deltas: 100% <span class="o">(</span>259/259<span class="o">)</span>, <span class="k">done</span><span class="nb">.</span>
Tapped 11 formulae <span class="o">(</span>39 files, 196.2KB<span class="o">)</span><span class="nb">.</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>mongodb-community@4.4
<span class="o">==&gt;</span> Installing mongodb-community from mongodb/brew
<span class="o">==&gt;</span> Downloading https://fastdl.mongodb.org/tools/db/mongodb-database-tools-macos-x86_64-100.3.0.zip
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Downloading https://fastdl.mongodb.org/osx/mongodb-macos-x86_64-4.4.3.tgz
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Installing dependencies <span class="k">for </span>mongodb/brew/mongodb-community: mongodb-database-tools
<span class="o">==&gt;</span> Installing mongodb/brew/mongodb-community dependency: mongodb-database-tools
Error: The <span class="sb">`</span>brew <span class="nb">link</span><span class="sb">`</span> step did not <span class="nb">complete </span>successfully
The formula built, but is not symlinked into /usr/local
Could not symlink bin/bsondump
Target /usr/local/bin/bsondump
is a symlink belonging to mongodb. You can <span class="nb">unlink </span>it:
  brew <span class="nb">unlink </span>mongodb

To force the <span class="nb">link </span>and overwrite all conflicting files:
  brew <span class="nb">link</span> <span class="nt">--overwrite</span> mongodb-database-tools

To list all files that would be deleted:
  brew <span class="nb">link</span> <span class="nt">--overwrite</span> <span class="nt">--dry-run</span> mongodb-database-tools

Possible conflicting files are:
/usr/local/bin/bsondump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/bsondump
/usr/local/bin/mongodump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongodump
/usr/local/bin/mongoexport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoexport
/usr/local/bin/mongofiles -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongofiles
/usr/local/bin/mongoimport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoimport
/usr/local/bin/mongorestore -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongorestore
/usr/local/bin/mongostat -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongostat
/usr/local/bin/mongotop -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongotop
<span class="o">==&gt;</span> Summary
🍺  /usr/local/Cellar/mongodb-database-tools/100.3.0: 13 files, 154MB, built <span class="k">in </span>11 seconds
<span class="o">==&gt;</span> Installing mongodb/brew/mongodb-community
Error: The <span class="sb">`</span>brew <span class="nb">link</span><span class="sb">`</span> step did not <span class="nb">complete </span>successfully
The formula built, but is not symlinked into /usr/local
Could not symlink bin/mongo
Target /usr/local/bin/mongo
is a symlink belonging to mongodb. You can <span class="nb">unlink </span>it:
  brew <span class="nb">unlink </span>mongodb

To force the <span class="nb">link </span>and overwrite all conflicting files:
  brew <span class="nb">link</span> <span class="nt">--overwrite</span> mongodb-community

To list all files that would be deleted:
  brew <span class="nb">link</span> <span class="nt">--overwrite</span> <span class="nt">--dry-run</span> mongodb-community

Possible conflicting files are:
/usr/local/bin/mongo -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongo
/usr/local/bin/mongod -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongod
/usr/local/bin/mongos -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongos
<span class="o">==&gt;</span> Caveats
To have launchd start mongodb/brew/mongodb-community now and restart at login:
  brew services start mongodb/brew/mongodb-community
Or, <span class="k">if </span>you don<span class="s1">'t want/need a background service you can just run:
  mongod --config /usr/local/etc/mongod.conf
==&gt; Summary
🍺  /usr/local/Cellar/mongodb-community/4.4.3: 11 files, 156.8MB, built in 10 seconds
==&gt; Caveats
==&gt; mongodb-community
To have launchd start mongodb/brew/mongodb-community now and restart at login:
  brew services start mongodb/brew/mongodb-community
Or, if you don'</span>t want/need a background service you can just run:
  mongod <span class="nt">--config</span> /usr/local/etc/mongod.conf
</code></pre></div></div>

<p>之前我安装一个旧版本的。解除一下链接。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">unlink </span>mongodb
Unlinking /usr/local/Cellar/mongodb/3.0.7... 11 symlinks removed
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--version</span>
db version v4.4.3
Build Info: <span class="o">{</span>
    <span class="s2">"version"</span>: <span class="s2">"4.4.3"</span>,
    <span class="s2">"gitVersion"</span>: <span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span>,
    <span class="s2">"modules"</span>: <span class="o">[]</span>,
    <span class="s2">"allocator"</span>: <span class="s2">"system"</span>,
    <span class="s2">"environment"</span>: <span class="o">{</span>
        <span class="s2">"distarch"</span>: <span class="s2">"x86_64"</span>,
        <span class="s2">"target_arch"</span>: <span class="s2">"x86_64"</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>接着运行<code class="language-plaintext highlighter-rouge">mongod</code>启动mongo数据库服务器。然而第一次启动时说<code class="language-plaintext highlighter-rouge">/data/db</code>不存在。我们创建一个目录，<code class="language-plaintext highlighter-rouge">~/mongodb</code> ，这里来保存数据库文件。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--dbpath</span> ~/mongodb
</code></pre></div></div>

<p>输出为：</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.838+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23285</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"W"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"ASIO"</span><span class="p">,</span><span class="w">     </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">22601</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"No TransportLayer configured during NetworkInterface startup"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"NETWORK"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4648602</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Implicit TCP FastOpen in use."</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"STORAGE"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4615611</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"MongoDB starting"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"pid"</span><span class="p">:</span><span class="mi">46256</span><span class="p">,</span><span class="nl">"port"</span><span class="p">:</span><span class="mi">27017</span><span class="p">,</span><span class="nl">"dbPath"</span><span class="p">:</span><span class="s2">"/Users/lzw/mongodb"</span><span class="p">,</span><span class="nl">"architecture"</span><span class="p">:</span><span class="s2">"64-bit"</span><span class="p">,</span><span class="nl">"host"</span><span class="p">:</span><span class="s2">"lzwjava"</span><span class="p">}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23403</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Build Info"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"buildInfo"</span><span class="p">:{</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"4.4.3"</span><span class="p">,</span><span class="nl">"gitVersion"</span><span class="p">:</span><span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span><span class="p">,</span><span class="nl">"modules"</span><span class="p">:[],</span><span class="nl">"allocator"</span><span class="p">:</span><span class="s2">"system"</span><span class="p">,</span><span class="nl">"environment"</span><span class="p">:{</span><span class="nl">"distarch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">,</span><span class="nl">"target_arch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">}}}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.843+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">51765</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Operating System"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"os"</span><span class="p">:{</span><span class="nl">"name"</span><span class="p">:</span><span class="s2">"Mac OS X"</span><span class="p">,</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"20.3.0"</span><span class="p">}}}</span><span class="w">
</span><span class="err">...</span><span class="w">
</span></code></pre></div></div>

<p>可见都是<code class="language-plaintext highlighter-rouge">JSON</code>格式。MongoDB就是一切数据文件都是用<code class="language-plaintext highlighter-rouge">JSON</code>格式来保存的。接着，打开另外一个终端标签。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongo
MongoDB shell version v4.4.3
connecting to: mongodb://127.0.0.1:27017/?compressors<span class="o">=</span>disabled&amp;gssapiServiceName<span class="o">=</span>mongodb
Implicit session: session <span class="o">{</span> <span class="s2">"id"</span> : UUID<span class="o">(</span><span class="s2">"4f55c561-70d3-4289-938d-4b90a284891f"</span><span class="o">)</span> <span class="o">}</span>
MongoDB server version: 4.4.3
<span class="nt">---</span>
The server generated these startup warnings when booting:
        2021-03-11T18:17:33.743+08:00: Access control is not enabled <span class="k">for </span>the database. Read and write access to data and configuration is unrestricted
        2021-03-11T18:17:33.743+08:00: This server is bound to localhost. Remote systems will be unable to connect to this server. Start the server with <span class="nt">--bind_ip</span> &lt;address&gt; to specify which IP addresses it should serve responses from, or with <span class="nt">--bind_ip_all</span> to <span class="nb">bind </span>to all interfaces. If this behavior is desired, start the server with <span class="nt">--bind_ip</span> 127.0.0.1 to disable this warning
        2021-03-11T18:17:33.743+08:00: Soft rlimits too low
        2021-03-11T18:17:33.743+08:00:         currentValue: 4864
        2021-03-11T18:17:33.743+08:00:         recommendedMinimum: 64000
<span class="nt">---</span>
<span class="nt">---</span>
        Enable MongoDB<span class="s1">'s free cloud-based monitoring service, which will then receive and display
        metrics about your deployment (disk utilization, CPU, operation statistics, etc).

        The monitoring data will be available on a MongoDB website with a unique URL accessible to you
        and anyone you share the URL with. MongoDB may use this information to make product
        improvements and to suggest MongoDB products and deployment options to you.

        To enable free monitoring, run the following command: db.enableFreeMonitoring()
        To permanently disable this reminder, run the following command: db.disableFreeMonitoring()
</span></code></pre></div></div>

<p>接着可以尝试插入数据、查询数据。</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> db.inventory.insertOne<span class="o">(</span>
...    <span class="o">{</span> item: <span class="s2">"canvas"</span>, qty: 100, tags: <span class="o">[</span><span class="s2">"cotton"</span><span class="o">]</span>, size: <span class="o">{</span> h: 28, w: 35.5, uom: <span class="s2">"cm"</span> <span class="o">}</span> <span class="o">}</span>
... <span class="o">)</span>
<span class="o">{</span>
	<span class="s2">"acknowledged"</span> : <span class="nb">true</span>,
	<span class="s2">"insertedId"</span> : ObjectId<span class="o">(</span><span class="s2">"6049ef91b653541cf355facb"</span><span class="o">)</span>
<span class="o">}</span>
<span class="o">&gt;</span>
<span class="o">&gt;</span> db.inventory.find<span class="o">()</span>
<span class="o">{</span> <span class="s2">"_id"</span> : ObjectId<span class="o">(</span><span class="s2">"6049ef91b653541cf355facb"</span><span class="o">)</span>, <span class="s2">"item"</span> : <span class="s2">"canvas"</span>, <span class="s2">"qty"</span> : 100, <span class="s2">"tags"</span> : <span class="o">[</span> <span class="s2">"cotton"</span> <span class="o">]</span>, <span class="s2">"size"</span> : <span class="o">{</span> <span class="s2">"h"</span> : 28, <span class="s2">"w"</span> : 35.5, <span class="s2">"uom"</span> : <span class="s2">"cm"</span> <span class="o">}</span> <span class="o">}</span>
</code></pre></div></div>

<h2 id="最后">最后</h2>

<p>先到这儿。后面我们再上手别的工具。我们做这些意义是什么。大概是先有个脉络。万事开头难，而我们一上来就把这些全部折腾一遍。这给了我们信心，接下来，就是更多折腾这些软件了。</p>

<h2 id="练习">练习</h2>

<ul>
  <li>学生像上面一样类似探索一遍。</li>
</ul>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-zh" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
