<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Costos de LLM, Agentes y Herramientas de Codificación</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Costos de LLM, Agentes y Herramientas de Codificación | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Costos de LLM, Agentes y Herramientas de Codificación" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="es" />
<meta name="description" content="Índice" />
<meta property="og:description" content="Índice" />
<link rel="canonical" href="https://lzwjava.github.io/llm-es" />
<meta property="og:url" content="https://lzwjava.github.io/llm-es" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-18T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Costos de LLM, Agentes y Herramientas de Codificación" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2025-08-18T00:00:00+08:00","datePublished":"2025-08-18T00:00:00+08:00","description":"Índice","headline":"Costos de LLM, Agentes y Herramientas de Codificación","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/llm-es"},"url":"https://lzwjava.github.io/llm-es"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=723f9d846fdfc30288c9b260a52561574f5c672d">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=723f9d846fdfc30288c9b260a52561574f5c672d" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Costos de LLM, Agentes y Herramientas de Codificación | Original, traducido por IA
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/es/2025-08-18-llm-es.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postses2025-08-18-llm-es.md</span> -->
      

      <!-- <span>2025-08-18-llm-es.md</span> -->

      
        

        
          
          <a href="#" class="button">2025.08</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/llm-en" >English</option>
        <option value="/llm-zh" >中文</option>
        <option value="/llm-ja" >日本語</option>
        <option value="/llm-es" selected>Español</option>
        <option value="/llm-hi" >हिंदी</option>
        <option value="/llm-fr" >Français</option>
        <option value="/llm-de" >Deutsch</option>
        <option value="/llm-ar" >العربية</option>
        <option value="/llm-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <h3 id="índice">Índice</h3>

<ol>
  <li><strong><a href="#optimización-de-costos-de-api-de-llm">Optimización de costos de API de LLM</a></strong>
    <ul>
      <li>Comienza con modelos rentables primero</li>
      <li>Evita el uso innecesario de modelos avanzados</li>
      <li>Prefiere bibliotecas NLP para tareas simples</li>
      <li>Construye agentes especializados para eficiencia</li>
      <li>Compara modelos mediante pruebas extensivas</li>
    </ul>
  </li>
  <li><strong><a href="#uso-de-api-de-deepseek-y-mistral">Uso de API de Deepseek y Mistral</a></strong>
    <ul>
      <li>Los costos de DeepSeek escalan con fallos de caché</li>
      <li>Los tokens de salida dominan los gastos de Mistral</li>
      <li>El precio de Grok favorece mucho los tokens de entrada</li>
      <li>El uso de tokens varía según la complejidad de la tarea</li>
      <li>Los precios se alinean con las tarifas documentadas</li>
    </ul>
  </li>
  <li><strong><a href="#agentes-generales-vs-agentes-verticales">Agentes generales vs agentes verticales</a></strong>
    <ul>
      <li>Los agentes generales luchan con la complejidad</li>
      <li>Los agentes verticales sobresalen en especialización</li>
      <li>Las herramientas de flujo de trabajo limitan la flexibilidad</li>
      <li>Los agentes personalizados en Python ofrecen control</li>
      <li>Compromisos entre conveniencia y potencia</li>
    </ul>
  </li>
  <li><strong><a href="#la-opinión-de-un-ingeniero-exigente-sobre-herramientas-de-ia-para-codificación">La opinión de un ingeniero exigente sobre herramientas de IA para codificación</a></strong>
    <ul>
      <li>Prefiero utilidad práctica sobre el hype de marca</li>
      <li>VSCode + Copilot sigue siendo confiable</li>
      <li>Claude Code impresiona con ediciones estilo diff</li>
      <li>Las herramientas de gramática requieren verificación manual</li>
      <li>La experimentación supera la adopción ciega</li>
    </ul>
  </li>
</ol>

<h2 id="optimización-de-costos-de-api-de-llm">Optimización de costos de API de LLM</h2>

<p><em>2025.08</em></p>

<p class="centered"><img src="assets/images/tokens/tokens1.png" alt="" class="responsive" />
<em class="caption">Fuente: openrouter.ai</em></p>

<p class="centered"><img src="assets/images/tokens/tokens2.png" alt="" class="responsive" />
<em class="caption">Fuente: openrouter.ai</em></p>

<p>Al optimizar el uso de tokens, es recomendable comenzar con modelos más rentables. Si surgen problemas, considera actualizar a modelos más avanzados. Mistral, Gemini Flash y DeepSeek suelen ser económicos, mientras que Claude Sonnet generalmente es más costoso. Es crucial entender cómo Claude Code utiliza los enrutadores mostrados a continuación.</p>

<p>En mi experiencia reciente, incurrí en costos significativos por descuidar este principio. Intentaba alcanzar mi uso máximo para determinar el costo, lo cual no es un enfoque racional; es un cálculo simple. Por ejemplo, ¿realmente necesito Sonnet 4? No necesariamente. Aunque lo percibo como un modelo más avanzado de Anthropic y tiene una alta clasificación en OpenRouter, no tengo claro las diferencias entre Sonnet 4 y Sonnet 3.5.</p>

<p>Aprendí algo valioso de una <a href="https://www.vanta.com/resources/replit-future-of-code">entrevista reciente</a> con el fundador de Replit, Amjad Masad. Para muchas tareas, los modelos altamente avanzados no son necesarios. Idealmente, si podemos evitar usar la API de LLM por completo, sería perfecto. Ciertas bibliotecas NLP son efectivas para tareas más simples; por ejemplo, <a href="https://github.com/hankcs/HanLP">HanLP</a> sobresale en tareas de idioma chino.</p>

<p>Además, podemos desarrollar agentes personalizados o especializados para manejar tareas de manera eficiente desde el principio. Claude Code puede no ser siempre la mejor o más rentable solución para cada tarea.</p>

<p>Una forma de discernir las diferencias entre modelos es usarlos extensamente y comparar su desempeño. Después de algún tiempo usando Gemini 2.5 Flash, encuentro que es menos capaz que Sonnet 4.</p>

<p>Después de unos días, uso la configuración a continuación para ayudar. El parámetro longContextThreshold es realmente importante. Puedes limpiar periódicamente la consola de Claude Code o reiniciarla. Es muy fácil alcanzar el umbral de contexto largo cuando usas Claude Code para escribir código.</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"PROXY_URL"</span><span class="p">:</span><span class="w"> </span><span class="s2">"http://127.0.0.1:7890"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"LOG"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w">
  </span><span class="nl">"Providers"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"openrouter"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"api_base_url"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://openrouter.ai/api/v1/chat/completions"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"api_key"</span><span class="p">:</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w">
      </span><span class="nl">"models"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="s2">"moonshotai/kimi-k2"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"anthropic/claude-sonnet-4"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"anthropic/claude-3.5-sonnet"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"anthropic/claude-3.7-sonnet:thinking"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"anthropic/claude-opus-4"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"google/gemini-2.5-flash"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"google/gemini-2.5-pro"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"deepseek/deepseek-chat-v3-0324"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"deepseek/deepseek-chat-v3.1"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"deepseek/deepseek-r1"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"mistralai/mistral-medium-3.1"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"qwen/qwen3-coder"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"openai/gpt-oss-120b"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"openai/gpt-5"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"openai/gpt-5-mini"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"x-ai/grok-3-mini"</span><span class="w">
      </span><span class="p">],</span><span class="w">
      </span><span class="nl">"transformer"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"use"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
          </span><span class="s2">"openrouter"</span><span class="w">
        </span><span class="p">]</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">],</span><span class="w">
  </span><span class="nl">"Router"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"default"</span><span class="p">:</span><span class="w"> </span><span class="s2">"openrouter,openai/gpt-5-mini"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"background"</span><span class="p">:</span><span class="w"> </span><span class="s2">"openrouter,google/gemini-2.5-flash"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"think"</span><span class="p">:</span><span class="w"> </span><span class="s2">"openrouter,qwen/qwen3-coder"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"longContext"</span><span class="p">:</span><span class="w"> </span><span class="s2">"openrouter,deepseek/deepseek-chat-v3.1"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"longContextThreshold"</span><span class="p">:</span><span class="w"> </span><span class="mi">2000</span><span class="p">,</span><span class="w">
    </span><span class="nl">"webSearch"</span><span class="p">:</span><span class="w"> </span><span class="s2">"openrouter,mistralai/mistral-medium-3.1"</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<hr />

<h2 id="agentes-generales-vs-agentes-verticales">Agentes generales vs agentes verticales</h2>

<p><em>2025.08</em></p>

<p><a href="https://manus.im">Manus</a> afirma ser una herramienta de agente de IA general, pero probablemente no funcione tan bien.</p>

<p>Una razón es que es muy lento, haciendo mucho trabajo innecesario y siendo ineficiente. Otra razón es que si encuentra un problema complejo o golpea un punto débil, es probable que fallen en su tarea.</p>

<p>Los agentes verticales funcionan genial porque están altamente especializados. Están diseñados para tareas muy específicas. Hay docenas de bases de datos y más de cien marcos de desarrollo web como Spring. También hay numerosos marcos web, como Vue o React.</p>

<p><a href="https://dify.ai">Dify</a> se enfoca en usar IA para conectar flujos de trabajo, empleando un método de arrastrar y conectar para definir flujos de trabajo de IA. Necesitan hacer mucho para conectar información, datos y plataformas.</p>

<p>He construido algunos agentes simples también, como un agente de refactorización de código Python, un agente de corrección gramatical, un agente de corrección de errores y un agente de fusión de ensayos.</p>

<p>El código es muy flexible. Entonces, Dify solo cubre una pequeña porción del espacio de ideas posibles.</p>

<p>Manus realiza tareas y muestra a los usuarios cómo funciona usando un método VNC para mostrar una computadora.</p>

<p>Creo que el futuro se asentará en estos dos enfoques.</p>

<p>Para Manus, necesitas subir código o texto para realizar tareas, lo cual no es conveniente. Con Dify, necesitas construir flujos de trabajo usando arrastrar y soltar, similar a MIT Scratch.</p>

<p>¿Por qué Scratch no es tan popular como Python? Porque con Python puedes hacer muchas cosas, mientras que Scratch está limitado a programas simples con fines educativos.</p>

<p>Dify probablemente tiene limitaciones similares.</p>

<p>Manus puede manejar muchas tareas simples. Sin embargo, para algunas tareas, especialmente aquellas que golpean las debilidades de Manus, fallará.</p>

<p>Además, muchos programas o servicios llevan tiempo configurar. En el enfoque de Manus, este proceso es lento.</p>

<p>Como programador, uso IA con Python para construir mis agentes verticales. Este es el enfoque más simple para mí. También puedo configurar mensajes y contextos para asegurar una salida relativamente estable de las APIs de LLM.</p>

<p>Manus y Dify también están construidos con estas APIs de LLM. Su ventaja es que ya tienen muchas herramientas o código listo para usar.</p>

<p>Si quiero construir un agente bot para Twitter, usar Dify puede ser más conveniente que construirlo yo mismo con tecnologías de código abierto.</p>

<hr />

<h2 id="la-opinión-de-un-ingeniero-exigente-sobre-herramientas-de-ia-para-codificación">La opinión de un ingeniero exigente sobre herramientas de IA para codificación</h2>

<p><em>2025.08</em></p>

<p>Recientemente, ejecuté Claude Code con éxito, así que quiero compartir mi viaje de selección de herramientas. También he recopilado algunos <a href="ai-tips-en.md">Consejos de herramientas de IA</a> en el camino.</p>

<p>Fui bastante tardío en adoptar Claude Code.</p>

<p><a href="https://www.anthropic.com/news/claude-3-5-sonnet">Claude Code</a> fue lanzado alrededor de finales de febrero de 2025.</p>

<p>No logré probarlo con éxito hasta hace poco. Una razón es que requiere la API de Anthropic, que no admite tarjetas Visa chinas.</p>

<p>Otra razón es que <a href="https://github.com/musistudio/claude-code-router">Claude Code Router</a> estuvo disponible, lo que hizo que mi intento reciente tuviera éxito.</p>

<p>Sigo escuchando elogios al respecto. Probé la CLI de Gemini en julio de 2025 pero la abandoné después de varios intentos fallidos de hacer que corrigiera mi código.</p>

<p>También probé Aider, otro agente de software. Dejé de usar Cursor después de unos seis meses porque muchos de sus complementos basados en VSCode fallaban. Además, no quiero darle mucho crédito a Cursor ya que está construido sobre VSCode. Como el complemento Copilot en VSCode ha mejorado recientemente y no se queda muy atrás, prefiero usarlo más a menudo.</p>

<p>Sin embargo, VSCode está construido sobre Electron, una tecnología de código abierto. Es difícil atribuir el crédito al equipo o individuo correcto. Considerando que muchas empresas grandes y startups obtienen ganancias de proyectos de código abierto, debo enfocarme en mi presupuesto y lo que mejor me convenga. No debería preocuparme demasiado por dar crédito. Prefiero usar herramientas asequibles y efectivas.</p>

<p>Brevemente experimenté con Cline pero no lo adopté.</p>

<p>Uso el complemento Copilot en VSCode con un modelo personalizado, Grok 3 beta a través de OpenRouter, que funciona bien.</p>

<p>No creo que Claude Code cambie mis hábitos, pero como puedo ejecutarlo con éxito y tengo la paciencia para probarlo algunas veces más, veré cómo me siento en las próximas semanas.</p>

<p>Soy un usuario exigente con 10 años de experiencia en ingeniería de software. Espero que las herramientas sean geniales en el uso real. No me interesa la marca, solo me importa la utilidad diaria.</p>

<p>Después de usar Claude Code para corregir la gramática de esta publicación, encontré que funciona bien en ciertos escenarios. Aunque aprecio la IA para asistencia gramatical (incluso escribí un script en Python para llamar a las APIs de LLM para este propósito), he notado un patrón frustrante: incluso cuando solicito correcciones mínimas, las herramientas siguen mostrando numerosas sugerencias gramaticales para revisión. Este proceso de verificación manual frustra el propósito de la automatización. Como compromiso, ahora permito que la IA maneje ensayos completos, aunque este enfoque limita mis oportunidades de aprendizaje ya que no veo las correcciones específicas que se están haciendo.</p>

<p>Lo que más me impresionó fue cómo Claude Code muestra los cambios: mostrando comparaciones de antes y después similares a los diffs de git, lo que hace que revisar las ediciones sea mucho más fácil.</p>

<p>Después de un día, usé Claude para corregir algún código también. Sin embargo, sigo usando el complemento Copilot con el modelo Grok 3 beta, ya que es simple y fácil para mí.</p>

<p>Después de usar Claude Code durante varios días, tengo que decir que es muy impresionante. Realmente me gusta cómo corrige mi código.</p>

<p class="centered"><img src="assets/images/claude/claude-code.jpg" alt="" class="responsive" />
<em class="caption">Fuente: Captura propia</em></p>

<p class="centered"><img src="assets/images/claude/claude-fix.jpg" alt="" class="responsive" />
<em class="caption">Fuente: Captura propia</em></p>

<p class="centered"><img src="assets/images/claude/vscode-fix.jpg" alt="" class="responsive" />
<em class="caption">Fuente: Captura propia</em></p>

<hr />

<h2 id="uso-de-api-de-deepseek-y-mistral">Uso de API de Deepseek y Mistral</h2>

<p><em>2025.01.25</em></p>

<h3 id="deepseek">DeepSeek</h3>

<p>En un mes, 15 millones de tokens me costaron aproximadamente 23.5 CNY.</p>

<p>Este fue mi uso en un día:</p>

<table>
  <thead>
    <tr>
      <th>Tipo</th>
      <th>Tokens</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Entrada (Acierto de caché)</td>
      <td>946,816</td>
    </tr>
    <tr>
      <td>Entrada (Fallo de caché)</td>
      <td>2,753,752</td>
    </tr>
    <tr>
      <td>Salida</td>
      <td>3,100,977</td>
    </tr>
  </tbody>
</table>

<p>El cálculo es el siguiente:</p>

<p>0.94 * 0.1 + 2.75 * 1 + 3.10 * 2 = 11.83</p>

<p>Entonces, dependiendo de la tarea, el uso de tokens depende en gran medida de la entrada (fallo de caché) y la salida.</p>

<p>Este resultado se alinea con el costo esperado.</p>

<p><a href="https://api-docs.deepseek.com/quick_start/pricing/">Precios de API de DeepSeek</a></p>

<p class="centered"><img src="assets/images/deepseek/d.jpg" alt="" />
<em class="caption">Fuente: Captura propia</em></p>

<h3 id="mistral">Mistral</h3>

<p>Los precios para los modelos de Mistral son los siguientes:</p>

<table>
  <thead>
    <tr>
      <th>Modelo</th>
      <th>Entrada (USD por millón de tokens)</th>
      <th>Salida (USD por millón de tokens)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">mistral-large-2411</code></td>
      <td>2</td>
      <td>6</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">mistral-small-latest</code></td>
      <td>0.2</td>
      <td>0.6</td>
    </tr>
  </tbody>
</table>

<p>En un día, el uso de mi cuenta Mistral fue el siguiente (Modelo: <code class="language-plaintext highlighter-rouge">mistral-large-2411</code>):</p>

<table>
  <thead>
    <tr>
      <th>Tipo</th>
      <th>Tokens</th>
      <th>Costo (USD)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Total</td>
      <td>772,284</td>
      <td>3.44</td>
    </tr>
    <tr>
      <td>Salida</td>
      <td>474,855</td>
      <td>2.85</td>
    </tr>
    <tr>
      <td>Entrada</td>
      <td>297,429</td>
      <td>0.59</td>
    </tr>
  </tbody>
</table>

<p>Para el modelo <code class="language-plaintext highlighter-rouge">mistral-small-2409</code>, el uso total fue de 1,022,407 tokens.</p>

<p>Suponiendo que 1/3 fueron tokens de entrada y 2/3 fueron tokens de salida:</p>

<p>Hubo 340,802 tokens de entrada y 681,605 tokens de salida.</p>

<p>Por lo tanto, el costo total se calcula como 340,802 * 0.2 / 1,000,000 + 681,605 * 0.6 / 1,000,000 = 0.07 + 0.41 = 0.48 USD.</p>

<p>La consola de Mistral reporta un costo total de uso de 0.43 USD, que coincide aproximadamente con nuestro cálculo.</p>

<h3 id="grok">Grok</h3>

<table>
  <thead>
    <tr>
      <th>Modelo</th>
      <th>Entrada (USD por millón de tokens)</th>
      <th>Salida (USD por millón de tokens)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">grok-2-latest</code></td>
      <td>2</td>
      <td>10</td>
    </tr>
  </tbody>
</table>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-es" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
