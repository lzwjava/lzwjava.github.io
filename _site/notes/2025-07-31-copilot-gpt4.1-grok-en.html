<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Configuring Copilot for Custom Models</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Configuring Copilot for Custom Models | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Configuring Copilot for Custom Models" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="en" />
<meta name="description" content="李智维" />
<meta property="og:description" content="李智维" />
<link rel="canonical" href="https://lzwjava.github.io/notes/2025-07-31-copilot-gpt4.1-grok-en" />
<meta property="og:url" content="https://lzwjava.github.io/notes/2025-07-31-copilot-gpt4.1-grok-en" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Configuring Copilot for Custom Models" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Zhiwei Li"},"description":"李智维","headline":"Configuring Copilot for Custom Models","url":"https://lzwjava.github.io/notes/2025-07-31-copilot-gpt4.1-grok-en"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=94e4cd8209ac787dd4e04306e0b2d884f4b33237">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=94e4cd8209ac787dd4e04306e0b2d884f4b33237" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Configuring Copilot for Custom Models | Generated by AI
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="notes/2025-07-31-copilot-gpt4.1-grok-en.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>notes2025-07-31-copilot-gpt4.1-grok-en.md</span> -->
      

      <!-- <span></span> -->

      
        <a href="#" class="button">2025.10</a>
      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/copilot-gpt4.1-grok-en" selected>English</option>
        <option value="/copilot-gpt4.1-grok-zh" >中文</option>
        <option value="/copilot-gpt4.1-grok-ja" >日本語</option>
        <option value="/copilot-gpt4.1-grok-es" >Español</option>
        <option value="/copilot-gpt4.1-grok-hi" >हिंदी</option>
        <option value="/copilot-gpt4.1-grok-fr" >Français</option>
        <option value="/copilot-gpt4.1-grok-de" >Deutsch</option>
        <option value="/copilot-gpt4.1-grok-ar" >العربية</option>
        <option value="/copilot-gpt4.1-grok-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>When you select “managed models” in GitHub Copilot and still see GPT-4.1 as the default, or can’t use Grok or Kimi models from OpenRouter as expected, there are a few potential reasons and steps to address this. Here’s a breakdown of the issue and how to configure Copilot to use Grok or Kimi models via OpenRouter:</p>

<h3 id="why-gpt-41-is-still-used">Why GPT-4.1 Is Still Used</h3>
<ol>
  <li><strong>Default Model Setting</strong>: GitHub Copilot defaults to GPT-4.1 for Copilot Chat, Edits, and Agent Mode unless explicitly changed. Even when you select “managed models,” the default model may persist if you haven’t fully configured OpenRouter integration or selected a specific model.<a href="https://github.blog/changelog/2025-05-08-openai-gpt-4-1-is-now-generally-available-in-github-copilot-as-the-new-default-model/"></a></li>
  <li><strong>Context-Specific Model Usage</strong>: The “fix box” (inline chat or code completion) in Copilot might not support switching to custom models like Grok or Kimi in certain contexts. For example, the Copilot Chat panel or inline suggestions might use the default model (GPT-4.1) unless you explicitly switch to a custom model in the immersive view or Agent Mode.<a href="https://docs.github.com/en/copilot/how-tos/use-ai-models/change-the-chat-model"></a></li>
  <li><strong>OpenRouter Integration Limitations</strong>: OpenRouter allows access to models like Grok (created by xAI) and Kimi (from Moonshot AI), but Copilot’s integration with OpenRouter requires a specific setup, and not all models may be immediately available due to API limitations or configuration issues. For instance, OpenRouter’s API may not announce tool support for all models, which can prevent Agent Mode or certain features from working with Grok or Kimi.<a href="https://bas.codes/posts/how-to-use-third-party-models-in-copilot-agent-mode/"></a><a href="https://dev.to/bascodes/agent-mode-with-third-party-models-in-copilot-317k"></a></li>
  <li><strong>Subscription or Configuration Restrictions</strong>: If you’re using a free tier or a non-Pro/Business Copilot subscription, you might be limited to default models like GPT-4.1. Additionally, some models (e.g., Grok or Kimi) may require specific configurations or premium access through OpenRouter.<a href="https://www.reddit.com/r/LocalLLaMA/comments/1jslnxb/github_copilot_now_supports_ollama_and_openrouter/"></a><a href="https://github.com/microsoft/vscode-copilot-release/issues/10193"></a></li>
</ol>

<h3 id="how-to-use-grok-or-kimi-models-in-copilot-via-openrouter">How to Use Grok or Kimi Models in Copilot via OpenRouter</h3>
<p>To use Grok or Kimi models from OpenRouter in Copilot, particularly for the “fix box” (inline chat or code completion), follow these steps:</p>

<ol>
  <li><strong>Set Up OpenRouter with Copilot</strong>:
    <ul>
      <li><strong>Get an OpenRouter API Key</strong>: Sign up at <a href="https://openrouter.ai">openrouter.ai</a> and obtain an API key. Ensure you have credits or a plan that supports access to Grok (xAI) and Kimi (Moonshot AI K2) models.<a href="https://openrouter.ai/models"></a><a href="https://openrouter.ai"></a></li>
      <li><strong>Configure OpenRouter in VS Code</strong>:
        <ul>
          <li>Open Visual Studio Code (VS Code) and ensure the latest GitHub Copilot extension is installed (v1.100.2 or later).<a href="https://github.com/microsoft/vscode-copilot-release/issues/10193"></a></li>
          <li>Go to the Copilot dashboard in the Status Bar, or open the Command Palette (<code class="language-plaintext highlighter-rouge">Ctrl+Shift+P</code> or <code class="language-plaintext highlighter-rouge">Command+Shift+P</code> on Mac) and type <code class="language-plaintext highlighter-rouge">GitHub Copilot: Manage Models</code>.</li>
          <li>Add your OpenRouter API key and configure the endpoint to include OpenRouter models. You may need to follow OpenRouter’s documentation for integrating with VS Code’s Copilot extension.<a href="https://www.reddit.com/r/LocalLLaMA/comments/1jslnxb/github_copilot_now_supports_ollama_and_openrouter/"></a></li>
        </ul>
      </li>
      <li><strong>Verify Model Availability</strong>: After adding the OpenRouter endpoint, check the “Manage Models” section in Copilot. Models like <code class="language-plaintext highlighter-rouge">openrouter/xai/grok</code> or <code class="language-plaintext highlighter-rouge">openrouter/moonshotai/kimi-k2</code> should appear in the model picker. If they don’t, ensure your OpenRouter account has access to these models and that there are no restrictions (e.g., free tier limitations).<a href="https://github.com/microsoft/vscode-copilot-release/issues/10193"></a></li>
    </ul>
  </li>
  <li><strong>Switch Models for the Fix Box</strong>:
    <ul>
      <li><strong>For Inline Chat (Fix Box)</strong>: The “fix box” likely refers to Copilot’s inline chat or code completion feature. To change the model for inline chat:
        <ul>
          <li>Open the Copilot Chat interface in VS Code (via the icon in the title bar or sidebar).</li>
          <li>In the chat view, select the <code class="language-plaintext highlighter-rouge">CURRENT-MODEL</code> dropdown menu (usually in the bottom right) and choose <code class="language-plaintext highlighter-rouge">openrouter/xai/grok</code> or <code class="language-plaintext highlighter-rouge">openrouter/moonshotai/kimi-k2</code> if available.<a href="https://docs.github.com/en/copilot/how-tos/use-ai-models/change-the-chat-model"></a></li>
          <li>If the dropdown doesn’t show Grok or Kimi, it might be due to OpenRouter’s API not announcing tool support for these models, which can limit their use in certain Copilot features like Agent Mode or inline fixes.<a href="https://bas.codes/posts/how-to-use-third-party-models-in-copilot-agent-mode/"></a><a href="https://dev.to/bascodes/agent-mode-with-third-party-models-in-copilot-317k"></a></li>
        </ul>
      </li>
      <li><strong>For Code Completion</strong>: To change the model for code completions (not just chat):
        <ul>
          <li>Open the Command Palette (<code class="language-plaintext highlighter-rouge">Ctrl+Shift+P</code> or <code class="language-plaintext highlighter-rouge">Command+Shift+P</code>) and type <code class="language-plaintext highlighter-rouge">GitHub Copilot: Change Completions Model</code>.</li>
          <li>Select the desired OpenRouter model (e.g., Grok or Kimi) from the list. Note that not all OpenRouter models may support code completion due to VS Code’s current limitation of supporting only Ollama endpoints for custom models, though OpenRouter can work with a proxy workaround.<a href="https://docs.github.com/en/copilot/how-tos/use-ai-models/change-the-completion-model"></a><a href="https://dev.to/bascodes/agent-mode-with-third-party-models-in-copilot-317k"></a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Workaround for OpenRouter Models</strong>:
    <ul>
      <li><strong>Proxy Solution</strong>: Since OpenRouter’s API doesn’t always announce tool support (required for Agent Mode or advanced features), you can use a proxy like <code class="language-plaintext highlighter-rouge">litellm</code> to enable Grok or Kimi in Copilot. Edit the <code class="language-plaintext highlighter-rouge">config.yaml</code> file to include:
```yaml
model_list:
        <ul>
          <li>model_name: grok
litellm_params:
  model: openrouter/xai/grok</li>
          <li>model_name: kimi-k2
litellm_params:
  model: openrouter/moonshotai/kimi-k2
```</li>
          <li>Follow the setup instructions from sources like <a href="https://bas.codes">Bas codes</a> or <a href="https://dev.to">DEV Community</a> for detailed steps on configuring the proxy.<a href="https://bas.codes/posts/how-to-use-third-party-models-in-copilot-agent-mode/"></a><a href="https://dev.to/bascodes/agent-mode-with-third-party-models-in-copilot-317k"></a></li>
        </ul>
      </li>
      <li><strong>Restart VS Code</strong>: After configuring the proxy, restart VS Code to ensure the new models are available in the model picker.</li>
    </ul>
  </li>
  <li><strong>Check Subscription and Permissions</strong>:
    <ul>
      <li><strong>Copilot Subscription</strong>: Ensure you have a Copilot Pro or Business subscription, as free-tier users may not have the option to add custom models.<a href="https://www.reddit.com/r/LocalLLaMA/comments/1jslnxb/github_copilot_now_supports_ollama_and_openrouter/"></a></li>
      <li><strong>Business Restrictions</strong>: If you’re using a Copilot Business subscription, your organization must enable model switching. Check with your admin or refer to GitHub’s documentation on managing Copilot policies.<a href="https://docs.github.com/en/copilot/how-tos/use-ai-models/change-the-chat-model"></a></li>
      <li><strong>OpenRouter Credits</strong>: Verify that your OpenRouter account has sufficient credits to access premium models like Grok or Kimi, as these may consume more credits than others.<a href="https://www.reddit.com/r/GithubCopilot/comments/1la87wr/why_are_gh_copilot_pro_models_so_much_worse_than/"></a></li>
    </ul>
  </li>
  <li><strong>Troubleshooting the Fix Box</strong>:
    <ul>
      <li>If the fix box still uses GPT-4.1, it could be because the inline chat feature is locked to the default model in certain contexts (e.g., non-immersive view). Try switching to the immersive view of Copilot Chat (<code class="language-plaintext highlighter-rouge">https://github.com/copilot</code>) to select Grok or Kimi explicitly.<a href="https://docs.github.com/en/copilot/how-tos/use-ai-models/change-the-chat-model"></a></li>
      <li>If Grok or Kimi don’t appear in the model picker, double-check the OpenRouter integration in <code class="language-plaintext highlighter-rouge">Manage Models</code>. You may need to refresh the model list or re-add the OpenRouter API key.<a href="https://github.com/microsoft/vscode-copilot-release/issues/10193"></a></li>
      <li>If the issue persists, test the models in Copilot’s Agent Mode or chat interface first to confirm they’re working, then try applying them to inline fixes.</li>
    </ul>
  </li>
  <li><strong>Alternative Tools</strong>:
    <ul>
      <li>If OpenRouter integration with Copilot remains problematic, consider using Grok directly via <a href="https://grok.com">grok.com</a> or the Grok iOS/Android apps, which offer free access with usage quotas. Kimi models can also be tested via OpenRouter’s chat interface to ensure they’re accessible.<a href="https://openrouter.ai"></a></li>
      <li>For a more seamless experience, you might explore other IDEs or tools like Cursor, which has been noted to work well with OpenRouter’s Kimi K2 model.<a href="https://openrouter.ai"></a></li>
    </ul>
  </li>
</ol>

<h3 id="additional-notes">Additional Notes</h3>
<ul>
  <li><strong>Model Performance</strong>: Grok is optimized for reasoning and truth-seeking, making it suitable for complex debugging or architectural tasks, while Kimi (K2) may excel in specific coding scenarios. Test both to see which performs better for your use case.<a href="https://github.blog/ai-and-ml/github-copilot/which-ai-model-should-i-use-with-github-copilot/"></a></li>
  <li><strong>Community Feedback</strong>: Some users report issues with OpenRouter models not appearing in Copilot’s model picker, especially with free-tier accounts. This might require a paid OpenRouter plan or Copilot Pro subscription to resolve.<a href="https://github.com/microsoft/vscode-copilot-release/issues/10193"></a><a href="https://www.reddit.com/r/GithubCopilot/comments/1la87wr/why_are_gh_copilot_pro_models_so_much_worse_than/"></a></li>
  <li><strong>Ongoing Limitations</strong>: There’s an open discussion about enabling custom API endpoints directly in Copilot (see <a href="https://github.com/microsoft/vscode-copilot-release/issues/7518">microsoft/vscode-copilot-release#7518</a>). Until this is implemented, the proxy workaround is the most reliable method for using Grok or Kimi.<a href="https://bas.codes/posts/how-to-use-third-party-models-in-copilot-agent-mode/"></a><a href="https://dev.to/bascodes/agent-mode-with-third-party-models-in-copilot-317k"></a></li>
</ul>

<h3 id="citations">Citations</h3>
<ul>
  <li><a href="https://docs.github.com/en/copilot/managing-copilot/changing-the-ai-model-for-copilot-chat">Changing the AI model for Copilot Chat - GitHub Docs</a><a href="https://docs.github.com/en/copilot/how-tos/use-ai-models/change-the-chat-model"></a></li>
  <li><a href="https://bas.codes">How to Use Third Party Models in GitHub Copilot Agent Mode - Bas codes</a><a href="https://bas.codes/posts/how-to-use-third-party-models-in-copilot-agent-mode/"></a></li>
  <li><a href="https://openrouter.ai">Openrouter - openrouter.ai</a><a href="https://openrouter.ai/models"></a></li>
  <li><a href="https://dev.to">Agent Mode With Third-Party Models in Copilot - DEV Community</a><a href="https://dev.to/bascodes/agent-mode-with-third-party-models-in-copilot-317k"></a></li>
  <li><a href="https://openrouter.ai">Openrouter - openrouter.ai</a><a href="https://openrouter.ai"></a></li>
  <li><a href="https://www.reddit.com">r/LocalLLaMA on Reddit: Github Copilot now supports Ollama and OpenRouter Models</a><a href="https://www.reddit.com/r/LocalLLaMA/comments/1jslnxb/github_copilot_now_supports_ollama_and_openrouter/"></a></li>
  <li><a href="https://github.blog">Which AI model should I use with GitHub Copilot? - The GitHub Blog</a><a href="https://github.blog/ai-and-ml/github-copilot/which-ai-model-should-i-use-with-github-copilot/"></a></li>
  <li><a href="https://github.blog">OpenAI GPT-4.1 is now generally available in GitHub Copilot - GitHub Changelog</a><a href="https://github.blog/changelog/2025-05-08-openai-gpt-4-1-is-now-generally-available-in-github-copilot-as-the-new-default-model/"></a></li>
  <li><a href="https://github.com/microsoft/vscode-copilot-release/issues/10193">OpenRouter (free) Models Missing from Manage Models - GitHub Issues</a><a href="https://github.com/microsoft/vscode-copilot-release/issues/10193"></a></li>
</ul>

<p>If you encounter specific errors or need further assistance with the setup, please provide more details (e.g., error messages, VS Code version, or subscription type), and I can tailor the solution further!</p>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-en" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
