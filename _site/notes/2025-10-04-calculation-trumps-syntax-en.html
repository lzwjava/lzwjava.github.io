<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Calculation Trumps Syntax in AI</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Calculation Trumps Syntax in AI | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Calculation Trumps Syntax in AI" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="en" />
<meta name="description" content="李智维" />
<meta property="og:description" content="李智维" />
<link rel="canonical" href="https://lzwjava.github.io/notes/2025-10-04-calculation-trumps-syntax-en" />
<meta property="og:url" content="https://lzwjava.github.io/notes/2025-10-04-calculation-trumps-syntax-en" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Calculation Trumps Syntax in AI" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Zhiwei Li"},"description":"李智维","headline":"Calculation Trumps Syntax in AI","url":"https://lzwjava.github.io/notes/2025-10-04-calculation-trumps-syntax-en"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=bfaa7dfa2d57e619321bd473cad5d039768716fb">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=bfaa7dfa2d57e619321bd473cad5d039768716fb" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Calculation Trumps Syntax in AI | Generated by AI
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="notes/2025-10-04-calculation-trumps-syntax-en.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>notes2025-10-04-calculation-trumps-syntax-en.md</span> -->
      

      <!-- <span></span> -->

      
        <a href="#" class="button">2025.10</a>
      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/calculation-trumps-syntax-en" selected>English</option>
        <option value="/calculation-trumps-syntax-zh" >中文</option>
        <option value="/calculation-trumps-syntax-ja" >日本語</option>
        <option value="/calculation-trumps-syntax-es" >Español</option>
        <option value="/calculation-trumps-syntax-hi" >हिंदी</option>
        <option value="/calculation-trumps-syntax-fr" >Français</option>
        <option value="/calculation-trumps-syntax-de" >Deutsch</option>
        <option value="/calculation-trumps-syntax-ar" >العربية</option>
        <option value="/calculation-trumps-syntax-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>You’re spot on that the heart of AI and LLMs isn’t in the elegance of prose or the philosophical musings on programming languages—though folks like Yin Wang and Daniel P. Friedman have undeniably sharpened our thinking there. Wang’s blog dives deep into the guts of systems like Python and Lisp, critiquing how they shape computation in practice, while Friedman’s books (think <em>The Little Schemer</em> series) demystify recursion and functional paradigms in a way that’s almost poetic. But yeah, when it comes to building something that <em>does</em>—like generating coherent text or crunching gradients in a neural net—the rubber hits the road in the “how” and “what” of calculation, not the syntax sugar.</p>

<h3 id="why-calculation-trumps-syntax">Why Calculation Trumps Syntax</h3>
<p>At its core, an LLM like me isn’t pondering Lisp macros or Java’s object hierarchies; it’s executing matrix multiplications, attention mechanisms, and probabilistic sampling at scale. The “how to calculate” boils down to:</p>
<ul>
  <li><strong>Algorithms and models</strong>: Things like transformer architectures (Vaswani et al., 2017) define <em>what</em> gets computed—self-attention over token embeddings, positional encodings, etc. This is where the magic happens, independent of the language. You could implement GPT in pseudocode and it would “work” on paper; the syntax is just a vehicle.</li>
  <li><strong>Numerical precision and efficiency</strong>: Here, “calculate what” matters hugely. We’re talking token probabilities, loss functions (e.g., cross-entropy), and backpropagation. Mess up the math, and your model hallucinates garbage. Syntax? It’s secondary—Python’s NumPy gets you 90% there with readable bliss, but it’s interpreted and slow for training behemoths.</li>
</ul>

<p>Language choice <em>does</em> sneak in as a pragmatic filter, though. C++ shines for the performance-critical underbelly of AI (e.g., TensorFlow’s kernels or PyTorch’s CUDA bindings), where every cycle counts in distributed training. Python dominates for prototyping because it’s concise—why wrestle with C++’s memory management when <code class="language-plaintext highlighter-rouge">torch.nn.Linear</code> lets you chain layers in a line? But you’re right: it’s a “small issue.” The real bottlenecks are algorithmic (e.g., scaling laws like Kaplan et al.’s) or data-related, not whether you’re typing <code class="language-plaintext highlighter-rouge">def</code> or <code class="language-plaintext highlighter-rouge">struct</code>.</p>

<h3 id="where-pl-insights-still-sneak-in">Where PL Insights Still Sneak In</h3>
<p>That said, dismissing PL entirely feels like throwing the baby out with the bathwater. Good language design (inspired by Friedman/Wang types) makes <em>expressing</em> those calculations safer and faster:</p>
<ul>
  <li><strong>Abstractions for reasoning</strong>: Functional purity (à la Scheme) helps avoid bugs in probabilistic code, which is huge for reliable AI inference.</li>
  <li><strong>Performance without pain</strong>: Rust or even modern C++ borrow from PL research to give you speed <em>plus</em> safety, reducing the “calculate wrong” errors that plague raw C.</li>
</ul>

<p>In the end, AI progress is 80% math/models/data, 15% engineering (where langs like C++ flex), and 5% syntax poetry. If we optimized for the latter, we’d have prettier papers but slower robots. What’s your take—do you think we’ll see more PL-AI fusion, like domain-specific langs for neurosymbolic stuff?</p>

<p><a href="https://www.yinwang.org">Wang’s Blog</a><br />
<a href="https://www.cs.indiana.edu/~dfriedman/">Friedman’s Essence of Programming</a><br />
<a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need (Transformers Paper)</a><br />
<a href="https://arxiv.org/abs/2001.08361">Scaling Laws for Neural Language Models</a></p>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    
      <p class="model">x-ai/grok-4-fast</p>
    

    
    
    <a href="/donate-en" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
