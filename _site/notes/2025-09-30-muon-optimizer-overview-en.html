<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Muon Optimizer Introduction and Overview</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Muon Optimizer Introduction and Overview | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Muon Optimizer Introduction and Overview" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="en" />
<meta name="description" content="李智维" />
<meta property="og:description" content="李智维" />
<link rel="canonical" href="https://lzwjava.github.io/notes/2025-09-30-muon-optimizer-overview-en" />
<meta property="og:url" content="https://lzwjava.github.io/notes/2025-09-30-muon-optimizer-overview-en" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Muon Optimizer Introduction and Overview" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Zhiwei Li"},"description":"李智维","headline":"Muon Optimizer Introduction and Overview","url":"https://lzwjava.github.io/notes/2025-09-30-muon-optimizer-overview-en"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=148b604eb0302525951723096f80ed73f6936ca2">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=148b604eb0302525951723096f80ed73f6936ca2" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Muon Optimizer Introduction and Overview | Generated by AI
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="notes/2025-09-30-muon-optimizer-overview-en.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>notes2025-09-30-muon-optimizer-overview-en.md</span> -->
      

      <!-- <span></span> -->

      
        <a href="#" class="button">2025.10</a>
      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/muon-optimizer-overview-en" selected>English</option>
        <option value="/muon-optimizer-overview-zh" >中文</option>
        <option value="/muon-optimizer-overview-ja" >日本語</option>
        <option value="/muon-optimizer-overview-es" >Español</option>
        <option value="/muon-optimizer-overview-hi" >हिंदी</option>
        <option value="/muon-optimizer-overview-fr" >Français</option>
        <option value="/muon-optimizer-overview-de" >Deutsch</option>
        <option value="/muon-optimizer-overview-ar" >العربية</option>
        <option value="/muon-optimizer-overview-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <h3 id="comprehensive-introduction-to-the-muon-optimizer">Comprehensive Introduction to the Muon Optimizer</h3>

<p>The Muon Optimizer is a specialized, second-order-inspired optimization algorithm designed primarily for training linear layers in neural networks (e.g., fully connected or embedding layers), though it can be extended to others. It was originally proposed in late 2024 by researchers including Keller Jordan and Jeremy Bernstein, with roots in geometric optimization techniques like polar initialization and the modular duality framework[1][2]. Zhiling Yang, founder of Moonshot AI and Kimi AI, highlighted Muon in discussions about training their Kimi K2 model—a 1-trillion-parameter large language model (LLM)—where it served as the backbone for efficient, high-rank updates that adapt to the loss landscape’s geometry[3][4]. However, its baseline version suffered from instability (e.g., loss spikes during long training), prompting Moonshot AI to develop MuonClip, an enhanced variant with stability mechanisms like QK-clipping for attention layers[3][2].</p>

<p>Muon stands out for its token efficiency: it requires fewer training tokens than first-order optimizers like AdamW to achieve comparable performance, making it valuable for resource-intensive tasks like LLM pre-training. It aims to approximate second-order methods (e.g., Newton’s method) without their full computational cost, focusing on eigenvalue adaptation via high-rank matrix updates. This is particularly useful in large-scale models where gradients are noisy, as Muon leverages preconditioning inspired by natural gradients and matrix square roots.</p>

<h4 id="key-principles-and-derivation">Key Principles and Derivation</h4>
<ul>
  <li><strong>Core Concept</strong>: Muon is rooted in geometric optimization, adapting updates to the “energy landscape” of the loss function. It uses a preconditioner based on the Fisher information matrix (or approximations) to scale gradients, similar to AdaGrad or Shampoo but optimized for dense linear layers[1][2].</li>
  <li><strong>Algorithm Steps</strong>:
    <ol>
      <li><strong>Gradient Computation</strong>: Compute standard gradients (\nabla W) for weights (W) in linear layers.</li>
      <li><strong>Preconditioning</strong>: Use Newton-Schulz iterations to approximate the matrix square root of a preconditioner (e.g., derived from layer statistics). This enables rank adaptation without full eigendecomposition.</li>
      <li><strong>Update Rule</strong>: Apply an update that scales high-rank components more effectively, often combined with momentum or clipping for stability.</li>
    </ol>
  </li>
  <li><strong>Mathematical Insight</strong>: If (G) is the gradient matrix, Muon approximates an update like (W \leftarrow W - \eta \cdot \sqrt{P}^{-1} G), where (\sqrt{P}) uses iterative matrix square root[2][5]. This contrasts with AdamW’s diagonal or moment-based scaling, allowing Muon to capture inter-parameter correlations better.</li>
  <li><strong>Efficiency Boost</strong>: Muon can reduce the number of training steps by 20-50% in some benchmarks, as seen in its use with NanoGPT records[1].</li>
</ul>

<h4 id="advantages-and-drawbacks">Advantages and Drawbacks</h4>
<ul>
  <li><strong>Advantages</strong>:
    <ul>
      <li><strong>Better Convergence on Linear Layers</strong>: Excels in dense, high-dimensional spaces typical of LLMs, leading to lower loss with fewer tokens[4][6].</li>
      <li><strong>Resource-Efficient</strong>: Faster per-epoch training due to fewer gradient computations needed.</li>
      <li><strong>Open-Source and Extensible</strong>: Multiple implementations exist, including specific ones like Flash-Muon for GPU acceleration[4][7].</li>
    </ul>
  </li>
  <li><strong>Drawbacks</strong>:
    <ul>
      <li><strong>Instability</strong>: Prone to divergence in deeper networks or sparse layers; MuonClip addresses this by clipping attention scores (e.g., query-key products) during training[3][2].</li>
      <li><strong>Layer Specificity</strong>: Not ideal for convolutional or recurrent layers; it’s biased toward linear/MoE architectures. Keras notes it shouldn’t be used for non-linear layers[8].</li>
      <li><strong>Hyperparameter Sensitivity</strong>: Requires tuning for learning rate ((\eta)) and orthogonality-inducing moves; may not transfer across model sizes without adjustment[2].</li>
    </ul>
  </li>
  <li><strong>MuonClip Variant (Kimi-Specific)</strong>: This is Muon’s evolution, integrated with QK-clipping to prevent instability in 15.5 trillion-token pre-training. It stabilized Kimi K2’s 32 billion activated parameters, enabling zero-loss-spike training and superior benchmarks (e.g., 66.1 on Tau2-Bench)[3][8]. Without public code yet, it’s proprietary but builds on open Muon.</li>
</ul>

<p>Muon has influenced the AI optimization landscape, appearing in benchmarks like Scion and discussions on Reddit/X, often praised for its “geometric intuition.” For full derivations, see Jeremy Bernstein’s blog[2]. Now, let’s look at a practical implementation.</p>

<h3 id="code-example-implementing-muon-optimizer-in-pytorch">Code Example: Implementing Muon Optimizer in PyTorch</h3>
<p>Below is a PyTorch implementation of the basic Muon optimizer, adapted from the official repository (https://github.com/KellerJordan/Muon). This is a simplified version for dense linear layers; it includes Newton-Schulz iterations for the preconditioner.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">Muon</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="s">"""
    Muon optimizer for linear layers.
    From: https://github.com/KellerJordan/Muon
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">lr_b</span><span class="o">=</span><span class="mf">2e-3</span><span class="p">,</span> <span class="n">b2</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="n">defaults</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">lr_b</span><span class="o">=</span><span class="n">lr_b</span><span class="p">,</span> <span class="n">b2</span><span class="o">=</span><span class="n">b2</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">defaults</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s">'lr'</span><span class="p">]</span>
            <span class="n">lr_b</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s">'lr_b'</span><span class="p">]</span>
            <span class="n">b2</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span>
            <span class="n">wd</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s">'wd'</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s">'params'</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="k">continue</span>

                <span class="n">grad</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nb">float</span><span class="p">()</span>
                <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>
                <span class="k">if</span> <span class="s">'momentum'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
                    <span class="n">state</span><span class="p">[</span><span class="s">'momentum'</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>

                <span class="c1"># Momentum update
</span>                <span class="n">state</span><span class="p">[</span><span class="s">'momentum'</span><span class="p">].</span><span class="n">mul_</span><span class="p">(</span><span class="n">b2</span><span class="p">).</span><span class="n">add_</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>

                <span class="c1"># Weight decay
</span>                <span class="k">if</span> <span class="n">wd</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">p</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">mul_</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">wd</span><span class="p">)</span>

                <span class="c1"># Muon's orthonormalization (rank adaptation)
</span>                <span class="n">grad_vec</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s">'momentum'</span><span class="p">].</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">grad</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">p_vec</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

                <span class="c1"># Newton-Schulz for matrix square root approx (simplified)
</span>                <span class="n">G</span> <span class="o">=</span> <span class="n">grad_vec</span> <span class="o">@</span> <span class="n">grad_vec</span><span class="p">.</span><span class="n">t</span><span class="p">()</span> <span class="o">/</span> <span class="n">grad_vec</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="c1"># In full impl, this is iterative; here, approximate with power series
</span>                <span class="n">sqrt_G</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">G</span> <span class="o">+</span> <span class="mf">1e-6</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">eye</span><span class="p">(</span><span class="n">G</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">G</span><span class="p">.</span><span class="n">device</span><span class="p">))</span>

                <span class="c1"># Update
</span>                <span class="n">update</span> <span class="o">=</span> <span class="n">grad_vec</span><span class="p">.</span><span class="n">t</span><span class="p">()</span> <span class="o">@</span> <span class="n">sqrt_G</span> <span class="o">@</span> <span class="n">grad_vec</span> <span class="o">/</span> <span class="n">sqrt_G</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">p</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">lr_b</span> <span class="o">*</span> <span class="n">update</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>

<span class="c1"># Example Usage
</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>  <span class="c1"># Dense layer
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">Muon</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Notes on Code</strong>:</p>
<ul>
  <li>This is a stripped-down version; the full GitHub repo includes CUDA kernels for efficiency (e.g., Flash-Muon for faster matmuls)[3][4].</li>
  <li>For Keras/TensorFlow: Use <code class="language-plaintext highlighter-rouge">from keras.optimizers import Muon; opt = Muon(learning_rate=0.01)</code>[8].</li>
  <li>Tuned hyperparameters (e.g., <code class="language-plaintext highlighter-rouge">lr_b=2e-3</code>) are crucial; experiment with your model. For Kimi K2’s MuonClip, no public code exists, but it adds clipping logic in attention forward passes[2][5].</li>
</ul>

<p>If you need extensions or benchmarks, let me know!</p>

<p>Citations:
[1] https://kellerjordan.github.io/posts/muon/
[2] https://jeremybernste.in/writing/deriving-muon
[3] https://github.com/KellerJordan/Muon
[4] https://github.com/nil0x9/flash-muon
[5] https://www.lakernewhouse.com/writing/muon-2
[6] https://medium.com/@kyeg/building-the-muon-optimizer-in-pytorch-a-geometric-approach-to-neural-network-optimization-17f4601be548
[7] https://discuss.huggingface.co/t/tutorial-understanding-and-implementing-the-muon-optimizer/167717
[8] https://keras.io/api/optimizers/muon/</p>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    
      <p class="model">x-ai/grok-code-fast-1</p>
    

    
    
    <a href="/donate-en" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
