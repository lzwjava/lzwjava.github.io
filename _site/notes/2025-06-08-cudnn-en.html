<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>cuDNN</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>cuDNN | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="cuDNN" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="en" />
<meta name="description" content="李智维" />
<meta property="og:description" content="李智维" />
<link rel="canonical" href="https://lzwjava.github.io/notes/2025-06-08-cudnn-en" />
<meta property="og:url" content="https://lzwjava.github.io/notes/2025-06-08-cudnn-en" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="cuDNN" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Zhiwei Li"},"description":"李智维","headline":"cuDNN","url":"https://lzwjava.github.io/notes/2025-06-08-cudnn-en"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=7a71cc86f57a3ba2717d4782faa496be1ddabe54">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=7a71cc86f57a3ba2717d4782faa496be1ddabe54" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       cuDNN | Generated by AI
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="notes/2025-06-08-cudnn-en.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>notes2025-06-08-cudnn-en.md</span> -->
      

      <!-- <span></span> -->

      
        <a href="#" class="button">2025.10</a>
      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/cudnn-en" selected>English</option>
        <option value="/cudnn-zh" >中文</option>
        <option value="/cudnn-ja" >日本語</option>
        <option value="/cudnn-es" >Español</option>
        <option value="/cudnn-hi" >हिंदी</option>
        <option value="/cudnn-fr" >Français</option>
        <option value="/cudnn-de" >Deutsch</option>
        <option value="/cudnn-ar" >العربية</option>
        <option value="/cudnn-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>The <code class="language-plaintext highlighter-rouge">nvidia-cudnn-cu12</code> library is part of NVIDIA’s CUDA Deep Neural Network library, commonly known as cuDNN. This library is designed to accelerate deep learning frameworks on NVIDIA GPUs. Specifically, <code class="language-plaintext highlighter-rouge">nvidia-cudnn-cu12</code> is tailored for use with CUDA 12, which is NVIDIA’s parallel computing platform and API model.</p>

<p>cuDNN provides highly tuned implementations for standard routines such as forward and backward convolution, pooling, normalization, and activation layers. These routines are essential for training deep neural networks and significantly speed up computation times, making them crucial for applications in areas like image and speech recognition, natural language processing, and more.</p>

<p>The library is widely used in both research and industry to enhance the performance of deep learning models by leveraging the power of GPU acceleration. It supports various platforms and is compatible with multiple versions of CUDA, ensuring flexibility and broad applicability across different hardware configurations.</p>

<hr />

<p>The <code class="language-plaintext highlighter-rouge">nvidia-cudnn-cu12</code> library, part of NVIDIA’s cuDNN, includes a set of APIs designed to accelerate deep neural network operations on NVIDIA GPUs. The library provides optimized implementations for several key operations used in deep learning. Here are some of the main components and APIs included:</p>

<ol>
  <li>
    <p><strong>Convolution Operations</strong>: APIs for performing forward and backward convolution operations, which are fundamental in many neural network architectures, especially Convolutional Neural Networks (CNNs).</p>
  </li>
  <li>
    <p><strong>Pooling Operations</strong>: APIs for different types of pooling operations such as max pooling and average pooling, which are used to reduce the spatial dimensions of the input volume for the next convolutional layer.</p>
  </li>
  <li>
    <p><strong>Normalization Operations</strong>: APIs for batch normalization, which helps in stabilizing and potentially accelerating the training of deep neural networks.</p>
  </li>
  <li>
    <p><strong>Activation Functions</strong>: APIs for various activation functions like ReLU (Rectified Linear Unit), sigmoid, and tanh, which introduce non-linearity into the model, enabling it to learn complex patterns.</p>
  </li>
  <li>
    <p><strong>Recurrent Neural Network (RNN) Operations</strong>: APIs for operations commonly used in RNNs, such as LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Unit).</p>
  </li>
  <li>
    <p><strong>Tensor Transformations</strong>: APIs for tensor manipulation operations, which are essential for preparing data for neural network layers and processing outputs.</p>
  </li>
  <li>
    <p><strong>Optimization Operations</strong>: APIs that support various optimization algorithms used during the training of neural networks.</p>
  </li>
</ol>

<p>The cuDNN library is designed to be used with NVIDIA’s CUDA platform and is accessible through both a direct C API and an open-source C++ frontend, making it versatile for integration into various deep learning frameworks and applications. This allows developers to define computations as a graph of operations on tensors, leveraging GPU acceleration for improved performance.</p>

<hr />

<h1 id="using-cudnn-in-python-and-c">Using cuDNN in Python and C</h1>

<p>cuDNN (CUDA Deep Neural Network library) is NVIDIA’s GPU-accelerated library for deep neural networks. Here’s how to use it in both Python and C:</p>

<h2 id="using-cudnn-in-python">Using cuDNN in Python</h2>

<p>The most common way to use cuDNN in Python is through deep learning frameworks that have cuDNN integration:</p>

<h3 id="1-using-with-pytorch">1. Using with PyTorch</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Check if cuDNN is enabled
</span><span class="k">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">cudnn</span><span class="p">.</span><span class="n">enabled</span><span class="p">)</span>  <span class="c1"># Should be True
</span>
<span class="c1"># Create some tensors and operations that will use cuDNN
</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>  <span class="c1"># 4D tensor (batch, channels, height, width)
</span><span class="n">conv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1"># This convolution will use cuDNN under the hood
</span><span class="n">output</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="2-using-with-tensorflow">2. Using with TensorFlow</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="c1"># Check if cuDNN is available
</span><span class="k">print</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">test</span><span class="p">.</span><span class="n">is_built_with_cuda</span><span class="p">())</span>  <span class="c1"># Should be True
</span><span class="k">print</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">test</span><span class="p">.</span><span class="n">is_built_with_cudnn</span><span class="p">())</span>  <span class="c1"># Should be True
</span>
<span class="c1"># Create a simple model that will use cuDNN
</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># This will use cuDNN for the convolution and pooling operations
</span><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<h2 id="using-cudnn-in-c">Using cuDNN in C</h2>

<p>For direct usage of cuDNN in C, you need to use the cuDNN C API:</p>

<h3 id="basic-cudnn-c-example">Basic cuDNN C Example</h3>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;cudnn.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;cuda_runtime.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">cudnnHandle_t</span> <span class="n">cudnn</span><span class="p">;</span>
    <span class="n">cudnnCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cudnn</span><span class="p">);</span>  <span class="c1">// Initialize cuDNN</span>
    
    <span class="c1">// Create a tensor descriptor</span>
    <span class="n">cudnnTensorDescriptor_t</span> <span class="n">input_descriptor</span><span class="p">;</span>
    <span class="n">cudnnCreateTensorDescriptor</span><span class="p">(</span><span class="o">&amp;</span><span class="n">input_descriptor</span><span class="p">);</span>
    
    <span class="c1">// Set 4D tensor dimensions (NCHW format)</span>
    <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="mi">224</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">224</span><span class="p">;</span>
    <span class="n">cudnnSetTensor4dDescriptor</span><span class="p">(</span><span class="n">input_descriptor</span><span class="p">,</span>
                              <span class="n">CUDNN_TENSOR_NCHW</span><span class="p">,</span>
                              <span class="n">CUDNN_DATA_FLOAT</span><span class="p">,</span>
                              <span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">);</span>
    
    <span class="c1">// Create a filter descriptor for convolution</span>
    <span class="n">cudnnFilterDescriptor_t</span> <span class="n">filter_descriptor</span><span class="p">;</span>
    <span class="n">cudnnCreateFilterDescriptor</span><span class="p">(</span><span class="o">&amp;</span><span class="n">filter_descriptor</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">out_channels</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
    <span class="n">cudnnSetFilter4dDescriptor</span><span class="p">(</span><span class="n">filter_descriptor</span><span class="p">,</span>
                             <span class="n">CUDNN_DATA_FLOAT</span><span class="p">,</span>
                             <span class="n">CUDNN_TENSOR_NCHW</span><span class="p">,</span>
                             <span class="n">out_channels</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="p">);</span>
    
    <span class="c1">// Create convolution descriptor</span>
    <span class="n">cudnnConvolutionDescriptor_t</span> <span class="n">conv_descriptor</span><span class="p">;</span>
    <span class="n">cudnnCreateConvolutionDescriptor</span><span class="p">(</span><span class="o">&amp;</span><span class="n">conv_descriptor</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">pad</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">cudnnSetConvolution2dDescriptor</span><span class="p">(</span><span class="n">conv_descriptor</span><span class="p">,</span>
                                   <span class="n">pad</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span>
                                   <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1">// dilation</span>
                                   <span class="n">CUDNN_CROSS_CORRELATION</span><span class="p">,</span>
                                   <span class="n">CUDNN_DATA_FLOAT</span><span class="p">);</span>
    
    <span class="c1">// Find convolution algorithm</span>
    <span class="n">cudnnConvolutionFwdAlgo_t</span> <span class="n">algo</span><span class="p">;</span>
    <span class="n">cudnnGetConvolutionForwardAlgorithm</span><span class="p">(</span><span class="n">cudnn</span><span class="p">,</span>
                                       <span class="n">input_descriptor</span><span class="p">,</span>
                                       <span class="n">filter_descriptor</span><span class="p">,</span>
                                       <span class="n">conv_descriptor</span><span class="p">,</span>
                                       <span class="n">input_descriptor</span><span class="p">,</span>
                                       <span class="n">CUDNN_CONVOLUTION_FWD_PREFER_FASTEST</span><span class="p">,</span>
                                       <span class="mi">0</span><span class="p">,</span>  <span class="c1">// no memory limit</span>
                                       <span class="o">&amp;</span><span class="n">algo</span><span class="p">);</span>
    
    <span class="n">printf</span><span class="p">(</span><span class="s">"Using convolution algorithm: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">algo</span><span class="p">);</span>
    
    <span class="c1">// Cleanup</span>
    <span class="n">cudnnDestroyTensorDescriptor</span><span class="p">(</span><span class="n">input_descriptor</span><span class="p">);</span>
    <span class="n">cudnnDestroyFilterDescriptor</span><span class="p">(</span><span class="n">filter_descriptor</span><span class="p">);</span>
    <span class="n">cudnnDestroyConvolutionDescriptor</span><span class="p">(</span><span class="n">conv_descriptor</span><span class="p">);</span>
    <span class="n">cudnnDestroy</span><span class="p">(</span><span class="n">cudnn</span><span class="p">);</span>
    
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>To compile this C program:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvcc your_program.c <span class="nt">-o</span> your_program <span class="nt">-lcudnn</span>
</code></pre></div></div>

<h2 id="key-points">Key Points</h2>

<ol>
  <li><strong>Python Usage</strong>:
    <ul>
      <li>Most users interact with cuDNN indirectly through frameworks like PyTorch or TensorFlow</li>
      <li>These frameworks automatically use cuDNN when available and appropriate</li>
    </ul>
  </li>
  <li><strong>Direct C Usage</strong>:
    <ul>
      <li>Provides more control but requires more boilerplate code</li>
      <li>You need to manage descriptors for tensors, filters, convolutions, etc.</li>
      <li>Requires careful memory management</li>
    </ul>
  </li>
  <li><strong>Prerequisites</strong>:
    <ul>
      <li>NVIDIA GPU with CUDA support</li>
      <li>Properly installed CUDA toolkit</li>
      <li>cuDNN library installed and in your library path</li>
    </ul>
  </li>
  <li><strong>Performance</strong>:
    <ul>
      <li>cuDNN provides highly optimized implementations</li>
      <li>Different algorithms may be available for the same operation</li>
      <li>Some frameworks allow you to benchmark and select the fastest algorithm</li>
    </ul>
  </li>
</ol>

<p>For most deep learning applications, using cuDNN through a high-level framework like PyTorch or TensorFlow is recommended, as it provides a good balance between performance and ease of use.</p>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-en" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
