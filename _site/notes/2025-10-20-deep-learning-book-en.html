<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Deep Learning Book by Goodfellow Bengio Courville</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Deep Learning Book by Goodfellow Bengio Courville | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Deep Learning Book by Goodfellow Bengio Courville" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="en" />
<meta name="description" content="李智维" />
<meta property="og:description" content="李智维" />
<link rel="canonical" href="https://lzwjava.github.io/notes/2025-10-20-deep-learning-book-en" />
<meta property="og:url" content="https://lzwjava.github.io/notes/2025-10-20-deep-learning-book-en" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Deep Learning Book by Goodfellow Bengio Courville" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Zhiwei Li"},"description":"李智维","headline":"Deep Learning Book by Goodfellow Bengio Courville","url":"https://lzwjava.github.io/notes/2025-10-20-deep-learning-book-en"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=5592bdc6a776674fac55c39688916d90707b2273">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=5592bdc6a776674fac55c39688916d90707b2273" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Deep Learning Book by Goodfellow Bengio Courville | Generated by AI
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="notes/2025-10-20-deep-learning-book-en.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>notes2025-10-20-deep-learning-book-en.md</span> -->
      

      <!-- <span></span> -->

      
        <a href="#" class="button">2025.10</a>
      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/deep-learning-book-en" selected>English</option>
        <option value="/deep-learning-book-zh" >中文</option>
        <option value="/deep-learning-book-ja" >日本語</option>
        <option value="/deep-learning-book-es" >Español</option>
        <option value="/deep-learning-book-hi" >हिंदी</option>
        <option value="/deep-learning-book-fr" >Français</option>
        <option value="/deep-learning-book-de" >Deutsch</option>
        <option value="/deep-learning-book-ar" >العربية</option>
        <option value="/deep-learning-book-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p><strong>Ian Goodfellow</strong><br />
<strong>Yoshua Bengio</strong><br />
<strong>Aaron Courville</strong></p>

<h2 id="contents">Contents</h2>

<ul>
  <li>Website viii</li>
  <li>Acknowledgments ix</li>
  <li>Notation xiii</li>
</ul>

<h3 id="1-introduction-1">1 Introduction 1</h3>

<ul>
  <li>1.1 Who Should Read This Book? 8</li>
  <li>1.2 Historical Trends in Deep Learning 12</li>
</ul>

<h2 id="i-applied-math-and-machine-learning-basics-27">I Applied Math and Machine Learning Basics 27</h2>

<h3 id="2-linear-algebra-29">2 Linear Algebra 29</h3>

<ul>
  <li>2.1 Scalars, Vectors, Matrices and Tensors 29</li>
  <li>2.2 Multiplying Matrices and Vectors 32</li>
  <li>2.3 Identity and Inverse Matrices 34</li>
  <li>2.4 Linear Dependence and Span 35</li>
  <li>2.5 Norms 37</li>
  <li>2.6 Special Kinds of Matrices and Vectors 38</li>
  <li>2.7 Eigendecomposition 40</li>
  <li>2.8 Singular Value Decomposition 42</li>
  <li>2.9 The Moore-Penrose Pseudoinverse 43</li>
  <li>2.10 The Trace Operator 44</li>
  <li>2.11 The Determinant 45</li>
  <li>2.12 Example: Principal Components Analysis 45</li>
</ul>

<h3 id="3-probability-and-information-theory-51">3 Probability and Information Theory 51</h3>

<ul>
  <li>3.1 Why Probability? 52</li>
  <li>3.2 Random Variables 54</li>
  <li>3.3 Probability Distributions 54</li>
  <li>3.4 Marginal Probability 56</li>
  <li>3.5 Conditional Probability 57</li>
  <li>3.6 The Chain Rule of Conditional Probabilities 57</li>
  <li>3.7 Independence and Conditional Independence 58</li>
  <li>3.8 Expectation, Variance and Covariance 58</li>
  <li>3.9 Common Probability Distributions 60</li>
  <li>3.10 Useful Properties of Common Functions 65</li>
  <li>3.11 Bayes’ Rule 68</li>
  <li>3.12 Technical Details of Continuous Variables 69</li>
  <li>3.13 Information Theory 71</li>
  <li>3.14 Structured Probabilistic Models 73</li>
</ul>

<h3 id="4-numerical-computation-78">4 Numerical Computation 78</h3>

<ul>
  <li>4.1 Overflow and Underflow 78</li>
  <li>4.2 Poor Conditioning 80</li>
  <li>4.3 Gradient-Based Optimization 80</li>
  <li>4.4 Constrained Optimization 91</li>
  <li>4.5 Example: Linear Least Squares 94</li>
</ul>

<h3 id="5-machine-learning-basics-96">5 Machine Learning Basics 96</h3>

<ul>
  <li>5.1 Learning Algorithms 97</li>
  <li>5.2 Capacity, Overfitting and Underfitting 108</li>
  <li>5.3 Hyperparameters and Validation Sets 118</li>
  <li>5.4 Estimators, Bias and Variance 120</li>
  <li>5.5 Maximum Likelihood Estimation 129</li>
  <li>5.6 Bayesian Statistics 133</li>
  <li>5.7 Supervised Learning Algorithms 137</li>
  <li>5.8 Unsupervised Learning Algorithms 142</li>
  <li>5.9 Stochastic Gradient Descent 149</li>
  <li>5.10 Building a Machine Learning Algorithm 151</li>
  <li>5.11 Challenges Motivating Deep Learning 152</li>
</ul>

<h2 id="ii-deep-networks-modern-practices-162">II Deep Networks: Modern Practices 162</h2>

<h3 id="6-deep-feedforward-networks-164">6 Deep Feedforward Networks 164</h3>

<ul>
  <li>6.1 Example: Learning XOR 167</li>
  <li>6.2 Gradient-Based Learning 172</li>
  <li>6.3 Hidden Units 187</li>
  <li>6.4 Architecture Design 193</li>
  <li>6.5 Back-Propagation and Other Differentiation Algorithms 200</li>
  <li>6.6 Historical Notes 220</li>
</ul>

<h3 id="7-regularization-for-deep-learning-224">7 Regularization for Deep Learning 224</h3>

<ul>
  <li>7.1 Parameter Norm Penalties 226</li>
  <li>7.2 Norm Penalties as Constrained Optimization 233</li>
  <li>7.3 Regularization and Under-Constrained Problems 235</li>
  <li>7.4 Dataset Augmentation 236</li>
  <li>7.5 Noise Robustness 238</li>
  <li>7.6 Semi-Supervised Learning 240</li>
  <li>7.7 Multitask Learning 241</li>
  <li>7.8 Early Stopping 241</li>
  <li>7.9 Parameter Tying and Parameter Sharing 249</li>
  <li>7.10 Sparse Representations 251</li>
  <li>7.11 Bagging and Other Ensemble Methods 253</li>
  <li>7.12 Dropout 255</li>
  <li>7.13 Adversarial Training 265</li>
  <li>7.14 Tangent Distance, Tangent Prop and Manifold Tangent Classifier 267</li>
</ul>

<h3 id="8-optimization-for-training-deep-models-271">8 Optimization for Training Deep Models 271</h3>

<ul>
  <li>8.1 How Learning Differs from Pure Optimization 272</li>
  <li>8.2 Challenges in Neural Network Optimization 279</li>
  <li>8.3 Basic Algorithms 290</li>
  <li>8.4 Parameter Initialization Strategies 296</li>
  <li>8.5 Algorithms with Adaptive Learning Rates 302</li>
  <li>8.6 Approximate Second-Order Methods 307</li>
  <li>8.7 Optimization Strategies and Meta-Algorithms 313</li>
</ul>

<h3 id="9-convolutional-networks-326">9 Convolutional Networks 326</h3>

<ul>
  <li>9.1 The Convolution Operation 327</li>
  <li>9.2 Motivation 329</li>
  <li>9.3 Pooling 335</li>
  <li>9.4 Convolution and Pooling as an Infinitely Strong Prior 339</li>
  <li>9.5 Variants of the Basic Convolution Function 342</li>
  <li>9.6 Structured Outputs 352</li>
  <li>9.7 Data Types 354</li>
  <li>9.8 Efficient Convolution Algorithms 356</li>
  <li>9.9 Random or Unsupervised Features 356</li>
  <li>9.10 The Neuroscientific Basis for Convolutional Networks 358</li>
  <li>9.11 Convolutional Networks and the History of Deep Learning 365</li>
</ul>

<h3 id="10-sequence-modeling-recurrent-and-recursive-nets-367">10 Sequence Modeling: Recurrent and Recursive Nets 367</h3>

<ul>
  <li>10.1 Unfolding Computational Graphs 369</li>
  <li>10.2 Recurrent Neural Networks 372</li>
  <li>10.3 Bidirectional RNNs 388</li>
  <li>10.4 Encoder-Decoder Sequence-to-Sequence Architectures 390</li>
  <li>10.5 Deep Recurrent Networks 392</li>
  <li>10.6 Recursive Neural Networks 394</li>
  <li>10.7 The Challenge of Long-Term Dependencies 396</li>
  <li>10.8 Echo State Networks 399</li>
  <li>10.9 Leaky Units and Other Strategies for Multiple Time Scales 402</li>
  <li>10.10 The Long Short-Term Memory and Other Gated RNNs 404</li>
  <li>10.11 Optimization for Long-Term Dependencies 408</li>
  <li>10.12 Explicit Memory 412</li>
</ul>

<h3 id="11-practical-methodology-416">11 Practical Methodology 416</h3>

<ul>
  <li>11.1 Performance Metrics</li>
  <li>11.2 Default Baseline Models</li>
  <li>11.3 Determining Whether to Gather More Data</li>
  <li>11.4 Selecting Hyperparameters</li>
  <li>11.5 Debugging Strategies</li>
  <li>11.6 Example: Multi-Digit Number Recognition</li>
</ul>

<h2 id="iii-deep-learning-research-482">III Deep Learning Research 482</h2>

<h3 id="12-linear-factor-models-485">12 Linear Factor Models 485</h3>

<ul>
  <li>12.1 Probabilistic PCA and Factor Analysis</li>
  <li>12.2 Independent Component Analysis (ICA)</li>
  <li>12.3 Slow Feature Analysis</li>
  <li>12.4 Sparse Coding</li>
  <li>12.5 Manifold Interpretation of PCA</li>
</ul>

<h3 id="13-autoencoders-500">13 Autoencoders 500</h3>

<ul>
  <li>13.1 Undercomplete Autoencoders</li>
  <li>13.2 Regularized Autoencoders</li>
  <li>13.3 Representational Power, Layer Size and Depth</li>
  <li>13.4 Stochastic Encoders and Decoders</li>
  <li>13.5 Denoising Autoencoders</li>
  <li>13.6 Learning Manifolds with Autoencoders</li>
  <li>13.7 Contractive Autoencoders</li>
  <li>13.8 Predictive Sparse Decomposition</li>
  <li>13.9 Applications of Autoencoders</li>
</ul>

<h3 id="14-representation-learning-525">14 Representation Learning 525</h3>

<ul>
  <li>14.1 Greedy Layer-Wise Unsupervised Pretraining</li>
  <li>14.2 Transfer Learning and Domain Adaptation</li>
  <li>14.3 Semi-Supervised Disentangling of Causal Factors</li>
  <li>14.4 Distributed Representation</li>
  <li>14.5 Exponential Gains from Depth</li>
  <li>14.6 Providing Clues to Discover Underlying Causes</li>
</ul>

<h3 id="15-structured-probabilistic-models-for-deep-learning-540">15 Structured Probabilistic Models for Deep Learning 540</h3>

<ul>
  <li>15.1 The Challenge of Unstructured Modeling</li>
  <li>15.2 Using Graphs to Describe Model Structure</li>
  <li>15.3 Sampling from Graphical Models</li>
  <li>15.4 Advantages of Structured Modeling</li>
  <li>15.5 Learning about Dependencies</li>
  <li>15.6 Inference and Approximate Inference</li>
  <li>15.7 The Deep Learning Approach to Structured Probabilistic Models</li>
</ul>

<h3 id="16-monte-carlo-methods-557">16 Monte Carlo Methods 557</h3>

<ul>
  <li>16.1 Sampling and Monte Carlo Methods</li>
  <li>16.2 Importance Sampling</li>
  <li>16.3 Markov Chain Monte Carlo Methods</li>
  <li>16.4 Gibbs Sampling</li>
  <li>16.5 The Challenge of Mixing between Separated Modes</li>
</ul>

<h3 id="17-confronting-the-partition-function-567">17 Confronting the Partition Function 567</h3>

<ul>
  <li>17.1 The Log-Likelihood Gradient</li>
  <li>17.2 Stochastic Maximum Likelihood and Contrastive Divergence</li>
  <li>17.3 Pseudolikelihood</li>
  <li>17.4 Score Matching and Ratio Matching</li>
  <li>17.5 Denoising Score Matching</li>
  <li>17.6 Noise-Contrastive Estimation</li>
  <li>17.7 Estimating the Partition Function</li>
</ul>

<h3 id="18-approximate-inference-579">18 Approximate Inference 579</h3>

<ul>
  <li>18.1 Inference as Optimization</li>
  <li>18.2 Expectation Maximization</li>
  <li>18.3 MAP Inference and Sparse Coding</li>
  <li>18.4 Variational Inference and Learning</li>
  <li>18.5 Learned Approximate Inference</li>
</ul>

<h3 id="19-deep-generative-models-594">19 Deep Generative Models 594</h3>

<ul>
  <li>19.1 Boltzmann Machines</li>
  <li>19.2 Restricted Boltzmann Machines</li>
  <li>19.3 Deep Belief Networks</li>
  <li>19.4 Deep Boltzmann Machines</li>
  <li>19.5 Boltzmann Machines for Real-Valued Data</li>
  <li>19.6 Convolutional Boltzmann Machines</li>
  <li>19.7 Boltzmann Machines for Structured or Sequential Outputs</li>
  <li>19.8 Other Boltzmann Machines</li>
  <li>19.9 Back-Propagation through Random Operations</li>
  <li>19.10 Directed Generative Nets</li>
  <li>19.11 Drawing Samples from Autoencoders</li>
  <li>19.12 Generative Stochastic Networks</li>
  <li>19.13 Other Generation Schemes</li>
  <li>19.14 Evaluating Generative Models</li>
  <li>19.15 Conclusion</li>
</ul>

<p><a href="https://www.deeplearningbook.org/contents/toc.html">Deep Learning Table of Contents</a></p>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    
      <p class="model">x-ai/grok-4-fast</p>
    

    
    
    <a href="/donate-en" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
