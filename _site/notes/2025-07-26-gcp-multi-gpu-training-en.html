<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Training ML Models on GCP with NVIDIA GPUs</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Training ML Models on GCP with NVIDIA GPUs | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Training ML Models on GCP with NVIDIA GPUs" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="en" />
<meta name="description" content="李智维" />
<meta property="og:description" content="李智维" />
<link rel="canonical" href="https://lzwjava.github.io/notes/2025-07-26-gcp-multi-gpu-training-en" />
<meta property="og:url" content="https://lzwjava.github.io/notes/2025-07-26-gcp-multi-gpu-training-en" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Training ML Models on GCP with NVIDIA GPUs" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Zhiwei Li"},"description":"李智维","headline":"Training ML Models on GCP with NVIDIA GPUs","url":"https://lzwjava.github.io/notes/2025-07-26-gcp-multi-gpu-training-en"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=6d4d9b1160a90f16b87b2fdeb6fa9c55d4725a21">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=6d4d9b1160a90f16b87b2fdeb6fa9c55d4725a21" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Training ML Models on GCP with NVIDIA GPUs | Generated by AI
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="notes/2025-07-26-gcp-multi-gpu-training-en.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>notes2025-07-26-gcp-multi-gpu-training-en.md</span> -->
      

      <!-- <span></span> -->

      
        <a href="#" class="button">2025.10</a>
      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/gcp-multi-gpu-training-en" selected>English</option>
        <option value="/gcp-multi-gpu-training-zh" >中文</option>
        <option value="/gcp-multi-gpu-training-ja" >日本語</option>
        <option value="/gcp-multi-gpu-training-es" >Español</option>
        <option value="/gcp-multi-gpu-training-hi" >हिंदी</option>
        <option value="/gcp-multi-gpu-training-fr" >Français</option>
        <option value="/gcp-multi-gpu-training-de" >Deutsch</option>
        <option value="/gcp-multi-gpu-training-ar" >العربية</option>
        <option value="/gcp-multi-gpu-training-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>Google Cloud Platform (GCP) provides robust options for training machine learning models using NVIDIA GPUs through services like Vertex AI (for managed training jobs) and Compute Engine (for custom virtual machines). However, NVIDIA RTX 4090 GPUs are not available on GCP. The RTX 4090 is a consumer-grade GPU primarily for desktops and gaming, not designed for cloud data centers. Instead, GCP offers enterprise-grade NVIDIA GPUs such as A100, H100, L4, and others, which are optimized for AI workloads and often outperform the RTX 4090 in training scenarios due to higher memory bandwidth and tensor core efficiency.</p>

<p>For multi-GPU setups (at least 2 GPUs), you can configure resources to use 2, 4, 8, or more GPUs depending on the machine type. I’ll focus on Vertex AI for simplicity, as it’s tailored for ML training and handles scaling automatically. If you need more control, I’ll cover Compute Engine briefly.</p>

<h2 id="prerequisites">Prerequisites</h2>
<ul>
  <li>Set up a Google Cloud account and create a project.</li>
  <li>Enable the Vertex AI API and Compute Engine API in your project.</li>
  <li>Install the Google Cloud SDK (gcloud CLI) and the Vertex AI SDK if using Python.</li>
  <li>Prepare your training code in a Docker container (e.g., using TensorFlow or PyTorch with distributed training support like Horovod or torch.distributed).</li>
  <li>Ensure your model code supports multi-GPU training (e.g., via DataParallel or DistributedDataParallel in PyTorch).</li>
</ul>

<h2 id="using-vertex-ai-for-multi-gpu-training">Using Vertex AI for Multi-GPU Training</h2>
<p>Vertex AI is GCP’s managed platform for ML workflows. It supports custom training jobs where you can specify machine types with multiple GPUs.</p>

<h3 id="available-gpu-types-for-multi-gpu">Available GPU Types for Multi-GPU</h3>
<p>Common NVIDIA GPUs supporting at least 2 attachments:</p>
<ul>
  <li>NVIDIA H100 (80GB or Mega 80GB): High-performance for large models; supports 2, 4, or 8 GPUs.</li>
  <li>NVIDIA A100 (40GB or 80GB): Widely used for training; supports 2, 4, 8, or 16 GPUs.</li>
  <li>NVIDIA L4: Cost-effective for inference and lighter training; supports 2, 4, or 8 GPUs.</li>
  <li>NVIDIA T4 or V100: Older but still available; supports 2, 4, or 8 GPUs.</li>
</ul>

<p>Full list includes GB200, B200, H200, P4, P100—check regions for availability, as not all are in every zone.</p>

<h3 id="steps-to-create-a-training-job-with-at-least-2-gpus">Steps to Create a Training Job with at Least 2 GPUs</h3>
<ol>
  <li><strong>Prepare Your Container</strong>: Build a Docker image with your training script and push it to Google Container Registry or Artifact Registry. Example Dockerfile for PyTorch:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FROM pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime
COPY train.py /app/train.py
WORKDIR /app
CMD ["python", "train.py"]
</code></pre></div>    </div>
  </li>
  <li><strong>Configure the Job Using gcloud CLI</strong>:
    <ul>
      <li>Create a <code class="language-plaintext highlighter-rouge">config.yaml</code> file:
        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">workerPoolSpecs</span><span class="pi">:</span>
  <span class="na">machineSpec</span><span class="pi">:</span>
    <span class="na">machineType</span><span class="pi">:</span> <span class="s">a3-highgpu-2g</span>  <span class="c1"># Example: 2x H100 GPUs; alternatives: a2-ultragpu-2g (2x A100), g2-standard-24 (2x L4)</span>
    <span class="na">acceleratorType</span><span class="pi">:</span> <span class="s">NVIDIA_H100_80GB</span>  <span class="c1"># Or NVIDIA_A100_80GB, NVIDIA_L4</span>
    <span class="na">acceleratorCount</span><span class="pi">:</span> <span class="m">2</span>  <span class="c1"># At least 2</span>
  <span class="na">replicaCount</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">containerSpec</span><span class="pi">:</span>
    <span class="na">imageUri</span><span class="pi">:</span> <span class="s">gcr.io/your-project/your-image:latest</span>  <span class="c1"># Your Docker image URI</span>
</code></pre></div>        </div>
      </li>
      <li>Run the command:
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud ai custom-jobs create <span class="se">\</span>
  <span class="nt">--region</span><span class="o">=</span>us-central1 <span class="se">\ </span> <span class="c"># Choose a region with GPU availability</span>
  <span class="nt">--display-name</span><span class="o">=</span>your-training-job <span class="se">\</span>
  <span class="nt">--config</span><span class="o">=</span>config.yaml
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>Using Python SDK</strong>:
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">google.cloud</span> <span class="kn">import</span> <span class="n">aiplatform</span>

<span class="n">aiplatform</span><span class="p">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="s">'your-project-id'</span><span class="p">,</span> <span class="n">location</span><span class="o">=</span><span class="s">'us-central1'</span><span class="p">)</span>

<span class="n">job</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="p">.</span><span class="n">CustomJob</span><span class="p">(</span>
    <span class="n">display_name</span><span class="o">=</span><span class="s">'your-training-job'</span><span class="p">,</span>
    <span class="n">worker_pool_specs</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s">'machine_spec'</span><span class="p">:</span> <span class="p">{</span>
                <span class="s">'machine_type'</span><span class="p">:</span> <span class="s">'a3-highgpu-2g'</span><span class="p">,</span>  <span class="c1"># 2x H100
</span>                <span class="s">'accelerator_type'</span><span class="p">:</span> <span class="s">'NVIDIA_H100_80GB'</span><span class="p">,</span>
                <span class="s">'accelerator_count'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s">'replica_count'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s">'container_spec'</span><span class="p">:</span> <span class="p">{</span>
                <span class="s">'image_uri'</span><span class="p">:</span> <span class="s">'gcr.io/your-project/your-image:latest'</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">}</span>
    <span class="p">],</span>
<span class="p">)</span>
<span class="n">job</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Monitor and Scale</strong>:
    <ul>
      <li>Use the Vertex AI console to view job status and logs.</li>
      <li>For distributed training across multiple machines (e.g., more replicas), add additional worker pools and use reduction servers if needed for large-scale jobs.</li>
      <li>Costs: GPUs are billed per hour; check pricing in your region (e.g., 2x H100 might cost ~$6-10/hour).</li>
    </ul>
  </li>
  <li><strong>Tips for Multi-GPU Training</strong>:
    <ul>
      <li>Enable distributed training in your code (e.g., <code class="language-plaintext highlighter-rouge">torch.nn.parallel.DistributedDataParallel</code>).</li>
      <li>Use spot VMs or reservations for cost savings if interruptions are okay.</li>
      <li>Verify GPU availability in your region/zone via the GCP console.</li>
    </ul>
  </li>
</ol>

<h2 id="alternative-using-compute-engine-vms">Alternative: Using Compute Engine VMs</h2>
<p>If you prefer a custom setup without Vertex AI:</p>
<ol>
  <li>Create a VM instance:
    <ul>
      <li>Go to Compute Engine &gt; VM instances &gt; Create instance.</li>
      <li>Machine type: Select from A3 (H100), A2 (A100), G2 (L4) series, e.g., <code class="language-plaintext highlighter-rouge">a3-highgpu-2g</code> for 2x H100.</li>
      <li>Boot disk: Use a Deep Learning VM image (pre-installed with CUDA, TensorFlow/PyTorch).</li>
      <li>Add GPUs: Specify 2 accelerators of the chosen type.</li>
    </ul>
  </li>
  <li>SSH into the VM and run your training script:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud compute ssh your-vm-name <span class="nt">--zone</span><span class="o">=</span>your-zone
python train.py  <span class="c"># Ensure CUDA is detected: nvidia-smi</span>
</code></pre></div>    </div>
  </li>
  <li>For multi-GPU: Your code must handle it (e.g., <code class="language-plaintext highlighter-rouge">CUDA_VISIBLE_DEVICES=0,1</code>).</li>
</ol>

<p>This is more hands-on but gives full control.</p>

<h2 id="limitations-and-alternatives">Limitations and Alternatives</h2>
<ul>
  <li>If you specifically need RTX 4090-like performance, consider alternatives like AWS (which offers consumer GPUs in some cases) or on-premises setups.</li>
  <li>For free/limited GPU training, try Google Colab (up to 1-2 GPUs, but not guaranteed multi-GPU or 4090-equivalent).</li>
  <li>Always check quotas and request increases if needed via the GCP console.</li>
</ul>

<p><a href="https://cloud.google.com/vertex-ai/docs/training/configure-compute">Configure compute resources for custom training | Vertex AI | Google Cloud</a><br />
<a href="https://cloud.google.com/compute/docs/gpus">GPU machine types | Compute Engine Documentation | Google Cloud</a><br />
<a href="https://cloud.google.com/gpu">Cloud GPUs (Graphics Processing Units) - Google Cloud</a></p>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-en" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
