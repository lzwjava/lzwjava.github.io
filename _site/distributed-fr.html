<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Introduction au Cloud Computing et au Big Data</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Introduction au Cloud Computing et au Big Data | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Introduction au Cloud Computing et au Big Data" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="fr" />
<meta name="description" content="Cette leÃ§on couvre les sujets suivants :" />
<meta property="og:description" content="Cette leÃ§on couvre les sujets suivants :" />
<link rel="canonical" href="https://lzwjava.github.io/distributed-fr" />
<meta property="og:url" content="https://lzwjava.github.io/distributed-fr" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-10T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Introduction au Cloud Computing et au Big Data" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2021-03-10T00:00:00+08:00","datePublished":"2021-03-10T00:00:00+08:00","description":"Cette leÃ§on couvre les sujets suivants :","headline":"Introduction au Cloud Computing et au Big Data","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/distributed-fr"},"url":"https://lzwjava.github.io/distributed-fr"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=b6961a1e24d6ebcab2f87a9c6b60431ffa00ffe2">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=b6961a1e24d6ebcab2f87a9c6b60431ffa00ffe2" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Introduction au Cloud Computing et au Big Data | Original, traduit par l'IA
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/fr/2021-03-10-distributed-fr.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postsfr2021-03-10-distributed-fr.md</span> -->
      

      <!-- <span>2021-03-10-distributed-fr.md</span> -->

      
        

        
          
          <a href="#" class="button">2021.03</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/distributed-en" >English</option>
        <option value="/distributed-zh" >ä¸­æ–‡</option>
        <option value="/distributed-ja" >æ—¥æœ¬èª</option>
        <option value="/distributed-es" >EspaÃ±ol</option>
        <option value="/distributed-hi" >à¤¹à¤¿à¤‚à¤¦à¥€</option>
        <option value="/distributed-fr" selected>FranÃ§ais</option>
        <option value="/distributed-de" >Deutsch</option>
        <option value="/distributed-ar" >Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</option>
        <option value="/distributed-hant" >ç¹é«”ä¸­æ–‡</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>Cette leÃ§on couvre les sujets suivants :</p>

<ul>
  <li>Spark</li>
  <li>Hadoop</li>
  <li>Kubernetes</li>
  <li>Docker</li>
  <li>Flink</li>
  <li>MongoDB</li>
</ul>

<p>Lorsquâ€™on parle de cloud computing, il semble difficile de ne pas mentionner de nombreux outils tels que Hadoop, Hive, Hbase, ZooKeeper, Docker, Kubernetes, Spark, Kafka, MongoDB, Flink, Druid, Presto, Kylin, et Elastic Search. Les avez-vous tous entendus ? Certains de ces outils, je les ai dÃ©couverts dans les descriptions de postes dâ€™<code class="language-plaintext highlighter-rouge">ingÃ©nieur en big data</code> et dâ€™<code class="language-plaintext highlighter-rouge">ingÃ©nieur back-end distribuÃ©</code>. Ce sont des postes bien rÃ©munÃ©rÃ©s. Essayons de les installer tous et de les manipuler un peu.</p>
<h2 id="premiÃ¨re-exploration-de-spark">PremiÃ¨re exploration de Spark</h2>

<p>Le site officiel indique que <code class="language-plaintext highlighter-rouge">Spark</code> est un moteur dâ€™analyse pour le traitement de donnÃ©es Ã  grande Ã©chelle. <code class="language-plaintext highlighter-rouge">Spark</code> est essentiellement une bibliothÃ¨que. Contrairement Ã  <code class="language-plaintext highlighter-rouge">Redis</code>, il ne semble pas Ãªtre divisÃ© en un serveur et un client. <code class="language-plaintext highlighter-rouge">Spark</code> est uniquement utilisÃ© cÃ´tÃ© client. Jâ€™ai tÃ©lÃ©chargÃ© la derniÃ¨re version depuis le site officiel, <code class="language-plaintext highlighter-rouge">spark-3.1.1-bin-hadoop3.2.tar</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
â”œâ”€â”€ LICENSE
â”œâ”€â”€ NOTICE
â”œâ”€â”€ R
â”œâ”€â”€ README.md
â”œâ”€â”€ RELEASE
â”œâ”€â”€ bin
â”œâ”€â”€ conf
â”œâ”€â”€ data
â”œâ”€â”€ examples
â”œâ”€â”€ jars
â”œâ”€â”€ kubernetes
â”œâ”€â”€ licenses
â”œâ”€â”€ python
â”œâ”€â”€ sbin
â””â”€â”€ yarn
</code></pre></div></div>

<p>11 rÃ©pertoires, 4 fichiers</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Il semble qu'il s'agisse principalement de bibliothÃ¨ques d'analyse Ã©crites dans diffÃ©rents langages.

En mÃªme temps, le site officiel indique que vous pouvez installer directement les dÃ©pendances sur Python. `pip install pyspark`

```shell
$ pip install pyspark
Collecting pyspark
  TÃ©lÃ©chargement de pyspark-3.1.1.tar.gz (212,3 Mo)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212,3 Mo 14 ko/s
Collecting py4j==0.10.9
  TÃ©lÃ©chargement de py4j-0.10.9-py2.py3-none-any.whl (198 ko)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198 ko 145 ko/s
Construction des roues pour les paquets collectÃ©s : pyspark
  Construction de la roue pour pyspark (setup.py) ... terminÃ©
  Roue crÃ©Ã©e pour pyspark : nom=pyspark-3.1.1-py2.py3-none-any.whl taille=212767604 sha256=0b8079e82f3a5bcadad99179902d8c8ff9f8eccad928a469c11b97abdc960b72
  StockÃ© dans le rÃ©pertoire : /Users/lzw/Library/Caches/pip/wheels/23/bf/e9/9f3500437422e2ab82246f25a51ee480a44d4efc6c27e50d33
pyspark construit avec succÃ¨s
Installation des paquets collectÃ©s : py4j, pyspark
py4j-0.10.9 et pyspark-3.1.1 installÃ©s avec succÃ¨s
</code></pre></div></div>

<p>InstallÃ©.</p>

<p>Je regarde le site officiel, il y a quelques exemples.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/run-example SparkPi 10
</code></pre></div></div>

<p>Ah, donc on peut exÃ©cuter le programme contenu dans le package dâ€™installation que lâ€™on vient de tÃ©lÃ©charger. Mais il y a une erreur.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/run-example SparkPi 10
21/03/11 00:06:15 WARN NativeCodeLoader: Impossible de charger la bibliothÃ¨que native-hadoop pour votre plateforme... utilisation des classes Java intÃ©grÃ©es lÃ  oÃ¹ c<span class="s1">'est applicable
21/03/11 00:06:16 INFO ResourceUtils: Aucune ressource personnalisÃ©e configurÃ©e pour spark.driver.
21/03/11 00:06:16 WARN Utils: Le service '</span>sparkDriver<span class="s1">' n'</span>a pas pu se lier sur un port libre alÃ©atoire. Vous pouvez vÃ©rifier si une adresse de liaison appropriÃ©e est configurÃ©e.
</code></pre></div></div>

<blockquote>
  <p>Spark est un moteur de traitement rapide et gÃ©nÃ©ral compatible avec les donnÃ©es Hadoop. Il peut fonctionner dans des clusters Hadoop via YARN ou en mode autonome de Spark, et il peut traiter des donnÃ©es dans HDFS, HBase, Cassandra, Hive et tout format dâ€™entrÃ©e Hadoop. Il est conÃ§u pour effectuer Ã  la fois du traitement par lots (similaire Ã  MapReduce) et de nouvelles charges de travail comme le streaming, les requÃªtes interactives et lâ€™apprentissage automatique.</p>
</blockquote>

<p>Le terme <code class="language-plaintext highlighter-rouge">hadoop</code> est apparu plusieurs fois. AprÃ¨s avoir cherchÃ© sur Google <code class="language-plaintext highlighter-rouge">spark depends hadoop</code>, jâ€™ai trouvÃ© ce passage. Il semble que cela dÃ©pende des donnÃ©es au format <code class="language-plaintext highlighter-rouge">Hadoop</code>. CommenÃ§ons par Ã©tudier <code class="language-plaintext highlighter-rouge">Hadoop</code>.</p>

<h2 id="hadoop">Hadoop</h2>

<p>AprÃ¨s avoir rapidement parcouru le site officiel, passons Ã  lâ€™installation.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>hadoop
</code></pre></div></div>

<p>Pendant lâ€™installation, prenons le temps de comprendre.</p>

<blockquote>
  <p>La bibliothÃ¨que logicielle Apache Hadoop est un framework qui permet le traitement distribuÃ© de grands ensembles de donnÃ©es Ã  travers des clusters dâ€™ordinateurs en utilisant des modÃ¨les de programmation simples. Il est conÃ§u pour Ã©voluer dâ€™un seul serveur Ã  des milliers de machines, chacune offrant des capacitÃ©s de calcul et de stockage locales. PlutÃ´t que de dÃ©pendre du matÃ©riel pour assurer une haute disponibilitÃ©, la bibliothÃ¨que elle-mÃªme est conÃ§ue pour dÃ©tecter et gÃ©rer les dÃ©faillances au niveau de la couche application, offrant ainsi un service hautement disponible sur un cluster dâ€™ordinateurs, dont chacun peut Ãªtre sujet Ã  des pannes.</p>
</blockquote>

<p>En dâ€™autres termes, Hadoop est un ensemble de frameworks conÃ§u pour traiter des ensembles de donnÃ©es distribuÃ©s. Ces ensembles de donnÃ©es peuvent Ãªtre rÃ©partis sur de nombreux ordinateurs. Il utilise un modÃ¨le de programmation trÃ¨s simple pour les traiter. Il est conÃ§u pour passer dâ€™un seul serveur Ã  des milliers de machines. PlutÃ´t que de dÃ©pendre de la haute disponibilitÃ© du matÃ©riel, cette bibliothÃ¨que est conÃ§ue pour dÃ©tecter et gÃ©rer les erreurs au niveau de la couche application. Ainsi, elle permet de dÃ©ployer des services hautement disponibles sur un cluster, mÃªme si chaque ordinateur du cluster est susceptible de tomber en panne.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>hadoop
Erreur :
  homebrew-core est un clone superficiel.
  homebrew-cask est un clone superficiel.
Pour effectuer <span class="sb">`</span>brew update<span class="sb">`</span>, exÃ©cutez d<span class="s1">'abord :
  git -C /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core fetch --unshallow
  git -C /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask fetch --unshallow
Ces commandes peuvent prendre quelques minutes Ã  s'</span>exÃ©cuter en raison de la taille importante des dÃ©pÃ´ts.
Cette restriction a Ã©tÃ© imposÃ©e Ã  la demande de GitHub car la mise Ã  jour de clones superficiels
est une opÃ©ration extrÃªmement coÃ»teuse en raison de la structure de l<span class="s1">'arborescence et du trafic des
dÃ©pÃ´ts Homebrew/homebrew-core et Homebrew/homebrew-cask. Nous ne le faisons pas automatiquement
pour vous afin d'</span>Ã©viter de rÃ©pÃ©ter une opÃ©ration coÃ»teuse de dÃ©superficialisation dans les systÃ¨mes CI
<span class="o">(</span>qui devraient plutÃ´t Ãªtre corrigÃ©s pour ne pas utiliser de clones superficiels<span class="o">)</span><span class="nb">.</span> Nous nous excusons pour
le dÃ©sagrÃ©ment <span class="o">!</span>
<span class="o">==&gt;</span> TÃ©lÃ©chargement de https://homebrew.bintray.com/bottles/openjdk-15.0.1.big_sur.bottle.tar.gz
DÃ©jÃ  tÃ©lÃ©chargÃ© : /Users/lzw/Library/Caches/Homebrew/downloads/d1e3ece4af1d225bc2607eaa4ce85a873d2c6d43757ae4415d195751bc431962--openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> TÃ©lÃ©chargement de https://www.apache.org/dyn/closer.lua?path<span class="o">=</span>hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
DÃ©jÃ  tÃ©lÃ©chargÃ© : /Users/lzw/Library/Caches/Homebrew/downloads/764c6a0ea7352bb8bb505989feee1b36dc628c2dcd6b93fef1ca829d191b4e1e--hadoop-3.3.0.tar.gz
<span class="o">==&gt;</span> Installation des dÃ©pendances pour hadoop : openjdk
<span class="o">==&gt;</span> Installation de la dÃ©pendance hadoop : openjdk
<span class="o">==&gt;</span> DÃ©versement de openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Avertissements
Pour que les wrappers Java <span class="nb">du </span>systÃ¨me trouvent ce JDK, crÃ©ez un lien symbolique avec
  <span class="nb">sudo ln</span> <span class="nt">-sfn</span> /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk
</code></pre></div></div>

<p>openjdk est keg-only, ce qui signifie quâ€™il nâ€™a pas Ã©tÃ© liÃ© symboliquement dans /usr/local,
car il masque le wrapper <code class="language-plaintext highlighter-rouge">java</code> de macOS.</p>

<p>Si vous devez avoir openjdk en premier dans votre PATH, exÃ©cutez :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>Pour que les compilateurs trouvent openjdk, vous devrez peut-Ãªtre dÃ©finir :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">export </span><span class="nv">CPPFLAGS</span><span class="o">=</span><span class="s2">"-I/usr/local/opt/openjdk/include"</span>
</code></pre></div></div>

<p>==&gt; RÃ©sumÃ©
ğŸº  /usr/local/Cellar/openjdk/15.0.1: 614 fichiers, 324,9 Mo
==&gt; Installation de hadoop
ğŸº  /usr/local/Cellar/hadoop/3.3.0: 21 819 fichiers, 954,7 Mo, construit en 2 minutes 15 secondes
==&gt; Mise Ã  jour de 1 dÃ©pendance :
maven 3.3.3 -&gt; 3.6.3_1
==&gt; Mise Ã  jour de maven 3.3.3 -&gt; 3.6.3_1
==&gt; TÃ©lÃ©chargement de https://www.apache.org/dyn/closer.lua?path=maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
==&gt; TÃ©lÃ©chargement depuis https://mirror.olnevhost.net/pub/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
######################################################################## 100,0%
Erreur : Lâ€™Ã©tape <code class="language-plaintext highlighter-rouge">brew link</code> ne sâ€™est pas terminÃ©e avec succÃ¨s
La formule a Ã©tÃ© construite, mais nâ€™est pas liÃ©e symboliquement dans /usr/local
Impossible de crÃ©er un lien symbolique pour bin/mvn
La cible /usr/local/bin/mvn
est un lien symbolique appartenant Ã  maven. Vous pouvez le supprimer :
  brew unlink maven</p>

<p>Pour forcer le lien et Ã©craser tous les fichiers en conflit :
  brew link â€“overwrite maven</p>

<p>Pour lister tous les fichiers qui seraient supprimÃ©s :
  brew link â€“overwrite â€“dry-run maven</p>

<p>Les fichiers potentiellement en conflit sont :
/usr/local/bin/mvn -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvn
/usr/local/bin/mvnDebug -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnDebug
/usr/local/bin/mvnyjp -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnyjp
==&gt; RÃ©sumÃ©
ğŸº  /usr/local/Cellar/maven/3.6.3_1: 87 fichiers, 10.7MB, construit en 7 secondes
Suppression : /usr/local/Cellar/maven/3.3.3â€¦ (92 fichiers, 9MB)
==&gt; VÃ©rification des dÃ©pendants des formules mises Ã  niveauâ€¦
==&gt; Aucun dÃ©pendant cassÃ© trouvÃ© !
==&gt; Avertissements
==&gt; openjdk
Pour que les wrappers Java du systÃ¨me trouvent ce JDK, crÃ©ez un lien symbolique avec
  sudo ln -sfn /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk</p>

<p>openjdk est keg-only, ce qui signifie quâ€™il nâ€™a pas Ã©tÃ© liÃ© symboliquement dans /usr/local,
car il masque le wrapper <code class="language-plaintext highlighter-rouge">java</code> de macOS.</p>

<p>Si vous devez avoir openjdk en premier dans votre PATH, exÃ©cutez :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>Pour que les compilateurs trouvent openjdk, vous devrez peut-Ãªtre dÃ©finir :
  export CPPFLAGS=â€-I/usr/local/opt/openjdk/includeâ€</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
J'ai remarquÃ© dans les logs de sortie de `brew` que `maven` n'Ã©tait pas correctement liÃ©. Ensuite, j'ai procÃ©dÃ© Ã  un lien forcÃ© vers la version `3.6.3_1`.

```shell
  brew link --overwrite maven
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Hadoop</code> est maintenant installÃ© avec succÃ¨s.</p>

<blockquote>
  <h2 id="modules">Modules</h2>

  <p>Le projet inclut les modules suivants :</p>

  <ul>
    <li><strong>Hadoop Common</strong> : Les utilitaires communs qui prennent en charge les autres modules Hadoop.</li>
    <li><strong>Hadoop Distributed File System (HDFSâ„¢)</strong> : Un systÃ¨me de fichiers distribuÃ© qui offre un accÃ¨s Ã  haut dÃ©bit aux donnÃ©es des applications.</li>
    <li><strong>Hadoop YARN</strong> : Un framework pour la planification des tÃ¢ches et la gestion des ressources du cluster.</li>
    <li><strong>Hadoop MapReduce</strong> : Un systÃ¨me basÃ© sur YARN pour le traitement parallÃ¨le de grands ensembles de donnÃ©es.</li>
    <li><strong>Hadoop Ozone</strong> : Un magasin dâ€™objets pour Hadoop.</li>
  </ul>
</blockquote>

<p>Il dit quâ€™il y a ces modules. Cela a tapÃ© <code class="language-plaintext highlighter-rouge">hadoop</code> et voici ce qui est apparu :</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hadoop
Usage : hadoop <span class="o">[</span>OPTIONS] SUBCOMMAND <span class="o">[</span>SUBCOMMAND OPTIONS]
 ou     hadoop <span class="o">[</span>OPTIONS] CLASSNAME <span class="o">[</span>CLASSNAME OPTIONS]
  oÃ¹ CLASSNAME est une classe Java fournie par l<span class="s1">'utilisateur
</span></code></pre></div></div>

<p>OPTIONS peut Ãªtre <code class="language-plaintext highlighter-rouge">none</code> ou lâ€™une des options suivantes :</p>

<p>â€“config dir                     RÃ©pertoire de configuration Hadoop
â€“debug                          activer le mode de dÃ©bogage du script shell
â€“help                           informations sur lâ€™utilisation
buildpaths                       tenter dâ€™ajouter des fichiers de classe depuis lâ€™arborescence de construction
hostnames list[,of,host,names]   hÃ´tes Ã  utiliser en mode esclave
hosts filename                   liste des hÃ´tes Ã  utiliser en mode esclave
loglevel level                   dÃ©finir le niveau log4j pour cette commande
workers                          activer le mode travailleur</p>

<p>SUBCOMMAND est lâ€™un des :
    Commandes Administrateur :</p>

<p>daemonlog     obtenir/dÃ©finir le niveau de journalisation pour chaque dÃ©mon</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Commandes Client :
</code></pre></div></div>

<p>archive       crÃ©er une archive Hadoop
checknative   vÃ©rifier la disponibilitÃ© des bibliothÃ¨ques natives Hadoop et de compression
classpath     affiche le chemin de classe nÃ©cessaire pour obtenir le fichier jar Hadoop et les bibliothÃ¨ques requises
conftest      valider les fichiers de configuration XML
credential    interagir avec les fournisseurs dâ€™identifiants
distch        changeur de mÃ©tadonnÃ©es distribuÃ©
distcp        copier un fichier ou des rÃ©pertoires de maniÃ¨re rÃ©cursive
dtutil        opÃ©rations liÃ©es aux jetons de dÃ©lÃ©gation
envvars       afficher les variables dâ€™environnement Hadoop calculÃ©es
fs            exÃ©cuter un client utilisateur gÃ©nÃ©rique de systÃ¨me de fichiers
gridmix       soumettre un mÃ©lange de travaux synthÃ©tiques, modÃ©lisant une charge de production profilÃ©e
jar <jar>     exÃ©cuter un fichier jar. REMARQUE : veuillez utiliser "yarn jar" pour lancer des applications YARN, pas cette commande.
jnipath       affiche le java.library.path
kdiag         diagnostiquer les problÃ¨mes Kerberos
kerbname      montrer la conversion du principal auth_to_local
key           gÃ©rer les clÃ©s via le KeyProvider
rumenfolder   mettre Ã  l'Ã©chelle une trace d'entrÃ©e rumen
rumentrace    convertir des journaux en une trace rumen
s3guard       gÃ©rer les mÃ©tadonnÃ©es sur S3
trace         afficher et modifier les paramÃ¨tres de traÃ§age Hadoop
version       afficher la version</jar></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Commandes Daemon :
</code></pre></div></div>

<p>kms           exÃ©cuter KMS, le serveur de gestion des clÃ©s
registrydns   exÃ©cuter le serveur DNS du registre</p>

<p>SUBCOMMAND peut afficher lâ€™aide lorsquâ€™il est invoquÃ© sans paramÃ¨tres ou avec -h.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Le site officiel fournit quelques exemples.

```shell
  $ mkdir input
  $ cp etc/hadoop/*.xml input
  $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'
  $ cat output/*
</code></pre></div></div>

<p>On remarque la prÃ©sence de <code class="language-plaintext highlighter-rouge">share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar</code>. Cela signifie quâ€™il y a peut-Ãªtre des fichiers dâ€™exemple que nous nâ€™avons pas obtenus. On suppose que lâ€™installation via <code class="language-plaintext highlighter-rouge">Homebrew</code> ne fournit pas ces fichiers. Nous avons donc tÃ©lÃ©chargÃ© le package dâ€™installation depuis le site officiel.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
â”œâ”€â”€ LICENSE-binary
â”œâ”€â”€ LICENSE.txt
â”œâ”€â”€ NOTICE-binary
â”œâ”€â”€ NOTICE.txt
â”œâ”€â”€ README.txt
â”œâ”€â”€ bin
â”œâ”€â”€ etc
â”œâ”€â”€ include
â”œâ”€â”€ lib
â”œâ”€â”€ libexec
â”œâ”€â”€ licenses-binary
â”œâ”€â”€ sbin
â””â”€â”€ share
</code></pre></div></div>

<p>Le rÃ©pertoire <code class="language-plaintext highlighter-rouge">share</code> est apparu. Cependant, est-ce que <code class="language-plaintext highlighter-rouge">Homebrew</code> nâ€™a vraiment pas ces fichiers supplÃ©mentaires ? Trouvez le rÃ©pertoire dâ€™installation de <code class="language-plaintext highlighter-rouge">Homebrew</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">type </span>hadoop
hadoop est /usr/local/bin/hadoop
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-alrt</span> /usr/local/bin/hadoop
lrwxr-xr-x  1 lzw  admin  33 Mar 11 00:48 /usr/local/bin/hadoop -&gt; ../Cellar/hadoop/3.3.0/bin/hadoop
<span class="nv">$ </span><span class="nb">cd</span> /usr/local/Cellar/hadoop/3.3.0
</code></pre></div></div>

<p>Voici lâ€™arborescence des rÃ©pertoires imprimÃ©e sous <code class="language-plaintext highlighter-rouge">/usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop</code> :</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 2
<span class="nb">.</span>
â”œâ”€â”€ client
â”‚Â Â  â”œâ”€â”€ hadoop-client-api-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-client-minicluster-3.3.0.jar
â”‚Â Â  â””â”€â”€ hadoop-client-runtime-3.3.0.jar
â”œâ”€â”€ common
â”‚Â Â  â”œâ”€â”€ hadoop-common-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-common-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-kms-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-nfs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-registry-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ jdiff
â”‚Â Â  â”œâ”€â”€ lib
â”‚Â Â  â”œâ”€â”€ sources
â”‚Â Â  â””â”€â”€ webapps
â”œâ”€â”€ hdfs
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-client-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-client-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-httpfs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-native-client-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-native-client-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-nfs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-rbf-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-hdfs-rbf-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ jdiff
â”‚Â Â  â”œâ”€â”€ lib
â”‚Â Â  â”œâ”€â”€ sources
â”‚Â Â  â””â”€â”€ webapps
â”œâ”€â”€ mapreduce
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-app-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-common-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-core-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-hs-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-hs-plugins-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-jobclient-3.3.0-tests.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-jobclient-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-nativetask-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-shuffle-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-client-uploader-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ hadoop-mapreduce-examples-3.3.0.jar
â”‚Â Â  â”œâ”€â”€ jdiff
â”‚Â Â  â”œâ”€â”€ lib-examples
â”‚Â Â  â””â”€â”€ sources
â”œâ”€â”€ tools
â”‚Â Â  â”œâ”€â”€ dynamometer
â”‚Â Â  â”œâ”€â”€ lib
â”‚Â Â  â”œâ”€â”€ resourceestimator
â”‚Â Â  â”œâ”€â”€ sls
â”‚Â Â  â””â”€â”€ sources
â””â”€â”€ yarn
    â”œâ”€â”€ csi
    â”œâ”€â”€ hadoop-yarn-api-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-applications-catalog-webapp-3.3.0.war
    â”œâ”€â”€ hadoop-yarn-applications-distributedshell-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-applications-mawo-core-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-client-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-common-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-registry-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-applicationhistoryservice-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-common-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-nodemanager-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-resourcemanager-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-router-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-sharedcachemanager-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-tests-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-timeline-pluginstorage-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-web-proxy-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-services-api-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-services-core-3.3.0.jar
    â”œâ”€â”€ lib
    â”œâ”€â”€ sources
    â”œâ”€â”€ <span class="nb">test</span>
    â”œâ”€â”€ timelineservice
    â”œâ”€â”€ webapps
    â””â”€â”€ yarn-service-examples
</code></pre></div></div>

<p>Vous pouvez voir quâ€™il y a de nombreux fichiers <code class="language-plaintext highlighter-rouge">jar</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>input
<span class="nv">$ </span><span class="nb">ls
</span>bin			hadoop-config.sh	hdfs-config.sh		libexec			sbin			yarn-config.sh
etc			hadoop-functions.sh	input			mapred-config.sh	share
<span class="nv">$ </span><span class="nb">cp </span>etc/hadoop/<span class="k">*</span>.xml input
<span class="nv">$ </span><span class="nb">cd </span>input/
<span class="nv">$ </span><span class="nb">ls
</span>capacity-scheduler.xml	hadoop-policy.xml	hdfs-site.xml		kms-acls.xml		mapred-site.xml
core-site.xml		hdfs-rbf-site.xml	httpfs-site.xml		kms-site.xml		yarn-site.xml
<span class="nv">$ </span><span class="nb">cd</span> ..
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
Le fichier JAR n<span class="s1">'existe pas ou n'</span>est pas un fichier normal : /usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar
<span class="err">$</span>
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
2021-03-11 01:54:30,791 WARN util.NativeCodeLoader: Impossible de charger la bibliothÃ¨que native-hadoop pour votre plateforme... utilisation des classes Java intÃ©grÃ©es lÃ  oÃ¹ applicable
2021-03-11 01:54:31,115 INFO impl.MetricsConfig: PropriÃ©tÃ©s chargÃ©es depuis hadoop-metrics2.properties
2021-03-11 01:54:31,232 INFO impl.MetricsSystemImpl: PÃ©riode de capture des mÃ©triques planifiÃ©e Ã  10 seconde<span class="o">(</span>s<span class="o">)</span><span class="nb">.</span>
...
</code></pre></div></div>

<p>En suivant lâ€™exemple du site officiel, on remarque la commande <code class="language-plaintext highlighter-rouge">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input</code>. Ici, le fichier <code class="language-plaintext highlighter-rouge">jar</code> est prÃ©cÃ©dÃ© dâ€™un numÃ©ro de version. Il faut donc le remplacer par notre version <code class="language-plaintext highlighter-rouge">3.3.0</code>.</p>

<p>Fin du journal :</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2021-03-11 01:54:35,374 INFO mapreduce.Job:  map 100% reduce 100%
2021-03-11 01:54:35,374 INFO mapreduce.Job: Job job_local2087514596_0002 terminÃ© avec succÃ¨s
2021-03-11 01:54:35,377 INFO mapreduce.Job: Compteurs : 30
	Compteurs <span class="nb">du </span>systÃ¨me de fichiers
		FILE: Nombre d<span class="s1">'octets lus=1204316
		FILE: Nombre d'</span>octets Ã©crits<span class="o">=</span>3565480
		FILE: Nombre d<span class="s1">'opÃ©rations de lecture=0
		FILE: Nombre de grandes opÃ©rations de lecture=0
		FILE: Nombre d'</span>opÃ©rations d<span class="s1">'Ã©criture=0
	Framework Map-Reduce
		Enregistrements d'</span>entrÃ©e de <span class="nv">map</span><span class="o">=</span>1
		Enregistrements de sortie de <span class="nv">map</span><span class="o">=</span>1
		Octets de sortie de <span class="nv">map</span><span class="o">=</span>17
		Octets matÃ©rialisÃ©s de sortie de <span class="nv">map</span><span class="o">=</span>25
		Octets de <span class="nb">split </span>d<span class="s1">'entrÃ©e=141
		Enregistrements d'</span>entrÃ©e de <span class="nv">combine</span><span class="o">=</span>0
		Enregistrements de sortie de <span class="nv">combine</span><span class="o">=</span>0
		Groupes d<span class="s1">'entrÃ©e de reduce=1
		Octets de shuffle de reduce=25
		Enregistrements d'</span>entrÃ©e de <span class="nv">reduce</span><span class="o">=</span>1
		Enregistrements de sortie de <span class="nv">reduce</span><span class="o">=</span>1
		Enregistrements dÃ©versÃ©s<span class="o">=</span>2
		Maps mÃ©langÃ©s<span class="o">=</span>1
		Shuffles Ã©chouÃ©s<span class="o">=</span>0
		Sorties de map fusionnÃ©es<span class="o">=</span>1
		Temps Ã©coulÃ© GC <span class="o">(</span>ms<span class="o">)=</span>57
		Utilisation totale <span class="nb">du </span>tas engagÃ© <span class="o">(</span>octets<span class="o">)=</span>772800512
	Erreurs de Shuffle
		<span class="nv">BAD_ID</span><span class="o">=</span>0
		<span class="nv">CONNECTION</span><span class="o">=</span>0
		<span class="nv">IO_ERROR</span><span class="o">=</span>0
		<span class="nv">WRONG_LENGTH</span><span class="o">=</span>0
		<span class="nv">WRONG_MAP</span><span class="o">=</span>0
		<span class="nv">WRONG_REDUCE</span><span class="o">=</span>0
	Compteurs <span class="nb">du </span>format d<span class="s1">'entrÃ©e de fichier
		Octets lus=123
	Compteurs du format de sortie de fichier
		Octets Ã©crits=23
</span></code></pre></div></div>

<p>Continuons Ã  regarder.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>Quâ€™est-ce que cela signifie exactement ? Peu importe, en tout cas, nous avons rÃ©ussi Ã  dÃ©marrer <code class="language-plaintext highlighter-rouge">Hadoop</code>. Et nous avons exÃ©cutÃ© notre premier exemple de calcul en mode standalone.</p>

<h2 id="spark">Spark</h2>

<p>Revenons Ã  Spark. Prenons un exemple.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
</code></pre></div></div>

<p>Un fichier <code class="language-plaintext highlighter-rouge">hdfs</code> est apparu ici. AprÃ¨s avoir effectuÃ© des recherches, jâ€™ai dÃ©couvert quâ€™il est possible de crÃ©er un fichier <code class="language-plaintext highlighter-rouge">hdfs</code> de cette maniÃ¨re :</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-mkdir</span> /test
</code></pre></div></div>

<p>Voyons la commande <code class="language-plaintext highlighter-rouge">hdfs</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hdfs
Usage : hdfs <span class="o">[</span>OPTIONS] SUBCOMMAND <span class="o">[</span>SUBCOMMAND OPTIONS]
</code></pre></div></div>

<p>OPTIONS est soit <code class="language-plaintext highlighter-rouge">none</code>, soit lâ€™une des options suivantes :</p>

<p>â€“buildpaths                       tenter dâ€™ajouter des fichiers de classe Ã  partir de lâ€™arborescence de construction
â€“config dir                       rÃ©pertoire de configuration Hadoop
â€“daemon (start|status|stop)       opÃ©rer sur un dÃ©mon
â€“debug                            activer le mode de dÃ©bogage des scripts shell
â€“help                             informations dâ€™utilisation
â€“hostnames list[,of,host,names]   hÃ´tes Ã  utiliser en mode worker
â€“hosts filename                   liste des hÃ´tes Ã  utiliser en mode worker
â€“loglevel level                   dÃ©finir le niveau log4j pour cette commande
â€“workers                          activer le mode worker</p>

<p>SUBCOMMAND est lâ€™un des :
    Commandes dâ€™administration :</p>

<p>cacheadmin           configurer le cache HDFS
crypto               configurer les zones de chiffrement HDFS
debug                exÃ©cuter un Debug Admin pour exÃ©cuter des commandes de dÃ©bogage HDFS
dfsadmin             exÃ©cuter un client admin DFS
dfsrouteradmin       gÃ©rer la fÃ©dÃ©ration basÃ©e sur Router
ec                   exÃ©cuter une CLI de codage dâ€™effacement HDFS
fsck                 exÃ©cuter un utilitaire de vÃ©rification du systÃ¨me de fichiers DFS
haadmin              exÃ©cuter un client admin DFS HA
jmxget               obtenir les valeurs JMX exportÃ©es depuis NameNode ou DataNode
oev                  appliquer le visualiseur de modifications hors ligne Ã  un fichier dâ€™Ã©ditions
oiv                  appliquer le visualiseur dâ€™image de systÃ¨me de fichiers hors ligne Ã  une image de systÃ¨me de fichiers
oiv_legacy           appliquer le visualiseur dâ€™image de systÃ¨me de fichiers hors ligne Ã  une image de systÃ¨me de fichiers hÃ©ritÃ©e
storagepolicies      lister/obtenir/dÃ©finir/satisfaire les politiques de stockage des blocs</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Commandes client :
</code></pre></div></div>

<p>classpath            affiche le chemin de classe nÃ©cessaire pour obtenir le fichier JAR Hadoop et les bibliothÃ¨ques requises
dfs                  exÃ©cute une commande de systÃ¨me de fichiers sur le systÃ¨me de fichiers
envvars              affiche les variables dâ€™environnement Hadoop calculÃ©es
fetchdt              rÃ©cupÃ¨re un jeton de dÃ©lÃ©gation depuis le NameNode
getconf              obtient les valeurs de configuration Ã  partir de la configuration
groups               obtient les groupes auxquels les utilisateurs appartiennent
lsSnapshottableDir   liste tous les rÃ©pertoires pouvant Ãªtre snapshotÃ©s appartenant Ã  lâ€™utilisateur actuel
snapshotDiff         compare deux snapshots dâ€™un rÃ©pertoire ou compare le contenu actuel du rÃ©pertoire avec un snapshot
version              affiche la version</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Commandes Daemon :
</code></pre></div></div>

<p>balancer             exÃ©cuter un utilitaire dâ€™Ã©quilibrage de cluster<br />
datanode             exÃ©cuter un datanode DFS<br />
dfsrouter            exÃ©cuter le routeur DFS<br />
diskbalancer         rÃ©partir les donnÃ©es de maniÃ¨re uniforme entre les disques dâ€™un nÅ“ud donnÃ©<br />
httpfs               exÃ©cuter le serveur HttpFS, la passerelle HTTP HDFS<br />
journalnode          exÃ©cuter le journalnode DFS<br />
mover                exÃ©cuter un utilitaire pour dÃ©placer les rÃ©plicas de blocs entre les types de stockage<br />
namenode             exÃ©cuter le namenode DFS<br />
nfs3                 exÃ©cuter une passerelle NFS version 3<br />
portmap              exÃ©cuter un service portmap<br />
secondarynamenode    exÃ©cuter le namenode secondaire DFS<br />
sps                  exÃ©cuter le satisfacteur de politique de stockage externe<br />
zkfc                 exÃ©cuter le dÃ©mon ZK Failover Controller</p>

<p>SUBCOMMAND peut afficher lâ€™aide lorsquâ€™il est invoquÃ© sans paramÃ¨tres ou avec -h.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Continuer Ã  modifier le code.

```python
from pyspark.sql import SparkSession
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">master</span><span class="p">(</span><span class="s">"local[*]"</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">config</span><span class="p">(</span><span class="s">'spark.driver.bindAddress'</span><span class="p">,</span> <span class="s">'127.0.0.1'</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"a.txt"</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"b.txt"</span><span class="p">)</span>
</code></pre></div></div>

<p>Il est important de noter <code class="language-plaintext highlighter-rouge">.config('spark.driver.bindAddress', '127.0.0.1')</code>. Sinon, vous pourriez rencontrer lâ€™erreur suivante : <code class="language-plaintext highlighter-rouge">Service 'sparkDriver' could not bind on a random free port. You may check whether configuring an appropriate binding address</code>.</p>

<p>Cependant, une erreur est survenue Ã  ce moment-lÃ .</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Caused by: org.apache.spark.api.python.PythonException: Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
  File <span class="s2">"/usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py"</span>, line 473, <span class="k">in </span>main
    raise Exception<span class="o">((</span><span class="s2">"Python in worker has different version %s than that in "</span> +
Exception: Python dans le worker a une version diffÃ©rente 3.8 de celle <span class="nb">du </span>driver 3.9, PySpark ne peut pas fonctionner avec des versions mineures diffÃ©rentes. Veuillez vÃ©rifier que les variables d<span class="s1">'environnement PYSPARK_PYTHON et PYSPARK_DRIVER_PYTHON sont correctement configurÃ©es.
</span></code></pre></div></div>

<p>Cela indique que diffÃ©rentes versions de <code class="language-plaintext highlighter-rouge">Python</code> ont Ã©tÃ© exÃ©cutÃ©es.</p>

<p>Modifier le fichier <code class="language-plaintext highlighter-rouge">.bash_profile</code> :</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
<span class="nv">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
</code></pre></div></div>

<p>Cependant, lâ€™erreur persiste. AprÃ¨s quelques recherches, il semble que cela pourrait Ãªtre dÃ» au fait que <code class="language-plaintext highlighter-rouge">spark</code> ne charge pas cette variable dâ€™environnement lors de son exÃ©cution, et nâ€™utilise donc pas les variables dâ€™environnement par dÃ©faut du terminal.</p>

<p>Vous devez configurer dans le code :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
</code></pre></div></div>

<h1 id="configurer-les-environnements-spark">Configurer les environnements Spark</h1>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYSPARK_PYTHON'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'</span>
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYSPARK_DRIVER_PYTHON'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'</span>
</code></pre></div></div>

<p>Cela fonctionnera.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python sc.py
21/03/11 02:54:52 WARN NativeCodeLoader: Impossible de charger la bibliothÃ¨que native-hadoop pour votre plateforme... utilisation des classes Java intÃ©grÃ©es lÃ  oÃ¹ applicable
Utilisation <span class="nb">du </span>profil log4j par dÃ©faut de Spark : org/apache/spark/log4j-defaults.properties
DÃ©finition <span class="nb">du </span>niveau de journalisation par dÃ©faut Ã  <span class="s2">"WARN"</span><span class="nb">.</span>
Pour ajuster le niveau de journalisation, utilisez sc.setLogLevel<span class="o">(</span>newLevel<span class="o">)</span><span class="nb">.</span> Pour SparkR, utilisez setLogLevel<span class="o">(</span>newLevel<span class="o">)</span><span class="nb">.</span>
PythonRDD[6] Ã  RDD Ã  PythonRDD.scala:53
</code></pre></div></div>

<p>Ã€ ce moment, le fichier <code class="language-plaintext highlighter-rouge">b.txt</code> a Ã©tÃ© gÃ©nÃ©rÃ©.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>â”œâ”€â”€ b.txt
â”‚Â Â  â”œâ”€â”€ _SUCCESS
â”‚Â Â  â”œâ”€â”€ part-00000
â”‚Â Â  â””â”€â”€ part-00001
</code></pre></div></div>

<p>Ouvrez-le.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>b.txt/part-00000
<span class="o">(</span><span class="s1">'college'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'two'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'things'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'worked'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'on,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'of'</span>, 8<span class="o">)</span>
<span class="o">(</span><span class="s1">'school,'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'writing'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'programming.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s2">"didn't"</span>, 4<span class="o">)</span>
<span class="o">(</span><span class="s1">'then,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'probably'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'are:'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'short'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'awful.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'They'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'plot,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'just'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'characters'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'them'</span>, 2<span class="o">)</span>
...
</code></pre></div></div>

<p>Ã‡a a marchÃ© ! Cela ne vous semble-t-il pas familier ? Câ€™est comme dans lâ€™exemple avec <code class="language-plaintext highlighter-rouge">Hadoop</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>Ces fichiers sont appelÃ©s <code class="language-plaintext highlighter-rouge">HDFS</code>. On peut voir ici que <code class="language-plaintext highlighter-rouge">Spark</code> est utilisÃ© pour compter les mots. En quelques lignes seulement, cela semble trÃ¨s pratique.</p>

<h2 id="kubernetes">Kubernetes</h2>

<p>Passons maintenant Ã  <code class="language-plaintext highlighter-rouge">Kubernetes</code>, Ã©galement appelÃ© <code class="language-plaintext highlighter-rouge">k8s</code>, oÃ¹ le â€œ8â€ reprÃ©sente les 8 lettres omises entre le â€œKâ€ et le â€œsâ€. Il sâ€™agit dâ€™un systÃ¨me open-source conÃ§u pour automatiser le dÃ©ploiement, la mise Ã  lâ€™Ã©chelle et la gestion des applications conteneurisÃ©es.</p>

<p>Lâ€™outil en ligne de commande <code class="language-plaintext highlighter-rouge">kubectl</code> est utilisÃ© pour exÃ©cuter des commandes sur un cluster Kubernetes (k8s). Il permet de dÃ©ployer des applications, de visualiser et de gÃ©rer les ressources du cluster, ainsi que de consulter les journaux.</p>

<p>Il est Ã©galement possible dâ€™installer via Homebrew.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>kubectl
</code></pre></div></div>

<p>Journalisation des sorties :</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">==&gt;</span> TÃ©lÃ©chargement de https://homebrew.bintray.com/bottles/kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> TÃ©lÃ©chargement depuis https://d29vzk4ow07wi7.cloudfront.net/0b4f08bd1d47cb913d7cd4571e3394c6747dfbad7ff114c5589c8396c1085ecf?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Extraction de kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Avertissements
La complÃ©tion Bash a Ã©tÃ© installÃ©e dans :
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> RÃ©sumÃ©
ğŸº  /usr/local/Cellar/kubernetes-cli/1.20.1: 246 fichiers, 46.1 Mo
</code></pre></div></div>

<p>Installation terminÃ©e.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl
kubectl contrÃ´le le gestionnaire de cluster Kubernetes.
</code></pre></div></div>

<p>Pour plus dâ€™informations, consultez : https://kubernetes.io/docs/reference/kubectl/overview/</p>

<p>Commandes de base (DÃ©butant) :
  create        CrÃ©er une ressource Ã  partir dâ€™un fichier ou de stdin.
  expose        Prendre un contrÃ´leur de rÃ©plication, un service, un dÃ©ploiement ou un pod et lâ€™exposer en tant que nouveau service Kubernetes
  run           ExÃ©cuter une image spÃ©cifique sur le cluster
  set           DÃ©finir des fonctionnalitÃ©s spÃ©cifiques sur des objets</p>

<p>Commandes de base (intermÃ©diaires) :
  explain       Documentation des ressources
  get           Afficher une ou plusieurs ressources
  edit          Modifier une ressource sur le serveur
  delete        Supprimer des ressources par fichiers, stdin, ressources et noms, ou par ressources et sÃ©lecteur de label</p>

<p>Commandes de dÃ©ploiement :
  rollout       GÃ©rer le dÃ©ploiement dâ€™une ressource
  scale         DÃ©finir une nouvelle taille pour un Deployment, ReplicaSet ou Replication Controller
  autoscale     Mettre Ã  lâ€™Ã©chelle automatiquement un Deployment, ReplicaSet ou ReplicationController</p>

<p>Commandes de gestion de cluster :
  certificate   Modifier les ressources de certificat.
  cluster-info  Afficher les informations du cluster.
  top           Afficher lâ€™utilisation des ressources (CPU/MÃ©moire/Stockage).
  cordon        Marquer un nÅ“ud comme non planifiable.
  uncordon      Marquer un nÅ“ud comme planifiable.
  drain         Vider un nÅ“ud en prÃ©paration Ã  une maintenance.
  taint         Mettre Ã  jour les taints sur un ou plusieurs nÅ“uds.</p>

<p>Commandes de dÃ©pannage et de dÃ©bogage :
  describe      Afficher les dÃ©tails dâ€™une ressource spÃ©cifique ou dâ€™un groupe de ressources
  logs          Afficher les logs dâ€™un conteneur dans un pod
  attach        Se connecter Ã  un conteneur en cours dâ€™exÃ©cution
  exec          ExÃ©cuter une commande dans un conteneur
  port-forward  Rediriger un ou plusieurs ports locaux vers un pod
  proxy         Lancer un proxy vers le serveur API Kubernetes
  cp            Copier des fichiers et rÃ©pertoires vers et depuis des conteneurs
  auth          Inspecter les autorisations
  debug         CrÃ©er des sessions de dÃ©bogage pour le dÃ©pannage des charges de travail et des nÅ“uds</p>

<p>Commandes avancÃ©es :
  diff          Comparer la version en direct avec la version qui serait appliquÃ©e
  apply         Appliquer une configuration Ã  une ressource par nom de fichier ou stdin
  patch         Mettre Ã  jour un ou plusieurs champs dâ€™une ressource
  replace       Remplacer une ressource par nom de fichier ou stdin
  wait          ExpÃ©rimental : Attendre une condition spÃ©cifique sur une ou plusieurs ressources.
  kustomize     Construire une cible de kustomization Ã  partir dâ€™un rÃ©pertoire ou dâ€™une URL distante.</p>

<p>Commandes de configuration :
  label         Mettre Ã  jour les Ã©tiquettes sur une ressource
  annotate      Mettre Ã  jour les annotations sur une ressource
  completion    GÃ©nÃ©rer le code de complÃ©tion pour le shell spÃ©cifiÃ© (bash ou zsh)</p>

<p>Autres Commandes :
  api-resources Affiche les ressources API prises en charge sur le serveur
  api-versions  Affiche les versions API prises en charge sur le serveur, sous la forme â€œgroupe/versionâ€
  config        Modifie les fichiers kubeconfig
  plugin        Fournit des utilitaires pour interagir avec les plugins.
  version       Affiche les informations de version du client et du serveur</p>

<p>Utilisation :
  kubectl [flags] [options]</p>

<p>Utilisez â€œkubectl <commande> --help" pour obtenir plus d'informations sur une commande donnÃ©e.
Utilisez "kubectl options" pour obtenir une liste des options globales de ligne de commande (s'applique Ã  toutes les commandes).</commande></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
CrÃ©ons un fichier de configuration.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  minReadySeconds: 5
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
```shell
$ kubectl apply -f simple_deployment.yaml
La connexion au serveur localhost:8080 a Ã©tÃ© refusÃ©e - avez-vous spÃ©cifiÃ© le bon hÃ´te ou port ?
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl cluster-info
</code></pre></div></div>

<p>Pour dÃ©boguer et diagnostiquer davantage les problÃ¨mes du cluster, utilisez <code class="language-plaintext highlighter-rouge">kubectl cluster-info dump</code>.
La connexion au serveur localhost:8080 a Ã©tÃ© refusÃ©e - avez-vous spÃ©cifiÃ© le bon hÃ´te ou port ?</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Lorsque vous essayez de l'exÃ©cuter dans le terminal du site officiel.

```shell
$ start.sh
DÃ©marrage de Kubernetes...version de minikube : v1.8.1
commit : cbda04cf6bbe65e987ae52bb393c10099ab62014
* minikube v1.8.1 sur Ubuntu 18.04
* Utilisation du pilote none basÃ© sur la configuration utilisateur
* ExÃ©cution sur localhost (CPU=2, MÃ©moire=2460MB, Disque=145651MB) ...
* La version du systÃ¨me d'exploitation est Ubuntu 18.04.4 LTS
</code></pre></div></div>

<ul>
  <li>PrÃ©paration de Kubernetes v1.17.3 sur Docker 19.03.6 â€¦
    <ul>
      <li>kubelet.resolv-conf=/run/systemd/resolve/resolv.conf</li>
    </ul>
  </li>
  <li>Lancement de Kubernetes â€¦</li>
  <li>Activation des modules complÃ©mentaires : default-storageclass, storage-provisioner</li>
  <li>Configuration de lâ€™environnement local â€¦</li>
  <li>TerminÃ© ! kubectl est maintenant configurÃ© pour utiliser â€œminikubeâ€</li>
  <li>Le module complÃ©mentaire â€˜dashboardâ€™ est activÃ©
Kubernetes dÃ©marrÃ©
```</li>
</ul>

<p>Revenons Ã  notre terminal.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
<span class="nv">$ </span>kubectl version
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
La connexion au serveur localhost:8080 a Ã©tÃ© refusÃ©e - avez-vous spÃ©cifiÃ© le bon hÃ´te ou port ?
</code></pre></div></div>

<p>Il est intÃ©ressant de noter que lâ€™ajout de lâ€™option <code class="language-plaintext highlighter-rouge">--client</code> nâ€™a pas gÃ©nÃ©rÃ© dâ€™erreur.</p>

<p>La documentation indique quâ€™il faut dâ€™abord installer <code class="language-plaintext highlighter-rouge">Minikube</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>minikube
<span class="o">==&gt;</span> TÃ©lÃ©chargement de https://homebrew.bintray.com/bottles/minikube-1.16.0.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> TÃ©lÃ©chargement depuis https://d29vzk4ow07wi7.cloudfront.net/1b6d7d1b97b11b6b07e4fa531c2dc21770da290da9b2816f360fd923e00c85fc?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Extraction de minikube-1.16.0.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Notes
La complÃ©tion Bash a Ã©tÃ© installÃ©e dans :
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> RÃ©sumÃ©
ğŸº  /usr/local/Cellar/minikube/1.16.0: 8 fichiers, 64,6 Mo
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube start
ğŸ˜„  minikube v1.16.0 sur Darwin 11.2.2
ğŸ‰  minikube 1.18.1 est disponible <span class="o">!</span> TÃ©lÃ©chargez-le : https://github.com/kubernetes/minikube/releases/tag/v1.18.1
ğŸ’¡  Pour dÃ©sactiver cette notification, exÃ©cutez : <span class="s1">'minikube config set WantUpdateNotification false'</span>
</code></pre></div></div>

<p>âœ¨  SÃ©lection automatique du pilote virtualbox
ğŸ’¿  TÃ©lÃ©chargement de lâ€™image de dÃ©marrage de la VM â€¦
    &gt; minikube-v1.16.0.iso.sha256: 65 B / 65 B [â€”â€”â€”â€”-] 100.00% ? p/s 0s
    &gt; minikube-v1.16.0.iso: 212.62 MiB / 212.62 MiB [] 100.00% 5.32 MiB p/s 40s
ğŸ‘  DÃ©marrage du nÅ“ud de contrÃ´le plane minikube dans le cluster minikube
ğŸ’¾  TÃ©lÃ©chargement de Kubernetes v1.20.0 preload â€¦
    &gt; preloaded-images-k8s-v8-v1â€¦.: 491.00 MiB / 491.00 MiB  100.00% 7.52 MiB
ğŸ”¥  CrÃ©ation de la VM virtualbox (CPU=2, MÃ©moire=4000MB, Disque=20000MB) â€¦
â—  Cette VM rencontre des difficultÃ©s pour accÃ©der Ã  https://k8s.gcr.io
ğŸ’¡  Pour tÃ©lÃ©charger de nouvelles images externes, vous devrez peut-Ãªtre configurer un proxy : https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
ğŸ³  PrÃ©paration de Kubernetes v1.20.0 sur Docker 20.10.0 â€¦
    â–ª GÃ©nÃ©ration des certificats et clÃ©s â€¦
    â–ª DÃ©marrage du contrÃ´le plane â€¦
    â–ª Configuration des rÃ¨gles RBAC â€¦
ğŸ”  VÃ©rification des composants Kubernetesâ€¦
ğŸŒŸ  Modules complÃ©mentaires activÃ©s : storage-provisioner, default-storageclass
ğŸ„  TerminÃ© ! kubectl est maintenant configurÃ© pour utiliser le cluster â€œminikubeâ€ et lâ€™espace de noms â€œdefaultâ€ par dÃ©faut</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Ensuite, accÃ©dez Ã  ce cluster.

```shell
$ kubectl get po -A
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
kube-system   coredns-74ff55c5b-ndbcr            1/1     Running   0          60s
kube-system   etcd-minikube                      0/1     Running   0          74s
kube-system   kube-apiserver-minikube            1/1     Running   0          74s
kube-system   kube-controller-manager-minikube   1/1     Running   0          74s
kube-system   kube-proxy-g2296                   1/1     Running   0          60s
kube-system   kube-scheduler-minikube            0/1     Running   0          74s
kube-system   storage-provisioner                1/1     Running   1          74s
</code></pre></div></div>

<p>Pour ouvrir le tableau de bord de <code class="language-plaintext highlighter-rouge">minikube</code>, utilisez la commande suivante :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube dashboard
</code></pre></div></div>

<p>Cela ouvrira le tableau de bord de Kubernetes dans votre navigateur par dÃ©faut.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube dashboard
ğŸ”Œ  Activation <span class="nb">du </span>tableau de bord ...
ğŸ¤”  VÃ©rification de l<span class="s1">'Ã©tat du tableau de bord ...
ğŸš€  Lancement du proxy ...
ğŸ¤”  VÃ©rification de l'</span>Ã©tat <span class="nb">du </span>proxy ...
ğŸ‰  Ouverture de http://127.0.0.1:50030/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ dans votre navigateur par dÃ©faut...
</code></pre></div></div>

<p><img src="assets/images/distributed/k8s.png" alt="k8s" /></p>

<p>Comment lâ€™Ã©teindre ?</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube
minikube provisionne et gÃ¨re des clusters Kubernetes locaux optimisÃ©s pour les flux de travail de dÃ©veloppement.
</code></pre></div></div>

<p>Commandes de base :
  start          DÃ©marre un cluster Kubernetes local
  status         Obtient le statut dâ€™un cluster Kubernetes local
  stop           ArrÃªte un cluster Kubernetes en cours dâ€™exÃ©cution
  delete         Supprime un cluster Kubernetes local
  dashboard      AccÃ¨de au tableau de bord Kubernetes en cours dâ€™exÃ©cution dans le cluster minikube
  pause          Met Kubernetes en pause
  unpause        Reprend Kubernetes aprÃ¨s une pause</p>

<p>Commandes pour les images :
  docker-env     Configurer lâ€™environnement pour utiliser le dÃ©mon Docker de minikube
  podman-env     Configurer lâ€™environnement pour utiliser le service Podman de minikube
  cache          Ajouter, supprimer ou pousser une image locale dans minikube</p>

<p>Commandes de configuration et de gestion :
  addons         Activer ou dÃ©sactiver un module complÃ©mentaire de minikube
  config         Modifier les valeurs de configuration persistantes
  profile        Obtenir ou lister les profils actuels (clusters)
  update-context Mettre Ã  jour kubeconfig en cas de changement dâ€™adresse IP ou de port</p>

<p>Commandes de rÃ©seau et de connectivitÃ© :
  service        Retourne une URL pour se connecter Ã  un service
  tunnel         Se connecter aux services LoadBalancer</p>

<p>Commandes avancÃ©es :
  mount          Monte le rÃ©pertoire spÃ©cifiÃ© dans minikube
  ssh            Se connecter Ã  lâ€™environnement minikube (pour le dÃ©bogage)
  kubectl        ExÃ©cute une version de kubectl correspondant Ã  la version du cluster
  node           Ajouter, supprimer ou lister des nÅ“uds supplÃ©mentaires</p>

<p>Commandes de dÃ©pannage :
  ssh-key        RÃ©cupÃ¨re le chemin de la clÃ© dâ€™identitÃ© SSH du nÅ“ud spÃ©cifiÃ©
  ssh-host       RÃ©cupÃ¨re la clÃ© hÃ´te SSH du nÅ“ud spÃ©cifiÃ©
  ip             RÃ©cupÃ¨re lâ€™adresse IP du nÅ“ud spÃ©cifiÃ©
  logs           Retourne les journaux pour dÃ©boguer un cluster Kubernetes local
  update-check   Affiche les numÃ©ros de version actuelle et la plus rÃ©cente
  version        Affiche la version de minikube</p>

<p>Autres commandes :
  completion     GÃ©nÃ©rer la complÃ©tion de commande pour un shell</p>

<p>Utilisez â€œminikube <commande> --help" pour obtenir plus d'informations sur une commande donnÃ©e.</commande></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Il semble que ce soit `minikube stop`.

Revenons Ã  `kubernetes`, maintenant tout fonctionne correctement.

```shell
$ kubectl cluster-info
Le plan de contrÃ´le de Kubernetes est en cours d'exÃ©cution Ã  l'adresse https://192.168.99.100:8443
KubeDNS est en cours d'exÃ©cution Ã  l'adresse https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
</code></pre></div></div>

<p>Pour dÃ©boguer et diagnostiquer davantage les problÃ¨mes du cluster, utilisez <code class="language-plaintext highlighter-rouge">kubectl cluster-info dump</code>.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Lorsque nous ouvrons `https://192.168.99.100:8443`, le navigateur affiche :

```json
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "Ã‰chec",
  "message": "interdit : L'utilisateur \"system:anonymous\" ne peut pas accÃ©der au chemin \"/\"",
  "reason": "Interdit",
  "details": {
    
  },
  "code": 403
}
</code></pre></div></div>

<p>AccÃ©dez Ã  <code class="language-plaintext highlighter-rouge">https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</code> :</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Status"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"apiVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Ã‰chec"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">"services </span><span class="se">\"</span><span class="s2">kube-dns:dns</span><span class="se">\"</span><span class="s2"> est interdit : L'utilisateur </span><span class="se">\"</span><span class="s2">system:anonymous</span><span class="se">\"</span><span class="s2"> ne peut pas accÃ©der Ã  la ressource </span><span class="se">\"</span><span class="s2">services/proxy</span><span class="se">\"</span><span class="s2"> dans le groupe d'API </span><span class="se">\"\"</span><span class="s2"> dans l'espace de noms </span><span class="se">\"</span><span class="s2">kube-system</span><span class="se">\"</span><span class="s2">"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"reason"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Interdit"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"details"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-dns:dns"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"services"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"code"</span><span class="p">:</span><span class="w"> </span><span class="mi">403</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Essayons la configuration que nous venons de voir.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> simple_deployment.yaml
deployment.apps/nginx-deployment crÃ©Ã©
</code></pre></div></div>

<p>Il y a un petit problÃ¨me. Cependant, jusquâ€™Ã  prÃ©sent, nous avons rÃ©ussi Ã  faire fonctionner <code class="language-plaintext highlighter-rouge">kubernetes</code>. Terminons cela pour lâ€™instant. Nous y reviendrons plus tard.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube stop
âœ‹  ArrÃªt <span class="nb">du </span>nÅ“ud <span class="s2">"minikube"</span>  ...
ğŸ›‘  1 nÅ“ud arrÃªtÃ©.
</code></pre></div></div>

<p>VÃ©rifiez si câ€™est terminÃ©.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>w<span class="nv">$ </span>minikube dashboard
ğŸ¤·  Le nÅ“ud <span class="nb">du </span>plan de contrÃ´le doit Ãªtre en cours d<span class="s1">'exÃ©cution pour cette commande
ğŸ‘‰  Pour dÃ©marrer un cluster, exÃ©cutez : "minikube start"
</span></code></pre></div></div>

<h2 id="docker">Docker</h2>

<p><code class="language-plaintext highlighter-rouge">Docker</code> est Ã©galement une plateforme de conteneurs qui aide Ã  accÃ©lÃ©rer la crÃ©ation, le partage et lâ€™exÃ©cution dâ€™applications modernes. TÃ©lÃ©chargez lâ€™application depuis le site officiel.</p>

<p><img src="assets/images/distributed/docker.png" alt="docker" /></p>

<p>Lâ€™utilisation du client est un peu lente. Utilisons la ligne de commande.</p>

<div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker
</code></pre></div></div>

<p>Utilisation : docker [OPTIONS] COMMANDE</p>

<p>Un runtime autonome pour les conteneurs</p>

<p>Options :
      â€“config string      Emplacement des fichiers de configuration du client (par dÃ©faut â€œ/Users/lzw/.dockerâ€)
  -c, â€“context string     Nom du contexte Ã  utiliser pour se connecter au dÃ©mon (remplace la variable dâ€™environnement DOCKER_HOST et le contexte par dÃ©faut dÃ©fini avec â€œdocker context useâ€)
  -D, â€“debug              Activer le mode dÃ©bogage
  -H, â€“host list          Socket(s) du dÃ©mon au(x)quel(s) se connecter
  -l, â€“log-level string   DÃ©finir le niveau de journalisation (â€œdebugâ€|â€infoâ€|â€warnâ€|â€errorâ€|â€fatalâ€) (par dÃ©faut â€œinfoâ€)
      â€“tls                Utiliser TLS ; implicite avec â€“tlsverify
      â€“tlscacert string   Faire confiance uniquement aux certificats signÃ©s par cette CA (par dÃ©faut â€œ/Users/lzw/.docker/ca.pemâ€)
      â€“tlscert string     Chemin vers le fichier de certificat TLS (par dÃ©faut â€œ/Users/lzw/.docker/cert.pemâ€)
      â€“tlskey string      Chemin vers le fichier de clÃ© TLS (par dÃ©faut â€œ/Users/lzw/.docker/key.pemâ€)
      â€“tlsverify          Utiliser TLS et vÃ©rifier le serveur distant
  -v, â€“version            Afficher les informations de version et quitter</p>

<p>Commandes de gestion :
  app*        Docker App (Docker Inc., v0.9.1-beta3)
  builder     GÃ©rer les builds
  buildx*     Construire avec BuildKit (Docker Inc., v0.5.1-docker)
  config      GÃ©rer les configurations Docker
  container   GÃ©rer les conteneurs
  context     GÃ©rer les contextes
  image       GÃ©rer les images
  manifest    GÃ©rer les manifestes dâ€™images Docker et les listes de manifestes
  network     GÃ©rer les rÃ©seaux
  node        GÃ©rer les nÅ“uds Swarm
  plugin      GÃ©rer les plugins
  scan*       Docker Scan (Docker Inc., v0.5.0)
  secret      GÃ©rer les secrets Docker
  service     GÃ©rer les services
  stack       GÃ©rer les stacks Docker
  swarm       GÃ©rer Swarm
  system      GÃ©rer Docker
  trust       GÃ©rer la confiance sur les images Docker
  volume      GÃ©rer les volumes</p>

<p>Commandes :
  attach      Attacher les flux dâ€™entrÃ©e, de sortie et dâ€™erreur standard locaux Ã  un conteneur en cours dâ€™exÃ©cution
  build       Construire une image Ã  partir dâ€™un Dockerfile
  commit      CrÃ©er une nouvelle image Ã  partir des modifications dâ€™un conteneur
  cp          Copier des fichiers/dossiers entre un conteneur et le systÃ¨me de fichiers local
  create      CrÃ©er un nouveau conteneur
  diff        Inspecter les modifications apportÃ©es aux fichiers ou rÃ©pertoires sur le systÃ¨me de fichiers dâ€™un conteneur
  events      Obtenir des Ã©vÃ©nements en temps rÃ©el depuis le serveur
  exec        ExÃ©cuter une commande dans un conteneur en cours dâ€™exÃ©cution
  export      Exporter le systÃ¨me de fichiers dâ€™un conteneur sous forme dâ€™archive tar
  history     Afficher lâ€™historique dâ€™une image
  images      Lister les images
  import      Importer le contenu dâ€™une archive tar pour crÃ©er une image de systÃ¨me de fichiers
  info        Afficher des informations systÃ¨me globales
  inspect     Retourner des informations de bas niveau sur les objets Docker
  kill        Tuer un ou plusieurs conteneurs en cours dâ€™exÃ©cution
  load        Charger une image Ã  partir dâ€™une archive tar ou de STDIN
  login       Se connecter Ã  un registre Docker
  logout      Se dÃ©connecter dâ€™un registre Docker
  logs        RÃ©cupÃ©rer les logs dâ€™un conteneur
  pause       Suspendre tous les processus dans un ou plusieurs conteneurs
  port        Lister les mappages de ports ou un mappage spÃ©cifique pour le conteneur
  ps          Lister les conteneurs
  pull        TÃ©lÃ©charger une image ou un dÃ©pÃ´t depuis un registre
  push        Envoyer une image ou un dÃ©pÃ´t vers un registre
  rename      Renommer un conteneur
  restart     RedÃ©marrer un ou plusieurs conteneurs
  rm          Supprimer un ou plusieurs conteneurs
  rmi         Supprimer une ou plusieurs images
  run         ExÃ©cuter une commande dans un nouveau conteneur
  save        Sauvegarder une ou plusieurs images dans une archive tar (streamÃ©e vers STDOUT par dÃ©faut)
  search      Rechercher des images sur Docker Hub
  start       DÃ©marrer un ou plusieurs conteneurs arrÃªtÃ©s
  stats       Afficher un flux en direct des statistiques dâ€™utilisation des ressources des conteneurs
  stop        ArrÃªter un ou plusieurs conteneurs en cours dâ€™exÃ©cution
  tag         CrÃ©er une balise TARGET_IMAGE qui fait rÃ©fÃ©rence Ã  SOURCE_IMAGE
  top         Afficher les processus en cours dâ€™exÃ©cution dâ€™un conteneur
  unpause     Reprendre tous les processus dans un ou plusieurs conteneurs
  update      Mettre Ã  jour la configuration dâ€™un ou plusieurs conteneurs
  version     Afficher les informations de version de Docker
  wait        Bloquer jusquâ€™Ã  ce quâ€™un ou plusieurs conteneurs sâ€™arrÃªtent, puis afficher leurs codes de sortie</p>

<p>ExÃ©cutez â€˜docker COMMANDE â€“helpâ€™ pour obtenir plus dâ€™informations sur une commande.</p>

<p>Pour obtenir plus dâ€™aide sur Docker, consultez nos guides sur https://docs.docker.com/go/guides/</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Suivons le tutoriel pour essayer.

```shell
$ docker run -d -p 80:80 docker/getting-started
Unable to find image 'docker/getting-started:latest' locally
latest: Pulling from docker/getting-started
aad63a933944: Pull complete
b14da7a62044: Pull complete
343784d40d66: Pull complete
6f617e610986: Pull complete
Digest: sha256:d2c4fb0641519ea208f20ab03dc40ec2a5a53fdfbccca90bef14f870158ed577
Status: Downloaded newer image for docker/getting-started:latest
815f13fc8f99f6185257980f74c349e182842ca572fe60ff62cbb15641199eaf
docker: Error response from daemon: Les ports ne sont pas disponibles : Ã©coute tcp 0.0.0.0:80: bind: adresse dÃ©jÃ  utilisÃ©e.
</code></pre></div></div>

<p>Changez le port.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:80 docker/getting-started
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p><img src="assets/images/distributed/docker_run.png" alt="docker_run" /></p>

<p>Ouvrez votre navigateur, cela signifie que nous avons rÃ©ussi Ã  faire fonctionner <code class="language-plaintext highlighter-rouge">docker</code>.</p>

<p><img src="assets/images/distributed/browser.png" alt="navigateur" /></p>

<p>ArrÃªtez le conteneur. Utilisez lâ€™<code class="language-plaintext highlighter-rouge">ID</code> retournÃ© prÃ©cÃ©demment.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker stop 45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p>Ã€ ce moment-lÃ , le site web Ã©tait dÃ©jÃ  inaccessible.</p>

<p>Cela montre que <code class="language-plaintext highlighter-rouge">docker</code> ressemble Ã  une machine virtuelle.</p>

<h2 id="flink">Flink</h2>

<p>Ouvrez le site officiel.</p>

<p><img src="assets/images/distributed/flink-home-graphic.png" alt="flink-home-graphic" /></p>

<p><code class="language-plaintext highlighter-rouge">Flink</code> est un calcul <code class="language-plaintext highlighter-rouge">Stateful</code> des flux de donnÃ©es. Mais quâ€™est-ce que signifie <code class="language-plaintext highlighter-rouge">Stateful</code> ? Pour lâ€™instant, je ne comprends pas encore. Cependant, le schÃ©ma ci-dessus est trÃ¨s intÃ©ressant. Essayons de lâ€™explorer.</p>

<p>Il est dit quâ€™un environnement Java est nÃ©cessaire.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>java <span class="nt">-version</span>
java version <span class="s2">"1.8.0_151"</span>
Java<span class="o">(</span>TM<span class="o">)</span> SE Runtime Environment <span class="o">(</span>build 1.8.0_151-b12<span class="o">)</span>
Java HotSpot<span class="o">(</span>TM<span class="o">)</span> 64-Bit Server VM <span class="o">(</span>build 25.151-b12, mixed mode<span class="o">)</span>
</code></pre></div></div>

<p>TÃ©lÃ©chargez la derniÃ¨re version <code class="language-plaintext highlighter-rouge">flink-1.12.2-bin-scala_2.11.tar</code> depuis le site officiel.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/start-cluster.sh
DÃ©marrage <span class="nb">du </span>cluster.
DÃ©marrage <span class="nb">du </span>dÃ©mon standalonesession sur l<span class="s1">'hÃ´te lzwjava.
DÃ©marrage du dÃ©mon taskexecutor sur l'</span>hÃ´te lzwjava.
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/flink run examples/streaming/WordCount.jar
ExÃ©cution de l<span class="s1">'exemple WordCount avec le jeu de donnÃ©es d'</span>entrÃ©e par dÃ©faut.
Utilisez <span class="nt">--input</span> pour spÃ©cifier un fichier d<span class="s1">'entrÃ©e.
Affichage du rÃ©sultat sur stdout. Utilisez --output pour spÃ©cifier le chemin de sortie.
Le job a Ã©tÃ© soumis avec l'</span>ID de job 60f37647c20c2a6654359bd34edab807
L<span class="s1">'exÃ©cution du programme est terminÃ©e
Le job avec l'</span>ID 60f37647c20c2a6654359bd34edab807 est terminÃ©.
Temps d<span class="s1">'exÃ©cution du job : 757 ms
</span></code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">tail </span>log/flink-<span class="k">*</span><span class="nt">-taskexecutor-</span><span class="k">*</span>.out
<span class="o">(</span>nymph,1<span class="o">)</span>
<span class="o">(</span><span class="k">in</span>,3<span class="o">)</span>
<span class="o">(</span>thy,1<span class="o">)</span>
<span class="o">(</span>orisons,1<span class="o">)</span>
<span class="o">(</span>be,4<span class="o">)</span>
<span class="o">(</span>all,2<span class="o">)</span>
<span class="o">(</span>my,1<span class="o">)</span>
<span class="o">(</span>sins,1<span class="o">)</span>
<span class="o">(</span>remember,1<span class="o">)</span>
<span class="o">(</span>d,4<span class="o">)</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/stop-cluster.sh
ArrÃªt <span class="nb">du </span>dÃ©mon taskexecutor <span class="o">(</span>pid : 41812<span class="o">)</span> sur l<span class="s1">'hÃ´te lzwjava.
</span></code></pre></div></div>

<p>Oui, câ€™est parti. On voit que câ€™est trÃ¨s similaire Ã  <code class="language-plaintext highlighter-rouge">Spark</code>.</p>

<h2 id="kylin">Kylin</h2>

<p>AccÃ©dez au site officiel.</p>

<blockquote>
  <p>Apache Kylinâ„¢ est un entrepÃ´t de donnÃ©es analytiques distribuÃ© et open source conÃ§u pour le Big Data. Il a Ã©tÃ© crÃ©Ã© pour offrir des capacitÃ©s OLAP (Traitement Analytique en Ligne) Ã  lâ€™Ã¨re du Big Data. En rÃ©inventant la technologie des cubes multidimensionnels et du prÃ©calcul sur Hadoop et Spark, Kylin est capable dâ€™atteindre une vitesse de requÃªte quasi constante, quelle que soit la croissance du volume de donnÃ©es. En rÃ©duisant la latence des requÃªtes de plusieurs minutes Ã  moins dâ€™une seconde, Kylin ramÃ¨ne lâ€™analyse en ligne au cÅ“ur du Big Data.</p>
</blockquote>

<blockquote>
  <p>Apache Kylinâ„¢ vous permet dâ€™interroger des milliards de lignes avec une latence infÃ©rieure Ã  la seconde en 3 Ã©tapes.</p>

  <ol>
    <li>Identifiez un schÃ©ma en Ã©toile ou en flocon de neige sur Hadoop.</li>
    <li>Construisez un Cube Ã  partir des tables identifiÃ©es.</li>
    <li>Interrogez en utilisant ANSI-SQL et obtenez des rÃ©sultats en moins dâ€™une seconde, via ODBC, JDBC ou une API RESTful.</li>
  </ol>
</blockquote>

<p><img src="assets/images/distributed/kylin_diagram.png" alt="kylin_diagram" /></p>

<p>Cela fait essentiellement partie de lâ€™analyse des big data. On peut lâ€™utiliser pour effectuer des recherches trÃ¨s rapidement. Il sert de pont.</p>

<p>Malheureusement, pour le moment, cela ne fonctionne que dans un environnement <code class="language-plaintext highlighter-rouge">Linux</code>. Je reviendrai bricoler cela plus tard.</p>

<h2 id="mongodb">MongoDB</h2>

<p>Câ€™est aussi une base de donnÃ©es. Essayez de lâ€™installer.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew tap mongodb/brew
<span class="o">==&gt;</span> Tapping mongodb/brew
Clonage dans <span class="s1">'/usr/local/Homebrew/Library/Taps/mongodb/homebrew-brew'</span>...
remote: Ã‰numÃ©ration des objets: 63, fait.
remote: Comptage des objets: 100% <span class="o">(</span>63/63<span class="o">)</span>, fait.
remote: Compression des objets: 100% <span class="o">(</span>62/62<span class="o">)</span>, fait.
remote: Total 566 <span class="o">(</span>delta 21<span class="o">)</span>, rÃ©utilisÃ©s 6 <span class="o">(</span>delta 1<span class="o">)</span>, rÃ©utilisÃ©s <span class="nb">du </span>pack 503
RÃ©ception des objets: 100% <span class="o">(</span>566/566<span class="o">)</span>, 121.78 KiB | 335.00 KiB/s, fait.
RÃ©solution des deltas: 100% <span class="o">(</span>259/259<span class="o">)</span>, fait.
11 formules ajoutÃ©es <span class="o">(</span>39 fichiers, 196.2KB<span class="o">)</span><span class="nb">.</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>mongodb-community@4.4
<span class="o">==&gt;</span> Installation de mongodb-community depuis mongodb/brew
<span class="o">==&gt;</span> TÃ©lÃ©chargement de https://fastdl.mongodb.org/tools/db/mongodb-database-tools-macos-x86_64-100.3.0.zip
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> TÃ©lÃ©chargement de https://fastdl.mongodb.org/osx/mongodb-macos-x86_64-4.4.3.tgz
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Installation des dÃ©pendances pour mongodb/brew/mongodb-community: mongodb-database-tools
<span class="o">==&gt;</span> Installation de la dÃ©pendance mongodb/brew/mongodb-community: mongodb-database-tools
Erreur : L<span class="s1">'Ã©tape `brew link` ne s'</span>est pas terminÃ©e avec succÃ¨s
La formule a Ã©tÃ© construite, mais n<span class="s1">'est pas liÃ©e symboliquement dans /usr/local
Impossible de crÃ©er un lien symbolique pour bin/bsondump
La cible /usr/local/bin/bsondump
est un lien symbolique appartenant Ã  mongodb. Vous pouvez le dÃ©lier :
  brew unlink mongodb
</span></code></pre></div></div>

<p>Pour forcer le lien et Ã©craser tous les fichiers en conflit :
  brew link â€“overwrite mongodb-database-tools</p>

<p>Pour lister tous les fichiers qui seraient supprimÃ©s :
  brew link â€“overwrite â€“dry-run mongodb-database-tools</p>

<p>Les fichiers potentiellement en conflit sont :
/usr/local/bin/bsondump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/bsondump
/usr/local/bin/mongodump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongodump
/usr/local/bin/mongoexport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoexport
/usr/local/bin/mongofiles -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongofiles
/usr/local/bin/mongoimport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoimport
/usr/local/bin/mongorestore -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongorestore
/usr/local/bin/mongostat -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongostat
/usr/local/bin/mongotop -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongotop
==&gt; RÃ©sumÃ©
ğŸº  /usr/local/Cellar/mongodb-database-tools/100.3.0: 13 fichiers, 154 Mo, construit en 11 secondes
==&gt; Installation de mongodb/brew/mongodb-community
Erreur : Lâ€™Ã©tape <code class="language-plaintext highlighter-rouge">brew link</code> ne sâ€™est pas terminÃ©e avec succÃ¨s
La formule a Ã©tÃ© construite, mais nâ€™est pas liÃ©e symboliquement dans /usr/local
Impossible de crÃ©er un lien symbolique pour bin/mongo
La cible /usr/local/bin/mongo
est un lien symbolique appartenant Ã  mongodb. Vous pouvez le dissocier :
  brew unlink mongodb</p>

<p>Pour forcer le lien et Ã©craser tous les fichiers en conflit :
  brew link â€“overwrite mongodb-community</p>

<p>Pour lister tous les fichiers qui seraient supprimÃ©s :
  brew link â€“overwrite â€“dry-run mongodb-community</p>

<p>Les fichiers potentiellement en conflit sont :
/usr/local/bin/mongo -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongo
/usr/local/bin/mongod -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongod
/usr/local/bin/mongos -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongos
==&gt; Avertissements
Pour dÃ©marrer mongodb/brew/mongodb-community avec launchd maintenant et redÃ©marrer Ã  la connexion :
  brew services start mongodb/brew/mongodb-community
Ou, si vous ne voulez/pas besoin dâ€™un service en arriÃ¨re-plan, vous pouvez simplement exÃ©cuter :
  mongod â€“config /usr/local/etc/mongod.conf
==&gt; RÃ©sumÃ©
ğŸº  /usr/local/Cellar/mongodb-community/4.4.3: 11 fichiers, 156,8 Mo, construit en 10 secondes
==&gt; Avertissements
==&gt; mongodb-community
Pour dÃ©marrer mongodb/brew/mongodb-community avec launchd maintenant et redÃ©marrer Ã  la connexion :
  brew services start mongodb/brew/mongodb-community
Ou, si vous ne voulez/pas besoin dâ€™un service en arriÃ¨re-plan, vous pouvez simplement exÃ©cuter :
  mongod â€“config /usr/local/etc/mongod.conf</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
J'avais prÃ©cÃ©demment installÃ© une ancienne version. Je vais supprimer les liens.

```shell
$ brew unlink mongodb
DÃ©liaison de /usr/local/Cellar/mongodb/3.0.7... 11 liens symboliques supprimÃ©s
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--version</span>
db version v4.4.3
Build Info: <span class="o">{</span>
    <span class="s2">"version"</span>: <span class="s2">"4.4.3"</span>,
    <span class="s2">"gitVersion"</span>: <span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span>,
    <span class="s2">"modules"</span>: <span class="o">[]</span>,
    <span class="s2">"allocator"</span>: <span class="s2">"system"</span>,
    <span class="s2">"environment"</span>: <span class="o">{</span>
        <span class="s2">"distarch"</span>: <span class="s2">"x86_64"</span>,
        <span class="s2">"target_arch"</span>: <span class="s2">"x86_64"</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Ensuite, exÃ©cutez <code class="language-plaintext highlighter-rouge">mongod</code> pour dÃ©marrer le serveur de base de donnÃ©es MongoDB. Cependant, lors du premier dÃ©marrage, il a indiquÃ© que <code class="language-plaintext highlighter-rouge">/data/db</code> nâ€™existait pas. Nous avons donc crÃ©Ã© un rÃ©pertoire, <code class="language-plaintext highlighter-rouge">~/mongodb</code>, pour y stocker les fichiers de la base de donnÃ©es.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--dbpath</span> ~/mongodb
</code></pre></div></div>

<p>Sortie :</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.838+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23285</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"DÃ©sactivation automatique de TLS 1.0, pour forcer l'activation de TLS 1.0, spÃ©cifiez --sslDisabledProtocols 'none'"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"W"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"ASIO"</span><span class="p">,</span><span class="w">     </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">22601</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Aucune couche de transport configurÃ©e lors du dÃ©marrage de l'interface rÃ©seau"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"NETWORK"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4648602</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Utilisation implicite de TCP FastOpen."</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"STORAGE"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4615611</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"DÃ©marrage de MongoDB"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"pid"</span><span class="p">:</span><span class="mi">46256</span><span class="p">,</span><span class="nl">"port"</span><span class="p">:</span><span class="mi">27017</span><span class="p">,</span><span class="nl">"dbPath"</span><span class="p">:</span><span class="s2">"/Users/lzw/mongodb"</span><span class="p">,</span><span class="nl">"architecture"</span><span class="p">:</span><span class="s2">"64-bit"</span><span class="p">,</span><span class="nl">"host"</span><span class="p">:</span><span class="s2">"lzwjava"</span><span class="p">}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23403</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Informations de construction"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"buildInfo"</span><span class="p">:{</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"4.4.3"</span><span class="p">,</span><span class="nl">"gitVersion"</span><span class="p">:</span><span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span><span class="p">,</span><span class="nl">"modules"</span><span class="p">:[],</span><span class="nl">"allocator"</span><span class="p">:</span><span class="s2">"system"</span><span class="p">,</span><span class="nl">"environment"</span><span class="p">:{</span><span class="nl">"distarch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">,</span><span class="nl">"target_arch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">}}}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.843+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">51765</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"SystÃ¨me d'exploitation"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"os"</span><span class="p">:{</span><span class="nl">"name"</span><span class="p">:</span><span class="s2">"Mac OS X"</span><span class="p">,</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"20.3.0"</span><span class="p">}}}</span><span class="w">
</span><span class="err">...</span><span class="w">
</span></code></pre></div></div>

<p>On peut voir que tout est au format <code class="language-plaintext highlighter-rouge">JSON</code>. MongoDB enregistre tous les fichiers de donnÃ©es au format <code class="language-plaintext highlighter-rouge">JSON</code>. Ensuite, ouvrez un autre onglet de terminal.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongo
MongoDB shell version v4.4.3
connexion Ã  : mongodb://127.0.0.1:27017/?compressors<span class="o">=</span>disabled&amp;gssapiServiceName<span class="o">=</span>mongodb
Session implicite : session <span class="o">{</span> <span class="s2">"id"</span> : UUID<span class="o">(</span><span class="s2">"4f55c561-70d3-4289-938d-4b90a284891f"</span><span class="o">)</span> <span class="o">}</span>
Version <span class="nb">du </span>serveur MongoDB : 4.4.3
<span class="nt">---</span>
Le serveur a gÃ©nÃ©rÃ© ces avertissements de dÃ©marrage lors <span class="nb">du </span>dÃ©marrage :
        2021-03-11T18:17:33.743+08:00 : Le contrÃ´le d<span class="s1">'accÃ¨s n'</span>est pas activÃ© pour la base de donnÃ©es. L<span class="s1">'accÃ¨s en lecture et en Ã©criture aux donnÃ©es et Ã  la configuration est illimitÃ©.
        2021-03-11T18:17:33.743+08:00 : Ce serveur est liÃ© Ã  localhost. Les systÃ¨mes distants ne pourront pas se connecter Ã  ce serveur. DÃ©marrez le serveur avec --bind_ip &lt;adresse&gt; pour spÃ©cifier les adresses IP auxquelles il doit rÃ©pondre, ou avec --bind_ip_all pour le lier Ã  toutes les interfaces. Si ce comportement est souhaitÃ©, dÃ©marrez le serveur avec --bind_ip 127.0.0.1 pour dÃ©sactiver cet avertissement.
        2021-03-11T18:17:33.743+08:00 : Les limites de ressources (soft rlimits) sont trop basses.
        2021-03-11T18:17:33.743+08:00 :         valeur actuelle : 4864
        2021-03-11T18:17:33.743+08:00 :         minimum recommandÃ© : 64000
---
---
        Activez le service de surveillance cloud gratuit de MongoDB, qui recevra et affichera
        des mÃ©triques sur votre dÃ©ploiement (utilisation du disque, CPU, statistiques des opÃ©rations, etc.).
</span></code></pre></div></div>

<p>Les donnÃ©es de surveillance seront disponibles sur un site web MongoDB avec une URL unique accessible Ã  vous et Ã  toute personne avec qui vous partagez lâ€™URL. MongoDB peut utiliser ces informations pour amÃ©liorer ses produits et vous suggÃ©rer des produits MongoDB ainsi que des options de dÃ©ploiement.</p>

<p>Pour activer la surveillance gratuite, exÃ©cutez la commande suivante : <code class="language-plaintext highlighter-rouge">db.enableFreeMonitoring()</code><br />
Pour dÃ©sactiver dÃ©finitivement ce rappel, exÃ©cutez la commande suivante : <code class="language-plaintext highlighter-rouge">db.disableFreeMonitoring()</code></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Ensuite, vous pouvez essayer d'insÃ©rer des donnÃ©es et de les interroger.

```shell
&gt; db.inventory.insertOne(
...    { item: "canvas", qty: 100, tags: ["cotton"], size: { h: 28, w: 35.5, uom: "cm" } }
... )
{
	"acknowledged" : true,
	"insertedId" : ObjectId("6049ef91b653541cf355facb")
}
&gt;
&gt; db.inventory.find()
{ "_id" : ObjectId("6049ef91b653541cf355facb"), "item" : "canvas", "qty" : 100, "tags" : [ "cotton" ], "size" : { "h" : 28, "w" : 35.5, "uom" : "cm" } }
</code></pre></div></div>

<h2 id="enfin">Enfin</h2>

<p>ArrÃªtons-nous ici pour le moment. Nous aborderons dâ€™autres outils par la suite. Quelle est la signification de tout cela ? Il sâ€™agit probablement de tracer dâ€™abord une ligne directrice. Le dÃ©but est toujours difficile, mais nous avons dÃ©jÃ  parcouru tout cela dâ€™un seul coup. Cela nous donne confiance, et maintenant, il ne reste plus quâ€™Ã  explorer davantage ces logiciels.</p>

<h2 id="exercice">Exercice</h2>

<ul>
  <li>Les Ã©tudiants explorent de maniÃ¨re similaire comme ci-dessus.</li>
</ul>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-fr" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
