<!DOCTYPE html>
<html lang=" en-US">

<head>
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">

  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Zhiwei Li"
    href="https://lzwjava.github.io/feeds/feed.xml" />

  <title>Introduction au Cloud Computing et au Big Data</title>

  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
          data-cf-beacon='{"token": "70fc8c466cc1445098b3fc6f209c22c2"}'>
  </script>

  <!-- 
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66656236-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-66656236-1');
  </script>
   -->
  <meta charset="UTF-8">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Introduction au Cloud Computing et au Big Data | Zhiwei Li</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Introduction au Cloud Computing et au Big Data" />
<meta name="author" content="Zhiwei Li" />
<meta property="og:locale" content="fr" />
<meta name="description" content="Cette leçon couvre les sujets suivants :" />
<meta property="og:description" content="Cette leçon couvre les sujets suivants :" />
<link rel="canonical" href="https://lzwjava.github.io/distributed-fr" />
<meta property="og:url" content="https://lzwjava.github.io/distributed-fr" />
<meta property="og:site_name" content="Zhiwei Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-10T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Introduction au Cloud Computing et au Big Data" />
<meta name="twitter:site" content="@lzwjava" />
<meta name="twitter:creator" content="@lzwjava" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhiwei Li"},"dateModified":"2021-03-10T00:00:00+08:00","datePublished":"2021-03-10T00:00:00+08:00","description":"Cette leçon couvre les sujets suivants :","headline":"Introduction au Cloud Computing et au Big Data","mainEntityOfPage":{"@type":"WebPage","@id":"https://lzwjava.github.io/distributed-fr"},"url":"https://lzwjava.github.io/distributed-fr"}</script>
<!-- End Jekyll SEO tag -->


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- Facebook Meta Tags -->
  <!-- <meta property="og:url" content="https://lzwjava.github.io"> -->
  <meta property="og:type" content="website">
  <!-- <meta property="og:title" content="Zhiwei Li's Blog">
  <meta property="og:description" content="A personal blog featuring programming insights and projects."> -->
  
  
  
  
  
  
  
  
  <meta property="og:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@lzwjava">
  <meta property="twitter:domain" content="lzwjava.github.io">
  <!-- <meta property="twitter:url" content="https://lzwjava.github.io"> -->
  <!-- <meta name="twitter:title" content="Zhiwei Li's Blog">
  <meta name="twitter:description" content="A personal blog featuring programming insights and projects."> -->
  <meta name="twitter:image" content="https://lzwjava.github.io/assets/images/og/og4.jpg">


  <link rel="stylesheet" href="/assets/css/style.css?v=b6961a1e24d6ebcab2f87a9c6b60431ffa00ffe2">

  <!-- for mathjax support -->
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['\\(','\\)'], ['$', '$']],
            displayMath: [ ['$$','$$'], ['\\[','\\]']],
            processEscapes: false
          },
          "HTML-CSS": { linebreaks: { automatic: true } },
          "CommonHTML": {
            linebreaks: { automatic: true }
          },
          TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
      </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

  <!-- <script src="/assets/js/donatePopup.js?v=b6961a1e24d6ebcab2f87a9c6b60431ffa00ffe2" defer></script> -->
</head>

<body>
  <main id="content" class="main-content post-content" role="main">
  

  

  


  <div class="title-row post-title-row">
    <h2 class="title post-title">
       Introduction au Cloud Computing et au Big Data | Original, traduit par l'IA
    </h2>
  </div>

  <div class="button-container">
    <a href="/" class="button left-button">Home</a>

    <!-- PDF Button -->
     
    <!-- <a href="#" id="downloadPdfButton" class="button pdf-button" data-file-path="_posts/fr/2021-03-10-distributed-fr.md">PDF</a> -->

    <!-- Audio Button -->



    <!--  -->

        <!-- Date Button -->
    
      
      <!-- <span>_postsfr2021-03-10-distributed-fr.md</span> -->
      

      <!-- <span>2021-03-10-distributed-fr.md</span> -->

      
        

        
          
          <a href="#" class="button">2021.03</a>
        

      
    

    <button id="themeTogglePost" class="button icon-button" aria-label="Toggle Theme" style="float: right;margin-bottom: 5px;">
      <!-- theme-icons.html -->
<svg id="sunIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <circle cx="12" cy="12" r="5"></circle>
    <line x1="12" y1="1" x2="12" y2="3"></line>
    <line x1="12" y1="21" x2="12" y2="23"></line>
    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
    <line x1="1" y1="12" x2="3" y2="12"></line>
    <line x1="21" y1="12" x2="23" y2="12"></line>
    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
</svg>

<svg id="moonIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
    stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="display: none;">
    <path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79z"></path>
</svg>
    </button>    

    <!-- Language Select Section -->
    
    
    
    
    
    
    

    
    <select id="languageSelect" class="button right-button">
        
        <option value="/distributed-en" >English</option>
        <option value="/distributed-zh" >中文</option>
        <option value="/distributed-ja" >日本語</option>
        <option value="/distributed-es" >Español</option>
        <option value="/distributed-hi" >हिंदी</option>
        <option value="/distributed-fr" selected>Français</option>
        <option value="/distributed-de" >Deutsch</option>
        <option value="/distributed-ar" >العربية</option>
        <option value="/distributed-hant" >繁體中文</option>
    </select>
  </div>

  <!-- Audio player for text-to-speech -->
  <div class="audio-container">
    <audio id="audioPlayer" controls loop style="display:none;">
      <source id="audioSource" src="" type="audio/mp3">
      Your browser does not support the audio element.
    </audio>
  </div>

  <hr>

  <p>Cette leçon couvre les sujets suivants :</p>

<ul>
  <li>Spark</li>
  <li>Hadoop</li>
  <li>Kubernetes</li>
  <li>Docker</li>
  <li>Flink</li>
  <li>MongoDB</li>
</ul>

<p>Lorsqu’on parle de cloud computing, il semble difficile de ne pas mentionner de nombreux outils tels que Hadoop, Hive, Hbase, ZooKeeper, Docker, Kubernetes, Spark, Kafka, MongoDB, Flink, Druid, Presto, Kylin, et Elastic Search. Les avez-vous tous entendus ? Certains de ces outils, je les ai découverts dans les descriptions de postes d’<code class="language-plaintext highlighter-rouge">ingénieur en big data</code> et d’<code class="language-plaintext highlighter-rouge">ingénieur back-end distribué</code>. Ce sont des postes bien rémunérés. Essayons de les installer tous et de les manipuler un peu.</p>
<h2 id="première-exploration-de-spark">Première exploration de Spark</h2>

<p>Le site officiel indique que <code class="language-plaintext highlighter-rouge">Spark</code> est un moteur d’analyse pour le traitement de données à grande échelle. <code class="language-plaintext highlighter-rouge">Spark</code> est essentiellement une bibliothèque. Contrairement à <code class="language-plaintext highlighter-rouge">Redis</code>, il ne semble pas être divisé en un serveur et un client. <code class="language-plaintext highlighter-rouge">Spark</code> est uniquement utilisé côté client. J’ai téléchargé la dernière version depuis le site officiel, <code class="language-plaintext highlighter-rouge">spark-3.1.1-bin-hadoop3.2.tar</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
├── LICENSE
├── NOTICE
├── R
├── README.md
├── RELEASE
├── bin
├── conf
├── data
├── examples
├── jars
├── kubernetes
├── licenses
├── python
├── sbin
└── yarn
</code></pre></div></div>

<p>11 répertoires, 4 fichiers</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Il semble qu'il s'agisse principalement de bibliothèques d'analyse écrites dans différents langages.

En même temps, le site officiel indique que vous pouvez installer directement les dépendances sur Python. `pip install pyspark`

```shell
$ pip install pyspark
Collecting pyspark
  Téléchargement de pyspark-3.1.1.tar.gz (212,3 Mo)
     |████████████████████████████████| 212,3 Mo 14 ko/s
Collecting py4j==0.10.9
  Téléchargement de py4j-0.10.9-py2.py3-none-any.whl (198 ko)
     |████████████████████████████████| 198 ko 145 ko/s
Construction des roues pour les paquets collectés : pyspark
  Construction de la roue pour pyspark (setup.py) ... terminé
  Roue créée pour pyspark : nom=pyspark-3.1.1-py2.py3-none-any.whl taille=212767604 sha256=0b8079e82f3a5bcadad99179902d8c8ff9f8eccad928a469c11b97abdc960b72
  Stocké dans le répertoire : /Users/lzw/Library/Caches/pip/wheels/23/bf/e9/9f3500437422e2ab82246f25a51ee480a44d4efc6c27e50d33
pyspark construit avec succès
Installation des paquets collectés : py4j, pyspark
py4j-0.10.9 et pyspark-3.1.1 installés avec succès
</code></pre></div></div>

<p>Installé.</p>

<p>Je regarde le site officiel, il y a quelques exemples.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/run-example SparkPi 10
</code></pre></div></div>

<p>Ah, donc on peut exécuter le programme contenu dans le package d’installation que l’on vient de télécharger. Mais il y a une erreur.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/run-example SparkPi 10
21/03/11 00:06:15 WARN NativeCodeLoader: Impossible de charger la bibliothèque native-hadoop pour votre plateforme... utilisation des classes Java intégrées là où c<span class="s1">'est applicable
21/03/11 00:06:16 INFO ResourceUtils: Aucune ressource personnalisée configurée pour spark.driver.
21/03/11 00:06:16 WARN Utils: Le service '</span>sparkDriver<span class="s1">' n'</span>a pas pu se lier sur un port libre aléatoire. Vous pouvez vérifier si une adresse de liaison appropriée est configurée.
</code></pre></div></div>

<blockquote>
  <p>Spark est un moteur de traitement rapide et général compatible avec les données Hadoop. Il peut fonctionner dans des clusters Hadoop via YARN ou en mode autonome de Spark, et il peut traiter des données dans HDFS, HBase, Cassandra, Hive et tout format d’entrée Hadoop. Il est conçu pour effectuer à la fois du traitement par lots (similaire à MapReduce) et de nouvelles charges de travail comme le streaming, les requêtes interactives et l’apprentissage automatique.</p>
</blockquote>

<p>Le terme <code class="language-plaintext highlighter-rouge">hadoop</code> est apparu plusieurs fois. Après avoir cherché sur Google <code class="language-plaintext highlighter-rouge">spark depends hadoop</code>, j’ai trouvé ce passage. Il semble que cela dépende des données au format <code class="language-plaintext highlighter-rouge">Hadoop</code>. Commençons par étudier <code class="language-plaintext highlighter-rouge">Hadoop</code>.</p>

<h2 id="hadoop">Hadoop</h2>

<p>Après avoir rapidement parcouru le site officiel, passons à l’installation.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>hadoop
</code></pre></div></div>

<p>Pendant l’installation, prenons le temps de comprendre.</p>

<blockquote>
  <p>La bibliothèque logicielle Apache Hadoop est un framework qui permet le traitement distribué de grands ensembles de données à travers des clusters d’ordinateurs en utilisant des modèles de programmation simples. Il est conçu pour évoluer d’un seul serveur à des milliers de machines, chacune offrant des capacités de calcul et de stockage locales. Plutôt que de dépendre du matériel pour assurer une haute disponibilité, la bibliothèque elle-même est conçue pour détecter et gérer les défaillances au niveau de la couche application, offrant ainsi un service hautement disponible sur un cluster d’ordinateurs, dont chacun peut être sujet à des pannes.</p>
</blockquote>

<p>En d’autres termes, Hadoop est un ensemble de frameworks conçu pour traiter des ensembles de données distribués. Ces ensembles de données peuvent être répartis sur de nombreux ordinateurs. Il utilise un modèle de programmation très simple pour les traiter. Il est conçu pour passer d’un seul serveur à des milliers de machines. Plutôt que de dépendre de la haute disponibilité du matériel, cette bibliothèque est conçue pour détecter et gérer les erreurs au niveau de la couche application. Ainsi, elle permet de déployer des services hautement disponibles sur un cluster, même si chaque ordinateur du cluster est susceptible de tomber en panne.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>hadoop
Erreur :
  homebrew-core est un clone superficiel.
  homebrew-cask est un clone superficiel.
Pour effectuer <span class="sb">`</span>brew update<span class="sb">`</span>, exécutez d<span class="s1">'abord :
  git -C /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core fetch --unshallow
  git -C /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask fetch --unshallow
Ces commandes peuvent prendre quelques minutes à s'</span>exécuter en raison de la taille importante des dépôts.
Cette restriction a été imposée à la demande de GitHub car la mise à jour de clones superficiels
est une opération extrêmement coûteuse en raison de la structure de l<span class="s1">'arborescence et du trafic des
dépôts Homebrew/homebrew-core et Homebrew/homebrew-cask. Nous ne le faisons pas automatiquement
pour vous afin d'</span>éviter de répéter une opération coûteuse de désuperficialisation dans les systèmes CI
<span class="o">(</span>qui devraient plutôt être corrigés pour ne pas utiliser de clones superficiels<span class="o">)</span><span class="nb">.</span> Nous nous excusons pour
le désagrément <span class="o">!</span>
<span class="o">==&gt;</span> Téléchargement de https://homebrew.bintray.com/bottles/openjdk-15.0.1.big_sur.bottle.tar.gz
Déjà téléchargé : /Users/lzw/Library/Caches/Homebrew/downloads/d1e3ece4af1d225bc2607eaa4ce85a873d2c6d43757ae4415d195751bc431962--openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Téléchargement de https://www.apache.org/dyn/closer.lua?path<span class="o">=</span>hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
Déjà téléchargé : /Users/lzw/Library/Caches/Homebrew/downloads/764c6a0ea7352bb8bb505989feee1b36dc628c2dcd6b93fef1ca829d191b4e1e--hadoop-3.3.0.tar.gz
<span class="o">==&gt;</span> Installation des dépendances pour hadoop : openjdk
<span class="o">==&gt;</span> Installation de la dépendance hadoop : openjdk
<span class="o">==&gt;</span> Déversement de openjdk-15.0.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Avertissements
Pour que les wrappers Java <span class="nb">du </span>système trouvent ce JDK, créez un lien symbolique avec
  <span class="nb">sudo ln</span> <span class="nt">-sfn</span> /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk
</code></pre></div></div>

<p>openjdk est keg-only, ce qui signifie qu’il n’a pas été lié symboliquement dans /usr/local,
car il masque le wrapper <code class="language-plaintext highlighter-rouge">java</code> de macOS.</p>

<p>Si vous devez avoir openjdk en premier dans votre PATH, exécutez :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>Pour que les compilateurs trouvent openjdk, vous devrez peut-être définir :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">export </span><span class="nv">CPPFLAGS</span><span class="o">=</span><span class="s2">"-I/usr/local/opt/openjdk/include"</span>
</code></pre></div></div>

<p>==&gt; Résumé
🍺  /usr/local/Cellar/openjdk/15.0.1: 614 fichiers, 324,9 Mo
==&gt; Installation de hadoop
🍺  /usr/local/Cellar/hadoop/3.3.0: 21 819 fichiers, 954,7 Mo, construit en 2 minutes 15 secondes
==&gt; Mise à jour de 1 dépendance :
maven 3.3.3 -&gt; 3.6.3_1
==&gt; Mise à jour de maven 3.3.3 -&gt; 3.6.3_1
==&gt; Téléchargement de https://www.apache.org/dyn/closer.lua?path=maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
==&gt; Téléchargement depuis https://mirror.olnevhost.net/pub/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
######################################################################## 100,0%
Erreur : L’étape <code class="language-plaintext highlighter-rouge">brew link</code> ne s’est pas terminée avec succès
La formule a été construite, mais n’est pas liée symboliquement dans /usr/local
Impossible de créer un lien symbolique pour bin/mvn
La cible /usr/local/bin/mvn
est un lien symbolique appartenant à maven. Vous pouvez le supprimer :
  brew unlink maven</p>

<p>Pour forcer le lien et écraser tous les fichiers en conflit :
  brew link –overwrite maven</p>

<p>Pour lister tous les fichiers qui seraient supprimés :
  brew link –overwrite –dry-run maven</p>

<p>Les fichiers potentiellement en conflit sont :
/usr/local/bin/mvn -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvn
/usr/local/bin/mvnDebug -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnDebug
/usr/local/bin/mvnyjp -&gt; /usr/local/Cellar/maven/3.3.3/bin/mvnyjp
==&gt; Résumé
🍺  /usr/local/Cellar/maven/3.6.3_1: 87 fichiers, 10.7MB, construit en 7 secondes
Suppression : /usr/local/Cellar/maven/3.3.3… (92 fichiers, 9MB)
==&gt; Vérification des dépendants des formules mises à niveau…
==&gt; Aucun dépendant cassé trouvé !
==&gt; Avertissements
==&gt; openjdk
Pour que les wrappers Java du système trouvent ce JDK, créez un lien symbolique avec
  sudo ln -sfn /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk</p>

<p>openjdk est keg-only, ce qui signifie qu’il n’a pas été lié symboliquement dans /usr/local,
car il masque le wrapper <code class="language-plaintext highlighter-rouge">java</code> de macOS.</p>

<p>Si vous devez avoir openjdk en premier dans votre PATH, exécutez :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/openjdk/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> /Users/lzw/.bash_profile
</code></pre></div></div>

<p>Pour que les compilateurs trouvent openjdk, vous devrez peut-être définir :
  export CPPFLAGS=”-I/usr/local/opt/openjdk/include”</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
J'ai remarqué dans les logs de sortie de `brew` que `maven` n'était pas correctement lié. Ensuite, j'ai procédé à un lien forcé vers la version `3.6.3_1`.

```shell
  brew link --overwrite maven
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Hadoop</code> est maintenant installé avec succès.</p>

<blockquote>
  <h2 id="modules">Modules</h2>

  <p>Le projet inclut les modules suivants :</p>

  <ul>
    <li><strong>Hadoop Common</strong> : Les utilitaires communs qui prennent en charge les autres modules Hadoop.</li>
    <li><strong>Hadoop Distributed File System (HDFS™)</strong> : Un système de fichiers distribué qui offre un accès à haut débit aux données des applications.</li>
    <li><strong>Hadoop YARN</strong> : Un framework pour la planification des tâches et la gestion des ressources du cluster.</li>
    <li><strong>Hadoop MapReduce</strong> : Un système basé sur YARN pour le traitement parallèle de grands ensembles de données.</li>
    <li><strong>Hadoop Ozone</strong> : Un magasin d’objets pour Hadoop.</li>
  </ul>
</blockquote>

<p>Il dit qu’il y a ces modules. Cela a tapé <code class="language-plaintext highlighter-rouge">hadoop</code> et voici ce qui est apparu :</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hadoop
Usage : hadoop <span class="o">[</span>OPTIONS] SUBCOMMAND <span class="o">[</span>SUBCOMMAND OPTIONS]
 ou     hadoop <span class="o">[</span>OPTIONS] CLASSNAME <span class="o">[</span>CLASSNAME OPTIONS]
  où CLASSNAME est une classe Java fournie par l<span class="s1">'utilisateur
</span></code></pre></div></div>

<p>OPTIONS peut être <code class="language-plaintext highlighter-rouge">none</code> ou l’une des options suivantes :</p>

<p>–config dir                     Répertoire de configuration Hadoop
–debug                          activer le mode de débogage du script shell
–help                           informations sur l’utilisation
buildpaths                       tenter d’ajouter des fichiers de classe depuis l’arborescence de construction
hostnames list[,of,host,names]   hôtes à utiliser en mode esclave
hosts filename                   liste des hôtes à utiliser en mode esclave
loglevel level                   définir le niveau log4j pour cette commande
workers                          activer le mode travailleur</p>

<p>SUBCOMMAND est l’un des :
    Commandes Administrateur :</p>

<p>daemonlog     obtenir/définir le niveau de journalisation pour chaque démon</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Commandes Client :
</code></pre></div></div>

<p>archive       créer une archive Hadoop
checknative   vérifier la disponibilité des bibliothèques natives Hadoop et de compression
classpath     affiche le chemin de classe nécessaire pour obtenir le fichier jar Hadoop et les bibliothèques requises
conftest      valider les fichiers de configuration XML
credential    interagir avec les fournisseurs d’identifiants
distch        changeur de métadonnées distribué
distcp        copier un fichier ou des répertoires de manière récursive
dtutil        opérations liées aux jetons de délégation
envvars       afficher les variables d’environnement Hadoop calculées
fs            exécuter un client utilisateur générique de système de fichiers
gridmix       soumettre un mélange de travaux synthétiques, modélisant une charge de production profilée
jar <jar>     exécuter un fichier jar. REMARQUE : veuillez utiliser "yarn jar" pour lancer des applications YARN, pas cette commande.
jnipath       affiche le java.library.path
kdiag         diagnostiquer les problèmes Kerberos
kerbname      montrer la conversion du principal auth_to_local
key           gérer les clés via le KeyProvider
rumenfolder   mettre à l'échelle une trace d'entrée rumen
rumentrace    convertir des journaux en une trace rumen
s3guard       gérer les métadonnées sur S3
trace         afficher et modifier les paramètres de traçage Hadoop
version       afficher la version</jar></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Commandes Daemon :
</code></pre></div></div>

<p>kms           exécuter KMS, le serveur de gestion des clés
registrydns   exécuter le serveur DNS du registre</p>

<p>SUBCOMMAND peut afficher l’aide lorsqu’il est invoqué sans paramètres ou avec -h.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Le site officiel fournit quelques exemples.

```shell
  $ mkdir input
  $ cp etc/hadoop/*.xml input
  $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'
  $ cat output/*
</code></pre></div></div>

<p>On remarque la présence de <code class="language-plaintext highlighter-rouge">share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar</code>. Cela signifie qu’il y a peut-être des fichiers d’exemple que nous n’avons pas obtenus. On suppose que l’installation via <code class="language-plaintext highlighter-rouge">Homebrew</code> ne fournit pas ces fichiers. Nous avons donc téléchargé le package d’installation depuis le site officiel.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 1
<span class="nb">.</span>
├── LICENSE-binary
├── LICENSE.txt
├── NOTICE-binary
├── NOTICE.txt
├── README.txt
├── bin
├── etc
├── include
├── lib
├── libexec
├── licenses-binary
├── sbin
└── share
</code></pre></div></div>

<p>Le répertoire <code class="language-plaintext highlighter-rouge">share</code> est apparu. Cependant, est-ce que <code class="language-plaintext highlighter-rouge">Homebrew</code> n’a vraiment pas ces fichiers supplémentaires ? Trouvez le répertoire d’installation de <code class="language-plaintext highlighter-rouge">Homebrew</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">type </span>hadoop
hadoop est /usr/local/bin/hadoop
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-alrt</span> /usr/local/bin/hadoop
lrwxr-xr-x  1 lzw  admin  33 Mar 11 00:48 /usr/local/bin/hadoop -&gt; ../Cellar/hadoop/3.3.0/bin/hadoop
<span class="nv">$ </span><span class="nb">cd</span> /usr/local/Cellar/hadoop/3.3.0
</code></pre></div></div>

<p>Voici l’arborescence des répertoires imprimée sous <code class="language-plaintext highlighter-rouge">/usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop</code> :</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tree <span class="nb">.</span> <span class="nt">-L</span> 2
<span class="nb">.</span>
├── client
│   ├── hadoop-client-api-3.3.0.jar
│   ├── hadoop-client-minicluster-3.3.0.jar
│   └── hadoop-client-runtime-3.3.0.jar
├── common
│   ├── hadoop-common-3.3.0-tests.jar
│   ├── hadoop-common-3.3.0.jar
│   ├── hadoop-kms-3.3.0.jar
│   ├── hadoop-nfs-3.3.0.jar
│   ├── hadoop-registry-3.3.0.jar
│   ├── jdiff
│   ├── lib
│   ├── sources
│   └── webapps
├── hdfs
│   ├── hadoop-hdfs-3.3.0-tests.jar
│   ├── hadoop-hdfs-3.3.0.jar
│   ├── hadoop-hdfs-client-3.3.0-tests.jar
│   ├── hadoop-hdfs-client-3.3.0.jar
│   ├── hadoop-hdfs-httpfs-3.3.0.jar
│   ├── hadoop-hdfs-native-client-3.3.0-tests.jar
│   ├── hadoop-hdfs-native-client-3.3.0.jar
│   ├── hadoop-hdfs-nfs-3.3.0.jar
│   ├── hadoop-hdfs-rbf-3.3.0-tests.jar
│   ├── hadoop-hdfs-rbf-3.3.0.jar
│   ├── jdiff
│   ├── lib
│   ├── sources
│   └── webapps
├── mapreduce
│   ├── hadoop-mapreduce-client-app-3.3.0.jar
│   ├── hadoop-mapreduce-client-common-3.3.0.jar
│   ├── hadoop-mapreduce-client-core-3.3.0.jar
│   ├── hadoop-mapreduce-client-hs-3.3.0.jar
│   ├── hadoop-mapreduce-client-hs-plugins-3.3.0.jar
│   ├── hadoop-mapreduce-client-jobclient-3.3.0-tests.jar
│   ├── hadoop-mapreduce-client-jobclient-3.3.0.jar
│   ├── hadoop-mapreduce-client-nativetask-3.3.0.jar
│   ├── hadoop-mapreduce-client-shuffle-3.3.0.jar
│   ├── hadoop-mapreduce-client-uploader-3.3.0.jar
│   ├── hadoop-mapreduce-examples-3.3.0.jar
│   ├── jdiff
│   ├── lib-examples
│   └── sources
├── tools
│   ├── dynamometer
│   ├── lib
│   ├── resourceestimator
│   ├── sls
│   └── sources
└── yarn
    ├── csi
    ├── hadoop-yarn-api-3.3.0.jar
    ├── hadoop-yarn-applications-catalog-webapp-3.3.0.war
    ├── hadoop-yarn-applications-distributedshell-3.3.0.jar
    ├── hadoop-yarn-applications-mawo-core-3.3.0.jar
    ├── hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar
    ├── hadoop-yarn-client-3.3.0.jar
    ├── hadoop-yarn-common-3.3.0.jar
    ├── hadoop-yarn-registry-3.3.0.jar
    ├── hadoop-yarn-server-applicationhistoryservice-3.3.0.jar
    ├── hadoop-yarn-server-common-3.3.0.jar
    ├── hadoop-yarn-server-nodemanager-3.3.0.jar
    ├── hadoop-yarn-server-resourcemanager-3.3.0.jar
    ├── hadoop-yarn-server-router-3.3.0.jar
    ├── hadoop-yarn-server-sharedcachemanager-3.3.0.jar
    ├── hadoop-yarn-server-tests-3.3.0.jar
    ├── hadoop-yarn-server-timeline-pluginstorage-3.3.0.jar
    ├── hadoop-yarn-server-web-proxy-3.3.0.jar
    ├── hadoop-yarn-services-api-3.3.0.jar
    ├── hadoop-yarn-services-core-3.3.0.jar
    ├── lib
    ├── sources
    ├── <span class="nb">test</span>
    ├── timelineservice
    ├── webapps
    └── yarn-service-examples
</code></pre></div></div>

<p>Vous pouvez voir qu’il y a de nombreux fichiers <code class="language-plaintext highlighter-rouge">jar</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>input
<span class="nv">$ </span><span class="nb">ls
</span>bin			hadoop-config.sh	hdfs-config.sh		libexec			sbin			yarn-config.sh
etc			hadoop-functions.sh	input			mapred-config.sh	share
<span class="nv">$ </span><span class="nb">cp </span>etc/hadoop/<span class="k">*</span>.xml input
<span class="nv">$ </span><span class="nb">cd </span>input/
<span class="nv">$ </span><span class="nb">ls
</span>capacity-scheduler.xml	hadoop-policy.xml	hdfs-site.xml		kms-acls.xml		mapred-site.xml
core-site.xml		hdfs-rbf-site.xml	httpfs-site.xml		kms-site.xml		yarn-site.xml
<span class="nv">$ </span><span class="nb">cd</span> ..
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
Le fichier JAR n<span class="s1">'existe pas ou n'</span>est pas un fichier normal : /usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar
<span class="err">$</span>
<span class="nv">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar <span class="nb">grep </span>input output <span class="s1">'dfs[a-z.]+'</span>
2021-03-11 01:54:30,791 WARN util.NativeCodeLoader: Impossible de charger la bibliothèque native-hadoop pour votre plateforme... utilisation des classes Java intégrées là où applicable
2021-03-11 01:54:31,115 INFO impl.MetricsConfig: Propriétés chargées depuis hadoop-metrics2.properties
2021-03-11 01:54:31,232 INFO impl.MetricsSystemImpl: Période de capture des métriques planifiée à 10 seconde<span class="o">(</span>s<span class="o">)</span><span class="nb">.</span>
...
</code></pre></div></div>

<p>En suivant l’exemple du site officiel, on remarque la commande <code class="language-plaintext highlighter-rouge">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input</code>. Ici, le fichier <code class="language-plaintext highlighter-rouge">jar</code> est précédé d’un numéro de version. Il faut donc le remplacer par notre version <code class="language-plaintext highlighter-rouge">3.3.0</code>.</p>

<p>Fin du journal :</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2021-03-11 01:54:35,374 INFO mapreduce.Job:  map 100% reduce 100%
2021-03-11 01:54:35,374 INFO mapreduce.Job: Job job_local2087514596_0002 terminé avec succès
2021-03-11 01:54:35,377 INFO mapreduce.Job: Compteurs : 30
	Compteurs <span class="nb">du </span>système de fichiers
		FILE: Nombre d<span class="s1">'octets lus=1204316
		FILE: Nombre d'</span>octets écrits<span class="o">=</span>3565480
		FILE: Nombre d<span class="s1">'opérations de lecture=0
		FILE: Nombre de grandes opérations de lecture=0
		FILE: Nombre d'</span>opérations d<span class="s1">'écriture=0
	Framework Map-Reduce
		Enregistrements d'</span>entrée de <span class="nv">map</span><span class="o">=</span>1
		Enregistrements de sortie de <span class="nv">map</span><span class="o">=</span>1
		Octets de sortie de <span class="nv">map</span><span class="o">=</span>17
		Octets matérialisés de sortie de <span class="nv">map</span><span class="o">=</span>25
		Octets de <span class="nb">split </span>d<span class="s1">'entrée=141
		Enregistrements d'</span>entrée de <span class="nv">combine</span><span class="o">=</span>0
		Enregistrements de sortie de <span class="nv">combine</span><span class="o">=</span>0
		Groupes d<span class="s1">'entrée de reduce=1
		Octets de shuffle de reduce=25
		Enregistrements d'</span>entrée de <span class="nv">reduce</span><span class="o">=</span>1
		Enregistrements de sortie de <span class="nv">reduce</span><span class="o">=</span>1
		Enregistrements déversés<span class="o">=</span>2
		Maps mélangés<span class="o">=</span>1
		Shuffles échoués<span class="o">=</span>0
		Sorties de map fusionnées<span class="o">=</span>1
		Temps écoulé GC <span class="o">(</span>ms<span class="o">)=</span>57
		Utilisation totale <span class="nb">du </span>tas engagé <span class="o">(</span>octets<span class="o">)=</span>772800512
	Erreurs de Shuffle
		<span class="nv">BAD_ID</span><span class="o">=</span>0
		<span class="nv">CONNECTION</span><span class="o">=</span>0
		<span class="nv">IO_ERROR</span><span class="o">=</span>0
		<span class="nv">WRONG_LENGTH</span><span class="o">=</span>0
		<span class="nv">WRONG_MAP</span><span class="o">=</span>0
		<span class="nv">WRONG_REDUCE</span><span class="o">=</span>0
	Compteurs <span class="nb">du </span>format d<span class="s1">'entrée de fichier
		Octets lus=123
	Compteurs du format de sortie de fichier
		Octets écrits=23
</span></code></pre></div></div>

<p>Continuons à regarder.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>Qu’est-ce que cela signifie exactement ? Peu importe, en tout cas, nous avons réussi à démarrer <code class="language-plaintext highlighter-rouge">Hadoop</code>. Et nous avons exécuté notre premier exemple de calcul en mode standalone.</p>

<h2 id="spark">Spark</h2>

<p>Revenons à Spark. Prenons un exemple.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"hdfs://..."</span><span class="p">)</span>
</code></pre></div></div>

<p>Un fichier <code class="language-plaintext highlighter-rouge">hdfs</code> est apparu ici. Après avoir effectué des recherches, j’ai découvert qu’il est possible de créer un fichier <code class="language-plaintext highlighter-rouge">hdfs</code> de cette manière :</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-mkdir</span> /test
</code></pre></div></div>

<p>Voyons la commande <code class="language-plaintext highlighter-rouge">hdfs</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>hdfs
Usage : hdfs <span class="o">[</span>OPTIONS] SUBCOMMAND <span class="o">[</span>SUBCOMMAND OPTIONS]
</code></pre></div></div>

<p>OPTIONS est soit <code class="language-plaintext highlighter-rouge">none</code>, soit l’une des options suivantes :</p>

<p>–buildpaths                       tenter d’ajouter des fichiers de classe à partir de l’arborescence de construction
–config dir                       répertoire de configuration Hadoop
–daemon (start|status|stop)       opérer sur un démon
–debug                            activer le mode de débogage des scripts shell
–help                             informations d’utilisation
–hostnames list[,of,host,names]   hôtes à utiliser en mode worker
–hosts filename                   liste des hôtes à utiliser en mode worker
–loglevel level                   définir le niveau log4j pour cette commande
–workers                          activer le mode worker</p>

<p>SUBCOMMAND est l’un des :
    Commandes d’administration :</p>

<p>cacheadmin           configurer le cache HDFS
crypto               configurer les zones de chiffrement HDFS
debug                exécuter un Debug Admin pour exécuter des commandes de débogage HDFS
dfsadmin             exécuter un client admin DFS
dfsrouteradmin       gérer la fédération basée sur Router
ec                   exécuter une CLI de codage d’effacement HDFS
fsck                 exécuter un utilitaire de vérification du système de fichiers DFS
haadmin              exécuter un client admin DFS HA
jmxget               obtenir les valeurs JMX exportées depuis NameNode ou DataNode
oev                  appliquer le visualiseur de modifications hors ligne à un fichier d’éditions
oiv                  appliquer le visualiseur d’image de système de fichiers hors ligne à une image de système de fichiers
oiv_legacy           appliquer le visualiseur d’image de système de fichiers hors ligne à une image de système de fichiers héritée
storagepolicies      lister/obtenir/définir/satisfaire les politiques de stockage des blocs</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Commandes client :
</code></pre></div></div>

<p>classpath            affiche le chemin de classe nécessaire pour obtenir le fichier JAR Hadoop et les bibliothèques requises
dfs                  exécute une commande de système de fichiers sur le système de fichiers
envvars              affiche les variables d’environnement Hadoop calculées
fetchdt              récupère un jeton de délégation depuis le NameNode
getconf              obtient les valeurs de configuration à partir de la configuration
groups               obtient les groupes auxquels les utilisateurs appartiennent
lsSnapshottableDir   liste tous les répertoires pouvant être snapshotés appartenant à l’utilisateur actuel
snapshotDiff         compare deux snapshots d’un répertoire ou compare le contenu actuel du répertoire avec un snapshot
version              affiche la version</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Commandes Daemon :
</code></pre></div></div>

<p>balancer             exécuter un utilitaire d’équilibrage de cluster<br />
datanode             exécuter un datanode DFS<br />
dfsrouter            exécuter le routeur DFS<br />
diskbalancer         répartir les données de manière uniforme entre les disques d’un nœud donné<br />
httpfs               exécuter le serveur HttpFS, la passerelle HTTP HDFS<br />
journalnode          exécuter le journalnode DFS<br />
mover                exécuter un utilitaire pour déplacer les réplicas de blocs entre les types de stockage<br />
namenode             exécuter le namenode DFS<br />
nfs3                 exécuter une passerelle NFS version 3<br />
portmap              exécuter un service portmap<br />
secondarynamenode    exécuter le namenode secondaire DFS<br />
sps                  exécuter le satisfacteur de politique de stockage externe<br />
zkfc                 exécuter le démon ZK Failover Controller</p>

<p>SUBCOMMAND peut afficher l’aide lorsqu’il est invoqué sans paramètres ou avec -h.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Continuer à modifier le code.

```python
from pyspark.sql import SparkSession
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">master</span><span class="p">(</span><span class="s">"local[*]"</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">config</span><span class="p">(</span><span class="s">'spark.driver.bindAddress'</span><span class="p">,</span> <span class="s">'127.0.0.1'</span><span class="p">)</span>\
           <span class="p">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_file</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"a.txt"</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" "</span><span class="p">))</span> \
             <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
             <span class="p">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">counts</span><span class="p">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">"b.txt"</span><span class="p">)</span>
</code></pre></div></div>

<p>Il est important de noter <code class="language-plaintext highlighter-rouge">.config('spark.driver.bindAddress', '127.0.0.1')</code>. Sinon, vous pourriez rencontrer l’erreur suivante : <code class="language-plaintext highlighter-rouge">Service 'sparkDriver' could not bind on a random free port. You may check whether configuring an appropriate binding address</code>.</p>

<p>Cependant, une erreur est survenue à ce moment-là.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Caused by: org.apache.spark.api.python.PythonException: Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
  File <span class="s2">"/usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py"</span>, line 473, <span class="k">in </span>main
    raise Exception<span class="o">((</span><span class="s2">"Python in worker has different version %s than that in "</span> +
Exception: Python dans le worker a une version différente 3.8 de celle <span class="nb">du </span>driver 3.9, PySpark ne peut pas fonctionner avec des versions mineures différentes. Veuillez vérifier que les variables d<span class="s1">'environnement PYSPARK_PYTHON et PYSPARK_DRIVER_PYTHON sont correctement configurées.
</span></code></pre></div></div>

<p>Cela indique que différentes versions de <code class="language-plaintext highlighter-rouge">Python</code> ont été exécutées.</p>

<p>Modifier le fichier <code class="language-plaintext highlighter-rouge">.bash_profile</code> :</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PYSPARK_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
<span class="nv">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span>/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
</code></pre></div></div>

<p>Cependant, l’erreur persiste. Après quelques recherches, il semble que cela pourrait être dû au fait que <code class="language-plaintext highlighter-rouge">spark</code> ne charge pas cette variable d’environnement lors de son exécution, et n’utilise donc pas les variables d’environnement par défaut du terminal.</p>

<p>Vous devez configurer dans le code :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
</code></pre></div></div>

<h1 id="configurer-les-environnements-spark">Configurer les environnements Spark</h1>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYSPARK_PYTHON'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'</span>
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYSPARK_DRIVER_PYTHON'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'</span>
</code></pre></div></div>

<p>Cela fonctionnera.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python sc.py
21/03/11 02:54:52 WARN NativeCodeLoader: Impossible de charger la bibliothèque native-hadoop pour votre plateforme... utilisation des classes Java intégrées là où applicable
Utilisation <span class="nb">du </span>profil log4j par défaut de Spark : org/apache/spark/log4j-defaults.properties
Définition <span class="nb">du </span>niveau de journalisation par défaut à <span class="s2">"WARN"</span><span class="nb">.</span>
Pour ajuster le niveau de journalisation, utilisez sc.setLogLevel<span class="o">(</span>newLevel<span class="o">)</span><span class="nb">.</span> Pour SparkR, utilisez setLogLevel<span class="o">(</span>newLevel<span class="o">)</span><span class="nb">.</span>
PythonRDD[6] à RDD à PythonRDD.scala:53
</code></pre></div></div>

<p>À ce moment, le fichier <code class="language-plaintext highlighter-rouge">b.txt</code> a été généré.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── b.txt
│   ├── _SUCCESS
│   ├── part-00000
│   └── part-00001
</code></pre></div></div>

<p>Ouvrez-le.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>b.txt/part-00000
<span class="o">(</span><span class="s1">'college'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'two'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'things'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'worked'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'on,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'of'</span>, 8<span class="o">)</span>
<span class="o">(</span><span class="s1">'school,'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'writing'</span>, 2<span class="o">)</span>
<span class="o">(</span><span class="s1">'programming.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s2">"didn't"</span>, 4<span class="o">)</span>
<span class="o">(</span><span class="s1">'then,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'probably'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'are:'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'short'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'awful.'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'They'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'plot,'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'just'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'characters'</span>, 1<span class="o">)</span>
<span class="o">(</span><span class="s1">'them'</span>, 2<span class="o">)</span>
...
</code></pre></div></div>

<p>Ça a marché ! Cela ne vous semble-t-il pas familier ? C’est comme dans l’exemple avec <code class="language-plaintext highlighter-rouge">Hadoop</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>output/<span class="k">*</span>
1	dfsadmin
</code></pre></div></div>

<p>Ces fichiers sont appelés <code class="language-plaintext highlighter-rouge">HDFS</code>. On peut voir ici que <code class="language-plaintext highlighter-rouge">Spark</code> est utilisé pour compter les mots. En quelques lignes seulement, cela semble très pratique.</p>

<h2 id="kubernetes">Kubernetes</h2>

<p>Passons maintenant à <code class="language-plaintext highlighter-rouge">Kubernetes</code>, également appelé <code class="language-plaintext highlighter-rouge">k8s</code>, où le “8” représente les 8 lettres omises entre le “K” et le “s”. Il s’agit d’un système open-source conçu pour automatiser le déploiement, la mise à l’échelle et la gestion des applications conteneurisées.</p>

<p>L’outil en ligne de commande <code class="language-plaintext highlighter-rouge">kubectl</code> est utilisé pour exécuter des commandes sur un cluster Kubernetes (k8s). Il permet de déployer des applications, de visualiser et de gérer les ressources du cluster, ainsi que de consulter les journaux.</p>

<p>Il est également possible d’installer via Homebrew.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>kubectl
</code></pre></div></div>

<p>Journalisation des sorties :</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">==&gt;</span> Téléchargement de https://homebrew.bintray.com/bottles/kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Téléchargement depuis https://d29vzk4ow07wi7.cloudfront.net/0b4f08bd1d47cb913d7cd4571e3394c6747dfbad7ff114c5589c8396c1085ecf?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Extraction de kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Avertissements
La complétion Bash a été installée dans :
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Résumé
🍺  /usr/local/Cellar/kubernetes-cli/1.20.1: 246 fichiers, 46.1 Mo
</code></pre></div></div>

<p>Installation terminée.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl
kubectl contrôle le gestionnaire de cluster Kubernetes.
</code></pre></div></div>

<p>Pour plus d’informations, consultez : https://kubernetes.io/docs/reference/kubectl/overview/</p>

<p>Commandes de base (Débutant) :
  create        Créer une ressource à partir d’un fichier ou de stdin.
  expose        Prendre un contrôleur de réplication, un service, un déploiement ou un pod et l’exposer en tant que nouveau service Kubernetes
  run           Exécuter une image spécifique sur le cluster
  set           Définir des fonctionnalités spécifiques sur des objets</p>

<p>Commandes de base (intermédiaires) :
  explain       Documentation des ressources
  get           Afficher une ou plusieurs ressources
  edit          Modifier une ressource sur le serveur
  delete        Supprimer des ressources par fichiers, stdin, ressources et noms, ou par ressources et sélecteur de label</p>

<p>Commandes de déploiement :
  rollout       Gérer le déploiement d’une ressource
  scale         Définir une nouvelle taille pour un Deployment, ReplicaSet ou Replication Controller
  autoscale     Mettre à l’échelle automatiquement un Deployment, ReplicaSet ou ReplicationController</p>

<p>Commandes de gestion de cluster :
  certificate   Modifier les ressources de certificat.
  cluster-info  Afficher les informations du cluster.
  top           Afficher l’utilisation des ressources (CPU/Mémoire/Stockage).
  cordon        Marquer un nœud comme non planifiable.
  uncordon      Marquer un nœud comme planifiable.
  drain         Vider un nœud en préparation à une maintenance.
  taint         Mettre à jour les taints sur un ou plusieurs nœuds.</p>

<p>Commandes de dépannage et de débogage :
  describe      Afficher les détails d’une ressource spécifique ou d’un groupe de ressources
  logs          Afficher les logs d’un conteneur dans un pod
  attach        Se connecter à un conteneur en cours d’exécution
  exec          Exécuter une commande dans un conteneur
  port-forward  Rediriger un ou plusieurs ports locaux vers un pod
  proxy         Lancer un proxy vers le serveur API Kubernetes
  cp            Copier des fichiers et répertoires vers et depuis des conteneurs
  auth          Inspecter les autorisations
  debug         Créer des sessions de débogage pour le dépannage des charges de travail et des nœuds</p>

<p>Commandes avancées :
  diff          Comparer la version en direct avec la version qui serait appliquée
  apply         Appliquer une configuration à une ressource par nom de fichier ou stdin
  patch         Mettre à jour un ou plusieurs champs d’une ressource
  replace       Remplacer une ressource par nom de fichier ou stdin
  wait          Expérimental : Attendre une condition spécifique sur une ou plusieurs ressources.
  kustomize     Construire une cible de kustomization à partir d’un répertoire ou d’une URL distante.</p>

<p>Commandes de configuration :
  label         Mettre à jour les étiquettes sur une ressource
  annotate      Mettre à jour les annotations sur une ressource
  completion    Générer le code de complétion pour le shell spécifié (bash ou zsh)</p>

<p>Autres Commandes :
  api-resources Affiche les ressources API prises en charge sur le serveur
  api-versions  Affiche les versions API prises en charge sur le serveur, sous la forme “groupe/version”
  config        Modifie les fichiers kubeconfig
  plugin        Fournit des utilitaires pour interagir avec les plugins.
  version       Affiche les informations de version du client et du serveur</p>

<p>Utilisation :
  kubectl [flags] [options]</p>

<p>Utilisez “kubectl <commande> --help" pour obtenir plus d'informations sur une commande donnée.
Utilisez "kubectl options" pour obtenir une liste des options globales de ligne de commande (s'applique à toutes les commandes).</commande></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Créons un fichier de configuration.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  minReadySeconds: 5
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
```shell
$ kubectl apply -f simple_deployment.yaml
La connexion au serveur localhost:8080 a été refusée - avez-vous spécifié le bon hôte ou port ?
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl cluster-info
</code></pre></div></div>

<p>Pour déboguer et diagnostiquer davantage les problèmes du cluster, utilisez <code class="language-plaintext highlighter-rouge">kubectl cluster-info dump</code>.
La connexion au serveur localhost:8080 a été refusée - avez-vous spécifié le bon hôte ou port ?</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Lorsque vous essayez de l'exécuter dans le terminal du site officiel.

```shell
$ start.sh
Démarrage de Kubernetes...version de minikube : v1.8.1
commit : cbda04cf6bbe65e987ae52bb393c10099ab62014
* minikube v1.8.1 sur Ubuntu 18.04
* Utilisation du pilote none basé sur la configuration utilisateur
* Exécution sur localhost (CPU=2, Mémoire=2460MB, Disque=145651MB) ...
* La version du système d'exploitation est Ubuntu 18.04.4 LTS
</code></pre></div></div>

<ul>
  <li>Préparation de Kubernetes v1.17.3 sur Docker 19.03.6 …
    <ul>
      <li>kubelet.resolv-conf=/run/systemd/resolve/resolv.conf</li>
    </ul>
  </li>
  <li>Lancement de Kubernetes …</li>
  <li>Activation des modules complémentaires : default-storageclass, storage-provisioner</li>
  <li>Configuration de l’environnement local …</li>
  <li>Terminé ! kubectl est maintenant configuré pour utiliser “minikube”</li>
  <li>Le module complémentaire ‘dashboard’ est activé
Kubernetes démarré
```</li>
</ul>

<p>Revenons à notre terminal.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl version <span class="nt">--client</span>
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
<span class="nv">$ </span>kubectl version
Client Version: version.Info<span class="o">{</span>Major:<span class="s2">"1"</span>, Minor:<span class="s2">"20"</span>, GitVersion:<span class="s2">"v1.20.1"</span>, GitCommit:<span class="s2">"c4d752765b3bbac2237bf87cf0b1c2e307844666"</span>, GitTreeState:<span class="s2">"clean"</span>, BuildDate:<span class="s2">"2020-12-19T08:38:20Z"</span>, GoVersion:<span class="s2">"go1.15.5"</span>, Compiler:<span class="s2">"gc"</span>, Platform:<span class="s2">"darwin/amd64"</span><span class="o">}</span>
La connexion au serveur localhost:8080 a été refusée - avez-vous spécifié le bon hôte ou port ?
</code></pre></div></div>

<p>Il est intéressant de noter que l’ajout de l’option <code class="language-plaintext highlighter-rouge">--client</code> n’a pas généré d’erreur.</p>

<p>La documentation indique qu’il faut d’abord installer <code class="language-plaintext highlighter-rouge">Minikube</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>minikube
<span class="o">==&gt;</span> Téléchargement de https://homebrew.bintray.com/bottles/minikube-1.16.0.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Téléchargement depuis https://d29vzk4ow07wi7.cloudfront.net/1b6d7d1b97b11b6b07e4fa531c2dc21770da290da9b2816f360fd923e00c85fc?response-content-disposition<span class="o">=</span>a
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Extraction de minikube-1.16.0.big_sur.bottle.tar.gz
<span class="o">==&gt;</span> Notes
La complétion Bash a été installée dans :
  /usr/local/etc/bash_completion.d
<span class="o">==&gt;</span> Résumé
🍺  /usr/local/Cellar/minikube/1.16.0: 8 fichiers, 64,6 Mo
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube start
😄  minikube v1.16.0 sur Darwin 11.2.2
🎉  minikube 1.18.1 est disponible <span class="o">!</span> Téléchargez-le : https://github.com/kubernetes/minikube/releases/tag/v1.18.1
💡  Pour désactiver cette notification, exécutez : <span class="s1">'minikube config set WantUpdateNotification false'</span>
</code></pre></div></div>

<p>✨  Sélection automatique du pilote virtualbox
💿  Téléchargement de l’image de démarrage de la VM …
    &gt; minikube-v1.16.0.iso.sha256: 65 B / 65 B [————-] 100.00% ? p/s 0s
    &gt; minikube-v1.16.0.iso: 212.62 MiB / 212.62 MiB [] 100.00% 5.32 MiB p/s 40s
👍  Démarrage du nœud de contrôle plane minikube dans le cluster minikube
💾  Téléchargement de Kubernetes v1.20.0 preload …
    &gt; preloaded-images-k8s-v8-v1….: 491.00 MiB / 491.00 MiB  100.00% 7.52 MiB
🔥  Création de la VM virtualbox (CPU=2, Mémoire=4000MB, Disque=20000MB) …
❗  Cette VM rencontre des difficultés pour accéder à https://k8s.gcr.io
💡  Pour télécharger de nouvelles images externes, vous devrez peut-être configurer un proxy : https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
🐳  Préparation de Kubernetes v1.20.0 sur Docker 20.10.0 …
    ▪ Génération des certificats et clés …
    ▪ Démarrage du contrôle plane …
    ▪ Configuration des règles RBAC …
🔎  Vérification des composants Kubernetes…
🌟  Modules complémentaires activés : storage-provisioner, default-storageclass
🏄  Terminé ! kubectl est maintenant configuré pour utiliser le cluster “minikube” et l’espace de noms “default” par défaut</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Ensuite, accédez à ce cluster.

```shell
$ kubectl get po -A
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
kube-system   coredns-74ff55c5b-ndbcr            1/1     Running   0          60s
kube-system   etcd-minikube                      0/1     Running   0          74s
kube-system   kube-apiserver-minikube            1/1     Running   0          74s
kube-system   kube-controller-manager-minikube   1/1     Running   0          74s
kube-system   kube-proxy-g2296                   1/1     Running   0          60s
kube-system   kube-scheduler-minikube            0/1     Running   0          74s
kube-system   storage-provisioner                1/1     Running   1          74s
</code></pre></div></div>

<p>Pour ouvrir le tableau de bord de <code class="language-plaintext highlighter-rouge">minikube</code>, utilisez la commande suivante :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube dashboard
</code></pre></div></div>

<p>Cela ouvrira le tableau de bord de Kubernetes dans votre navigateur par défaut.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube dashboard
🔌  Activation <span class="nb">du </span>tableau de bord ...
🤔  Vérification de l<span class="s1">'état du tableau de bord ...
🚀  Lancement du proxy ...
🤔  Vérification de l'</span>état <span class="nb">du </span>proxy ...
🎉  Ouverture de http://127.0.0.1:50030/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ dans votre navigateur par défaut...
</code></pre></div></div>

<p><img src="assets/images/distributed/k8s.png" alt="k8s" /></p>

<p>Comment l’éteindre ?</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube
minikube provisionne et gère des clusters Kubernetes locaux optimisés pour les flux de travail de développement.
</code></pre></div></div>

<p>Commandes de base :
  start          Démarre un cluster Kubernetes local
  status         Obtient le statut d’un cluster Kubernetes local
  stop           Arrête un cluster Kubernetes en cours d’exécution
  delete         Supprime un cluster Kubernetes local
  dashboard      Accède au tableau de bord Kubernetes en cours d’exécution dans le cluster minikube
  pause          Met Kubernetes en pause
  unpause        Reprend Kubernetes après une pause</p>

<p>Commandes pour les images :
  docker-env     Configurer l’environnement pour utiliser le démon Docker de minikube
  podman-env     Configurer l’environnement pour utiliser le service Podman de minikube
  cache          Ajouter, supprimer ou pousser une image locale dans minikube</p>

<p>Commandes de configuration et de gestion :
  addons         Activer ou désactiver un module complémentaire de minikube
  config         Modifier les valeurs de configuration persistantes
  profile        Obtenir ou lister les profils actuels (clusters)
  update-context Mettre à jour kubeconfig en cas de changement d’adresse IP ou de port</p>

<p>Commandes de réseau et de connectivité :
  service        Retourne une URL pour se connecter à un service
  tunnel         Se connecter aux services LoadBalancer</p>

<p>Commandes avancées :
  mount          Monte le répertoire spécifié dans minikube
  ssh            Se connecter à l’environnement minikube (pour le débogage)
  kubectl        Exécute une version de kubectl correspondant à la version du cluster
  node           Ajouter, supprimer ou lister des nœuds supplémentaires</p>

<p>Commandes de dépannage :
  ssh-key        Récupère le chemin de la clé d’identité SSH du nœud spécifié
  ssh-host       Récupère la clé hôte SSH du nœud spécifié
  ip             Récupère l’adresse IP du nœud spécifié
  logs           Retourne les journaux pour déboguer un cluster Kubernetes local
  update-check   Affiche les numéros de version actuelle et la plus récente
  version        Affiche la version de minikube</p>

<p>Autres commandes :
  completion     Générer la complétion de commande pour un shell</p>

<p>Utilisez “minikube <commande> --help" pour obtenir plus d'informations sur une commande donnée.</commande></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Il semble que ce soit `minikube stop`.

Revenons à `kubernetes`, maintenant tout fonctionne correctement.

```shell
$ kubectl cluster-info
Le plan de contrôle de Kubernetes est en cours d'exécution à l'adresse https://192.168.99.100:8443
KubeDNS est en cours d'exécution à l'adresse https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
</code></pre></div></div>

<p>Pour déboguer et diagnostiquer davantage les problèmes du cluster, utilisez <code class="language-plaintext highlighter-rouge">kubectl cluster-info dump</code>.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Lorsque nous ouvrons `https://192.168.99.100:8443`, le navigateur affiche :

```json
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "Échec",
  "message": "interdit : L'utilisateur \"system:anonymous\" ne peut pas accéder au chemin \"/\"",
  "reason": "Interdit",
  "details": {
    
  },
  "code": 403
}
</code></pre></div></div>

<p>Accédez à <code class="language-plaintext highlighter-rouge">https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</code> :</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Status"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"apiVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Échec"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">"services </span><span class="se">\"</span><span class="s2">kube-dns:dns</span><span class="se">\"</span><span class="s2"> est interdit : L'utilisateur </span><span class="se">\"</span><span class="s2">system:anonymous</span><span class="se">\"</span><span class="s2"> ne peut pas accéder à la ressource </span><span class="se">\"</span><span class="s2">services/proxy</span><span class="se">\"</span><span class="s2"> dans le groupe d'API </span><span class="se">\"\"</span><span class="s2"> dans l'espace de noms </span><span class="se">\"</span><span class="s2">kube-system</span><span class="se">\"</span><span class="s2">"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"reason"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Interdit"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"details"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kube-dns:dns"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"services"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"code"</span><span class="p">:</span><span class="w"> </span><span class="mi">403</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Essayons la configuration que nous venons de voir.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> simple_deployment.yaml
deployment.apps/nginx-deployment créé
</code></pre></div></div>

<p>Il y a un petit problème. Cependant, jusqu’à présent, nous avons réussi à faire fonctionner <code class="language-plaintext highlighter-rouge">kubernetes</code>. Terminons cela pour l’instant. Nous y reviendrons plus tard.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>minikube stop
✋  Arrêt <span class="nb">du </span>nœud <span class="s2">"minikube"</span>  ...
🛑  1 nœud arrêté.
</code></pre></div></div>

<p>Vérifiez si c’est terminé.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>w<span class="nv">$ </span>minikube dashboard
🤷  Le nœud <span class="nb">du </span>plan de contrôle doit être en cours d<span class="s1">'exécution pour cette commande
👉  Pour démarrer un cluster, exécutez : "minikube start"
</span></code></pre></div></div>

<h2 id="docker">Docker</h2>

<p><code class="language-plaintext highlighter-rouge">Docker</code> est également une plateforme de conteneurs qui aide à accélérer la création, le partage et l’exécution d’applications modernes. Téléchargez l’application depuis le site officiel.</p>

<p><img src="assets/images/distributed/docker.png" alt="docker" /></p>

<p>L’utilisation du client est un peu lente. Utilisons la ligne de commande.</p>

<div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker
</code></pre></div></div>

<p>Utilisation : docker [OPTIONS] COMMANDE</p>

<p>Un runtime autonome pour les conteneurs</p>

<p>Options :
      –config string      Emplacement des fichiers de configuration du client (par défaut “/Users/lzw/.docker”)
  -c, –context string     Nom du contexte à utiliser pour se connecter au démon (remplace la variable d’environnement DOCKER_HOST et le contexte par défaut défini avec “docker context use”)
  -D, –debug              Activer le mode débogage
  -H, –host list          Socket(s) du démon au(x)quel(s) se connecter
  -l, –log-level string   Définir le niveau de journalisation (“debug”|”info”|”warn”|”error”|”fatal”) (par défaut “info”)
      –tls                Utiliser TLS ; implicite avec –tlsverify
      –tlscacert string   Faire confiance uniquement aux certificats signés par cette CA (par défaut “/Users/lzw/.docker/ca.pem”)
      –tlscert string     Chemin vers le fichier de certificat TLS (par défaut “/Users/lzw/.docker/cert.pem”)
      –tlskey string      Chemin vers le fichier de clé TLS (par défaut “/Users/lzw/.docker/key.pem”)
      –tlsverify          Utiliser TLS et vérifier le serveur distant
  -v, –version            Afficher les informations de version et quitter</p>

<p>Commandes de gestion :
  app*        Docker App (Docker Inc., v0.9.1-beta3)
  builder     Gérer les builds
  buildx*     Construire avec BuildKit (Docker Inc., v0.5.1-docker)
  config      Gérer les configurations Docker
  container   Gérer les conteneurs
  context     Gérer les contextes
  image       Gérer les images
  manifest    Gérer les manifestes d’images Docker et les listes de manifestes
  network     Gérer les réseaux
  node        Gérer les nœuds Swarm
  plugin      Gérer les plugins
  scan*       Docker Scan (Docker Inc., v0.5.0)
  secret      Gérer les secrets Docker
  service     Gérer les services
  stack       Gérer les stacks Docker
  swarm       Gérer Swarm
  system      Gérer Docker
  trust       Gérer la confiance sur les images Docker
  volume      Gérer les volumes</p>

<p>Commandes :
  attach      Attacher les flux d’entrée, de sortie et d’erreur standard locaux à un conteneur en cours d’exécution
  build       Construire une image à partir d’un Dockerfile
  commit      Créer une nouvelle image à partir des modifications d’un conteneur
  cp          Copier des fichiers/dossiers entre un conteneur et le système de fichiers local
  create      Créer un nouveau conteneur
  diff        Inspecter les modifications apportées aux fichiers ou répertoires sur le système de fichiers d’un conteneur
  events      Obtenir des événements en temps réel depuis le serveur
  exec        Exécuter une commande dans un conteneur en cours d’exécution
  export      Exporter le système de fichiers d’un conteneur sous forme d’archive tar
  history     Afficher l’historique d’une image
  images      Lister les images
  import      Importer le contenu d’une archive tar pour créer une image de système de fichiers
  info        Afficher des informations système globales
  inspect     Retourner des informations de bas niveau sur les objets Docker
  kill        Tuer un ou plusieurs conteneurs en cours d’exécution
  load        Charger une image à partir d’une archive tar ou de STDIN
  login       Se connecter à un registre Docker
  logout      Se déconnecter d’un registre Docker
  logs        Récupérer les logs d’un conteneur
  pause       Suspendre tous les processus dans un ou plusieurs conteneurs
  port        Lister les mappages de ports ou un mappage spécifique pour le conteneur
  ps          Lister les conteneurs
  pull        Télécharger une image ou un dépôt depuis un registre
  push        Envoyer une image ou un dépôt vers un registre
  rename      Renommer un conteneur
  restart     Redémarrer un ou plusieurs conteneurs
  rm          Supprimer un ou plusieurs conteneurs
  rmi         Supprimer une ou plusieurs images
  run         Exécuter une commande dans un nouveau conteneur
  save        Sauvegarder une ou plusieurs images dans une archive tar (streamée vers STDOUT par défaut)
  search      Rechercher des images sur Docker Hub
  start       Démarrer un ou plusieurs conteneurs arrêtés
  stats       Afficher un flux en direct des statistiques d’utilisation des ressources des conteneurs
  stop        Arrêter un ou plusieurs conteneurs en cours d’exécution
  tag         Créer une balise TARGET_IMAGE qui fait référence à SOURCE_IMAGE
  top         Afficher les processus en cours d’exécution d’un conteneur
  unpause     Reprendre tous les processus dans un ou plusieurs conteneurs
  update      Mettre à jour la configuration d’un ou plusieurs conteneurs
  version     Afficher les informations de version de Docker
  wait        Bloquer jusqu’à ce qu’un ou plusieurs conteneurs s’arrêtent, puis afficher leurs codes de sortie</p>

<p>Exécutez ‘docker COMMANDE –help’ pour obtenir plus d’informations sur une commande.</p>

<p>Pour obtenir plus d’aide sur Docker, consultez nos guides sur https://docs.docker.com/go/guides/</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Suivons le tutoriel pour essayer.

```shell
$ docker run -d -p 80:80 docker/getting-started
Unable to find image 'docker/getting-started:latest' locally
latest: Pulling from docker/getting-started
aad63a933944: Pull complete
b14da7a62044: Pull complete
343784d40d66: Pull complete
6f617e610986: Pull complete
Digest: sha256:d2c4fb0641519ea208f20ab03dc40ec2a5a53fdfbccca90bef14f870158ed577
Status: Downloaded newer image for docker/getting-started:latest
815f13fc8f99f6185257980f74c349e182842ca572fe60ff62cbb15641199eaf
docker: Error response from daemon: Les ports ne sont pas disponibles : écoute tcp 0.0.0.0:80: bind: adresse déjà utilisée.
</code></pre></div></div>

<p>Changez le port.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:80 docker/getting-started
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p><img src="assets/images/distributed/docker_run.png" alt="docker_run" /></p>

<p>Ouvrez votre navigateur, cela signifie que nous avons réussi à faire fonctionner <code class="language-plaintext highlighter-rouge">docker</code>.</p>

<p><img src="assets/images/distributed/browser.png" alt="navigateur" /></p>

<p>Arrêtez le conteneur. Utilisez l’<code class="language-plaintext highlighter-rouge">ID</code> retourné précédemment.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker stop 45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
</code></pre></div></div>

<p>À ce moment-là, le site web était déjà inaccessible.</p>

<p>Cela montre que <code class="language-plaintext highlighter-rouge">docker</code> ressemble à une machine virtuelle.</p>

<h2 id="flink">Flink</h2>

<p>Ouvrez le site officiel.</p>

<p><img src="assets/images/distributed/flink-home-graphic.png" alt="flink-home-graphic" /></p>

<p><code class="language-plaintext highlighter-rouge">Flink</code> est un calcul <code class="language-plaintext highlighter-rouge">Stateful</code> des flux de données. Mais qu’est-ce que signifie <code class="language-plaintext highlighter-rouge">Stateful</code> ? Pour l’instant, je ne comprends pas encore. Cependant, le schéma ci-dessus est très intéressant. Essayons de l’explorer.</p>

<p>Il est dit qu’un environnement Java est nécessaire.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>java <span class="nt">-version</span>
java version <span class="s2">"1.8.0_151"</span>
Java<span class="o">(</span>TM<span class="o">)</span> SE Runtime Environment <span class="o">(</span>build 1.8.0_151-b12<span class="o">)</span>
Java HotSpot<span class="o">(</span>TM<span class="o">)</span> 64-Bit Server VM <span class="o">(</span>build 25.151-b12, mixed mode<span class="o">)</span>
</code></pre></div></div>

<p>Téléchargez la dernière version <code class="language-plaintext highlighter-rouge">flink-1.12.2-bin-scala_2.11.tar</code> depuis le site officiel.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/start-cluster.sh
Démarrage <span class="nb">du </span>cluster.
Démarrage <span class="nb">du </span>démon standalonesession sur l<span class="s1">'hôte lzwjava.
Démarrage du démon taskexecutor sur l'</span>hôte lzwjava.
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/flink run examples/streaming/WordCount.jar
Exécution de l<span class="s1">'exemple WordCount avec le jeu de données d'</span>entrée par défaut.
Utilisez <span class="nt">--input</span> pour spécifier un fichier d<span class="s1">'entrée.
Affichage du résultat sur stdout. Utilisez --output pour spécifier le chemin de sortie.
Le job a été soumis avec l'</span>ID de job 60f37647c20c2a6654359bd34edab807
L<span class="s1">'exécution du programme est terminée
Le job avec l'</span>ID 60f37647c20c2a6654359bd34edab807 est terminé.
Temps d<span class="s1">'exécution du job : 757 ms
</span></code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">tail </span>log/flink-<span class="k">*</span><span class="nt">-taskexecutor-</span><span class="k">*</span>.out
<span class="o">(</span>nymph,1<span class="o">)</span>
<span class="o">(</span><span class="k">in</span>,3<span class="o">)</span>
<span class="o">(</span>thy,1<span class="o">)</span>
<span class="o">(</span>orisons,1<span class="o">)</span>
<span class="o">(</span>be,4<span class="o">)</span>
<span class="o">(</span>all,2<span class="o">)</span>
<span class="o">(</span>my,1<span class="o">)</span>
<span class="o">(</span>sins,1<span class="o">)</span>
<span class="o">(</span>remember,1<span class="o">)</span>
<span class="o">(</span>d,4<span class="o">)</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./bin/stop-cluster.sh
Arrêt <span class="nb">du </span>démon taskexecutor <span class="o">(</span>pid : 41812<span class="o">)</span> sur l<span class="s1">'hôte lzwjava.
</span></code></pre></div></div>

<p>Oui, c’est parti. On voit que c’est très similaire à <code class="language-plaintext highlighter-rouge">Spark</code>.</p>

<h2 id="kylin">Kylin</h2>

<p>Accédez au site officiel.</p>

<blockquote>
  <p>Apache Kylin™ est un entrepôt de données analytiques distribué et open source conçu pour le Big Data. Il a été créé pour offrir des capacités OLAP (Traitement Analytique en Ligne) à l’ère du Big Data. En réinventant la technologie des cubes multidimensionnels et du précalcul sur Hadoop et Spark, Kylin est capable d’atteindre une vitesse de requête quasi constante, quelle que soit la croissance du volume de données. En réduisant la latence des requêtes de plusieurs minutes à moins d’une seconde, Kylin ramène l’analyse en ligne au cœur du Big Data.</p>
</blockquote>

<blockquote>
  <p>Apache Kylin™ vous permet d’interroger des milliards de lignes avec une latence inférieure à la seconde en 3 étapes.</p>

  <ol>
    <li>Identifiez un schéma en étoile ou en flocon de neige sur Hadoop.</li>
    <li>Construisez un Cube à partir des tables identifiées.</li>
    <li>Interrogez en utilisant ANSI-SQL et obtenez des résultats en moins d’une seconde, via ODBC, JDBC ou une API RESTful.</li>
  </ol>
</blockquote>

<p><img src="assets/images/distributed/kylin_diagram.png" alt="kylin_diagram" /></p>

<p>Cela fait essentiellement partie de l’analyse des big data. On peut l’utiliser pour effectuer des recherches très rapidement. Il sert de pont.</p>

<p>Malheureusement, pour le moment, cela ne fonctionne que dans un environnement <code class="language-plaintext highlighter-rouge">Linux</code>. Je reviendrai bricoler cela plus tard.</p>

<h2 id="mongodb">MongoDB</h2>

<p>C’est aussi une base de données. Essayez de l’installer.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew tap mongodb/brew
<span class="o">==&gt;</span> Tapping mongodb/brew
Clonage dans <span class="s1">'/usr/local/Homebrew/Library/Taps/mongodb/homebrew-brew'</span>...
remote: Énumération des objets: 63, fait.
remote: Comptage des objets: 100% <span class="o">(</span>63/63<span class="o">)</span>, fait.
remote: Compression des objets: 100% <span class="o">(</span>62/62<span class="o">)</span>, fait.
remote: Total 566 <span class="o">(</span>delta 21<span class="o">)</span>, réutilisés 6 <span class="o">(</span>delta 1<span class="o">)</span>, réutilisés <span class="nb">du </span>pack 503
Réception des objets: 100% <span class="o">(</span>566/566<span class="o">)</span>, 121.78 KiB | 335.00 KiB/s, fait.
Résolution des deltas: 100% <span class="o">(</span>259/259<span class="o">)</span>, fait.
11 formules ajoutées <span class="o">(</span>39 fichiers, 196.2KB<span class="o">)</span><span class="nb">.</span>
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>mongodb-community@4.4
<span class="o">==&gt;</span> Installation de mongodb-community depuis mongodb/brew
<span class="o">==&gt;</span> Téléchargement de https://fastdl.mongodb.org/tools/db/mongodb-database-tools-macos-x86_64-100.3.0.zip
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Téléchargement de https://fastdl.mongodb.org/osx/mongodb-macos-x86_64-4.4.3.tgz
<span class="c">######################################################################## 100.0%</span>
<span class="o">==&gt;</span> Installation des dépendances pour mongodb/brew/mongodb-community: mongodb-database-tools
<span class="o">==&gt;</span> Installation de la dépendance mongodb/brew/mongodb-community: mongodb-database-tools
Erreur : L<span class="s1">'étape `brew link` ne s'</span>est pas terminée avec succès
La formule a été construite, mais n<span class="s1">'est pas liée symboliquement dans /usr/local
Impossible de créer un lien symbolique pour bin/bsondump
La cible /usr/local/bin/bsondump
est un lien symbolique appartenant à mongodb. Vous pouvez le délier :
  brew unlink mongodb
</span></code></pre></div></div>

<p>Pour forcer le lien et écraser tous les fichiers en conflit :
  brew link –overwrite mongodb-database-tools</p>

<p>Pour lister tous les fichiers qui seraient supprimés :
  brew link –overwrite –dry-run mongodb-database-tools</p>

<p>Les fichiers potentiellement en conflit sont :
/usr/local/bin/bsondump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/bsondump
/usr/local/bin/mongodump -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongodump
/usr/local/bin/mongoexport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoexport
/usr/local/bin/mongofiles -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongofiles
/usr/local/bin/mongoimport -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongoimport
/usr/local/bin/mongorestore -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongorestore
/usr/local/bin/mongostat -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongostat
/usr/local/bin/mongotop -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongotop
==&gt; Résumé
🍺  /usr/local/Cellar/mongodb-database-tools/100.3.0: 13 fichiers, 154 Mo, construit en 11 secondes
==&gt; Installation de mongodb/brew/mongodb-community
Erreur : L’étape <code class="language-plaintext highlighter-rouge">brew link</code> ne s’est pas terminée avec succès
La formule a été construite, mais n’est pas liée symboliquement dans /usr/local
Impossible de créer un lien symbolique pour bin/mongo
La cible /usr/local/bin/mongo
est un lien symbolique appartenant à mongodb. Vous pouvez le dissocier :
  brew unlink mongodb</p>

<p>Pour forcer le lien et écraser tous les fichiers en conflit :
  brew link –overwrite mongodb-community</p>

<p>Pour lister tous les fichiers qui seraient supprimés :
  brew link –overwrite –dry-run mongodb-community</p>

<p>Les fichiers potentiellement en conflit sont :
/usr/local/bin/mongo -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongo
/usr/local/bin/mongod -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongod
/usr/local/bin/mongos -&gt; /usr/local/Cellar/mongodb/3.0.7/bin/mongos
==&gt; Avertissements
Pour démarrer mongodb/brew/mongodb-community avec launchd maintenant et redémarrer à la connexion :
  brew services start mongodb/brew/mongodb-community
Ou, si vous ne voulez/pas besoin d’un service en arrière-plan, vous pouvez simplement exécuter :
  mongod –config /usr/local/etc/mongod.conf
==&gt; Résumé
🍺  /usr/local/Cellar/mongodb-community/4.4.3: 11 fichiers, 156,8 Mo, construit en 10 secondes
==&gt; Avertissements
==&gt; mongodb-community
Pour démarrer mongodb/brew/mongodb-community avec launchd maintenant et redémarrer à la connexion :
  brew services start mongodb/brew/mongodb-community
Ou, si vous ne voulez/pas besoin d’un service en arrière-plan, vous pouvez simplement exécuter :
  mongod –config /usr/local/etc/mongod.conf</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
J'avais précédemment installé une ancienne version. Je vais supprimer les liens.

```shell
$ brew unlink mongodb
Déliaison de /usr/local/Cellar/mongodb/3.0.7... 11 liens symboliques supprimés
</code></pre></div></div>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--version</span>
db version v4.4.3
Build Info: <span class="o">{</span>
    <span class="s2">"version"</span>: <span class="s2">"4.4.3"</span>,
    <span class="s2">"gitVersion"</span>: <span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span>,
    <span class="s2">"modules"</span>: <span class="o">[]</span>,
    <span class="s2">"allocator"</span>: <span class="s2">"system"</span>,
    <span class="s2">"environment"</span>: <span class="o">{</span>
        <span class="s2">"distarch"</span>: <span class="s2">"x86_64"</span>,
        <span class="s2">"target_arch"</span>: <span class="s2">"x86_64"</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Ensuite, exécutez <code class="language-plaintext highlighter-rouge">mongod</code> pour démarrer le serveur de base de données MongoDB. Cependant, lors du premier démarrage, il a indiqué que <code class="language-plaintext highlighter-rouge">/data/db</code> n’existait pas. Nous avons donc créé un répertoire, <code class="language-plaintext highlighter-rouge">~/mongodb</code>, pour y stocker les fichiers de la base de données.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongod <span class="nt">--dbpath</span> ~/mongodb
</code></pre></div></div>

<p>Sortie :</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.838+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23285</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Désactivation automatique de TLS 1.0, pour forcer l'activation de TLS 1.0, spécifiez --sslDisabledProtocols 'none'"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"W"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"ASIO"</span><span class="p">,</span><span class="w">     </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">22601</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Aucune couche de transport configurée lors du démarrage de l'interface réseau"</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"NETWORK"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4648602</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"main"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Utilisation implicite de TCP FastOpen."</span><span class="p">}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"STORAGE"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">4615611</span><span class="p">,</span><span class="w"> </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Démarrage de MongoDB"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"pid"</span><span class="p">:</span><span class="mi">46256</span><span class="p">,</span><span class="nl">"port"</span><span class="p">:</span><span class="mi">27017</span><span class="p">,</span><span class="nl">"dbPath"</span><span class="p">:</span><span class="s2">"/Users/lzw/mongodb"</span><span class="p">,</span><span class="nl">"architecture"</span><span class="p">:</span><span class="s2">"64-bit"</span><span class="p">,</span><span class="nl">"host"</span><span class="p">:</span><span class="s2">"lzwjava"</span><span class="p">}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.842+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">23403</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Informations de construction"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"buildInfo"</span><span class="p">:{</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"4.4.3"</span><span class="p">,</span><span class="nl">"gitVersion"</span><span class="p">:</span><span class="s2">"913d6b62acfbb344dde1b116f4161360acd8fd13"</span><span class="p">,</span><span class="nl">"modules"</span><span class="p">:[],</span><span class="nl">"allocator"</span><span class="p">:</span><span class="s2">"system"</span><span class="p">,</span><span class="nl">"environment"</span><span class="p">:{</span><span class="nl">"distarch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">,</span><span class="nl">"target_arch"</span><span class="p">:</span><span class="s2">"x86_64"</span><span class="p">}}}}</span><span class="w">
</span><span class="p">{</span><span class="nl">"t"</span><span class="p">:{</span><span class="nl">"$date"</span><span class="p">:</span><span class="s2">"2021-03-11T18:17:32.843+08:00"</span><span class="p">},</span><span class="nl">"s"</span><span class="p">:</span><span class="s2">"I"</span><span class="p">,</span><span class="w">  </span><span class="nl">"c"</span><span class="p">:</span><span class="s2">"CONTROL"</span><span class="p">,</span><span class="w">  </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">51765</span><span class="p">,</span><span class="w">   </span><span class="nl">"ctx"</span><span class="p">:</span><span class="s2">"initandlisten"</span><span class="p">,</span><span class="nl">"msg"</span><span class="p">:</span><span class="s2">"Système d'exploitation"</span><span class="p">,</span><span class="nl">"attr"</span><span class="p">:{</span><span class="nl">"os"</span><span class="p">:{</span><span class="nl">"name"</span><span class="p">:</span><span class="s2">"Mac OS X"</span><span class="p">,</span><span class="nl">"version"</span><span class="p">:</span><span class="s2">"20.3.0"</span><span class="p">}}}</span><span class="w">
</span><span class="err">...</span><span class="w">
</span></code></pre></div></div>

<p>On peut voir que tout est au format <code class="language-plaintext highlighter-rouge">JSON</code>. MongoDB enregistre tous les fichiers de données au format <code class="language-plaintext highlighter-rouge">JSON</code>. Ensuite, ouvrez un autre onglet de terminal.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mongo
MongoDB shell version v4.4.3
connexion à : mongodb://127.0.0.1:27017/?compressors<span class="o">=</span>disabled&amp;gssapiServiceName<span class="o">=</span>mongodb
Session implicite : session <span class="o">{</span> <span class="s2">"id"</span> : UUID<span class="o">(</span><span class="s2">"4f55c561-70d3-4289-938d-4b90a284891f"</span><span class="o">)</span> <span class="o">}</span>
Version <span class="nb">du </span>serveur MongoDB : 4.4.3
<span class="nt">---</span>
Le serveur a généré ces avertissements de démarrage lors <span class="nb">du </span>démarrage :
        2021-03-11T18:17:33.743+08:00 : Le contrôle d<span class="s1">'accès n'</span>est pas activé pour la base de données. L<span class="s1">'accès en lecture et en écriture aux données et à la configuration est illimité.
        2021-03-11T18:17:33.743+08:00 : Ce serveur est lié à localhost. Les systèmes distants ne pourront pas se connecter à ce serveur. Démarrez le serveur avec --bind_ip &lt;adresse&gt; pour spécifier les adresses IP auxquelles il doit répondre, ou avec --bind_ip_all pour le lier à toutes les interfaces. Si ce comportement est souhaité, démarrez le serveur avec --bind_ip 127.0.0.1 pour désactiver cet avertissement.
        2021-03-11T18:17:33.743+08:00 : Les limites de ressources (soft rlimits) sont trop basses.
        2021-03-11T18:17:33.743+08:00 :         valeur actuelle : 4864
        2021-03-11T18:17:33.743+08:00 :         minimum recommandé : 64000
---
---
        Activez le service de surveillance cloud gratuit de MongoDB, qui recevra et affichera
        des métriques sur votre déploiement (utilisation du disque, CPU, statistiques des opérations, etc.).
</span></code></pre></div></div>

<p>Les données de surveillance seront disponibles sur un site web MongoDB avec une URL unique accessible à vous et à toute personne avec qui vous partagez l’URL. MongoDB peut utiliser ces informations pour améliorer ses produits et vous suggérer des produits MongoDB ainsi que des options de déploiement.</p>

<p>Pour activer la surveillance gratuite, exécutez la commande suivante : <code class="language-plaintext highlighter-rouge">db.enableFreeMonitoring()</code><br />
Pour désactiver définitivement ce rappel, exécutez la commande suivante : <code class="language-plaintext highlighter-rouge">db.disableFreeMonitoring()</code></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Ensuite, vous pouvez essayer d'insérer des données et de les interroger.

```shell
&gt; db.inventory.insertOne(
...    { item: "canvas", qty: 100, tags: ["cotton"], size: { h: 28, w: 35.5, uom: "cm" } }
... )
{
	"acknowledged" : true,
	"insertedId" : ObjectId("6049ef91b653541cf355facb")
}
&gt;
&gt; db.inventory.find()
{ "_id" : ObjectId("6049ef91b653541cf355facb"), "item" : "canvas", "qty" : 100, "tags" : [ "cotton" ], "size" : { "h" : 28, "w" : 35.5, "uom" : "cm" } }
</code></pre></div></div>

<h2 id="enfin">Enfin</h2>

<p>Arrêtons-nous ici pour le moment. Nous aborderons d’autres outils par la suite. Quelle est la signification de tout cela ? Il s’agit probablement de tracer d’abord une ligne directrice. Le début est toujours difficile, mais nous avons déjà parcouru tout cela d’un seul coup. Cela nous donne confiance, et maintenant, il ne reste plus qu’à explorer davantage ces logiciels.</p>

<h2 id="exercice">Exercice</h2>

<ul>
  <li>Les étudiants explorent de manière similaire comme ci-dessus.</li>
</ul>


  <hr>

  <div class="button-container">
    <a href="/" class="button left-button">Back</a>


    

    
    
    <a href="/donate-fr" class="button right-button">Donate</a>
  </div>
</main>

<script src="/assets/js/dark-mode.js"></script>
<script src="/assets/js/audio.js" defer></script>
<script src="/assets/js/pdf.js" defer></script>
<script>
    document.getElementById('languageSelect').addEventListener('change', function() {
        var selectedValue = this.value;
        if (selectedValue) {
            window.location.href = selectedValue;
        }
    });
</script>

</body>

</html>
